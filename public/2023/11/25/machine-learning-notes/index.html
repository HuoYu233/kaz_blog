<!DOCTYPE html>
<html>
  <!-- meta/link... -->
  



<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
  <!-- Global site tag (gtag.js) - Google Analytics -->


  <title>Machine Learning Notes | Kaz&#39;s Blog</title>

  <link rel="icon" type="image/x-icon, image/vnd.microsoft.icon" href="/img/favicon.ico">
  <link rel="stylesheet" href="https://at.alicdn.com/t/font_1911880_c1nvbyezg17.css">
  <link href="https://unpkg.com/@fortawesome/fontawesome-free/css/all.min.css" rel="stylesheet">
  <link href="/js/swiper/swiper@5.4.1.min.css" rel="stylesheet">
  
  
  
  
<link rel="stylesheet" href="/css/animate.min.css">

  
<link rel="stylesheet" href="/css/style.css">

  
  
    <link href="https://unpkg.com/@fancyapps/ui@5.0/dist/fancybox/fancybox.css" rel="stylesheet">
  
  
  <style>
        @media (max-width: 992px) {
            #waifu {
                display: none;
            }
        }
    </style>
    <script defer src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">

    
    
    <!-- 依赖于jquery和vue -->
    <script src="https://unpkg.com/jquery@3.5.1/dist/jquery.min.js"></script>
    <script src="https://unpkg.com/vue@2.6.11/dist/vue.min.js"></script>

    <!-- import link -->
    
        
            
        
            
        
    
    <!-- import script -->
    
        
            
        
            
        
    

<meta name="generator" content="Hexo 7.3.0"></head>

  
  <!-- 预加载动画 -->
  
  
  <div class="preloader_6" id="loader">
  <div class="loader"></div>
</div>
  <script>
    var endLoading = function () {
      document.body.style.overflow = 'auto';
      document.getElementById('loader').classList.add("loaded");
    }
    window.addEventListener('DOMContentLoaded', endLoading);
  </script>


  <body>
    <!-- 判断是否为暗黑风格 -->
    <!-- 判断是否为黑夜模式 -->
<script defer>
  let isDark = JSON.parse(localStorage.getItem('dark')) || JSON.parse('false');

  if (isDark) {
    $(document.body).addClass('darkModel');
  }
</script>

    <!-- 需要在上面加载的js -->
    <script>
  function loadScript(src, cb) {
    return new Promise(resolve => {
      setTimeout(function () {
        var HEAD = document.getElementsByTagName("head")[0] || document.documentElement;
        var script = document.createElement("script");
        script.setAttribute("type", "text/javascript");
        if (cb) {
          if (JSON.stringify(cb)) {
            for (let p in cb) {
              if (p == "onload") {
                script[p] = () => {
                  cb[p]()
                  resolve()
                }
              } else {
                script[p] = cb[p]
                script.onload = resolve
              }
            }
          } else {
            script.onload = () => {
              cb()
              resolve()
            };
          }
        } else {
          script.onload = resolve
        }
        script.setAttribute("src", src);
        HEAD.appendChild(script);
      });
    });
  }

  //https://github.com/filamentgroup/loadCSS
  var loadCSS = function (src) {
    return new Promise(resolve => {
      setTimeout(function () {
        var link = document.createElement('link');
        link.rel = "stylesheet";
        link.href = src;
        link.onload = resolve;
        document.getElementsByTagName("head")[0].appendChild(link);
      });
    });
  };

</script> 

<!-- 轮播图所需要的js -->
<script src="/js/swiper/swiper.min.js"></script>
<script src="/js/swiper/vue-awesome-swiper.js"></script>
<script src="/js/swiper/swiper.animate1.0.3.min.js"></script>

<script type="text/javascript">
  Vue.use(window.VueAwesomeSwiper)
</script>


  <script src="/js/vue-typed-js/index.js"></script>


<!-- 首页的公告滚动插件的js需要重新加载 -->
<script src="/js/vue-seamless-scroll/index.js"></script>

<!-- 打字机效果js -->
<script src="https://unpkg.com/typed.js@2.0.11"></script>


    <div id="safearea">
      <main class="main" id="pjax-container">
        <!-- 头部导航 -->
        
<header class="header  " 
  id="navHeader"
  style="position: fixed;
  left: 0; top: 0; z-index: 10;width: 100%;"
>
  <div class="header-content">
    <div class="bars">
      <div id="appDrawer" class="sidebar-image">
  <div class="drawer-box-icon">
    <i class="fas fa-bars" aria-hidden="true" @click="showDialogDrawer"></i>
  </div>
  
  <transition name="fade">
    <div class="drawer-box_mask" v-cloak style="display: none;" v-show="visible" @click.self="cancelDialogDrawer">
    </div>
  </transition>
  <div class="drawer-box" :class="{'active': visible}">
    <div class="drawer-box-head bg-color">
      <img class="drawer-box-head_logo lazyload placeholder" src="/img/favicon.ico" class="lazyload placeholder" data-srcset="/img/favicon.ico" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="logo">
      <h3 class="drawer-box-head_title">Kaz&#39;s Blog</h3>
      <h5 class="drawer-box-head_desc"></h5>
    </div>
    
    <div class="drawer-box-content">
      <ul class="drawer-box-content_menu">
        
          
            <li class="drawer-box-content_item" style="position: relative;">
              
                <a href="/about" class="drawer-menu-item-link">
                  
                    <i class="fas fa-user" aria-hidden="true"></i>
                  
                  <span class="name">About</span>
                </a>
              
            </li>
          
            <li class="drawer-box-content_item" style="position: relative;">
              
                <a href="/log" class="drawer-menu-item-link">
                  
                    <i class="fas fa-book" aria-hidden="true"></i>
                  
                  <span class="name">Log</span>
                </a>
              
            </li>
          
        
        
          <li class="drawer-box-content_item">
            <a target="_blank" rel="noopener" href="https://github.com/HuoYu233">
              <i class="fas fa-github" aria-hidden="true"></i>
              <span>Github</span>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>

<script>
  var body = document.body || document.documentElement || window;
  var vm = new Vue({
    el: '#appDrawer',
    data: {
      visible: false,
      top: 0,
      openArr: [],
    },
    computed: {
    },
    mounted() {
    },
    methods: {
      isOpen(index) {
        if (this.openArr.includes(index)) {
          return true;
        } else {
          return false;
        }
      },
      openOrCloseMenu(curIndex) {
        const index = this.openArr.indexOf(curIndex);
        if (index !== -1) {
          this.openArr.splice(index, 1);
        } else {
          this.openArr.push(curIndex);
        }
      },
      showDialogDrawer() {
        this.visible = true;
        // 防止页面滚动，只能让弹框滚动
        this.top = $(document).scrollTop()
        body.style.cssText = 'width: 100%; height: 100%;overflow: hidden;';
      },
      cancelDialogDrawer() {
        this.visible = false;
        body.removeAttribute('style');
        $(document).scrollTop(this.top)
      }
    },
    created() {}
  })
</script>

    </div>
    <div class="blog-title" id="author-avatar">
      
        <div class="avatar">
          <img src="/img/favicon.ico" class="lazyload placeholder" data-srcset="/img/favicon.ico" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="logo">
        </div>
      
      <a href="/" class="logo">Kaz&#39;s Blog</a>
    </div>
    <nav class="navbar">
      <ul class="menu">
        
          
            <li class="menu-item" style="position: relative;">
              
                <a href="/about" class="menu-item-link" title="About">
                  
                    <i class="fas fa-user" aria-hidden="true"></i>
                  
                  <span class="name">About</span>
                </a>
              
            </li>
          
            <li class="menu-item" style="position: relative;">
              
                <a href="/log" class="menu-item-link" title="Log">
                  
                    <i class="fas fa-book" aria-hidden="true"></i>
                  
                  <span class="name">Log</span>
                </a>
              
            </li>
          
        
      </ul>
      
      

    </nav>
  </div>
  
    <a target="_blank" rel="noopener" href="https://github.com/HuoYu233" class="github-corner color-primary" aria-label="View source on GitHub"><svg width="60" height="60" viewBox="0 0 250 250" style="fill:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
  
  
</header>
        <!-- 内容区域 -->
        
<!-- prismjs 代码高亮 -->




<div class="bg-dark-floor" style="position: fixed;left: 0;top: 0;width: 100%;height: 100%;z-index: -1;"></div>


  <!-- 文章详情页顶部图片和标题 -->




<div class="post-detail-header" id="thumbnail_canvas" style="background-repeat: no-repeat; background-size: cover; 
  background-position: center center;position: relative;background-image:url('https://img2.baidu.com/it/u=1093757134,3274186314&fm=253&fmt=auto&app=120&f=JPEG?w=800&h=500')">
  <div class="post-detail-header-mask"></div>
  <canvas id="header_canvas"style="position:absolute;bottom:0;pointer-events:none;"></canvas>
  
  <div class="post-detail-header_info-box">
    <div class="title-box">
      <span class="title">
        Machine Learning Notes
      </span>
    </div>
    
    
      
        <span class="post-detail-header_date">
          <i class="fas fa-calendar"></i> Published in：2023-11-25 |
        </span>
      

      

      
    
  </div>
  
  
    <script defer src="/js/bubble/bubble.js"></script>
  
</div>





<div class="post-detail-content post-row" 
  style="padding-top: 0px;">
  <div class="main-content">
    <article class="post post-detail">
      <div class="post-content">
        <h1 id="Course-1"><a href="#Course-1" class="headerlink" title="Course 1"></a>Course 1</h1><p>监督学习：输入特征x，输出目标y。对数据集进行预测，分为<strong>回归</strong>和<strong>分类</strong></p>
<p>无监督学习：输入特征x，没有目标y，对数据集进行<strong>聚类预测</strong>，<strong>异常检测</strong>，<strong>降维</strong></p>
<h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>$$<br>y^i &#x3D; wx^i+b<br>$$</p>
<p>定义损失函数（成本函数），需要最小化损失函数</p>
<p>$$<br>J(w,b) &#x3D; \frac{1}{2m} \sum_{i&#x3D;1}^{m} {(y^i-\hat{y})}^2<br>$$</p>
<p>其中$y^i$为真实输出，$\hat{y}$为预测输出</p>
<ul>
<li>为了不让数据集变大而损失也变大，故采用平均平方误差而不是总平方误差</li>
<li>1&#x2F;2是为了方便求导计算</li>
</ul>
<p>loss针对一个训练样本，cost是所有训练样本的均值</p>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>需要最小会损失函数，需要使用梯度下降算法</p>
<p>定义学习率<code>learning_rate</code>为$\alpha$,一般$\alpha \subseteq [0,1]$</p>
<p>$w &#x3D; w- \alpha \frac{\partial{J(w,b)}}{\partial{w}}$</p>
<p>$b &#x3D; b- \alpha \frac{\partial{J(w,b)}}{\partial{b}}$</p>
<ul>
<li>梯度下降时建议<strong>同步</strong>梯度下降，如下图</li>
</ul>
<p><img src="/img/machine-learning-notes/pic-1.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>如果$\alpha$太小，可以得到答案，但是时间过长</p>
<p>如果$\alpha$太大，大交叉无法收敛，甚至发散</p>
<p>当参数值每次更新时，$J(w,b)$变小，导数项（斜率）也会变小，对于固定学习率$\alpha$，步长也会变小，从而达到局部最优解</p>
<p>对导数项分别求导</p>
<p>$\frac{\partial{J(w,b)}}{\partial{w}} &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i$</p>
<p>$\frac{\partial{J(w,b)}}{\partial{b}} &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^{m} (f(x^i)-y^i)$</p>
<p>其中$f(x^i) &#x3D; wx^i+b$</p>
<p>对于线性回归损失，他的损失函数图像是一个凸函数，只有一个全局最小值，没有局部最小值</p>
<p>选择合适得到学习率，就可以得到$min(J(w,b))$</p>
<p>线性回归的梯度下降也是batch gradient descent，批次梯度下降每次更新关心整批的训练样例</p>
<h3 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h3><p>假设特征有$n$个，定义$\vec{x} &#x3D; \begin{bmatrix} x_1 &amp; x_2 &amp; x_3 &amp; … \end{bmatrix}$，参数$\vec{w} &#x3D; \begin{bmatrix} w_1 &amp; w_2 &amp; w_3 &amp; … \end{bmatrix}$</p>
<p>则$f_{\vec{w},b}&#x3D;\vec{w} \cdot \vec{x} +b$</p>
<p><code>·</code>为两个向量的点积(dot)。</p>
<p>$\vec{w} \cdot \vec{x} &#x3D; w_1<em>x_1+w_2</em>x_2+….+w_n*x_n$</p>
<p><strong>矢量化</strong>：利用计算机的并行硬件，代码简洁、运行速度快</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f = np.dot(w, x) + b</span><br></pre></td></tr></table></figure>

<p><strong>多元线性回归的梯度下降</strong></p>
<p><img src="/img/machine-learning-notes/pic-2.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>PS: 正规方程：某些机器学习库在后端求$w,b$的方法，<strong>只适用于线性回归</strong>，而且速度慢，不要求掌握</p>
<h3 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h3><p>不同特征的估计值范围差异很大，梯度下降等高线图可能某些轴范围宽某些窄，梯度下降过程中可能波 动</p>
<p>加快梯度下降速度</p>
<p>避免特征的取值范围差异过大，将其进行缩放，几种常见方法：</p>
<ul>
<li><strong>除以最大值</strong>，$x_{1,scale} &#x3D; \frac{x_1}{max}$， $x \in [0,1]$</li>
<li><strong>均值归一化Mean Normalization</strong><ul>
<li>求均值$\mu$</li>
<li>$x_1 &#x3D; \frac{x_1-\mu}{max-min}$</li>
</ul>
</li>
<li><strong><code>Z-score</code>归一化</strong><ul>
<li>求标准差$\sigma$，均值$\mu$</li>
<li>$x_1 &#x3D; \frac{x_1-\mu}{\sigma}$</li>
</ul>
</li>
</ul>
<p><strong>判断梯度下降是否收敛：</strong></p>
<ol>
<li>观察iteration-loss曲线是否平稳 2. 自动收敛测试，当loss小于一个很小的值时停止（难用）</li>
</ol>
<p><strong>选择合适学习率</strong>：从0.001开始，每次乘以3，对比$J(w,b)$与迭代次数的关系，选择合适的$\alpha$</p>
<h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><p>利用知识和直觉设计新特征，通常通过转化与组合，使模型做出更准确的预测</p>
<p><strong>多项式回归</strong>：可以添加$x^q$项更好地拟合数据图像，$f(x)&#x3D;w_1x^3+w_2x^2+w_1x^1+b$</p>
<p>此时特征缩放尤为重要</p>
<h2 id="分类-逻辑回归"><a href="#分类-逻辑回归" class="headerlink" title="分类-逻辑回归"></a>分类-逻辑回归</h2><p>解决二分类问题</p>
<h3 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h3><p>输出介于$(0,1)$</p>
<p>$g(z)&#x3D; \frac{1}{1+e^{-z}},z \subseteq R$</p>
<p><strong>logistic regression</strong>:</p>
<p>$f_{\vec{w},b}(\vec{x})&#x3D;g(\vec{w} · \vec{x}+b) &#x3D; \frac{1}{1+e^{-(\vec{w} · \vec{x}+b)}}$</p>
<p>输出值可以理解为分类为1的可能性</p>
<p>$f_{\vec{w},b}(\vec{x})&#x3D;P(y&#x3D;1|\vec{x};\vec{w},b)$</p>
<h3 id="决策边界decision-boundary"><a href="#决策边界decision-boundary" class="headerlink" title="决策边界decision boundary"></a>决策边界decision boundary</h3><p>以0.5作为阈值，当$\vec{w} · \vec{x}+b \ge 0$，取值1；当$\vec{w} · \vec{x}+b &lt;0$，取值0</p>
<p>$\vec{w} · \vec{x}+b &#x3D; 0$称为决策边界</p>
<p>多项式回归也适用于非线性的决策边界</p>
<h3 id="成本函数"><a href="#成本函数" class="headerlink" title="成本函数"></a>成本函数</h3><p>如果使用平方误差成本函数，有多个局部最小值，$J(w,b)$<strong>不是凸函数，不适用于逻辑回归</strong></p>
<p>定义</p>
<p>$$<br>J(w,b)&#x3D;\frac{1}{m}\sum_{i-1}^{m}L(f_{w,b}(x^{(i)},y^{(i)})<br>$$<br>其中L代表单个样例的loss，J代表总的cost</p>
<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-log(f_{w,b}(x^{(i)})) \quad if\quad y^{(i)}&#x3D;1<br>$$<br><img src="/img/machine-learning-notes/pic-3.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-3.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>当y等于1，预测值越靠近1损失越小</p>
<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-log(1-f_{w,b}(x^{(i)})) \quad if \quad y^{(i)}&#x3D;0<br>$$<br><img src="/img/machine-learning-notes/pic-4.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-4.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>当y等于0，预测值越靠近0损失越小 </p>
<p><strong>简化</strong>成本函数                                                                                                                                                                                                                                                                                          </p>
<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))<br>$$</p>
<p>得到</p>
<p>$$<br>J(w,b) &#x3D; -\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))<br>$$</p>
<p>成本函数是凸函数，便于实现梯度下降</p>
<h3 id="梯度下降-1"><a href="#梯度下降-1" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>对J求偏导</p>
<p>$\frac{\partial{J(w,b)}}{\partial{w}} &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i$</p>
<p>$\frac{\partial{J(w,b)}}{\partial{b}} &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^{m} (f(x^i)-y^i)$</p>
<p>其中$f(x^i) &#x3D; \frac{1}{1+e^{-(\vec{w} · \vec{x}+b)}}$</p>
<p>可以使用相似方法进行特征缩放</p>
<h3 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h3><p>过拟合虽然可能完美通过训练集，但是有高方差，泛化能力差。应该避免欠拟合（高偏差high bias）和过拟合（高方差high variance）。</p>
<p><img src="/img/machine-learning-notes/pic-5.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-5.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p><strong>解决过拟合</strong></p>
<ul>
<li>收集更多训练数据</li>
<li>特征筛选，选择特征的一个子集</li>
<li>正则化(Regularization)：在维持多项式回归的基础上，减小参数$w_j$的值，减小一些特征的影响</li>
</ul>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>如果不知道哪个特征是重要的，一般惩罚所有特征，防止过拟合</p>
<p>$$<br>J(w,b) &#x3D; \frac{1}{2m} \sum_{i&#x3D;1}^{m} {(y^i-\hat{y})}^2 + \frac{\lambda}{\alpha m}\sum_{j&#x3D;1}^{n} {w_j}^2<br>$$</p>
<p>其中$\lambda$为正则化参数，$\alpha$为学习率，缩放得</p>
<p>$$<br>J(w,b) &#x3D; \frac{1}{2m} \sum_{i&#x3D;1}^{m} {(y^i-\hat{y})}^2 + \frac{\lambda}{2 m}\sum_{j&#x3D;1}^{n} {w_j}^2<br>$$</p>
<p>这样使得$w_j$尽可能小，几乎为0</p>
<p>参数$b$是否正则化无关紧要</p>
<p>**需要选择合适的$\lambda$**，太大趋于直线，太小惩罚效果不明显</p>
<ul>
<li>正则化线性回归</li>
</ul>
<p>对$J(w,b)$求偏导不断同步更新w,b的值</p>
<p>$$<br>\frac{\partial{J(w,b)}}{\partial{w}} &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i+\frac{\lambda}{m}\sum_{j&#x3D;1}^{m}{w_j}<br>$$</p>
<p>$$<br>w &#x3D; w- \alpha (\frac{1}{m} \sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i+\frac{\lambda}{m}\sum_{j&#x3D;1}^{m}{w_j}) &#x3D; (1-\alpha \frac{\lambda}{m})w+…..<br>$$</p>
<ul>
<li>正则化逻辑回归</li>
</ul>
<p>$$<br>J(w,b) &#x3D; -\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))+ \frac{\lambda}{2 m}\sum_{j&#x3D;1}^{n} {w_j}^2<br>$$</p>
<p>求导式和线性回归相同，只是需要注意<strong>正则化项偏导数没有求和</strong></p>
<p>$f(x^i) &#x3D; \frac{1}{1+e^{-(\vec{w} · \vec{x}+b)}}$</p>
<p><img src="/img/machine-learning-notes/pic-6.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-6.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<h1 id="Course-2"><a href="#Course-2" class="headerlink" title="Course 2"></a>Course 2</h1><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>起源于设计算法来模拟人脑活动（但无需过于重视深度学习的生物动机），21世纪定义为<strong>深度学习</strong></p>
<p>利用别人训练的神经网络参数称为推理或者预测</p>
<p>为了简化表达使用全连接，一层可以使用上一层的所有特征，对于不重要的特征可以选择适当的参数</p>
<p>神经网络不需要手动设计它可以学习的功能，在隐藏层自动提取特征（输入层-&gt;隐藏层-&gt;输出层）</p>
<p>多层神经网络叫做多层感知机</p>
<h2 id="神经网络中的层"><a href="#神经网络中的层" class="headerlink" title="神经网络中的层"></a>神经网络中的层</h2><p>讨论层数通常是隐藏层和输出层，不包括输入层</p>
<p>每一层输入向量$\vec{x}$或$\vec{a}_{i-1}$，经过当前层中多个神经元的逻辑回归处理，输出新的向量$\vec{a}^{[l]}$，进入到下一层&#x2F;输出结果</p>
<p>即$a_j^{[l]} &#x3D; g(\vec{w}_j^{[l]} \cdot \vec{a}^{[l-1]} + b_j^{[l]})$</p>
<p>$j$表示神经元单元序号，$l$表示层数，$g(x)$为<code>sigmod</code>函数</p>
<p><img src="/img/machine-learning-notes/pic-7.jpg" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-7.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>$a_j^{[l]}$构成$\vec{a}^{[l]}$</p>
<p><img src="/img/machine-learning-notes/pic-8.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-8.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<h2 id="前向传播-forward-prop"><a href="#前向传播-forward-prop" class="headerlink" title="前向传播(forward prop)"></a>前向传播(forward prop)</h2><p>从输入初步传递到输出，即为前向传播</p>
<p><strong>一般实现</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dense</span>(<span class="params">a_in, W, b, g</span>):</span><br><span class="line">	units = W.shape[<span class="number">1</span>] <span class="comment"># 单元数等于W矩阵的列数，w_j向量是列向量</span></span><br><span class="line">	a_out = np.zeros(units)</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(units):</span><br><span class="line">		w = W[:, j]</span><br><span class="line">		z = np.dot(w, a_in) + b</span><br><span class="line">		a_out[j] = g(z)</span><br><span class="line">	<span class="keyword">return</span> a_out</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sequential</span>(<span class="params">x</span>):</span><br><span class="line">    a1 = dense(x, W1, b1)</span><br><span class="line">    a2 = dense(a1, W2, b2)</span><br><span class="line">    a3 = dense(a2, W3, b3)</span><br><span class="line">    f_x = a3</span><br><span class="line">    <span class="keyword">return</span> f_x</span><br></pre></td></tr></table></figure>

<p><strong>使用框架（TensorFlow&#x2F;Pytorch)）进行矢量化加速</strong></p>
<h2 id="模型训练步骤"><a href="#模型训练步骤" class="headerlink" title="模型训练步骤"></a>模型训练步骤</h2><ol>
<li>指定如何在给定输入X和参数的情况下计算输出(模型<strong>结构</strong>)</li>
<li>指定<strong>损失函数</strong></li>
<li><strong>训练</strong>模型以最小化损失函数</li>
</ol>
<p>二元交叉熵损失</p>
<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))<br>$$<br>通过反向传播计算偏导数</p>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>用<code>ReLU</code>函数代替<code>sigmoid</code>激活，$g(z) &#x3D; max(0,z)$</p>
<p><img src="/img/machine-learning-notes/pic-9.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-9.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p><strong>如何选择合适的激活函数？</strong></p>
<p>取决于要预测的y，对于神经网络的<strong>输出层</strong>：</p>
<ul>
<li>二分类——&gt; sigmoid</li>
<li>y可正可负的回归——&gt; linear</li>
<li>回归中y大于等于0 ——&gt; ReLU</li>
</ul>
<p>对于神经网络的<strong>隐藏层</strong>建议使用ReLU</p>
<p><code>ReLU</code>常用且更快</p>
<ul>
<li>不涉及指数运算</li>
<li>当一个函数在许多地方都是平的，梯度下降会很慢，ReLU只有一端（x-&gt;-∞）,而sigmoid两端都是</li>
</ul>
<p><strong>为什么需要激活函数？</strong></p>
<p>对于隐藏层，只使用线性的所有层等价于线性回归</p>
<p>对于输出层，得到的结果显然可以仅仅使用线性回归（输出层用线性）或者逻辑回归（输出层用sigmoid）求解</p>
<h2 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h2><p><strong>softmax回归算法</strong>（logistic 推广）</p>
<p>$z_1&#x3D;\vec{w_1}·\vec{x_1}+b_1$</p>
<p>$a_1&#x3D;\frac{e^{z_1}}{e^{z_1}+…+e^{z_n}} &#x3D; P(y&#x3D;1|\vec{x})$</p>
<p>即，设有N个分类</p>
<p>$z_i&#x3D;\vec{w_1}·\vec{x_i}+b_i$</p>
<p>$$<br>a_i &#x3D; \frac{e^{z_i}}{\sum_{k&#x3D;1}^{N} e^{z_i}}&#x3D;P(y&#x3D;i|\vec{x})<br>$$<br>其中$a_1+a_2+…+a_N&#x3D;1$</p>
<p><strong>softmax损失函数</strong></p>
<p>回顾logistic回归</p>
<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))<br>$$</p>
<p>二分类问题，设$a_1 &#x3D; f_{w,b}(x^{(i)})$，即$y&#x3D;1$的概率</p>
<p>则$a_2 &#x3D; 1-f_{w,b}(x^{(i)})$，即$y&#x3D;0$的概率</p>
<p>简化为</p>
<p>$loss &#x3D; -log(a_1)$ 如果$y&#x3D;1$</p>
<p>$loss &#x3D; -log(a_2)$ 如果$y&#x3D;0$</p>
<p>对于softmax回归算法</p>
<p>$$<br>loss(a_1,a_2,…,a_N,y) &#x3D; \left{\begin{matrix} -log(a_1) \quad if \quad y&#x3D;1\ -log(a_2) \quad if \quad y&#x3D;2 \ … \ -log(a_N) \quad if \quad y&#x3D;N \end{matrix}\right.<br>$$</p>
<p><strong>神经网络中的softmax</strong></p>
<p>输出层变为N个神经元</p>
<p>注意：之前的激活函数$g(z_1)$只是$z_1$的函数，但是softmax是$z_1 … z_n$的函数</p>
<p><strong>softmax改进</strong></p>
<p>由于<a target="_blank" rel="noopener" href="https://blog.csdn.net/muyuu/article/details/122757470">数值溢出和精度问题</a></p>
<p>$log$函数当x趋于0变化一些都会影响很大，所以尽量不舍入$a_i$，得到精确得到损失</p>
<p>不先计算出$a_i$，再带入损失函数</p>
<p>而是<strong>直接</strong><br>$$<br>loss_i&#x3D;-log(\frac{e^{z_i}}{e_{z_1}+…+e_{z_N}})<br>$$</p>
<p>此时输出层只需要<code>linear</code>即可（就是不计算$a_i$），同时开启<code>from_logits=True</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=SparseCategoricalCrossEntropy(from_logits=<span class="literal">True</span>)) <span class="comment">#稀疏分类交叉熵损失</span></span><br></pre></td></tr></table></figure>

<p><code>from_logits=True</code>的<a target="_blank" rel="noopener" href="https://blog.csdn.net/muyuu/article/details/122762442">作用</a></p>
<p>需要概率时再调用<code>softmax</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">logits = model(X)</span><br><span class="line">f_x = tf.nn.softmax(logits)</span><br></pre></td></tr></table></figure>

<p><strong>多标签分类</strong></p>
<p><img src="/img/machine-learning-notes/pic-10.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-10.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>将每个标签看做一个二分类问题，输出层n个logistic函数，输出的y是一个向量。</p>
<h2 id="高级优化方法"><a href="#高级优化方法" class="headerlink" title="高级优化方法"></a>高级优化方法</h2><p>传统的梯度下降学习率固定</p>
<h3 id="Adam（Adaptive-Moment-estimation）"><a href="#Adam（Adaptive-Moment-estimation）" class="headerlink" title="Adam（Adaptive Moment estimation）"></a>Adam（Adaptive Moment estimation）</h3><p>如果看到学习率太小，而多次向同一个方向下降，会自动加大学习率</p>
<p>如果看到学习率太大，某个参数值来回振荡，会自动减小学习率</p>
<p>可以自动调整学习率$\alpha$</p>
<p>对于每个参数都有一个$\alpha$</p>
<p>选择optimizer&#x3D;adam即可</p>
<h2 id="其他的网络层"><a href="#其他的网络层" class="headerlink" title="其他的网络层"></a>其他的网络层</h2><h3 id="卷积层（Convolutional-Layer）"><a href="#卷积层（Convolutional-Layer）" class="headerlink" title="卷积层（Convolutional Layer）"></a>卷积层（Convolutional Layer）</h3><p>每个神经元只能看到前一个层输入的一部分</p>
<ul>
<li>加快计算速度</li>
<li>需要更少的数据，不容易过拟合</li>
</ul>
<p>有多个卷积层，即卷积神经网络</p>
<p>每一层的单元只查看输入的一部分 </p>
<h2 id="构建机器学习系统"><a href="#构建机器学习系统" class="headerlink" title="构建机器学习系统"></a>构建机器学习系统</h2><h3 id="评估一个模型"><a href="#评估一个模型" class="headerlink" title="评估一个模型"></a>评估一个模型</h3><p>特征只有一到二个还可以通过画图判断过拟合或者欠拟合，但是再多的特征就不适用了。</p>
<p>将数据集分为训练集和测试集（73或者82开）</p>
<p>分三步计算</p>
<p><img src="/img/machine-learning-notes/pic-11.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-11.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p><strong>注意计算error时不包括正则化项</strong></p>
<p>过拟合$J_{train}$很低，$J_{test}$很高，很好地评估模型的泛化能力</p>
<p>对于分类问题，error就不再用交叉熵损失，直接用算法正确或者错误分类的个数（准确率accurate rate）</p>
<h3 id="如何选择模型"><a href="#如何选择模型" class="headerlink" title="如何选择模型"></a>如何选择模型</h3><p>数据集分为三个子集，训练集$J_{train}$，交叉验证集$J_{cv}$，测试集$J_{test}$</p>
<p>交叉验证集交叉检查不同模型的有效性和准确性，cross validation也叫<strong>dev set</strong>&#x2F;validation set</p>
<p>$J_{train}$优化参数，$J_{cv}$选择模型，也叫优化超参数，$J_{test}$评估模型的泛化能力</p>
<p>数据样本不够时622开可以，但是数据样本够的时候后两者不宜太多。</p>
<h3 id="偏差和方差"><a href="#偏差和方差" class="headerlink" title="偏差和方差"></a><strong>偏差和方差</strong></h3><p><img src="/img/machine-learning-notes/pic-12.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-12.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p><img src="/img/machine-learning-notes/pic-13.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-13.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>高偏差意味着在训练集上表现不好，高方差意味着在交叉验证集表现比训练集上差得多</p>
<p>高方差和高偏差同时存在是有可能的，大部分在神经网络中，线性回归不太可能。</p>
<p><strong>正则化项参数对偏差和方差的影响：</strong></p>
<p><img src="/img/machine-learning-notes/pic-14.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-14.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>但是这些数值多少才算大&#x2F;小呢？需要<strong>建立基准性能标准</strong>，通常是衡量人类在这项任务做的有多好。另一种估计性能基线水平的方法是，是否有一些前人实现的算法来建立性能的基线水平。通过自己的模型效果和基准的比较判断是否有高方差&#x2F;高偏差的问题</p>
<p><img src="/img/machine-learning-notes/pic-15.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-15.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p><strong>学习曲线</strong></p>
<p><img src="/img/machine-learning-notes/pic-16.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-16.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>高偏差时 </p>
<p><img src="/img/machine-learning-notes/pic-17.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-17.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>高方差时</p>
<p><img src="/img/machine-learning-notes/pic-18.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-18.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p><img src="/img/machine-learning-notes/pic-19.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-19.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>判断高方差或者高偏差决定下一步怎么做</p>
<p><strong>神经网络中的偏差和方差</strong></p>
<p>大型的神经网络有很小的偏差，所以只需要关注方差</p>
<p>并且在合适的正则化下，大型神经网络也会和更小的神经网络工作的一样好甚至更好</p>
<p>但是大型网络计算比较昂贵</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">layer = Dense(unit=<span class="number">25</span>, activation=<span class="string">&quot;relu&quot;</span>, kernel_regularizer=L2(<span class="number">0.01</span>))</span><br></pre></td></tr></table></figure>

<h2 id="开发机器学习系统的迭代"><a href="#开发机器学习系统的迭代" class="headerlink" title="开发机器学习系统的迭代"></a>开发机器学习系统的迭代</h2><p><img src="/img/machine-learning-notes/pic-20.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-20.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<h2 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h2><p>在交叉验证集手动选出几个（几百个）分类错误的例子，计数，归类几个原因，找到比较多的错误分类类型，更新学习算法</p>
<h2 id="添加数据"><a href="#添加数据" class="headerlink" title="添加数据"></a>添加数据</h2><p>由误差分析，可以针对性地选择一些特定的数据，对于图像和语音识别，常用<strong>数据增强</strong>，用原有的数据样本创造新的样本</p>
<p>例如旋转，放大，缩小图片，更改图片对比度，扭曲图片，对输入的x施加失真或变换。对语音添加背景噪声等</p>
<p>此外还有<strong>数据合成</strong>，对于OCR文字识别，可以在真实图片基础上，更改字体，生成新的数据。一般在计算机视觉</p>
<p>AI &#x3D; Code(algorithm&#x2F;model) + Data</p>
<h2 id="迁移学习（Transfer-Learning）"><a href="#迁移学习（Transfer-Learning）" class="headerlink" title="迁移学习（Transfer Learning）"></a>迁移学习（Transfer Learning）</h2><p>对于神经网络，假设要进行0-9分类，但是数据集很小，可以借用有一个很大数据集的猫狗等1000类分类的神经网络，使用其中除了输出层以外的所有参数。</p>
<p><img src="/img/machine-learning-notes/pic-21.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-21.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>第一步叫做<strong>监督预训练</strong>(supervised pretraining)，获得除了输出层以外的层的权重；第二步叫做<strong>微调</strong>(fine tuning)，更改输出层的权重</p>
<p>这样就可以在一个只有很小数据集的训练中，通过别的有很大数据集的不太相关的任务中学习</p>
<p>通常下载别人预训练好并开源的神经网络，微调输出层参数来很好地学习自己的任务，但是输入x的类型（图片、音频、文本）也要和预训练模型一样</p>
<p><img src="/img/machine-learning-notes/pic-22.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-22.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<h2 id="机器学习项目的完整周期"><a href="#机器学习项目的完整周期" class="headerlink" title="机器学习项目的完整周期"></a>机器学习项目的完整周期</h2><p><img src="/img/machine-learning-notes/pic-23.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-23.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>部署</p>
<p><img src="/img/machine-learning-notes/pic-24.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-24.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>MLOps(Machine Learning operations)：机器学习运维，系统构建，部署，维护机器学习系统的实践活动来确保机器学习系统可靠，监测损耗和及时更新。</p>
<h2 id="关注公平、偏见、伦理"><a href="#关注公平、偏见、伦理" class="headerlink" title="关注公平、偏见、伦理"></a>关注公平、偏见、伦理</h2><h2 id="倾斜数据集的误差指标"><a href="#倾斜数据集的误差指标" class="headerlink" title="倾斜数据集的误差指标"></a>倾斜数据集的误差指标</h2><p>某个系统的正例和负例不一定都是对半开，例如判断某个稀有的病，构造<strong>混淆矩阵</strong>，包括<strong>真正例，假正例，真负例，假负例</strong></p>
<p>常用的计算指标是<strong>精确度(precision)<strong>和</strong>召回率(recall)</strong></p>
<p><img src="/img/machine-learning-notes/pic-25.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-25.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>精确度展示预测出的的真实精确程度，召回率展示实际真实中预测出的精确程度</p>
<p>权衡：</p>
<p>当我们只有十分确信时才设置y&#x3D;1，设置logistic门槛为大于0.5，会导致精确度提高，召回率降低</p>
<p>当我们不希望错过实际上的y&#x3D;1，设置logistic门槛为小于0.5，导致精确度降低，召回率提高</p>
<p>通过设置threshold权衡precision和recall</p>
<p>F1 score：自动组合精确度和召回率，选择最佳值，强调有比较低的值的算法（可能效果不好）</p>
<p>$F1 score &#x3D; \frac{1}{\frac{1}{2}(\frac{1}{P}+\frac{1}{R})} &#x3D; 2\frac{PR}{P+R}$</p>
<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>决策树是一种树形结构，其中每个内部节点表示一个属性上的测试，每个分支代表一个测试输出，每个叶节点代表一种类别。</p>
<p><img src="/img/machine-learning-notes/pic-26.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-26.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p><strong>决策树学习</strong>：</p>
<ul>
<li>如果选择每个节点选择什么特征来分类？</li>
</ul>
<p>应该最大化纯度，每一边的种类尽可能少</p>
<ul>
<li>什么时候停止分类？</li>
</ul>
<p>当一个节点100%是一个种类</p>
<p>当分裂节点时会导致树超过最大高度（超参数）</p>
<p>当提高的纯度分数低于一个门槛值</p>
<p>当一个节点的样本数量低于一个门槛值</p>
<h3 id="衡量纯度（purity）"><a href="#衡量纯度（purity）" class="headerlink" title="衡量纯度（purity）"></a>衡量纯度（purity）</h3><p>熵是对一组数据杂质的度量，$p_1$是目标种类数量在总数量得到占比，$p_0 &#x3D; 1 - p_1$</p>
<p>$H(p_1)&#x3D;-p_1log_2(p_1)-p_0log_2(p_0) &#x3D; -p_1log_2(p_1)-(1-p_1)log_2(1-p_1)$</p>
<p>注意：$0log(0) &#x3D; 0$</p>
<p><img src="/img/machine-learning-notes/pic-27.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-27.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<h3 id="减小熵：信息增益（Information-Gain）"><a href="#减小熵：信息增益（Information-Gain）" class="headerlink" title="减小熵：信息增益（Information Gain）"></a>减小熵：信息增益（Information Gain）</h3><p>当选择一个节点选择什么特征时，计算左右分支的熵，并进行加权平均计算，选择有最小结果的特征</p>
<p>实际上是测量熵的减小量，由根节点原来的熵值$H(p)$减去左右分支的加权平均熵，此时选择更大的值</p>
<p>为什么？当熵减小的量很小时，可以选择不分裂，而避免过拟合</p>
<p><img src="/img/machine-learning-notes/pic-28.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-28.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>更一般地</p>
<p><img src="/img/machine-learning-notes/pic-29.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-29.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>p是当前节点样本中正例的个数，w是从上一节点样本中选择的样本数（当前样本&#x2F;上一节点样本）</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在根节点以所有数据样本开始</p>
<p>计算所有特征的信息增益，选择最大的</p>
<p>对选择的特征分裂，创建左右分支</p>
<p>保持分裂直到遇到终止条件：</p>
<ul>
<li>当一个节点100%是一个类</li>
<li>当分裂节点会导致树超过最大高度</li>
<li>信息增益的值小于某个门槛值</li>
<li>节点的样本数量小于某个门槛值</li>
</ul>
<p>实际上是一个递归的过程</p>
<h3 id="独热编码-One-Hot-Encoding"><a href="#独热编码-One-Hot-Encoding" class="headerlink" title="独热编码(One Hot Encoding)"></a>独热编码(One Hot Encoding)</h3><p>实现有两个以上离散值的特征：如果一个类的特征有k个离散值，创建k个二元特征（0&#x2F;1）</p>
<p>这样又转变为原来的左右分支分裂的情况</p>
<h3 id="连续值特征"><a href="#连续值特征" class="headerlink" title="连续值特征"></a>连续值特征</h3><p>选定一个阈值，判断数据样本大于或者小于该阈值</p>
<p>分割点将训练样本排序后取每对的中间值，10个样本就有9个分割点</p>
<p>对分割点分别计算信息增强来选择阈值</p>
<h3 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h3><p>分裂时，改成尽量选取输出的方差(Variance)小的特征</p>
<p>w还是从上一节点样本中选择的样本数（当前样本&#x2F;上一节点样本），之后计算加权平均方差</p>
<p>再用上一个节点所有数据的方差减去加权平均方差，选取最大的</p>
<p>分类的结果是样本的平均值</p>
<h2 id="使用多个决策树"><a href="#使用多个决策树" class="headerlink" title="使用多个决策树"></a>使用多个决策树</h2><p>单一决策树对数据中的微小变化十分敏感，所以要建立多个决策树（Tree Ensemble），并进行投票，使得算法更加健壮</p>
<h3 id="放回抽样"><a href="#放回抽样" class="headerlink" title="放回抽样"></a>放回抽样</h3><p>从n个样本中放回地抽取n次，结果作为一个新的数据集</p>
<h3 id="随机森林（Random-Forest）"><a href="#随机森林（Random-Forest）" class="headerlink" title="随机森林（Random Forest）"></a>随机森林（Random Forest）</h3><p>给定一个训练样本数m，进行b次的训练（一般不超过100），每次放回抽样创建一个新的大小为m的数据集，在此基础上训练一个决策树</p>
<p>b个决策树构成袋状决策树（Bagged Decision Tree），输出结果进行投票决定最终输出</p>
<p>对于每个节点，当要选择一个特征来分裂的时候，如果有n个特征可用，随机选择一个$k &lt; n$大小子集，使得算法只从这个子集里的特征选择信息增益最高得到特征进行分裂，当n很大时，经验做法是取$k &#x3D; \sqrt{n}$</p>
<h3 id="XGBoost（eXtreme-Gradient-Boosting）"><a href="#XGBoost（eXtreme-Gradient-Boosting）" class="headerlink" title="XGBoost（eXtreme Gradient Boosting）"></a>XGBoost（eXtreme Gradient Boosting）</h3><p>极端梯度提升树，与前面不同的是，进行放回抽样的时候，不是让每个样本有$\frac{1}{m}$的概率被抽中，而是更可能抽到前面训练的树错误匹配的样本</p>
<p>思想：关注我们已经训练好的树做的不好的地方，在之后刻意地尝试优化这部分</p>
<ul>
<li>提升树的开源实现</li>
<li>快速，有效</li>
<li>很好的设定结束分裂的标准</li>
<li>内置正则化</li>
</ul>
<h3 id="什么时候使用决策树"><a href="#什么时候使用决策树" class="headerlink" title="什么时候使用决策树"></a>什么时候使用决策树</h3><p>一个或多个决策树</p>
<ul>
<li>在表格化和结构化的数据上工作的很好</li>
<li>不建议在非结构化的数据上，例如图片，音频，文本</li>
<li>训练快速</li>
<li>决策树是人类可以理解的（可解释性）</li>
</ul>
<p>神经网络</p>
<ul>
<li><p>对于所有类型的数据都能工作的很好</p>
</li>
<li><p>比决策树更慢</p>
</li>
<li><p>可以很好地使用迁移学习（预训练+微调）</p>
</li>
<li><p>当建立一个有多个模型一起工作的系统，链接神经网络会更简单（输出都是光滑的，连在一起仍然可微，决策树一次只能训练一个）</p>
</li>
</ul>
<h1 id="Course-3"><a href="#Course-3" class="headerlink" title="Course 3"></a>Course 3</h1><p>除了监督学习，机器学习还包括</p>
<ul>
<li>无监督学习<ul>
<li>聚类</li>
<li>异常检测</li>
</ul>
</li>
<li>推荐系统</li>
<li>强化学习</li>
</ul>
<h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><p>一堆数据点中自动查找相互关联或者相似的数据点</p>
<h3 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h3><p>首先随机初始化K个簇中心点$\mu_1 ,\mu_2… \mu_k$，$\mu$应该是一个向量，与输入有相同的维度</p>
<ul>
<li>将每个点分配给离他最近的中心点（centroid质心）</li>
<li>将中心点移动到分配的点的平均中心</li>
<li>重复前两步，直到中心点不再移动，K-means算法收敛</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Repeat&#123;</span><br><span class="line">	<span class="keyword">for</span> i = 1 to m</span><br><span class="line">		c_i 是距离x_i点最近得到簇中心点的下标（从1-k）</span><br><span class="line">		//其中距离为 min_k ||x_i - u_k||，可以加平方</span><br><span class="line">	<span class="keyword">for</span> i = 1 to k</span><br><span class="line">		u_k更新为分配的点的中心（每个轴的点的平均值）</span><br><span class="line">		如果簇中心点没有分配到点，就删除</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p><img src="/img/machine-learning-notes/pic-30.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-30.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>$c^{(i)}$是$x^{(i)}$被分配到的簇的下标（1-k）</p>
<p>$u_k$是簇k</p>
<p>$\mu _{c^{(i)}}$是$x^{(i)}$被分配到的簇</p>
<p>损失函数就是每个点到其分配到的簇的距离平方的平均值，其中距离是<strong>欧几里得距离</strong></p>
<p>也叫Distortion Function</p>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>选择$K&lt;m$</p>
<p>随机选择K个训练样本，将$\mu_1 ,\mu_2… \mu_k$设定为这几个点，每次运行容易得到局部最小值，所以运行多次，找到效果最好的点</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i = 1 to 100&#123;</span><br><span class="line">	随机初始化</span><br><span class="line">	获取c_i, u_i</span><br><span class="line">	计算损失函数J</span><br><span class="line">&#125;</span><br><span class="line">选择J最小的初始化参数，i可以从50到1000，充分避免局部最小值</span><br></pre></td></tr></table></figure>

<h3 id="选择簇的个数"><a href="#选择簇的个数" class="headerlink" title="选择簇的个数"></a>选择簇的个数</h3><p><strong>肘法（Elbow Method）</strong></p>
<p>选取不同的K，绘制损失函数曲线，选择肘点，但是这个方法不通用，不是每一次都有肘点</p>
<p>所以K的选择还是按照之后的任务目的选择</p>
<h2 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h2><h3 id="密度估计（Density-estimation）"><a href="#密度估计（Density-estimation）" class="headerlink" title="密度估计（Density estimation）"></a>密度估计（Density estimation）</h3><p>根据数据集建立模型$p(x)$，其中特征向量x的概率，对于$x_{test}$，求得$p$，若$p(x_{test})&lt;\epsilon$，认为出现了异常（anomaly）</p>
<h3 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h3><p>Gaussian Distribution，也叫正态分布(Normal Distribution)</p>
<p>$p(x)&#x3D;\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)}{2\sigma^2}^2}$</p>
<p>其中$\mu$是平均值，$\sigma$是标准差</p>
<p><img src="/img/machine-learning-notes/pic-31.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-31.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><p>对于有多个特征的输入$\vec{x}$，$\vec{x} &#x3D; [x_1, x_2 … x_n]$</p>
<p>$$<br>p(\vec{x}) &#x3D; p(x_1;\mu_1,\sigma_1^2) * p(x_2;\mu_2,\sigma_2^2) <em>…</em> p(x_n;\mu_n,\sigma_n^2) &#x3D; \prod_{j&#x3D;1}^np(x_j;\mu_j,\sigma_j^2)<br>$$</p>
<h3 id="开发和评估异常检测系统"><a href="#开发和评估异常检测系统" class="headerlink" title="开发和评估异常检测系统"></a>开发和评估异常检测系统</h3><p>通常在训练集训练（无标签），在cv集加入异常的样本，打上标签0&#x2F;1，选择合适的$\epsilon$使得在cv集可以很好地工作，对于异常样本很多的情况下，可以再使用测试集</p>
<p><strong>流程：</strong></p>
<p>在训练集$x_1…x_m$上拟合模型$p(x)$</p>
<p>在交叉验证集或者测试集上，预测y（如果小于epsilon为1否则为0）</p>
<p>之后计算真正例，精确度Precision，召回率Recall和F1分数等指标衡量模型，并且选择更好的参数$\epsilon$</p>
<h3 id="权衡异常检测和监督学习"><a href="#权衡异常检测和监督学习" class="headerlink" title="权衡异常检测和监督学习"></a>权衡异常检测和监督学习</h3><p>异常检测：有很多种异常，对于算法来说很难从已知的异常中学习，因为未来的异常可能与当前的完全不一样</p>
<p>监督学习：有足够的正例使得算法学会识别正例，未来的正例也是与当前训练集里的类似</p>
<h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><p>监督学习中，特征如果不重要可以让参数变得小一点，但在异常检测中，特征的选择更加重要</p>
<ul>
<li>绘制直方图，转换保证特征符合高斯分布，注意cv集和测试集也要同样转换（开根号，取对数）</li>
<li>检查是否在cv集效果不好，分析原因，看看有没有新的特征可以选取</li>
</ul>
<h2 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h2><p>$r(i,j) &#x3D; 1$表示用户j为电影i打分</p>
<p>$y^{(i,j)}$表示用户j为电影i打的分</p>
<p>$w^{(j)}, b^{(j)}$是用户j的参数</p>
<p>$x^{(i)}$是电影i的特征向量</p>
<p>对于用户j和电影i，预测评分$w^{(j)} \cdot x^{(i)}+b^{(j)}$</p>
<p>$m^{(j)}$表示用户j打分的电影数量</p>
<p>通过训练学习$w^{(j)}, b^{(j)}$</p>
<p>$$<br>\min_{w^{(j)}b^{(j)}}J\left(w^{(j)},b^{(j)}\right)&#x3D;\frac{1}{2m^{(j)}}\sum_{(i:r(i,j)&#x3D;1}\left(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\right)^{2}+\frac{\lambda}{2m^{(j)}}\sum_{k&#x3D;1}^{n}\left(w_{k}^{(j)}\right)^{2}<br>$$</p>
<p>对所有用户都要学习参数$w^{(1)},b^{(1)},w^{(2)},b^{(2)},…,w^{(n_u)},b^{(n_u)}$</p>
<p>$$<br>\left.\mathrm{J}\left(<br>\begin{array}<br>{cc}{w^{(1)},} &amp; {…,w^{(n_{u})}} \<br>{b^{(1)},} &amp; {…,b^{(n_{u})}}<br>\end{array}\right.\right)&#x3D;\frac{1}{2}\sum_{j&#x3D;1}^{n_{u}}\sum_{i:r(i,j)&#x3D;1}\left(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\right)^{2}\quad+\frac{\lambda}{2}\sum_{j&#x3D;1}^{n_{u}}\sum_{k&#x3D;1}^{n}\left(w_{k}^{(j)}\right)^{2}<br>$$</p>
<h3 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h3><p>在上面的例子中，我们已经得到了每部电影的特征的值是多少，可以使用线性回归，但是当不知道的时候，需要使用$w^{(j)}, b^{(j)}$来推测每部电影的特征值是多少</p>
<p>$$<br>\mathrm{J}(x^{(i)})&#x3D;\frac{1}{2}\sum_{j:r(i,j)&#x3D;1}\left(w^{(j)}\cdot x^{(i)}+b^{(j)}-{y^{(i,j)}}\right)^{2}+\frac{\lambda}{2}\sum_{k&#x3D;1}^{n}\left(x_{k}^{(i)}\right)^{2}<br>$$</p>
<p>学习得到$x^{(1)},x^{(2)},…,x^{(n_m)}$</p>
<p>$$<br>\mathrm{J}\left(x^{(1)},x^{(2)},…,x^{(n_{m})}\right)&#x3D;\frac{1}{2}\sum_{i&#x3D;1}^{n_{m}}\sum_{j:r(i,j)&#x3D;1}\left(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\right)^{2}+\frac{\lambda}{2}\sum_{i&#x3D;1}^{n_{m}}\sum_{k&#x3D;1}^{n}\left(x_{k}^{(i)}\right)^{2}<br>$$</p>
<p>将这里与上面提到求w,b的算法结合起来，构成协同过滤算法：</p>
<p><img src="/img/machine-learning-notes/pic-32.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-32.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>梯度下降时，w，b，x都是参数</p>
<p><img src="/img/machine-learning-notes/pic-33.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-33.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/zhu_xian_gang/article/details/130243870">补充</a></p>
<h3 id="二进制标签"><a href="#二进制标签" class="headerlink" title="二进制标签"></a>二进制标签</h3><p>1-用户看到物品之后参与点击，停留，添加喜欢，购买</p>
<p>0-用户看到物品之后忽略</p>
<p>?-用户没有看到物品</p>
<p>预测$y^{(i,j)}&#x3D;1$的概率，由$g(w^{(j)} \cdot x^{(i)}+ b^{(i)})$，g是logistic函数</p>
<p><img src="/img/machine-learning-notes/pic-34.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-34.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<h3 id="均值归一化"><a href="#均值归一化" class="headerlink" title="均值归一化"></a>均值归一化</h3><p><strong>Mean Normalization</strong></p>
<ul>
<li>求均值$\mu$</li>
<li>$x_1 &#x3D; \frac{x_1-\mu}{max-min}$</li>
</ul>
<p>求出每个电影的平均用户平方$\mu_i$，构建向量$u$</p>
<p>对于用户j，预测其在电影i的评分：</p>
<p>$w^{(j)} \cdot x^{(i)}+ b^{(i)} + \mu_i$</p>
<p>以至于不会当用户没有评分时认为评分接近0，而是接近平均值</p>
<h3 id="查找相关项目"><a href="#查找相关项目" class="headerlink" title="查找相关项目"></a>查找相关项目</h3><p>对于项目$i$的特征$x^{(i)}$，为了找到相关的项目$k$，需要找到$x^{(k)}$与$x^{(i)}$相似</p>
<p>选取小的$\sum_{l&#x3D;1}^n(x_l^{(k)} - x_l^{(i)})^2$</p>
<p>也可以写作$||x^{(k)} - x^{(i)}||^2$</p>
<h3 id="协同过滤算法的限制"><a href="#协同过滤算法的限制" class="headerlink" title="协同过滤算法的限制"></a>协同过滤算法的限制</h3><p><strong>冷启动问题</strong></p>
<ul>
<li>如何对没有什么用户打分的项目评分？</li>
<li>如何对没有对很多项目打分的用户推荐一些项目？</li>
</ul>
<p><strong>没有很多信息的时候利用辅助信息</strong></p>
<h3 id="基于内容的过滤算法"><a href="#基于内容的过滤算法" class="headerlink" title="基于内容的过滤算法"></a>基于内容的过滤算法</h3><p>协同过滤：基于用户的评分与你的评分的相似推荐项目</p>
<p>基于内容过滤：基于用户和项目特征的匹配良好程度推荐项目</p>
<p>但是电影的特征数和用户的特征数大概率不一样多，所以需要提取出$v^{(j)}$和$v^{(i)}$（相同维度）进行匹配</p>
<p>对于v的获取，使用神经网络</p>
<p>可以分别建立user network和movie network，使用相同维度的输出层，将结果进行点积</p>
<p>也可以将两个网络合并，在内部进行点积输出结果</p>
<p>$J&#x3D;\sum_{(i,j):r(i,j)&#x3D;1}\left(v_{u}^{(j)}\cdot v_{m}^{(i)}-y^{(i,j)}\right)^{2}+\text{NN regularization term}$</p>
<p>为了找到电影i的相似电影，找$||v^{(k)} - v^{(i)}||^2$小的电影，最为相似</p>
<h3 id="Retrieval-and-Ranking"><a href="#Retrieval-and-Ranking" class="headerlink" title="Retrieval and Ranking"></a>Retrieval and Ranking</h3><p>通常样本有几百万或者几千几万，不可能对每个样本构造神经网络，所以采用检索和排名</p>
<p>检索：生成可能得项目列表，比如从用户最近观看的10个电影中找到相似的，从最常看的3个类别中选出其中的top10，用户所在国家的top20。将检索的项目列表，去除重复项目和用户已经观看</p>
<p>排名：对这些检索出的有限个项目进行学习，根据结果进行排名</p>
<p>权衡检索的项目数量</p>
<h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p>强化学习（Reinforcement Learning，简称RL）是一种机器学习范式，它通过让智能体（Agent）与环境（Environment）进行交互，学习如何做出最优决策，以最大化累积奖励（Reward）。强化学习的核心思想是通过试错（Trial and Error）的方式，让智能体逐步探索环境，找到最优的行为策略。</p>
<p>涉及状态，行动，奖励，折扣系数，回报，策略</p>
<h3 id="回报"><a href="#回报" class="headerlink" title="回报"></a>回报</h3><p>指的是系统获得的奖励总和</p>
<p>折扣系数$\gamma$，是一个无限接近1的数字，例如0.9,0.99</p>
<p>$\text{Return} &#x3D; R_1 + \gamma R_2 + \gamma^2R_3+…$，直到终止状态</p>
<h3 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h3><p>状态state通过策略π实行行动a</p>
<p>$\pi(s) &#x3D; a$，指明状态s情况下需要进行的决策a，从而最大化回报</p>
<h3 id="马尔科夫决策过程"><a href="#马尔科夫决策过程" class="headerlink" title="马尔科夫决策过程"></a>马尔科夫决策过程</h3><p>Markov Decision Process(MDP)</p>
<p><img src="/img/machine-learning-notes/pic-35.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-35.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<h3 id="状态-动作价值函数"><a href="#状态-动作价值函数" class="headerlink" title="状态-动作价值函数"></a>状态-动作价值函数</h3><p>State-action value function，也叫Q-function,Q*,Optimal Q function</p>
<p>$Q(s,a)$的值等于你从状态s开始执行一个动作a之后，表现的最好所获得的回报</p>
<p>在状态s的最好回报就是$max_aQ(s,a)$</p>
<p>在状态s的最好动作的就能够提供$max_aQ(s,a)$的</p>
<h3 id="Bellman方程"><a href="#Bellman方程" class="headerlink" title="Bellman方程"></a>Bellman方程</h3><p>$s$:当前状态</p>
<p>$a$:当前状态的决策</p>
<p>$R(s)$:当前状态的奖励</p>
<p>$s’$:采取动作a后的状态</p>
<p>$a’$:在状态s’采取的动作</p>
<p>$Q(s,a) &#x3D; R(s)+\gamma max_{a’}Q(s’,a’)$</p>
<p>R(s)也叫即时奖励，表示你可以立刻得到的奖励</p>
<p>后一项是从状态s’表现得最好获得的回报</p>
<p>$\text{Return} &#x3D; R_1 + \gamma R_2 + \gamma^2R_3+… &#x3D; R_1 + \gamma[R_2 + \gamma R_3+…]$</p>
<h3 id="随机环境"><a href="#随机环境" class="headerlink" title="随机环境"></a>随机环境</h3><p>由于不可控因素，强化学习问题是随机的，不一定会按照某个序列，而是有很多个可能得序列，得到不同的奖励</p>
<p>所以问题不是最大化回报，而是最大化奖励之和得到平均值，也就是期望</p>
<p>$\text{Return} &#x3D; \text{Average}(R_1 + \gamma R_2 + \gamma^2R_3+…) &#x3D; \text{E}(R_1 + \gamma R_2 + \gamma^2R_3+…)$</p>
<p>Bellman Equation变成：</p>
<p>$Q(s,a) &#x3D; R(s)+\gamma \text{E} [max_{a’}Q(s’,a’)]$</p>
<h3 id="连续状态空间"><a href="#连续状态空间" class="headerlink" title="连续状态空间"></a>连续状态空间</h3><p>状态参数可能是连续的，比如坐标，角度，速度</p>
<p>同时状态可能有多个，比如xyz坐标，速度等</p>
<p>此时也叫连续状态马尔科夫决策过程</p>
<h3 id="学习状态值函数"><a href="#学习状态值函数" class="headerlink" title="学习状态值函数"></a>学习状态值函数</h3><p><img src="/img/machine-learning-notes/pic-36.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-36.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>以随机猜测$Q(s,a)$初始化神经网络</p>
<p>重复：</p>
<p>采取措施，得到$(s,a,R(s),s’)$元组</p>
<p>存储最近的10k个 $(s,a,R(s),s’)$元组（Replay Buffer）</p>
<p>训练网络：</p>
<p>​	创建10k个训练集，其中$x&#x3D;(s,a)$，$y &#x3D; R(s)+\gamma max_{a’}Q(s’,a’)$</p>
<p>​	训练$Q_{new}$使得$Q_{new}(s,a) \approx y$</p>
<p>令$Q&#x3D;Q_{new}$</p>
<p>虽然刚开始Q是随机猜测的，但是随着训练迭代，Q的值会变成真实值的良好估计</p>
<p><strong>改进</strong></p>
<ul>
<li>神经网络架构</li>
</ul>
<p>可以直接将输出层改成每种决策的结果输出，就不用分别计算多次不同决策，只用计算一次就行</p>
<p><img src="/img/machine-learning-notes/pic-37.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-37.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<ul>
<li>$\epsilon$贪心策略</li>
</ul>
<p>当正在学习时如何选择决策，不应该都选择能最大化Q的a，因为当Q时随机初始化的，大的不一定好。</p>
<p>应该选择大概率例如0.95选择最大化的Q，也是贪心greedy，或者exploitation。再0.05概率随机选择别的策略（探索exploration）</p>
<p>小概率的值就是epsilon，这个策略也叫做epsilon贪心策略，开始的e比较大，逐渐减小。</p>
<ul>
<li>小批量$mini-batch$</li>
</ul>
<p>将数据集分成几个小的集合，每次迭代查看一个小数据集，梯度下降最开始虽然不是朝最优方向，但是越来越优</p>
<p><img src="/img/machine-learning-notes/pic-38.png" class="lazyload placeholder" data-srcset="/img/machine-learning-notes/pic-38.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="img"></p>
<p>假设子集大小为1000；</p>
<p>具体过程，是先取出1000个数据，前向计算出结果，再反向传导计算出代价函数对w和b的偏导数；接着计算出代价函数的和，然后取这1000次的平均值，进行优化；然后再拿出1000个数据，再次计算代价函数与导数，再次优化，重复进行直到全部数据集取完即可。</p>
<p>在强化学习中，可以把10k的数据集分解训练多个模型</p>
<ul>
<li>软更新</li>
</ul>
<p>令$Q&#x3D;Q_{new}$时，不直接把$w,b$换成$w_{new},b_{new}$</p>
<p>而是<br>$$<br>w &#x3D; 0.01w_{new} + 0.99w<br>$$</p>
<p>$$<br>b &#x3D; 0.01b_{new} + 0.99b<br>$$</p>
<p>对参数进行微小调整</p>

      </div>
      <div class="post-tags-categories">
        
      </div>
      
    </article>
    <!-- 上一篇文章和下一篇文章 -->
    
      <!-- 文章详情页的上一页和下一页 -->
<div class="post-nav">



  
  <div class="post-nav-prev post-nav-item">
    <div class="post-nav-img" style="background-size: cover; 
      background-position: center center;">
      <img class="lazyload lazyload placeholder" src="https://img1.baidu.com/it/u=4282277671,2501328998&fm=253&fmt=auto&app=138&f=JPEG?w=449&h=252" class="lazyload placeholder" data-srcset="https://img1.baidu.com/it/u=4282277671,2501328998&fm=253&fmt=auto&app=138&f=JPEG?w=449&h=252" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="">
    </div>
    <a href="/2025/01/26/ai-mianjing/" class="post-nav-link">
      <div class="title">
        <i class="fas fa-angle-left"></i> Prev:
        <div class="title-text">AI面经</div>
      </div>
      
      <!-- <div class="content">
        1 机器学习、深度学习、与人工智能对比
机器学习是一种实现人工智能的方法，深度学习是一种实现机器学习的技术


人工智能
      </div> -->
    </a>
  </div>



  
  <div class="post-nav-next post-nav-item">
    <div class="post-nav-img" style="background-size: cover; 
      background-position: center center;">
      <img class="lazyload lazyload placeholder" src="https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg" class="lazyload placeholder" data-srcset="https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" src="" alt="">
    </div>
    <a href="/2023/07/07/algorithm-data-structure/" class="post-nav-link">
      <div class="title">
        Next: <i class="fas fa-angle-right"></i>
        <div class="title-text">Algorithm-Data-Structure</div>
      </div>
      <!-- <div class="content">
        链表与邻接表由于用结构体+指针比较慢，一般在面试题使用，在这里使用数组模拟链表

单链表

e[N]：储存链表结点的值

      </div> -->
    </a>
  </div>

</div>

    
    

    <!-- 打赏 -->
    

    <!-- 分享 -->
    
    
    <!-- 评论 -->
    <!-- 评论 -->

  <div id="myComment">
    
      <div id="gitment-container"></div>

    
  </div>


<!-- 还需要在后面这个地址里设置script, comment script in themes\hexo-theme-bamboo\layout\_partial\scripts\index.ejs -->


  </div>

  <!-- 目录 -->
  <aside id='l_side'>
  
    
      <section class="widget side_blogger">
  <div class='content'>
    
      
        <a class='avatar flat-box rectangle' href='/about/index'>
          <img src='/img/Kaz.jpg'/>
        </a>
      
    
    
      <div class='text'>
        
          <h2>Kaz</h2>
        
        
          <p>雫</p>

        
        
      </div>
    
    
      <div class="social-wrapper">
        
          
            <a href="mailto:alanluo233@gmail.com"
              class="social fas fa-envelope flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
              
            </a>
          
        
          
            <a href="https://github.com/HuoYu233"
              class="social fab fa-github flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
              
            </a>
          
        
          
            <a href="tencent://AddContact/?fromId=50&amp;fromSubId=1&amp;subcmd=all&amp;uin=1981270473"
              class="social fab fa-qq flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
              
            </a>
          
        
          
            <a href="https://space.bilibili.com/82505737"
              class="social fab fa-bilibili flat-btn"
              target="_blank"
              rel="external nofollow noopener noreferrer">
              
            </a>
          
        
      </div>
    
  </div>
</section>

    
  
  
  

  <div class="layout_sticky">    
    
      
<section class="widget side_toc">
  
  <header>
    
      <i style="color: " class="fas fa-list fa-fw" aria-hidden="true"></i><span class='name' style="color: ">本文目录</span>
    
  </header>


  <div class='content'>
    <div class="toc-main">
      <div class="toc-content">
        <!-- <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Course-1"><span class="toc-text">Course 1</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-text">线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-text">梯度下降</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-text">多元线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE"><span class="toc-text">特征缩放</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-text">特征工程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-text">分类-逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sigmoid%E5%87%BD%E6%95%B0"><span class="toc-text">sigmoid函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8Cdecision-boundary"><span class="toc-text">决策边界decision boundary</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0"><span class="toc-text">成本函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-1"><span class="toc-text">梯度下降</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98"><span class="toc-text">过拟合问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-text">正则化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Course-2"><span class="toc-text">Course 2</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%B1%82"><span class="toc-text">神经网络中的层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD-forward-prop"><span class="toc-text">前向传播(forward prop)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%AD%A5%E9%AA%A4"><span class="toc-text">模型训练步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-text">激活函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-text">多分类问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-text">高级优化方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Adam%EF%BC%88Adaptive-Moment-estimation%EF%BC%89"><span class="toc-text">Adam（Adaptive Moment estimation）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E7%9A%84%E7%BD%91%E7%BB%9C%E5%B1%82"><span class="toc-text">其他的网络层</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%EF%BC%88Convolutional-Layer%EF%BC%89"><span class="toc-text">卷积层（Convolutional Layer）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F"><span class="toc-text">构建机器学习系统</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E4%B8%80%E4%B8%AA%E6%A8%A1%E5%9E%8B"><span class="toc-text">评估一个模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E6%A8%A1%E5%9E%8B"><span class="toc-text">如何选择模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%81%8F%E5%B7%AE%E5%92%8C%E6%96%B9%E5%B7%AE"><span class="toc-text">偏差和方差</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%80%E5%8F%91%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%AD%E4%BB%A3"><span class="toc-text">开发机器学习系统的迭代</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90"><span class="toc-text">误差分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E6%95%B0%E6%8D%AE"><span class="toc-text">添加数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%EF%BC%88Transfer-Learning%EF%BC%89"><span class="toc-text">迁移学习（Transfer Learning）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%AE%8C%E6%95%B4%E5%91%A8%E6%9C%9F"><span class="toc-text">机器学习项目的完整周期</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E6%B3%A8%E5%85%AC%E5%B9%B3%E3%80%81%E5%81%8F%E8%A7%81%E3%80%81%E4%BC%A6%E7%90%86"><span class="toc-text">关注公平、偏见、伦理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%80%BE%E6%96%9C%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E8%AF%AF%E5%B7%AE%E6%8C%87%E6%A0%87"><span class="toc-text">倾斜数据集的误差指标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-text">决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A1%E9%87%8F%E7%BA%AF%E5%BA%A6%EF%BC%88purity%EF%BC%89"><span class="toc-text">衡量纯度（purity）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%8F%E5%B0%8F%E7%86%B5%EF%BC%9A%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%EF%BC%88Information-Gain%EF%BC%89"><span class="toc-text">减小熵：信息增益（Information Gain）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81-One-Hot-Encoding"><span class="toc-text">独热编码(One Hot Encoding)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E5%80%BC%E7%89%B9%E5%BE%81"><span class="toc-text">连续值特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%A0%91"><span class="toc-text">回归树</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%A4%9A%E4%B8%AA%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-text">使用多个决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%BE%E5%9B%9E%E6%8A%BD%E6%A0%B7"><span class="toc-text">放回抽样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%EF%BC%88Random-Forest%EF%BC%89"><span class="toc-text">随机森林（Random Forest）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#XGBoost%EF%BC%88eXtreme-Gradient-Boosting%EF%BC%89"><span class="toc-text">XGBoost（eXtreme Gradient Boosting）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-text">什么时候使用决策树</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Course-3"><span class="toc-text">Course 3</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB"><span class="toc-text">聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K-means"><span class="toc-text">K-means</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-text">初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%89%E6%8B%A9%E7%B0%87%E7%9A%84%E4%B8%AA%E6%95%B0"><span class="toc-text">选择簇的个数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B"><span class="toc-text">异常检测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%86%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%88Density-estimation%EF%BC%89"><span class="toc-text">密度估计（Density estimation）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83"><span class="toc-text">高斯分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="toc-text">算法实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%80%E5%8F%91%E5%92%8C%E8%AF%84%E4%BC%B0%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F"><span class="toc-text">开发和评估异常检测系统</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%83%E8%A1%A1%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E5%92%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-text">权衡异常检测和监督学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="toc-text">特征选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="toc-text">推荐系统</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95"><span class="toc-text">协同过滤算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%A0%87%E7%AD%BE"><span class="toc-text">二进制标签</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9D%87%E5%80%BC%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-text">均值归一化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E6%89%BE%E7%9B%B8%E5%85%B3%E9%A1%B9%E7%9B%AE"><span class="toc-text">查找相关项目</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95%E7%9A%84%E9%99%90%E5%88%B6"><span class="toc-text">协同过滤算法的限制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95"><span class="toc-text">基于内容的过滤算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Retrieval-and-Ranking"><span class="toc-text">Retrieval and Ranking</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-text">强化学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E6%8A%A5"><span class="toc-text">回报</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AD%96%E7%95%A5"><span class="toc-text">策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B"><span class="toc-text">马尔科夫决策过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8A%B6%E6%80%81-%E5%8A%A8%E4%BD%9C%E4%BB%B7%E5%80%BC%E5%87%BD%E6%95%B0"><span class="toc-text">状态-动作价值函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bellman%E6%96%B9%E7%A8%8B"><span class="toc-text">Bellman方程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E7%8E%AF%E5%A2%83"><span class="toc-text">随机环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4"><span class="toc-text">连续状态空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E7%8A%B6%E6%80%81%E5%80%BC%E5%87%BD%E6%95%B0"><span class="toc-text">学习状态值函数</span></a></li></ol></li></ol></li></ol> -->
        <div class="toc"></div>
      </div>
    </div>
  </div>
</section>
<!-- 手机端目录按钮 -->
<div id="toc-mobile-btn">
  <i class="fas fa-list-ul" aria-hidden="true"></i>
</div>

      
    
  </div>
</aside>

  <!-- 图片放大 Wrap images with fancybox support -->
  <script defer src="/js/wrapImage.js"></script>
</div>

<!-- 文章详情页背景图 -->
<div id="appBgSwiper" style="position: fixed;left: 0;top: 0;width: 100%;height: 100%;z-index: -2;"
	:style="{'background-color': bgColor ? bgColor : 'transparent'}">
	<transition-group tag="ul" :name="names">
		<li v-for='(image,index) in img' :key='index' v-show="index === mark" class="bg-swiper-box">
			<img :src="image" class="bg-swiper-img no-lazy">
		</li>
	</transition-group>
</div>
<script>
	var vm = new Vue({
		el: '#appBgSwiper',
		data: {
			names: '' || 'fade' || 'fade', // translate-fade fade
			mark: 0,
			img: [],
			bgColor: '',
			time: null
		},
		methods: {   //添加方法
			change(i, m) {
				if (i > m) {
					// this.names = 'fade';
				} else if (i < m) {
					// this.names = 'fade';
				} else {
					return;
				}
				this.mark = i;
			},
			prev() {
				// this.names = 'fade';
				this.mark--;
				if (this.mark === -1) {
					this.mark = 3;
					return
				}
			},
			next() {
				// this.names = 'fade';
				this.mark++;
				if (this.mark === this.img.length) {
					this.mark = 0;
					return
				}
			},
			autoPlay() {
				// this.names = 'fade';
				this.mark++;
				if (this.mark === this.img.length) {
					this.mark = 0;
					return
				}
			},
			play() {
				let bgImgDelay = '' || '180000'
				let delay = parseInt(bgImgDelay) || 180000;
				this.time = setInterval(this.autoPlay, delay);
			},
			enter() {
				clearInterval(this.time);
			},
			leave() {
				this.play();
			}
		},
		created() {
			this.play()
		},
		beforeDestroy() {
			clearInterval(this.time);
		},
		mounted() {
			let prop = '' || '';
			let isImg = prop.includes('.bmp') || prop.includes('.jpg') || prop.includes('.png') || prop.includes('.tif') || prop.includes('.gif') || prop.includes('.pcx') || prop.includes('.tga') || prop.includes('.exif') || prop.includes('.fpx') || prop.includes('.psd') || prop.includes('.cdr') || prop.includes('.pcd') || prop.includes('.dxf') || prop.includes('.ufo') || prop.includes('.eps') || prop.includes('.ai') || prop.includes('.raw') || prop.includes('.WMF') || prop.includes('.webp') || prop.includes('.jpeg') || prop.includes('http://') || prop.includes('https://')
			if (isImg) {
				let img = prop.split(',');
				let configRoot = '/'
				let arrImg = [];
				img.forEach(el => {
					var Expression = /http(s)?:\/\/([\w-]+\.)+[\w-]+(\/[\w- .\/?%&=]*)?/;
					var objExp = new RegExp(Expression);

					if (objExp.test(el)) {
						// http or https
						arrImg.push(el);
					} else {
						// 非http or https开头
						// 本地文件
						let firstStr = el.charAt(0);
						if (firstStr == '/') {
							el = el.substr(1); // 删除第一个字符 '/',因为 configRoot最后一个字符为 /
						}
						el = configRoot + el;
						arrImg.push(el);
					}
				})
				this.img = arrImg;
			} else {
				this.bgColor = prop;
			}
		}
	})
</script>

<style>
	.bg-swiper-box {
		position: absolute;
		display: block;
		width: 100%;
		height: 100%;
	}

	.bg-swiper-img {
		object-fit: cover;
		width: 100%;
		height: 100%;
	}
</style>


  <script>
  // https://github.com/theme-next/hexo-theme-next/blob/master/layout/_third-party/math/mathjax.swig
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'https://unpkg.com/mathjax@3.0/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    // 文章章节标题不能为 “MathJax” ，否则会报错。
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>




  <script>
  function loadMermaid() {
    if (document.getElementsByClassName('mermaid').length) {
      if (window.mermaidJsLoad) mermaid.init()
      else {
        loadScript('https://unpkg.com/mermaid/dist/mermaid.min.js').then(() => {
          window.mermaidJsLoad = true
          mermaid.initialize({
            theme: 'default',
          })
          if ('true') {
            mermaid.init();
          }
        })
      }
    }
  };
  document.addEventListener("DOMContentLoaded", function () {
    loadMermaid();
  })

  document.addEventListener('pjax:complete', function () {
    loadMermaid();
  })
  
</script>


      </main>
    </div>

    <!-- 页脚 -->
    
  
  
    <!-- 底部鱼儿跳动效果，依赖于jquery-->
<div id="j-fish-skip" style=" position: relative;height: 153px;width: auto;"></div>
<script defer>
  var RENDERER = {
    POINT_INTERVAL: 5,
    FISH_COUNT: 3,
    MAX_INTERVAL_COUNT: 50,
    INIT_HEIGHT_RATE: .5,
    THRESHOLD: 50,
    FISH_COLOR: '',
    init: function () {
      this.setFishColor(); this.setParameters(), this.reconstructMethods(), this.setup(), this.bindEvent(), this.render()
    },
    setFishColor: function () {
      let isDark = JSON.parse(localStorage.getItem('dark')) || JSON.parse('false');
      if (isDark) {
        this.FISH_COLOR = '#222'; // 暗黑色，有时间把这整成一个变量
      } else {
        this.FISH_COLOR = '' || 'rgba(173, 216, 230, 0.8)';
      }
    },
    setParameters: function () {
      this.$window = $(window), this.$container = $("#j-fish-skip"), this.$canvas = $("<canvas />"), this.context = this.$canvas.appendTo(this.$container).get(0).getContext("2d"), this.points = [], this.fishes = [], this.watchIds = []
    },
    createSurfacePoints: function () {
      var t = Math.round(this.width / this.POINT_INTERVAL);
      this.pointInterval = this.width / (t - 1), this.points.push(new SURFACE_POINT(this, 0));
      for (var i = 1; i < t; i++) {
        var e = new SURFACE_POINT(this, i * this.pointInterval),
          h = this.points[i - 1];
        e.setPreviousPoint(h), h.setNextPoint(e), this.points.push(e)
      }
    },
    reconstructMethods: function () {
      this.watchWindowSize = this.watchWindowSize.bind(this), this.jdugeToStopResize = this.jdugeToStopResize.bind(this), this.startEpicenter = this.startEpicenter.bind(this), this.moveEpicenter = this.moveEpicenter.bind(this), this.reverseVertical = this.reverseVertical.bind(this), this.render = this.render.bind(this)
    },
    setup: function () {
      this.points.length = 0, this.fishes.length = 0, this.watchIds.length = 0, this.intervalCount = this.MAX_INTERVAL_COUNT, this.width = this.$container.width(), this.height = this.$container.height(), this.fishCount = this.FISH_COUNT * this.width / 500 * this.height / 500, this.$canvas.attr({
        width: this.width,
        height: this.height
      }), this.reverse = !1, this.fishes.push(new FISH(this)), this.createSurfacePoints()
    },
    watchWindowSize: function () {
      this.clearTimer(), this.tmpWidth = this.$window.width(), this.tmpHeight = this.$window.height(), this.watchIds.push(setTimeout(this.jdugeToStopResize, this.WATCH_INTERVAL))
    },
    clearTimer: function () {
      for (; this.watchIds.length > 0;) clearTimeout(this.watchIds.pop())
    },
    jdugeToStopResize: function () {
      var t = this.$window.width(),
        i = this.$window.height(),
        e = t == this.tmpWidth && i == this.tmpHeight;
      this.tmpWidth = t, this.tmpHeight = i, e && this.setup()
    },
    bindEvent: function () {
      this.$window.on("resize", this.watchWindowSize), this.$container.on("mouseenter", this.startEpicenter), this.$container.on("mousemove", this.moveEpicenter)
    },
    getAxis: function (t) {
      var i = this.$container.offset();
      return {
        x: t.clientX - i.left + this.$window.scrollLeft(),
        y: t.clientY - i.top + this.$window.scrollTop()
      }
    },
    startEpicenter: function (t) {
      this.axis = this.getAxis(t)
    },
    moveEpicenter: function (t) {
      var i = this.getAxis(t);
      this.axis || (this.axis = i), this.generateEpicenter(i.x, i.y, i.y - this.axis.y), this.axis = i
    },
    generateEpicenter: function (t, i, e) {
      if (!(i < this.height / 2 - this.THRESHOLD || i > this.height / 2 + this.THRESHOLD)) {
        var h = Math.round(t / this.pointInterval);
        h < 0 || h >= this.points.length || this.points[h].interfere(i, e)
      }
    },
    reverseVertical: function () {
      this.reverse = !this.reverse;
      for (var t = 0, i = this.fishes.length; t < i; t++) this.fishes[t].reverseVertical()
    },
    controlStatus: function () {
      for (var t = 0, i = this.points.length; t < i; t++) this.points[t].updateSelf();
      for (t = 0, i = this.points.length; t < i; t++) this.points[t].updateNeighbors();
      this.fishes.length < this.fishCount && 0 == --this.intervalCount && (this.intervalCount = this.MAX_INTERVAL_COUNT, this.fishes.push(new FISH(this)))
    },
    render: function () {
      requestAnimationFrame(this.render), this.controlStatus(), this.context.clearRect(0, 0, this.width, this.height), this.context.fillStyle = this.FISH_COLOR;
      for (var t = 0, i = this.fishes.length; t < i; t++) this.fishes[t].render(this.context);
      this.context.save(), this.context.globalCompositeOperation = "xor", this.context.beginPath(), this.context.moveTo(0, this.reverse ? 0 : this.height);
      for (t = 0, i = this.points.length; t < i; t++) this.points[t].render(this.context);
      this.context.lineTo(this.width, this.reverse ? 0 : this.height), this.context.closePath(), this.context.fill(), this.context.restore()
    }
  },
  SURFACE_POINT = function (t, i) {
    this.renderer = t, this.x = i, this.init()
  };
  SURFACE_POINT.prototype = {
    SPRING_CONSTANT: .03,
    SPRING_FRICTION: .9,
    WAVE_SPREAD: .3,
    ACCELARATION_RATE: .01,
    init: function () {
      this.initHeight = this.renderer.height * this.renderer.INIT_HEIGHT_RATE, this.height = this.initHeight, this.fy = 0, this.force = {
        previous: 0,
        next: 0
      }
    },
    setPreviousPoint: function (t) {
      this.previous = t
    },
    setNextPoint: function (t) {
      this.next = t
    },
    interfere: function (t, i) {
      this.fy = this.renderer.height * this.ACCELARATION_RATE * (this.renderer.height - this.height - t >= 0 ? -1 : 1) * Math.abs(i)
    },
    updateSelf: function () {
      this.fy += this.SPRING_CONSTANT * (this.initHeight - this.height), this.fy *= this.SPRING_FRICTION, this.height += this.fy
    },
    updateNeighbors: function () {
      this.previous && (this.force.previous = this.WAVE_SPREAD * (this.height - this.previous.height)), this.next && (this.force.next = this.WAVE_SPREAD * (this.height - this.next.height))
    },
    render: function (t) {
      this.previous && (this.previous.height += this.force.previous, this.previous.fy += this.force.previous), this.next && (this.next.height += this.force.next, this.next.fy += this.force.next), t.lineTo(this.x, this.renderer.height - this.height)
    }
  };
  var FISH = function (t) {
    this.renderer = t, this.init()
  };
  FISH.prototype = {
    GRAVITY: .4,
    init: function () {
      this.direction = Math.random() < .5, this.x = this.direction ? this.renderer.width + this.renderer.THRESHOLD : -this.renderer.THRESHOLD, this.previousY = this.y, this.vx = this.getRandomValue(4, 10) * (this.direction ? -1 : 1), this.renderer.reverse ? (this.y = this.getRandomValue(1 * this.renderer.height / 10, 4 * this.renderer.height / 10), this.vy = this.getRandomValue(2, 5), this.ay = this.getRandomValue(.05, .2)) : (this.y = this.getRandomValue(6 * this.renderer.height / 10, 9 * this.renderer.height / 10), this.vy = this.getRandomValue(-5, -2), this.ay = this.getRandomValue(-.2, -.05)), this.isOut = !1, this.theta = 0, this.phi = 0
    },
    getRandomValue: function (t, i) {
      return t + (i - t) * Math.random()
    },
    reverseVertical: function () {
      this.isOut = !this.isOut, this.ay *= -1
    },
    controlStatus: function (t) {
      this.previousY = this.y, this.x += this.vx, this.y += this.vy, this.vy += this.ay, this.renderer.reverse ? this.y > this.renderer.height * this.renderer.INIT_HEIGHT_RATE ? (this.vy -= this.GRAVITY, this.isOut = !0) : (this.isOut && (this.ay = this.getRandomValue(.05, .2)), this.isOut = !1) : this.y < this.renderer.height * this.renderer.INIT_HEIGHT_RATE ? (this.vy += this.GRAVITY, this.isOut = !0) : (this.isOut && (this.ay = this.getRandomValue(-.2, -.05)), this.isOut = !1), this.isOut || (this.theta += Math.PI / 20, this.theta %= 2 * Math.PI, this.phi += Math.PI / 30, this.phi %= 2 * Math.PI), this.renderer.generateEpicenter(this.x + (this.direction ? -1 : 1) * this.renderer.THRESHOLD, this.y, this.y - this.previousY), (this.vx > 0 && this.x > this.renderer.width + this.renderer.THRESHOLD || this.vx < 0 && this.x < -this.renderer.THRESHOLD) && this.init()
    },
    render: function (t) {
      t.save(), t.translate(this.x, this.y), t.rotate(Math.PI + Math.atan2(this.vy, this.vx)), t.scale(1, this.direction ? 1 : -1), t.beginPath(), t.moveTo(-30, 0), t.bezierCurveTo(-20, 15, 15, 10, 40, 0), t.bezierCurveTo(15, -10, -20, -15, -30, 0), t.fill(), t.save(), t.translate(40, 0), t.scale(.9 + .2 * Math.sin(this.theta), 1), t.beginPath(), t.moveTo(0, 0), t.quadraticCurveTo(5, 10, 20, 8), t.quadraticCurveTo(12, 5, 10, 0), t.quadraticCurveTo(12, -5, 20, -8), t.quadraticCurveTo(5, -10, 0, 0), t.fill(), t.restore(), t.save(), t.translate(-3, 0), t.rotate((Math.PI / 3 + Math.PI / 10 * Math.sin(this.phi)) * (this.renderer.reverse ? -1 : 1)), t.beginPath(), this.renderer.reverse ? (t.moveTo(5, 0), t.bezierCurveTo(10, 10, 10, 30, 0, 40), t.bezierCurveTo(-12, 25, -8, 10, 0, 0)) : (t.moveTo(-5, 0), t.bezierCurveTo(-10, -10, -10, -30, 0, -40), t.bezierCurveTo(12, -25, 8, -10, 0, 0)), t.closePath(), t.fill(), t.restore(), t.restore(), this.controlStatus(t)
    }
  }, $(function () {
    RENDERER.init()
    $('.dark').click(function () {
      setTimeout(() => {
        RENDERER.setFishColor();
        RENDERER.context.fill();
      });
    })
  });
</script>
  
  <div class="footer bg-color">
    <div class="footer-main">
      
        
          <div class="link">
            
          </div>
        
      
        
          <div class="footer-copyright">
            <p>Copyright © 2023 - 2025 <a target="_blank" rel="noopener" href="https://github.com/HuoYu233">Kaz</a> | Powered by <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/docs/">Hexo</a> | Theme <a target="_blank" rel="noopener" href="https://github.com/yuang01/theme">Bamboo</a> </p>

          </div>
        
      
        
          <div class="footer-custom">
            
          </div>
        
      
    </div>
  </div>



    <!-- 渲染暗黑按钮 -->
    
      <div class="dark" onclick="toggleDarkMode()">
  <div class="dark-content">
    <i class="fas" id="darkIcon" aria-hidden="true"></i>
  </div>
</div>

<script defer>
  $(function() {
    // 初始化暗黑模式状态
    let isDark = JSON.parse(localStorage.getItem('dark')) || JSON.parse('false');
    updateDarkModeIcon(isDark);
  });

  function toggleDarkMode() {
    const isDark = $(document.body).hasClass('darkModel');
    $(document.body).toggleClass('darkModel');
    localStorage.setItem('dark', !isDark);
    updateDarkModeIcon(!isDark);
  }

  function updateDarkModeIcon(isDark) {
    const iconElement = document.getElementById('darkIcon');
    if (isDark) {
      iconElement.classList.remove('fa-moon');
      iconElement.classList.add('fa-lightbulb');
    } else {
      iconElement.classList.remove('fa-lightbulb');
      iconElement.classList.add('fa-moon');
    }
  }
</script>

    
    <!-- 渲染回到顶部按钮 -->
    
      <div class="goTop top-btn-color" pointer>
  <i class="fas fa-arrow-up" aria-hidden="true"></i>
</div>
<script defer src="/js/goTop.js"></script>

    
    <!-- 渲染左下角音乐播放器 -->
    

    <!-- 图片放大 -->
    
      <script src="https://unpkg.com/@fancyapps/ui@5.0/dist/fancybox/fancybox.umd.js"></script>
    

    <!-- 百度解析 -->
    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script async>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <!-- 背景彩带 -->
    

    <script src="/js/utils/index.js"></script>
    <script src="/js/app.js"></script>
    
    <!-- 文章目录所需js -->
<!-- <link href="/js/tocbot/tocbot.css" rel="stylesheet">
<script src="/js/tocbot/tocbot.min.js"></script> -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.min.js"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.18.2/tocbot.css">

<script>
  var headerEl = 'h2, h3, h4',  //headers 
    content = '.post-detail',//文章容器
    idArr = {};  //标题数组以确定是否增加索引id
  //add #id
  var option = {
    // Where to render the table of contents.
    tocSelector: '.toc',
    // Where to grab the headings to build the table of contents.
    contentSelector: content,
    // Which headings to grab inside of the contentSelector element.
    headingSelector: headerEl,
    scrollSmooth: true,
    scrollSmoothOffset: -70,
    // headingsOffset: -($(window).height() * 0.4 - 45),
    headingsOffset: -($(window).height() * 0.4 - 70),
    // positionFixedSelector: '.toc-main',
    // positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto',
    activeLinkClass: 'is-active-link',
    orderedList: true,
    collapseDepth: 20,
    // onClick: function (e) {},
  }
  if ($('.toc').length > 0) {

    $(content).children(headerEl).each(function () {
      //去除空格以及多余标点
      var headerId = $(this).text().replace(/[\s|\~|`|\!|\@|\#|\$|\%|\^|\&|\*|\(|\)|\_|\+|\=|\||\|\[|\]|\{|\}|\;|\:|\"|\'|\,|\<|\.|\>|\/|\?|\：|\，|\。]/g, '');

      headerId = headerId.toLowerCase();
      if (idArr[headerId]) {
        //id已经存在
        $(this).attr('id', headerId + '-' + idArr[headerId]);
        idArr[headerId]++;
      }
      else {
        //id未存在
        idArr[headerId] = 1;
        $(this).attr('id', headerId);
      }
    });

    document.addEventListener("DOMContentLoaded", function () {
      tocbot.init(option);
      mobileTocClick();
    });

  }

  window.tocScrollFn = function () {
    return bamboo.throttle(function () {
      findHeadPosition();
    }, 100)()
  }
  window.addEventListener('scroll', tocScrollFn);

  const findHeadPosition = function (top) {
    if ($('.toc-list').length <= 0) {
      return false;
    }
    setTimeout(() => {  // or DOMContentLoaded 
      autoScrollToc();
    }, 0);
  }

  const autoScrollToc = function () {
    const $activeItem = document.querySelector('.is-active-link');
    const $cardToc = document.querySelector('.toc-content');
    const activePosition = $activeItem.getBoundingClientRect().top
    const sidebarScrollTop = $cardToc.scrollTop
    if (activePosition > (document.documentElement.clientHeight - 100)) {
      $cardToc.scrollTop = sidebarScrollTop + 150
    }
    if (activePosition < 150) {
      $cardToc.scrollTop = sidebarScrollTop - 150
    }
  }

  document.addEventListener('pjax:send', function () {
    if ($('.toc').length) {
      tocbot.destroy();
    }
  });

  document.addEventListener('pjax:complete', function () {
    if ($('.toc').length) {
      tocbot.init(option);
      mobileTocClick();
    }
  });
  
  // 手机端toc按钮点击出现目录
  const mobileTocClick = function () {
    const $cardTocLayout = document.getElementsByClassName('side_toc')[0];
    const $cardToc = $cardTocLayout.getElementsByClassName('toc-content')[0];
    let right = '45px';
    if (window.innerWidth >= 551 && window.innerWidth <= 992) {
      right = '100px'
    }
    const mobileToc = {
      open: () => {
        $cardTocLayout.style.cssText = 'animation: toc-open .3s; opacity: 1; right: ' + right
      },

      close: () => {
        $cardTocLayout.style.animation = 'toc-close .2s'
        setTimeout(() => {
          $cardTocLayout.style.cssText = "opacity:''; animation: ''; right: ''"
        }, 100)
      }
    }
    document.getElementById('toc-mobile-btn').addEventListener('click', () => {
      if (window.getComputedStyle($cardTocLayout).getPropertyValue('opacity') === '0') mobileToc.open()
      else mobileToc.close()
    })

    $cardToc.addEventListener('click', (e) => {
      if (window.innerWidth < 992) { // 小于992px的时候
        mobileToc.close()
      }
    })
  }
</script>

<style>
  /* .is-position-fixed {
    position: sticky !important;
    top: 74px;
  }

  .toc-main ul {
    counter-reset: show-list;
  }

  .toc-main ul li::before {
    content: counter(item)".";
    display: block;
    position: absolute;
    left: 12px;
    top: 0;
  } */
</style>
 

<!-- 设置导航背景 -->
<script>
  let setHeaderClass = () => {
    const nav = $('#navHeader');
    const navTop = nav.outerHeight();
    const winTop = $(window).scrollTop();
    if(winTop > navTop) {
      nav.addClass('header-bg-color');
    }
    else {
      nav.removeClass('header-bg-color');
    }
  };

  let scrollCollect = () => {
    return bamboo.throttle(function (e) {
      setHeaderClass();
    }, 200)()
  }

  let initHeaderBg = () => {
    setHeaderClass();
  }

  setHeaderClass();
  window.addEventListener('scroll', scrollCollect);

  document.addEventListener('pjax:send', function () {
    window.removeEventListener('scroll', scrollCollect)
  })
  document.addEventListener('pjax:complete', function () {
    window.addEventListener('scroll', scrollCollect);
    setHeaderClass();
  })
</script> 

<!-- 渲染issues标签里的内容 -->
<script>
  function loadIssuesJS() {
    if ($(".post-detail").find(".issues-api").length == 0) {
      return;
    } 
    loadScript('/js/issues/index.js');
  };
  $(function () {
    loadIssuesJS();
  });
  document.addEventListener('pjax:complete', function () {
    if (typeof IssuesAPI == "undefined") {
      loadIssuesJS();
    }
  })
</script>

<!-- 渲染远程json加载的图片标签(getPhotoOnline)里的内容 -->
<script>
  function loadPhotoOnlineJS() {
    if ($(".post-detail").find(".getJsonPhoto-api").length == 0) {
      return;
    } 
    loadScript('/js/getPhotoOnline/index.js');
  };
  $(function () {
    loadPhotoOnlineJS();
  });
  document.addEventListener('pjax:complete', function () {
    if (typeof getPhotoJson == "undefined") {
      loadPhotoOnlineJS();
    }
  })
</script>

<!-- 渲染远程json加载的talk标签(getTalkOnline)里的内容 -->
<script>
  function loadTalkOnlineJS() {
    if ($(".post-detail").find(".getJsonTalk-api").length == 0) {
      return;
    } 
    loadScript('https://cdnjs.cloudflare.com/ajax/libs/waterfall.js/1.0.2/waterfall.min.js'); // 瀑布流插件，https://raphamorim.io/waterfall.js/
    loadScript('/js/getTalkOnline/index.js');
  };
  $(function () {
    loadTalkOnlineJS();
  });
  document.addEventListener('pjax:complete', function () {
    if (typeof getTalkJson == "undefined") {
      loadTalkOnlineJS();
    }
  })
</script>

<!-- 渲染远程json加载的site-card标签(getSiteOnline)里的内容 -->
<script>
  function loadSiteOnlineJS() {
    if ($(".post-detail").find(".getJsonSite-api").length == 0) {
      return;
    } 
    loadScript('/js/getSiteOnline/index.js');
  };
  $(function () {
    loadSiteOnlineJS();
  });
  document.addEventListener('pjax:complete', function () {
    if (typeof getSiteJson == "undefined") {
      loadSiteOnlineJS();
    }
  })
</script>

<!-- 输入框打字特效 -->
<!-- 输入框打字特效 -->


<!-- markdown代码一键复制功能 -->

  <link rel="stylesheet" href="https://unpkg.com/v-plugs-ayu/lib/ayu.css">
  <script src="https://unpkg.com/v-plugs-ayu/lib/ayu.umd.min.js"></script>
  <script src="/js/clipboard/clipboard.min.js"></script>
  <div id="appCopy">
  </div>
  <script data-pjax>
    var vm = new Vue({
      el: '#appCopy',
      data: {
      },
      computed: {
      },
      mounted() {
        const that = this;
        var copy = 'copy';
        /* code */
        var initCopyCode = function () {
          var copyHtml = '';
          copyHtml += '<button class="btn-copy" data-clipboard-snippet="" style="position:absolute;top:0;right:0;z-index:1;">';
          copyHtml += '<i class="fas fa-copy"></i><span>' + copy + '</span>';
          copyHtml += '</button>';
          $(".post-detail pre").not('.gutter pre').wrap("<div class='codeBox' style='position:relative;width:100%;'></div>")
          $(".post-detail pre").not('.gutter pre').before(copyHtml);
          new ClipboardJS('.btn-copy', {
            target: function (trigger) {
              return trigger.nextElementSibling;
            }
          });
        }
        initCopyCode();
        $('.btn-copy').unbind('click').bind('click', function () {
          doSomething();
        })
        $(document).unbind('keypress').bind('keypress', function (e) {
          if (e.ctrlKey && e.keyCode == 67) {
            doSomething();
          }
        })

        function doSomething() {
          that.$notify({
            title: "成功",
            content: "代码已复制，请遵守相关授权协议。",
            type: 'success'
          })
        }
      },
      methods: {
      },
      created() { }
    })
  </script>
  

<!-- 图片懒加载 -->
<script defer src="https://unpkg.com/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>


<!-- 卡片滚动动画 -->
   

<!-- 评论所需js -->

  
        <script type="text/javascript">
  var utteranceComment = {};

  function check_utterance() {
    let isDark = JSON.parse(localStorage.getItem('dark')) || JSON.parse('false');
    if (isDark) {
      utteranceComment.Theme = 'github-dark';
    } else {
      utteranceComment.Theme = 'github-light';
    }

    return document.getElementById("gitment-container");
  }
  comment_el = '#gitment-container';
  load_utterance = function () {
    if ($(comment_el).length) {
      // 匿名函数，防止污染全局变量
      const HEAD = check_utterance();

      var utterances = document.createElement('script');
      utterances.type = 'text/javascript';
      utterances.async = true;
      utterances.setAttribute('issue-term', 'pathname')
      utterances.setAttribute('theme', utteranceComment.Theme)
      utterances.setAttribute('repo', '')
      utterances.crossorigin = 'anonymous';
      utterances.src = 'https://utteranc.es/client.js';
      // content 是要插入评论的地方
      document.getElementById('gitment-container').appendChild(utterances);

    }
  }

  function dark_utterance() {
    const HEAD = check_utterance();
    if (!HEAD) return;
    const message = {
      type: 'set-theme',
      theme: utteranceComment.Theme
    };
    const utteranceIframe = document.querySelector('iframe');
    utteranceIframe.contentWindow.postMessage(message, 'https://utteranc.es');
  }

  $(document).ready(load_utterance);
  document.addEventListener('pjax:complete', function () {
    load_utterance();
  });

  $('.dark').click(function () {
    setTimeout(() => {
      dark_utterance();
    });
  })

</script>

<style>
  .utterances {
    max-width: inherit !important;
  }
</style>
      


<!-- 鼠标点击特效 -->
<!-- 爱心点击 -->





<!-- 轮播图标签 -->
<script>
  var bambooSwiperTag = {};
  function load_swiper() {
    if (!document.querySelectorAll(".post-swiper-container")[0]) return;
    loadCSS("https://unpkg.com/swiper@6/swiper-bundle.min.css")
    loadScript("https://unpkg.com/swiper@6/swiper-bundle.min.js").then(() => {
      pjax_swiper();
    });
  }

  load_swiper();

  function pjax_swiper() {
    bambooSwiperTag.swiper = new Swiper('.post-swiper-container', {
      slidesPerView: 'auto',
      spaceBetween: 8,
      centeredSlides: true,
      loop: true,
      autoplay: true ? {
        delay: 3000,
        stopOnLastSlide: false,
        disableOnInteraction: false,
      } : false,
      pagination: {
        el: '.swiper-pagination',
        clickable: true,
      },
      navigation: {
        nextEl: '.swiper-button-next',
        prevEl: '.swiper-button-prev',
      },
      on:{
        init: function(){
          swiperAnimateCache(this); //隐藏动画元素 
          swiperAnimate(this); //初始化完成开始动画
        }, 
        slideChangeTransitionEnd: function(){ 
          swiperAnimate(this); //每个slide切换结束时也运行当前slide动画
          //this.slides.eq(this.activeIndex).find('.ani').removeClass('ani'); 动画只展现一次，去除ani类名
        } 
      }
    });
  }

  document.addEventListener('pjax:complete', function () {
    if (!document.querySelectorAll(".post-swiper-container")[0]) return;
    if (typeof bambooSwiperTag.swiper === "undefined") {
      load_swiper();
    } else {
      pjax_swiper();
    }
  });
</script>
    <!-- pjax -->
    

<!-- pjax -->


  <script src="/js/pjax@0.2.8/index.js"></script>
  
    <div class="pjax-animate">
  
    <div class="loading-circle"><div id="loader-circle"></div></div>
    <script>
      window.ShowLoading = function() {
        $(".loading-circle").css("display", "block");
      };
      window.HideLoading = function() {
        $(".loading-circle").css("display", "none");
      }
    </script>
  
	<script>
    document.addEventListener('pjax:complete', function () {
      window.HideLoading();
    })
    document.addEventListener('pjax:send', function () {
      window.ShowLoading();
    })
    document.addEventListener('pjax:error', function () {
      window.HideLoading();
    })
	</script>
</div>

  

  <script>
    var pjax = new Pjax({
      elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([no-pjax])',   // 拦截正常带链接的 a 标签
      selectors: ["#pjax-container","title"],                                   // 根据实际需要确认重载区域
      cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
      timeout: 5000
    });

    document.addEventListener('pjax:send', function (e) {

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      $(window).unbind('resize');
      $(window).unbind('scroll');
      $(document).unbind('scroll');
      $(document).unbind('click');
      $('body').unbind('click');

    })
    
    document.addEventListener('pjax:complete', function () {
      $('script[data-pjax], .pjax-reload script').each(function () {
        $(this).parent().append($(this).remove());
      });
    });

    document.addEventListener('pjax:error', function (e) {
      window.location.href = e.triggerElement.href;
    })
    
    // 刷新不从顶部开始
    document.addEventListener("DOMContentLoaded", function () {
      history.scrollRestoration = 'auto';
    })
  </script>



  </body>
</html>