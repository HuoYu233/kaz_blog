{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"themes/bamboo1/source/favicon.ico","path":"favicon.ico","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/medias/logo.png","path":"medias/logo.png","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/css/animate.min.css","path":"css/animate.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/activate-power-mode.js","path":"js/activate-power-mode.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/app.js","path":"js/app.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/goTop.js","path":"js/goTop.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/jquery3.5.1.js","path":"js/jquery3.5.1.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/local_search.js","path":"js/local_search.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/ribbon.min.js","path":"js/ribbon.min.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/wrapImage.js","path":"js/wrapImage.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/vue2.6.11.js","path":"js/vue2.6.11.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/medias/cursor/Horizontal.cur","path":"medias/cursor/Horizontal.cur","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/aplayer/APlayer@1.10.1.min.css","path":"js/aplayer/APlayer@1.10.1.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/bubble/bubble.js","path":"js/bubble/bubble.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/bubble/homeBubble.js","path":"js/bubble/homeBubble.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/danmu/barrager.css","path":"js/danmu/barrager.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/clipboard/clipboard.min.js","path":"js/clipboard/clipboard.min.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/danmu/close.png","path":"js/danmu/close.png","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/danmu/jquery.barrager.js","path":"js/danmu/jquery.barrager.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/cursor/explosion.min.js","path":"js/cursor/explosion.min.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/cursor/clicklove.js","path":"js/cursor/clicklove.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/cursor/fireworks.js","path":"js/cursor/fireworks.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/cursor/text.js","path":"js/cursor/text.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/falling/sakura.js","path":"js/falling/sakura.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/falling/snow.js","path":"js/falling/snow.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/getPhotoOnline/index.js","path":"js/getPhotoOnline/index.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/getSiteOnline/index.js","path":"js/getSiteOnline/index.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/getTalkOnline/index.js","path":"js/getTalkOnline/index.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/issues/index.js","path":"js/issues/index.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/pjax@0.2.8/index.js","path":"js/pjax@0.2.8/index.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/prism/prism-coy.min.css","path":"js/prism/prism-coy.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/prism/prism-dark.min.css","path":"js/prism/prism-dark.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/prism/prism-funky.min.css","path":"js/prism/prism-funky.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/prism/prism-okaidia.min.css","path":"js/prism/prism-okaidia.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/prism/prism-solarizedlight.min.css","path":"js/prism/prism-solarizedlight.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/prism/prism-line-numbers.css","path":"js/prism/prism-line-numbers.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/prism/prism.min.css","path":"js/prism/prism.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/shareJs/font.css","path":"js/shareJs/font.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/prism/prism-twilight.min.css","path":"js/prism/prism-twilight.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/shareJs/share.min.css","path":"js/shareJs/share.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/shareJs/social-share.min.js","path":"js/shareJs/social-share.min.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/prism/prism-tomorrow.min.css","path":"js/prism/prism-tomorrow.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/swiper/swiper.animate1.0.3.min.js","path":"js/swiper/swiper.animate1.0.3.min.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/swiper/swiper@5.4.1.min.css","path":"js/swiper/swiper@5.4.1.min.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/tocbot/tocbot.css","path":"js/tocbot/tocbot.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/utils/index.js","path":"js/utils/index.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/tocbot/tocbot.min.js","path":"js/tocbot/tocbot.min.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/valine/index.js","path":"js/valine/index.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/swiper/swiper.min.js","path":"js/swiper/swiper.min.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/vue-seamless-scroll/index.js","path":"js/vue-seamless-scroll/index.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/vue-typed-js/index.css","path":"js/vue-typed-js/index.css","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/waline/waline.min.js","path":"js/waline/waline.min.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/vue-typed-js/index.js","path":"js/vue-typed-js/index.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/swiper/vue-awesome-swiper.js","path":"js/swiper/vue-awesome-swiper.js","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/shareJs/fonts/iconfont.eot","path":"js/shareJs/fonts/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/shareJs/fonts/iconfont.svg","path":"js/shareJs/fonts/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/shareJs/fonts/iconfont.ttf","path":"js/shareJs/fonts/iconfont.ttf","modified":1,"renderable":1},{"_id":"themes/bamboo1/source/js/shareJs/fonts/iconfont.woff","path":"js/shareJs/fonts/iconfont.woff","modified":1,"renderable":1},{"_id":"source/img/Kaz.jpg","path":"img/Kaz.jpg","modified":1,"renderable":0},{"_id":"source/img/bg.jpg","path":"img/bg.jpg","modified":1,"renderable":0},{"_id":"source/img/favicon.ico","path":"img/favicon.ico","modified":1,"renderable":0},{"_id":"source/img/hello-world/Kaz.jpg","path":"img/hello-world/Kaz.jpg","modified":1,"renderable":0},{"_id":"source/img/all-in-rag/p1.png","path":"img/all-in-rag/p1.png","modified":1,"renderable":0},{"_id":"source/img/all-in-rag/p2.png","path":"img/all-in-rag/p2.png","modified":1,"renderable":0},{"_id":"source/img/protrek/fig1.png","path":"img/protrek/fig1.png","modified":1,"renderable":0},{"_id":"source/img/venusREM/p1.png","path":"img/venusREM/p1.png","modified":1,"renderable":0},{"_id":"source/img/venusREM/p2.png","path":"img/venusREM/p2.png","modified":1,"renderable":0},{"_id":"source/img/venusREM/p4.png","path":"img/venusREM/p4.png","modified":1,"renderable":0},{"_id":"source/img/venusREM/p3.png","path":"img/venusREM/p3.png","modified":1,"renderable":0},{"_id":"source/img/protrek/fig2.png","path":"img/protrek/fig2.png","modified":1,"renderable":0},{"_id":"source/img/prot2text/fig1.png","path":"img/prot2text/fig1.png","modified":1,"renderable":0},{"_id":"source/img/prot2text/fig4.png","path":"img/prot2text/fig4.png","modified":1,"renderable":0},{"_id":"source/img/prot2text/table1.png","path":"img/prot2text/table1.png","modified":1,"renderable":0},{"_id":"source/img/prot2text/fig2.png","path":"img/prot2text/fig2.png","modified":1,"renderable":0},{"_id":"source/img/prot2text/table2.png","path":"img/prot2text/table2.png","modified":1,"renderable":0},{"_id":"source/img/prot2text/fig3.png","path":"img/prot2text/fig3.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-10.png","path":"img/machine-learning-notes/pic-10.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-1.png","path":"img/machine-learning-notes/pic-1.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-11.png","path":"img/machine-learning-notes/pic-11.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-12.png","path":"img/machine-learning-notes/pic-12.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-13.png","path":"img/machine-learning-notes/pic-13.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-14.png","path":"img/machine-learning-notes/pic-14.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-15.png","path":"img/machine-learning-notes/pic-15.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-16.png","path":"img/machine-learning-notes/pic-16.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-17.png","path":"img/machine-learning-notes/pic-17.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-18.png","path":"img/machine-learning-notes/pic-18.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-19.png","path":"img/machine-learning-notes/pic-19.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-20.png","path":"img/machine-learning-notes/pic-20.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-2.png","path":"img/machine-learning-notes/pic-2.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-22.png","path":"img/machine-learning-notes/pic-22.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-21.png","path":"img/machine-learning-notes/pic-21.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-23.png","path":"img/machine-learning-notes/pic-23.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-24.png","path":"img/machine-learning-notes/pic-24.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-25.png","path":"img/machine-learning-notes/pic-25.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-26.png","path":"img/machine-learning-notes/pic-26.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-27.png","path":"img/machine-learning-notes/pic-27.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-28.png","path":"img/machine-learning-notes/pic-28.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-29.png","path":"img/machine-learning-notes/pic-29.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-3.png","path":"img/machine-learning-notes/pic-3.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-30.png","path":"img/machine-learning-notes/pic-30.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-31.png","path":"img/machine-learning-notes/pic-31.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-32.png","path":"img/machine-learning-notes/pic-32.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-33.png","path":"img/machine-learning-notes/pic-33.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-34.png","path":"img/machine-learning-notes/pic-34.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-35.png","path":"img/machine-learning-notes/pic-35.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-36.png","path":"img/machine-learning-notes/pic-36.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-37.png","path":"img/machine-learning-notes/pic-37.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-4.png","path":"img/machine-learning-notes/pic-4.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-38.png","path":"img/machine-learning-notes/pic-38.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-8.png","path":"img/machine-learning-notes/pic-8.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-5.png","path":"img/machine-learning-notes/pic-5.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-7.jpg","path":"img/machine-learning-notes/pic-7.jpg","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-9.png","path":"img/machine-learning-notes/pic-9.png","modified":1,"renderable":0},{"_id":"source/img/proteinMPNN/p1.png","path":"img/proteinMPNN/p1.png","modified":1,"renderable":0},{"_id":"source/img/proteinMPNN/p2.png","path":"img/proteinMPNN/p2.png","modified":1,"renderable":0},{"_id":"source/img/machine-learning-notes/pic-6.png","path":"img/machine-learning-notes/pic-6.png","modified":1,"renderable":0},{"_id":"source/img/transformer-notes/pic-1.png","path":"img/transformer-notes/pic-1.png","modified":1,"renderable":0},{"_id":"source/img/transformer-notes/pic-2.png","path":"img/transformer-notes/pic-2.png","modified":1,"renderable":0},{"_id":"source/img/transformer-notes/pic-3.png","path":"img/transformer-notes/pic-3.png","modified":1,"renderable":0},{"_id":"source/img/transformer-notes/pic-4.png","path":"img/transformer-notes/pic-4.png","modified":1,"renderable":0},{"_id":"source/img/proteinMPNN/p3.png","path":"img/proteinMPNN/p3.png","modified":1,"renderable":0},{"_id":"source/img/transformer-notes/pic-5.png","path":"img/transformer-notes/pic-5.png","modified":1,"renderable":0},{"_id":"source/img/proteinMPNN/p4.png","path":"img/proteinMPNN/p4.png","modified":1,"renderable":0},{"_id":"source/img/proteinMPNN/p5.png","path":"img/proteinMPNN/p5.png","modified":1,"renderable":0}],"Cache":[{"_id":"source/log/index.md","hash":"5deeb5b2f9716755f91cfcc3e6dda56bb45e951d","modified":1740672551623},{"_id":"source/about/index.md","hash":"cd6c3f9f7edd26b9c888d36262fab81b30c7061f","modified":1766060256190},{"_id":"source/out_of_date/ai4chem.md","hash":"d787b2f0f08d544a5a87a4cfeb4898216b25d2bb","modified":1742733082540},{"_id":"source/out_of_date/learning-cpp-notes.md","hash":"ec0f2fab0870e207e85a203f763931eb6e2b5f65","modified":1747028730248},{"_id":"source/img/Kaz.jpg","hash":"aa39b601ea6065577374034fd7a112d022ee3980","modified":1736256189325},{"_id":"source/out_of_date/cs106l.md","hash":"de810d5de3d28b82d04b5639c1c7a6822a26f982","modified":1746026490843},{"_id":"source/img/favicon.ico","hash":"a3a1b2c8f5bcd3faf1871d57d7923d6b45f35d34","modified":1737556566666},{"_id":"source/_posts/algorithm-data-structure.md","hash":"7086b1498dae97bf727896740ec9c29317e08af8","modified":1740033940656},{"_id":"source/_posts/algorithm-basic.md","hash":"77812d87aa99ed356be433e28f989246b78fa721","modified":1740711826487},{"_id":"source/_posts/Quantification.md","hash":"f8ac7a825948d30f34275b9f865ccd516a4e257c","modified":1765338181061},{"_id":"source/_posts/algorithm-dp.md","hash":"7b820bff87b39bd8ae211d74d1e70188aad9465e","modified":1740711998010},{"_id":"source/_posts/algorithm-math.md","hash":"b8837cdd921be28cf6b39e68c4ce91b71462487a","modified":1741144378052},{"_id":"source/_posts/hello-agent.md","hash":"493b9258ab871da887ff65b25bc30c09dfefb9b1","modified":1764061868775},{"_id":"source/_posts/algorithm-graph.md","hash":"f2fb24bafef83ec8c1e3a3a084a0bac8c22c04f7","modified":1740712608846},{"_id":"source/_posts/conditionMPNN.md","hash":"c211abb9c0a323c0d358a42341516391b7353b9e","modified":1769153694027},{"_id":"source/_posts/algorithm-search.md","hash":"f64e7202a8da9c39428826985838e59d0622e246","modified":1740712354855},{"_id":"source/_posts/algorithm-skills.md","hash":"cd89781466ab14e056400ee5153b05b29c0435ed","modified":1740711625621},{"_id":"source/_posts/dive-into-deep-learning.md","hash":"f0415b92f350fbb7dc3a91611bff4f546cd60131","modified":1740998538757},{"_id":"source/_posts/prot2text.md","hash":"da6faf15cbbbd2e609a749bf2cde05088f8d3e0e","modified":1759135127285},{"_id":"source/_posts/hello-world.md","hash":"662795e1685a6493db59dd5eafab94cdf24dd0ff","modified":1739795982971},{"_id":"source/_posts/memery-in-pytorch.md","hash":"d56c3d55158e9062d5e314afa9187fa857e8f3cf","modified":1768388854313},{"_id":"source/_posts/all-in-rag.md","hash":"f11d2e2b3e52533443b97c0dd719d9bf181ef0cc","modified":1764061780134},{"_id":"source/_posts/machine-learning-notes.md","hash":"94148eaa455f7f7bc90b10dff3aa48e232911498","modified":1740711414489},{"_id":"source/_posts/protrek.md","hash":"742e11c8d9db4ffc01309198b7cb2effc936aa49","modified":1758876534443},{"_id":"source/_posts/tudui-pytorch.md","hash":"50169f16006857e9e6810e660914ee1ac384844c","modified":1761974227881},{"_id":"source/_posts/minimind.md","hash":"981623a98562bbaa871d9897842905e8d0761bbd","modified":1769241407557},{"_id":"source/_posts/proteinMPNN.md","hash":"57a9362b3ec0915adf8065242b9a1f15feeabadb","modified":1769153685449},{"_id":"source/img/hello-world/Kaz.jpg","hash":"aa39b601ea6065577374034fd7a112d022ee3980","modified":1736256189325},{"_id":"source/_posts/venusREM.md","hash":"3d33a5b626460c1a56ffccee66180e51b0adc761","modified":1761293034135},{"_id":"source/_posts/transformer-notes.md","hash":"070011f2fecf71cc9e2b29a1bd2fb10290f9ff3f","modified":1754725215514},{"_id":"source/img/prot2text/fig4.png","hash":"5dc86acc0a978c0b797f714ebcf7e7267a32f175","modified":1759134040390},{"_id":"source/img/prot2text/table1.png","hash":"4b49e14efd1ef70827a9510964eb04b0b2b21625","modified":1759133459955},{"_id":"source/img/prot2text/table2.png","hash":"157d5535b362be68afadd9ffcfb90a4d99764852","modified":1759133537651},{"_id":"source/img/prot2text/fig2.png","hash":"edf2c023b1b4431bdb9edc638e28a7b0f61b0cba","modified":1759133378120},{"_id":"source/img/machine-learning-notes/pic-16.png","hash":"5b3c81945f400550dfc7140e20b1a53d27a196c5","modified":1739458454213},{"_id":"source/img/machine-learning-notes/pic-27.png","hash":"d36f66e7a82d7f1b17fa05b12be35f45d1046928","modified":1739622620308},{"_id":"source/img/machine-learning-notes/pic-3.png","hash":"7387a4682f742363b8c58677373d7549a9b9c1cf","modified":1738425420819},{"_id":"source/img/machine-learning-notes/pic-35.png","hash":"ccc02508f63a657179c124d7637397ff9851d6d4","modified":1740055846274},{"_id":"source/img/machine-learning-notes/pic-4.png","hash":"838d94327bb5086b731c649fdfb2d0ce109c71b0","modified":1738425452378},{"_id":"source/img/transformer-notes/pic-5.png","hash":"4fd2d84d2cf2517575388972a46e3c0c0ef6574e","modified":1754717350538},{"_id":"source/_posts/img/hello-world/Kaz.jpg","hash":"aa39b601ea6065577374034fd7a112d022ee3980","modified":1736256189325},{"_id":"source/_posts/img/prot2text/fig4.png","hash":"5dc86acc0a978c0b797f714ebcf7e7267a32f175","modified":1759134040390},{"_id":"source/_posts/img/prot2text/fig2.png","hash":"edf2c023b1b4431bdb9edc638e28a7b0f61b0cba","modified":1759133378120},{"_id":"source/_posts/img/prot2text/table1.png","hash":"4b49e14efd1ef70827a9510964eb04b0b2b21625","modified":1759133459955},{"_id":"source/_posts/img/prot2text/table2.png","hash":"157d5535b362be68afadd9ffcfb90a4d99764852","modified":1759133537651},{"_id":"source/_posts/img/transformer-notes/pic-5.png","hash":"4fd2d84d2cf2517575388972a46e3c0c0ef6574e","modified":1754717350538},{"_id":"source/_posts/img/machine-learning-notes/pic-16.png","hash":"5b3c81945f400550dfc7140e20b1a53d27a196c5","modified":1739458454213},{"_id":"source/_posts/img/machine-learning-notes/pic-27.png","hash":"d36f66e7a82d7f1b17fa05b12be35f45d1046928","modified":1739622620308},{"_id":"source/_posts/img/machine-learning-notes/pic-3.png","hash":"7387a4682f742363b8c58677373d7549a9b9c1cf","modified":1738425420819},{"_id":"source/_posts/img/machine-learning-notes/pic-35.png","hash":"ccc02508f63a657179c124d7637397ff9851d6d4","modified":1740055846274},{"_id":"source/_posts/img/machine-learning-notes/pic-4.png","hash":"838d94327bb5086b731c649fdfb2d0ce109c71b0","modified":1738425452378},{"_id":"source/img/prot2text/fig1.png","hash":"0bd29429de98d67f18efa01afe4d235ce9fc3ca1","modified":1759111785763},{"_id":"source/img/machine-learning-notes/pic-20.png","hash":"724d8995131fbaedbf2f05b313862866b53c4e87","modified":1739461102564},{"_id":"source/img/machine-learning-notes/pic-17.png","hash":"28493d22eede9861a75fe2a1d46390b78aa41ae5","modified":1739458598505},{"_id":"source/img/machine-learning-notes/pic-22.png","hash":"132aaa4f3e413125735dfd913e775837146ebde4","modified":1739537460909},{"_id":"source/img/machine-learning-notes/pic-26.png","hash":"2409d57d65cb3b6583023569b8a5cfda1146ce59","modified":1739619946353},{"_id":"source/img/machine-learning-notes/pic-37.png","hash":"037b77bcf91352c8ca863cc7da5fd8930850d7f8","modified":1740144875402},{"_id":"source/img/machine-learning-notes/pic-36.png","hash":"b02febe362dc4d704c4a266fea335d83107f0bdf","modified":1740143318932},{"_id":"themes/bamboo1/source/css/_tag/ghcard.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1740671571328},{"_id":"source/img/machine-learning-notes/pic-6.png","hash":"3d1c7fe6c3783781ac279f471bd8db7f4a96f396","modified":1738564459827},{"_id":"source/img/transformer-notes/pic-2.png","hash":"0df6ba77725900dcc7a9ad3e39790f0b8ecc967c","modified":1741693804900},{"_id":"source/_posts/img/prot2text/fig1.png","hash":"0bd29429de98d67f18efa01afe4d235ce9fc3ca1","modified":1759111785763},{"_id":"source/_posts/img/transformer-notes/pic-2.png","hash":"0df6ba77725900dcc7a9ad3e39790f0b8ecc967c","modified":1741693804900},{"_id":"source/_posts/img/machine-learning-notes/pic-17.png","hash":"28493d22eede9861a75fe2a1d46390b78aa41ae5","modified":1739458598505},{"_id":"source/_posts/img/machine-learning-notes/pic-20.png","hash":"724d8995131fbaedbf2f05b313862866b53c4e87","modified":1739461102564},{"_id":"source/_posts/img/machine-learning-notes/pic-22.png","hash":"132aaa4f3e413125735dfd913e775837146ebde4","modified":1739537460909},{"_id":"source/_posts/img/machine-learning-notes/pic-26.png","hash":"2409d57d65cb3b6583023569b8a5cfda1146ce59","modified":1739619946353},{"_id":"source/_posts/img/machine-learning-notes/pic-36.png","hash":"b02febe362dc4d704c4a266fea335d83107f0bdf","modified":1740143318932},{"_id":"source/_posts/img/machine-learning-notes/pic-37.png","hash":"037b77bcf91352c8ca863cc7da5fd8930850d7f8","modified":1740144875402},{"_id":"source/_posts/img/machine-learning-notes/pic-6.png","hash":"3d1c7fe6c3783781ac279f471bd8db7f4a96f396","modified":1738564459827},{"_id":"source/img/all-in-rag/p2.png","hash":"a7fdfe861c3bca2857dad69d9b076d1ab3231878","modified":1764057349414},{"_id":"source/img/venusREM/p2.png","hash":"095ab3be1daa0dc443dca1c2a4529ba769cdcfbe","modified":1761291421641},{"_id":"source/img/machine-learning-notes/pic-19.png","hash":"7598a0992232dac91613e65e9dc4fec58dd1c56c","modified":1739459181242},{"_id":"source/img/machine-learning-notes/pic-15.png","hash":"9f85209eae05833c0d6376d401f45e051023c4d2","modified":1739456947233},{"_id":"source/img/machine-learning-notes/pic-13.png","hash":"59de2b8eb3b6db9d4c564febdf7e3709130787a7","modified":1739453444035},{"_id":"source/img/machine-learning-notes/pic-18.png","hash":"1ad628440b4b5349cc6667348a33c9c97a012eff","modified":1739458743567},{"_id":"source/img/machine-learning-notes/pic-21.png","hash":"a8a3382060eab1be1c5a95e90fe7752721dbe801","modified":1739535680777},{"_id":"source/img/machine-learning-notes/pic-24.png","hash":"40e00390e74ff9cf3aba708c1e9bec5724c396ca","modified":1739542099791},{"_id":"source/img/machine-learning-notes/pic-29.png","hash":"b5bab6fddb0ad1c79c6d42362ac8a3a0319e6351","modified":1739624989401},{"_id":"source/img/machine-learning-notes/pic-33.png","hash":"278a77be72fa2c34cad1ae3ac6d0a492665c78a1","modified":1739946176241},{"_id":"source/img/machine-learning-notes/pic-31.png","hash":"a15f390cb899248c679527434ec08a5e4b06d6f2","modified":1739888230194},{"_id":"source/img/machine-learning-notes/pic-34.png","hash":"d25dcd2ed03f72135c38a4901e961d5ddda92778","modified":1739947190822},{"_id":"source/img/machine-learning-notes/pic-7.jpg","hash":"53a93542b958da7e52fe83aba886eb722dd26155","modified":1738910656446},{"_id":"source/img/proteinMPNN/p1.png","hash":"e2cac40872bc88771067c039f67baa4c6d28d64a","modified":1761548612536},{"_id":"themes/bamboo1/package.json","hash":"1db58d63b57e63d88e0a060e5b164db225cf2599","modified":1740671571298},{"_id":"themes/bamboo1/LICENSE","hash":"2f9d4d3c41f055757f8c86567cfe838846446e7b","modified":1740671571262},{"_id":"themes/bamboo1/README.md","hash":"2b81d4346abf63bd58483420ea54220c8d1101b3","modified":1740671571262},{"_id":"themes/bamboo1/source/favicon.ico","hash":"801ff7b3f358b77a813787a97ef59148eec93fd8","modified":1740671571332},{"_id":"themes/bamboo1/_config.yml","hash":"5f048373eb3fa237673d8a795a9a5df750fa18f0","modified":1758962547350},{"_id":"themes/bamboo1/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1740671571295},{"_id":"themes/bamboo1/languages/default.yml","hash":"4c604dc1344630ae5ab50edc282a3e46982884c1","modified":1740671571263},{"_id":"themes/bamboo1/languages/zh-TW.yml","hash":"bd3ef201b7dcbeeee54107301550d60e71d72ba7","modified":1740671571264},{"_id":"themes/bamboo1/layout/categories.ejs","hash":"b0f71816ca4c0899eb82b6fa100abf91b56508ab","modified":1740671571295},{"_id":"themes/bamboo1/languages/zh-CN.yml","hash":"2bf66fefa219ee8152d35bb5f823ca5096fedcf2","modified":1740671571264},{"_id":"themes/bamboo1/layout/category.ejs","hash":"d0d19ac565414123c24b312f7158dbe1c9e275f8","modified":1740671571296},{"_id":"themes/bamboo1/scripts/helpers/side_archives.js","hash":"a292f0a9e9242556b83219f519e3e92a4d85e904","modified":1740671571299},{"_id":"themes/bamboo1/layout/post.ejs","hash":"206c60b92ec1ce6332e75e85761ce0c6947f5dae","modified":1740671571297},{"_id":"themes/bamboo1/layout/layout.ejs","hash":"a7dbe3f3f900e30c49f02b4d3a99803a4aba59ec","modified":1740671571297},{"_id":"themes/bamboo1/scripts/z-lazyload/index.js","hash":"58b935fb699a98f0a9ceb741d2105a977e24cf59","modified":1740671571307},{"_id":"themes/bamboo1/layout/index.ejs","hash":"fea918c473fe66846b7a7f94da4617610cff3d07","modified":1740671571297},{"_id":"themes/bamboo1/scripts/tag/btn.js","hash":"0e628fa28e03f60e28f257af895b2e72a0cb8449","modified":1740671571300},{"_id":"themes/bamboo1/layout/tag.ejs","hash":"1061f8a9b51d983590a3efc536142a9b10acebf5","modified":1740671571297},{"_id":"themes/bamboo1/scripts/tag/checkbox.js","hash":"49da9041bd41c57a547d42fb7a6741757b848f1c","modified":1740671571300},{"_id":"themes/bamboo1/scripts/tag/btns.js","hash":"618e2f77ec244d8814f2b38c9820d1356580bbcd","modified":1740671571300},{"_id":"themes/bamboo1/scripts/tag/folding.js","hash":"832c55a45cfeeabcd2d317d42faaee09ee54d2a4","modified":1740671571301},{"_id":"themes/bamboo1/scripts/tag/file.js","hash":"260333b277073ba8f41472cdddb35ee3e8212267","modified":1740671571300},{"_id":"themes/bamboo1/scripts/tag/gallery.js","hash":"694a6a81dd3b3aa4a37e39b35402e99322941ec1","modified":1740671571301},{"_id":"themes/bamboo1/layout/tags.ejs","hash":"0c6a171fa56cf8bfa180db32f10f75c6760fd983","modified":1740671571297},{"_id":"themes/bamboo1/scripts/tag/getPhoto.js","hash":"e78765e6156ff261e564d8a22c6307ea98990a0d","modified":1740671571302},{"_id":"themes/bamboo1/scripts/tag/getPhotoOnline.js","hash":"16478a1a0d642b92cc4f86114d185bf79cbd0bf9","modified":1740671571302},{"_id":"themes/bamboo1/scripts/tag/getSiteOnline.js","hash":"2dce91bf40a1e6f856e317eba777fc29399ec2fc","modified":1740671571302},{"_id":"themes/bamboo1/scripts/tag/ghcard.js","hash":"4e893d79abc1e8e1e5b3bfe08249ff32b250314d","modified":1740671571303},{"_id":"themes/bamboo1/scripts/tag/getTalkOnline.js","hash":"30f63677757c051835fec668ec928bcd47f6ba66","modified":1740671571302},{"_id":"themes/bamboo1/scripts/tag/image.js","hash":"faa1d83114bc255cffc18bd0ab037f08b430f515","modified":1740671571303},{"_id":"themes/bamboo1/scripts/tag/inline-labels.js","hash":"eaaedc3d65384e0beb4306534ef4ed202b46da18","modified":1740671571303},{"_id":"themes/bamboo1/scripts/tag/link.js","hash":"a11fe06f20669f4b64a1a0dcc9f005a9f32e29dc","modified":1740671571304},{"_id":"themes/bamboo1/scripts/tag/note.js","hash":"9e990caa1fd815a760e31f1eaa02015d357fcef8","modified":1740671571305},{"_id":"themes/bamboo1/scripts/tag/media.js","hash":"1d163ee349818baeb95504f82d3497da6f6556e2","modified":1740671571304},{"_id":"themes/bamboo1/scripts/tag/mermaid.js","hash":"1e69a5e4a4a5f88fdb76d0fe55ea651c14301816","modified":1740671571304},{"_id":"themes/bamboo1/scripts/tag/swiper.js","hash":"26a587371f7d2f6715cdb0e5f4f7b63a7f7921cd","modified":1740671571306},{"_id":"themes/bamboo1/scripts/tag/issues.js","hash":"7dcb40af462e4131f6a52d354ed3b147b4e874af","modified":1740671571303},{"_id":"themes/bamboo1/scripts/tag/progress.js","hash":"99a10305e3924aaab05135ef25afd10d04574bfe","modified":1740671571305},{"_id":"themes/bamboo1/scripts/tag/timeline.js","hash":"da2b0d7760dea698429f370aba5cded5bb24501e","modified":1740671571306},{"_id":"themes/bamboo1/scripts/tag/tabs.js","hash":"133310460bdf70a7932b44c3ccca509b3f221e1c","modified":1740671571306},{"_id":"themes/bamboo1/scripts/tag/span.js","hash":"d617b5a0056c4a0c983225513c89eed6f5b56833","modified":1740671571305},{"_id":"themes/bamboo1/scripts/tag/site.js","hash":"1cb487b1435925a55eaf957d761bc08254092c36","modified":1740671571305},{"_id":"themes/bamboo1/scripts/tag/titleB.js","hash":"3dde507bf20477cd89e71549be8ddfc4964a76ed","modified":1740671571307},{"_id":"themes/bamboo1/scripts/events/index.js","hash":"514fb117a0c526de85c0338de7f66c23abc58b48","modified":1740671571298},{"_id":"themes/bamboo1/scripts/tag/title.js","hash":"8cfce58425366f805a5f2c88f01b76dca44f91ce","modified":1740671571306},{"_id":"themes/bamboo1/source/medias/logo.png","hash":"d08165f945567a08bd74d36b1241a0b8f1618536","modified":1740671571358},{"_id":"themes/bamboo1/source/css/style.styl","hash":"29848c643d866b6b3ae76bd7d4238c3ab7343618","modified":1740671571332},{"_id":"themes/bamboo1/source/css/animate.min.css","hash":"dc47ce9b8438909921b14e766febdabf3018e3c2","modified":1740671571331},{"_id":"themes/bamboo1/layout/_partial/goTop.ejs","hash":"fa802c5b70f3ac8cf98dad040d05867891d7d4ff","modified":1740671571276},{"_id":"themes/bamboo1/layout/_partial/archive.ejs","hash":"246967d57c31bd873f98603536df79c1f67c96e2","modified":1740671571265},{"_id":"themes/bamboo1/layout/_partial/dark.ejs","hash":"774216ad95828bc349310b4cad02660018ca06e9","modified":1740671571274},{"_id":"themes/bamboo1/layout/_partial/loaded.ejs","hash":"8e29d9924d2ee35c3da7c2f3e27652112252a185","modified":1740671571278},{"_id":"themes/bamboo1/layout/_partial/motto.ejs","hash":"535af08125435651591be103f8e6d98c7222907d","modified":1740671571279},{"_id":"themes/bamboo1/layout/_partial/lantern.ejs","hash":"225044aa82bf305e27a00adf1a8368146e860394","modified":1740671571278},{"_id":"themes/bamboo1/layout/_partial/home_widget.ejs","hash":"0882e6992cfc2fbf1e0b05acbc1463de68f77aa4","modified":1740671571277},{"_id":"themes/bamboo1/layout/_partial/paginator.ejs","hash":"26655627ce5b1eb7050b5e24cc262cf3fc46c400","modified":1740671571280},{"_id":"themes/bamboo1/layout/_partial/notice.ejs","hash":"ed4cad963e1a9b747864bd3ceb76bf9e763c1150","modified":1740671571280},{"_id":"themes/bamboo1/source/js/activate-power-mode.js","hash":"2e14b0f48c55eaec543d96ec0eb2f16e80c20c01","modified":1740671571332},{"_id":"themes/bamboo1/source/js/app.js","hash":"57f824da5f893a0c83c80522114797f09868ccf1","modified":1740671571333},{"_id":"themes/bamboo1/layout/_partial/swiper.ejs","hash":"767c0fcae79bf94fa718ba26ea4ad1fdb610fe10","modified":1740671571295},{"_id":"themes/bamboo1/layout/_partial/topArticle.ejs","hash":"9b321c75dbcbc424b2392e90426127182539a86d","modified":1740671571295},{"_id":"themes/bamboo1/layout/_partial/side.ejs","hash":"17f52c2fa6d771da94644d4fd0983d054a606384","modified":1740671571292},{"_id":"themes/bamboo1/source/js/local_search.js","hash":"131d74198aa41bdb74dc27ef3ed856bc3d752f8d","modified":1740671571342},{"_id":"themes/bamboo1/source/js/goTop.js","hash":"ae548538475ddea2aae8949194935582cc0ae972","modified":1740671571340},{"_id":"themes/bamboo1/source/js/ribbon.min.js","hash":"e6136a6243e04faca95844f47c21b070ade3661a","modified":1740671571345},{"_id":"themes/bamboo1/scripts/events/lib/stellar-tag-utils.js","hash":"315d9e8a8261e760e1001970e09c32a660c969e0","modified":1740671571299},{"_id":"themes/bamboo1/scripts/z-lazyload/lib/process.js","hash":"48a29bdb7026c4a9c8a58190d044140a8a05a64c","modified":1740671571308},{"_id":"themes/bamboo1/source/js/wrapImage.js","hash":"08fa22ecfb8a93bdb96e1063e37367fcc97be29c","modified":1740671571357},{"_id":"themes/bamboo1/source/css/_defines/variable.styl","hash":"ff4fff39224138f8cce1fe82dd8e0ab4077804b3","modified":1740671571308},{"_id":"themes/bamboo1/source/css/_plugins/mathjax.styl","hash":"499f59db53e9c57d99bebe4722156aeca7adb8b7","modified":1740671571321},{"_id":"themes/bamboo1/source/medias/cursor/Horizontal.cur","hash":"c3c5e8485a67b7ab16079a96b53aff7ff52de756","modified":1740671571357},{"_id":"themes/bamboo1/layout/_partial/analytics/baidu-push.ejs","hash":"e7fcc44a10565505e85417ad4416d0d5d5839523","modified":1740671571265},{"_id":"themes/bamboo1/layout/_partial/card/post.ejs","hash":"37fd6f4443620ff3b2963c19fc42bd21891428b0","modified":1740671571267},{"_id":"themes/bamboo1/source/css/_plugins/pjaxanimate.styl","hash":"f8c2d14c041bb87bc7f37d82ac939320e3d110bf","modified":1740671571321},{"_id":"themes/bamboo1/layout/_partial/analytics/google-analytics.ejs","hash":"cb7d5c76508fe8db43dbd4af9a691398fffccadb","modified":1740671571265},{"_id":"themes/bamboo1/layout/_partial/analytics/baidu-analytics.ejs","hash":"589ac42358e8f2e4b22aac4353caa0c2c462a332","modified":1740671571265},{"_id":"themes/bamboo1/source/css/_tag/btn.styl","hash":"dbba1c1f7d374bd7c69c5b9758a61371db334d87","modified":1740671571322},{"_id":"themes/bamboo1/source/css/_tag/circle.styl","hash":"c2adc73eab52952140420c2b5fc8bf134432b695","modified":1740671571322},{"_id":"themes/bamboo1/source/css/_tag/checkbox.styl","hash":"dbc18a5685879493b06016c85993d4522fe48564","modified":1740671571322},{"_id":"themes/bamboo1/source/css/_tag/gallery.styl","hash":"440ae8b7cd2802e068a82e044c35a3273eb98668","modified":1740671571327},{"_id":"themes/bamboo1/source/css/_tag/folding.styl","hash":"7a88c350d302c6a89ab008b6ce2a98ed6f19c007","modified":1740671571327},{"_id":"themes/bamboo1/source/css/_tag/galleryGroup.styl","hash":"ea9f387bc1bc00b4d6d4bd34e2df9046bda3610a","modified":1740671571327},{"_id":"themes/bamboo1/source/css/_tag/inline-label.styl","hash":"1903a258c5829c8370c4eb53fcb60df7f7921f08","modified":1740671571328},{"_id":"themes/bamboo1/source/css/_tag/image.styl","hash":"ce0c9f758f0f0be385c38d65e9bf4fb708cbaf5c","modified":1740671571328},{"_id":"themes/bamboo1/source/css/_tag/link.styl","hash":"7181435bed445840bb61d655451494f83ac4d7e9","modified":1740671571328},{"_id":"themes/bamboo1/source/css/_tag/media.styl","hash":"6727008f95ad9b3146c609a2e890af009472f9e4","modified":1740671571329},{"_id":"themes/bamboo1/source/css/_tag/note.styl","hash":"4487702c5348bf691e329fa8a9bbb6f42808436f","modified":1740671571329},{"_id":"themes/bamboo1/source/css/_tag/progress.styl","hash":"de1e1b08d23f95493ffda2a5375888e9e678891b","modified":1740671571329},{"_id":"themes/bamboo1/source/css/_tag/swiper.styl","hash":"ff02b78ba54cb71eafad141c3e4ef4a9cd9085cd","modified":1740671571330},{"_id":"themes/bamboo1/source/css/_tag/site-card.styl","hash":"ee95cbf6072dbe3ae11e6f73a3b38a9c09e31994","modified":1740671571330},{"_id":"themes/bamboo1/source/css/_tag/span.styl","hash":"bede49e1edf1049d4ea2f3dd0a17787fe084b2d2","modified":1740671571330},{"_id":"themes/bamboo1/source/css/_tag/title.styl","hash":"e17ce9da2937d314c71b459c43de5f01441fe421","modified":1740671571331},{"_id":"themes/bamboo1/source/css/_partial/about.styl","hash":"0673f15fbb3649e221da3b20ba091d03bbd1cc3e","modified":1740671571309},{"_id":"themes/bamboo1/source/css/_tag/tabs.styl","hash":"ca2dac222da40e13aa3b117d55b2da74d7ce9a35","modified":1740671571330},{"_id":"themes/bamboo1/source/css/_partial/archive.styl","hash":"caf5c83ba9897644582e60e29770f1bb7362ad5a","modified":1740671571309},{"_id":"themes/bamboo1/source/css/_tag/talkByJson.styl","hash":"2affd0fe4a640ab92c07198cd4df13bef1ea1575","modified":1740671571331},{"_id":"themes/bamboo1/source/css/_tag/timeline.styl","hash":"ae8e4487a32606127d26dc27c74df592b2175f82","modified":1740671571331},{"_id":"themes/bamboo1/source/css/_partial/base.styl","hash":"e3c5b4f828552be20a6f773f6a8c242d58a2dc23","modified":1740671571309},{"_id":"themes/bamboo1/source/css/_partial/comment.styl","hash":"6d70e8ec7481d11558b430ed3bbf437805b42bc0","modified":1740671571310},{"_id":"themes/bamboo1/source/css/_partial/categories.styl","hash":"ad6d70243be366677293ff88c2eec715d2c29e9e","modified":1740671571310},{"_id":"themes/bamboo1/source/css/_partial/category.styl","hash":"327d6d1f71d782f69fe0b365137b0abc331ca3bb","modified":1740671571310},{"_id":"themes/bamboo1/source/css/_partial/copyRyght.styl","hash":"ed1377ceb86204fa6b6c7430d14a1366d9ca568e","modified":1740671571310},{"_id":"themes/bamboo1/source/css/_partial/danmu.styl","hash":"8aaa764bb2b1c6a49c2f6c9ee868da24a0359669","modified":1740671571311},{"_id":"themes/bamboo1/source/css/_partial/custom.styl","hash":"badd12c63cb9bb5f38c829f00be2509fb546e2cd","modified":1740671571311},{"_id":"themes/bamboo1/source/css/_partial/donate.styl","hash":"a880996ca61f96ba1280d581a132deb924c4ff62","modified":1740671571312},{"_id":"themes/bamboo1/source/css/_partial/drawer.styl","hash":"0498b0cf2819b681eeeec35193e491d1d039302d","modified":1740671571312},{"_id":"themes/bamboo1/source/css/_partial/dark.styl","hash":"28d5269fae1cbaec4f40c21daa0378c098c7d801","modified":1740671571311},{"_id":"themes/bamboo1/source/css/_partial/footer.styl","hash":"598d193754645b22a0f1406303c1df66d95ffd9d","modified":1740671571312},{"_id":"themes/bamboo1/source/css/_partial/goTop.styl","hash":"08c3dc03570ca3738f18b99ebe95c79ec3d0ce0a","modified":1740671571313},{"_id":"themes/bamboo1/source/css/_partial/friends.styl","hash":"f7018f99210ccab74b2d315a55ba9c4350a12fc9","modified":1740671571313},{"_id":"themes/bamboo1/source/css/_partial/header.styl","hash":"db725d2648fc740aa59360502628e6de959504a6","modified":1740671571313},{"_id":"themes/bamboo1/source/css/_partial/notice.styl","hash":"8fd57b791e518c14e88c36510e1132c10288b86b","modified":1740671571314},{"_id":"themes/bamboo1/source/css/_partial/motto.styl","hash":"cb484d25bc6f0bcda4cadffb5f1cdbe5df93919e","modified":1740671571314},{"_id":"themes/bamboo1/source/css/_partial/highlight.styl","hash":"55fc39472aba296434fab0ffdc6be5684f01778a","modified":1740671571313},{"_id":"themes/bamboo1/source/css/_partial/lantern.styl","hash":"04acde311d7b9f7a732340626dbe677814ab502f","modified":1740671571314},{"_id":"themes/bamboo1/source/css/_partial/home.styl","hash":"0bd1214d90fcf7ae020ee0673da4a9fd7c225274","modified":1740671571314},{"_id":"themes/bamboo1/source/css/_partial/pace.styl","hash":"b666b9079262d2dcc2a7b6023f97f79c8535db0e","modified":1740671571314},{"_id":"themes/bamboo1/source/css/_partial/post-detail-header.styl","hash":"b316f4bcb9964bbfa4f6829e550578aa27d509a8","modified":1740671571315},{"_id":"themes/bamboo1/source/css/_partial/paginator.styl","hash":"df1fd26976fd5be8418cd49a5c65ec651a680496","modified":1740671571315},{"_id":"themes/bamboo1/source/css/_partial/post-nav.styl","hash":"a7c7b33ad813885af485815d8c787c0fb3b6c8c8","modified":1740671571315},{"_id":"themes/bamboo1/source/css/_partial/post.styl","hash":"32655204cccbf9861097efad65c1cf69dac11fd5","modified":1740671571316},{"_id":"themes/bamboo1/source/css/_partial/posts.styl","hash":"9464726d962229149d38841c087f6207cd8c2adc","modified":1740671571316},{"_id":"themes/bamboo1/source/css/_partial/side.styl","hash":"2999120872bff96f84381f76ad0a65015bd3f549","modified":1740671571319},{"_id":"themes/bamboo1/source/css/_partial/search.styl","hash":"2f67103cd8cb9b92d1ca4f334e41c195e01c3ce3","modified":1740671571319},{"_id":"themes/bamboo1/source/css/_partial/tag.styl","hash":"f2b741dddc033f1989d3c4710f339ee122900e58","modified":1740671571320},{"_id":"themes/bamboo1/layout/_partial/footer/busuanzi.ejs","hash":"bc3d2f6abc95b329dfe0186fa0364c48aab3772e","modified":1740671571274},{"_id":"themes/bamboo1/source/css/_partial/transition.styl","hash":"809b40b7214cda6691b2f22ae827cbdbfaf8c303","modified":1740671571321},{"_id":"themes/bamboo1/source/css/_partial/tags.styl","hash":"6fc3915d4a0f5d551b23f2281df868e0399bc13d","modified":1740671571320},{"_id":"themes/bamboo1/layout/_partial/footer/fish.ejs","hash":"c90e55153d7e83f5c054dd98add7dd9bbb6e095f","modified":1740671571275},{"_id":"themes/bamboo1/source/css/_partial/topArticle.styl","hash":"910e24383b1009e27c0ebf26a5958051451da47c","modified":1740671571320},{"_id":"themes/bamboo1/layout/_partial/footer/footer.ejs","hash":"3ed9b13b849c5a54dc667b9137beaa769d382980","modified":1740671571275},{"_id":"themes/bamboo1/layout/_partial/head/drawer.ejs","hash":"1f78c957b472a14c13301ea6a7ec59d5ecc777e6","modified":1740671571276},{"_id":"themes/bamboo1/layout/_partial/math/mathjax.ejs","hash":"dc9a1270d34448606e87e52a3b003a89f4f5b3aa","modified":1740671571278},{"_id":"themes/bamboo1/layout/_partial/head/head.ejs","hash":"aea1a32f47edda23b22b4e3444c13cedb4f3e5a6","modified":1740671571276},{"_id":"themes/bamboo1/layout/_partial/math/mermaid.ejs","hash":"2c6894abc259167170e274728467c7c7aa1ef8e5","modified":1740671571279},{"_id":"themes/bamboo1/layout/_partial/head/search.ejs","hash":"7cbf73c577874de0b6cc89180680b1e19c5e8348","modified":1740671571277},{"_id":"themes/bamboo1/layout/_partial/head/header.ejs","hash":"0583e814ef8af4cce35382a2b2634488e432de75","modified":1740671571277},{"_id":"themes/bamboo1/layout/_partial/meta/aplayer.ejs","hash":"33aeb95a90093ce66816676f9ac63f1f02d27852","modified":1740671571279},{"_id":"themes/bamboo1/layout/_partial/pjax/index.ejs","hash":"6ac774c816f9dcb7099612e2ef13bb0e7893476c","modified":1740671571281},{"_id":"themes/bamboo1/layout/_partial/preLoader/loader_2.ejs","hash":"d1df3a9050bae7cb7cf17d44359292999a1d0664","modified":1740671571284},{"_id":"themes/bamboo1/layout/_partial/pjax/animate.ejs","hash":"8a60b1b8ec8340f712ed6539bacba62d137232cc","modified":1740671571280},{"_id":"themes/bamboo1/layout/_partial/preLoader/loader_3.ejs","hash":"1ef0876d3a2f3ae43eccdf3c88dbd9c642d22d62","modified":1740671571284},{"_id":"themes/bamboo1/layout/_partial/preLoader/loader_4.ejs","hash":"458f5c179670b029178c037f1feb99f566b9408e","modified":1740671571284},{"_id":"themes/bamboo1/layout/_partial/preLoader/loader_1.ejs","hash":"e82a5a888ba376080b21d4e39ac9b4fff2623d24","modified":1740671571283},{"_id":"themes/bamboo1/layout/_partial/preLoader/loader_7.ejs","hash":"3b6d1da24786682b5d248f5e59f8f48510a55d4d","modified":1740671571285},{"_id":"themes/bamboo1/layout/_partial/post/categories.ejs","hash":"15f33099ef5f653b9ceb3e27f089b36bff50cc4f","modified":1740671571281},{"_id":"themes/bamboo1/layout/_partial/preLoader/loader_5.ejs","hash":"7db609c64eeabb8b68771097663d1ff427667e14","modified":1740671571284},{"_id":"themes/bamboo1/layout/_partial/post/bgSwiper.ejs","hash":"77ade59920c57fda25c2be421b77adf7b0c943d9","modified":1740671571281},{"_id":"themes/bamboo1/layout/_partial/preLoader/loader_8.ejs","hash":"2ab0a97498e0f35516c1db65949afd831a2800da","modified":1740671571285},{"_id":"themes/bamboo1/layout/_partial/preLoader/loader_6.ejs","hash":"7ce6bd6bf765d23acb30f1a054e56f265099a4dd","modified":1740671571285},{"_id":"themes/bamboo1/layout/_partial/post/copyright.ejs","hash":"fd3af5c33895f907b1e5daa56d8d7266549dd019","modified":1740671571282},{"_id":"themes/bamboo1/layout/_partial/post/donate.ejs","hash":"b54c1be4bf9a4b28a8c39d2835e8b4d9ee1e56ff","modified":1740671571282},{"_id":"themes/bamboo1/layout/_partial/post/share.ejs","hash":"c414ae139680a2e2a50e776de4e137265fd0178d","modified":1740671571283},{"_id":"themes/bamboo1/layout/_partial/post/post-detail-header.ejs","hash":"34ded5a37233689e991bb7292dc785d626430106","modified":1740671571282},{"_id":"themes/bamboo1/source/js/aplayer/APlayer@1.10.1.min.css","hash":"7f4f8913f2d46ade2def5134e2cc8684a4b87939","modified":1740671571333},{"_id":"themes/bamboo1/layout/_partial/post/tags.ejs","hash":"f92692427de2caa48033f975f193f9a8e4b02613","modified":1740671571283},{"_id":"themes/bamboo1/layout/_partial/post/post-nav.ejs","hash":"1e92a0ca46977f94ce27540ceb09ce05bc75accd","modified":1740671571282},{"_id":"themes/bamboo1/layout/_partial/scripts/copy.ejs","hash":"fda84bf47a5e7c5692f682a45f8fdcfab90900b0","modified":1740671571287},{"_id":"themes/bamboo1/layout/_partial/post/comment.ejs","hash":"364875140582c1b702e01b63791f97011ca24b40","modified":1740671571282},{"_id":"themes/bamboo1/layout/_partial/scripts/danmu.ejs","hash":"ca20ae64fbd2527f8b54fc8618a3a0502728420c","modified":1740671571287},{"_id":"themes/bamboo1/layout/_partial/post/prismjs.ejs","hash":"198a472f69517829caf2f2cb542d32996a8fed74","modified":1740671571282},{"_id":"themes/bamboo1/layout/_partial/scripts/dark.ejs","hash":"25558a06394cb251a140b5a8998069f9f776f67e","modified":1740671571288},{"_id":"themes/bamboo1/layout/_partial/scripts/getPhotoOnline.ejs","hash":"bd17b91d841055cef0fe7e4a70736f57a55e030b","modified":1740671571288},{"_id":"themes/bamboo1/layout/_partial/scripts/getSiteOnline.ejs","hash":"7735a6b702c32447e4667cbc7cab86cd28d5badf","modified":1740671571288},{"_id":"themes/bamboo1/layout/_partial/scripts/getTalkOnline.ejs","hash":"5e5806d276dcfad3702d460d43c4ee826d9ce9ea","modified":1740671571289},{"_id":"themes/bamboo1/layout/_partial/scripts/cursor_effect.ejs","hash":"0877a20709f046f693e4536fe70354ad1b67f195","modified":1740671571287},{"_id":"themes/bamboo1/layout/_partial/scripts/falling.ejs","hash":"79d1c7cc0de290ac35e41312ef62fc4bf04be766","modified":1740671571288},{"_id":"themes/bamboo1/layout/_partial/scripts/head.ejs","hash":"4536885880315fb90efd75935c133051a729d45c","modified":1740671571289},{"_id":"themes/bamboo1/layout/_partial/scripts/inputEffects.ejs","hash":"765c69436e021412dd8bbb852ea2403c97fc6adf","modified":1740671571290},{"_id":"themes/bamboo1/layout/_partial/scripts/global.ejs","hash":"16851de5516d2908787ed902b778c8f03f9ae63b","modified":1740671571289},{"_id":"themes/bamboo1/layout/_partial/scripts/issues.ejs","hash":"cf5436f10fb9a2fb7238a1c528a5ed64a2345840","modified":1740671571290},{"_id":"themes/bamboo1/layout/_partial/scripts/index.ejs","hash":"00a70fce835bc65801fd407236f72315e6df5934","modified":1740671571289},{"_id":"themes/bamboo1/layout/_partial/scripts/scrollreveal.ejs","hash":"4aba6d5b506b3a8fc7d84abe0d42875e0107d64e","modified":1740671571291},{"_id":"themes/bamboo1/layout/_partial/scripts/typed.ejs","hash":"262725f946bb3ae8957b8e3d50c1a7cd564f8866","modified":1740671571292},{"_id":"themes/bamboo1/layout/_partial/scripts/toc.ejs","hash":"af49e146385d28f5cbdaa6d7a5167fbbde25a917","modified":1740671571291},{"_id":"themes/bamboo1/layout/_partial/scripts/setHeader.ejs","hash":"c082c910282c3c96465b0812222874fbe87c58cd","modified":1740671571291},{"_id":"themes/bamboo1/layout/_partial/scripts/swiperTag.ejs","hash":"020d6cd78cd9ace5477a79e57e958a2f5a6d43f3","modified":1740671571291},{"_id":"themes/bamboo1/layout/_partial/side/sideHeader.ejs","hash":"3985bd41e1310500d44d42b02863d4b16815154b","modified":1740671571292},{"_id":"themes/bamboo1/layout/_partial/scripts/lazyload.ejs","hash":"b7e8071598a8dc70406aba8da949c5d6f5403e47","modified":1740671571290},{"_id":"themes/bamboo1/layout/_partial/side/side_archives.ejs","hash":"c82b7c669aaaa2b9575cf6daf6d0a133b64acfd0","modified":1740671571293},{"_id":"themes/bamboo1/layout/_partial/side/side_blogger.ejs","hash":"a2c637abf7943b273edfb69d0d8e0dc812c84127","modified":1740671571293},{"_id":"themes/bamboo1/layout/_partial/side/side_category.ejs","hash":"dccd4537a94cf6e210803d6ab2789e6cd57d755e","modified":1740671571293},{"_id":"themes/bamboo1/layout/_partial/side/side_recent_post.ejs","hash":"7fe61d14865e97988ff5d42047abb4a4ee8af7f0","modified":1740671571293},{"_id":"themes/bamboo1/source/js/bubble/bubble.js","hash":"57f116efe2418a389913a46909e018fa4c9b9e84","modified":1740671571334},{"_id":"themes/bamboo1/layout/_partial/side/side_webinfo.ejs","hash":"1efe51b2685b7c4ad2ab42849c5ebe59e2d20def","modified":1740671571294},{"_id":"themes/bamboo1/source/js/bubble/homeBubble.js","hash":"8475e7ed2004b9791b3f7ad4162b7a2b89467874","modified":1740671571334},{"_id":"themes/bamboo1/layout/_partial/side/widget_library_sticky.ejs","hash":"e3929f7edf85900e7becc71e0cbe14da2333f621","modified":1740671571294},{"_id":"themes/bamboo1/source/js/danmu/barrager.css","hash":"9de985f20d314f3f1182f30d1b0666e5eb9ca9b5","modified":1740671571337},{"_id":"themes/bamboo1/source/js/danmu/jquery.barrager.js","hash":"72ec0d8bbd0811973152fcbb316b0dd839ffb8f3","modified":1740671571337},{"_id":"themes/bamboo1/source/js/clipboard/clipboard.min.js","hash":"76fd19c15b1d0a2d7afc7b66ca5f80c9061aabe2","modified":1740671571335},{"_id":"themes/bamboo1/source/js/danmu/close.png","hash":"2c3ed4345f91dc1b74a57b6dcd1e1efa9e279dbb","modified":1740671571337},{"_id":"themes/bamboo1/source/js/cursor/clicklove.js","hash":"9e8e79d69ad8338761272f86fe5cad0ad5e503cc","modified":1740671571335},{"_id":"themes/bamboo1/source/js/cursor/text.js","hash":"7dd898cb00b46ceda065c92f2ac092c4ef41b4e4","modified":1740671571336},{"_id":"themes/bamboo1/source/js/cursor/explosion.min.js","hash":"ed2d0a5ad306a2745b7c8180b69e36b78d4b0698","modified":1740671571336},{"_id":"themes/bamboo1/source/js/cursor/fireworks.js","hash":"86ad9484e40268952b5e32c240fb04d0268f86dd","modified":1740671571336},{"_id":"themes/bamboo1/source/js/falling/sakura.js","hash":"b1566483a7d0deda2dd35db3d5a46f13aa5f1a86","modified":1740671571338},{"_id":"themes/bamboo1/source/js/falling/snow.js","hash":"99222d79ff36b05200b3ff7f54f8209d8f0a364b","modified":1740671571338},{"_id":"themes/bamboo1/source/js/getPhotoOnline/index.js","hash":"3b6354c11105aba544b08ded11295d83219d59ec","modified":1740671571339},{"_id":"themes/bamboo1/source/js/getSiteOnline/index.js","hash":"733f75aff00e0a62013089cb3e869878d6fcc535","modified":1740671571339},{"_id":"themes/bamboo1/source/js/issues/index.js","hash":"f02538ab609541489396a682879ce854519487ca","modified":1740671571340},{"_id":"themes/bamboo1/source/js/getTalkOnline/index.js","hash":"ba714c7ffe4abde553d0c54ce5d528453f279c06","modified":1740671571340},{"_id":"themes/bamboo1/layout/_partial/side/side_toc.ejs","hash":"670c9c8bbc0f8cadfaa1e5caca73fd641d2fe831","modified":1740671571294},{"_id":"themes/bamboo1/layout/_partial/side/side_tagcloud.ejs","hash":"7e716ce939cb8dd4004896adf41559d57bcfff0e","modified":1740671571293},{"_id":"themes/bamboo1/source/js/pjax@0.2.8/index.js","hash":"efb9166635c18f09f2c7604a8b15d6ac8aae4870","modified":1740671571342},{"_id":"themes/bamboo1/source/js/prism/prism-okaidia.min.css","hash":"50be6cc15d883ff3fa5d0885fed47241695a986c","modified":1740671571344},{"_id":"themes/bamboo1/source/js/prism/prism-funky.min.css","hash":"0220f68ccda78c2b5d1109e58f3879674c93b587","modified":1740671571344},{"_id":"themes/bamboo1/source/js/prism/prism-coy.min.css","hash":"fe1246de39c25eaa7ad1b0c997ee530dbdd39ad8","modified":1740671571343},{"_id":"themes/bamboo1/source/js/shareJs/font.css","hash":"f6407017418989fb0ced993509543fb07c6b0b33","modified":1740671571346},{"_id":"themes/bamboo1/source/js/prism/prism-dark.min.css","hash":"a3f604a19e9a46f83a2fde49dfb45782748957ca","modified":1740671571343},{"_id":"themes/bamboo1/source/js/prism/prism-solarizedlight.min.css","hash":"927b757cd8030d12953b5c0fa6eed5de15dda8ad","modified":1740671571344},{"_id":"themes/bamboo1/source/js/prism/prism.min.css","hash":"aa405e2bcb571595c822a80f5482454c1536fa52","modified":1740671571345},{"_id":"themes/bamboo1/source/js/prism/prism-line-numbers.css","hash":"c42732535ac61ac59a4356af3d89186a3071edf1","modified":1740671571344},{"_id":"themes/bamboo1/source/js/shareJs/share.min.css","hash":"9bd0cd6c81b60e10085cdda6aa724f147ee76599","modified":1740671571348},{"_id":"themes/bamboo1/source/js/prism/prism-twilight.min.css","hash":"ff4a6e3c4f1cb9bb59ec061656eacb750d238c15","modified":1740671571345},{"_id":"themes/bamboo1/source/js/tocbot/tocbot.css","hash":"45e469dffa7b9ebc03f99fd09fb97274cdc5e9b4","modified":1740671571350},{"_id":"themes/bamboo1/source/js/prism/prism-tomorrow.min.css","hash":"7b4247bc4d3b719afe5957779d0e5c8fb716c8ea","modified":1740671571345},{"_id":"themes/bamboo1/source/js/shareJs/social-share.min.js","hash":"efdfa6b695ac6f0dd04cd8153d3e3a1a1edd90c2","modified":1740671571348},{"_id":"themes/bamboo1/source/js/swiper/swiper.animate1.0.3.min.js","hash":"6a8d6aa926e552a563356c36d52d1e0e0c83521e","modified":1740671571349},{"_id":"themes/bamboo1/source/js/swiper/swiper@5.4.1.min.css","hash":"fd618d2bdf929821d9fa70ae377b840ffc47d756","modified":1740671571350},{"_id":"themes/bamboo1/source/js/utils/index.js","hash":"fcea598ed253006d79f78d34cc36fdc6649639f3","modified":1740671571351},{"_id":"themes/bamboo1/source/js/tocbot/tocbot.min.js","hash":"bc45d3586a21f7e364cd6efe58844932c00cf11c","modified":1740671571351},{"_id":"themes/bamboo1/source/js/vue-typed-js/index.css","hash":"b9dac4cfc5f0dc8854393d670b525fb63092fd38","modified":1740671571353},{"_id":"themes/bamboo1/source/js/vue-seamless-scroll/index.js","hash":"f2aaf3f9b1ab7362f7cc158e5360cb1d62a57172","modified":1740671571353},{"_id":"themes/bamboo1/source/js/vue-typed-js/index.js","hash":"c8e6f4510eb5fe55015401510ce03f5307556b1a","modified":1740671571354},{"_id":"themes/bamboo1/source/css/_partial/preLoader/loader_1.styl","hash":"ac20f1e2c9337396d590ceae03f9845b382ad534","modified":1740671571316},{"_id":"themes/bamboo1/source/js/swiper/vue-awesome-swiper.js","hash":"e6f36537ed091a6b69945b1acf49e426426f1cf0","modified":1740671571350},{"_id":"themes/bamboo1/source/css/_partial/preLoader/loader_4.styl","hash":"8dacae32f9ed4460546a75d313388b1b2497e097","modified":1740671571318},{"_id":"themes/bamboo1/source/css/_partial/preLoader/loader_6.styl","hash":"8a33ff2ed45cb2539743fd12b8ea4fc0d3873b98","modified":1740671571318},{"_id":"themes/bamboo1/source/css/_partial/preLoader/loader_7.styl","hash":"955a96e5829684f0021ef2ad6bdf42b928433ad1","modified":1740671571319},{"_id":"themes/bamboo1/source/css/_partial/preLoader/loader_5.styl","hash":"7e63625a1fc42f0403c3f933b9f642362f44ff46","modified":1740671571318},{"_id":"themes/bamboo1/source/css/_partial/preLoader/loader_2.styl","hash":"112c765730edc8d143b503b8407046ab8deb3835","modified":1740671571317},{"_id":"themes/bamboo1/source/css/_partial/preLoader/loader_8.styl","hash":"1826bd092b9ea3a028d41cacc993927899406deb","modified":1740671571319},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_10.styl","hash":"01bcf630c126f7fa273892245e6e6c59b654bf56","modified":1740671571323},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_1.styl","hash":"f7fc1257c6b402b1ddec85d45ac8e665580dc14d","modified":1740671571322},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_11.styl","hash":"f7b6a4ab283029f649a0ae2732fa6e7079ecc435","modified":1740671571323},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_14.styl","hash":"0ad1c7d9faaf46bc201d8c7c9b34e39ae7efec48","modified":1740671571324},{"_id":"themes/bamboo1/source/css/_partial/preLoader/loader_3.styl","hash":"be27e1a9f2c0d78ab31f7a6b59341dc8c4393f88","modified":1740671571318},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_13.styl","hash":"a5015270d9d79fa2f4ed246939d48bf4c9c7f7f6","modified":1740671571324},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_3.styl","hash":"083991d97f004f1f657c7a7649bd7b319dee652e","modified":1740671571325},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_5.styl","hash":"6fea986bd4c37188ce7da86b0839749ac188bd02","modified":1740671571326},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_4.styl","hash":"ea0a0fbfb605d7d0592a06bb94e38f386830aa24","modified":1740671571325},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_2.styl","hash":"dbf766a7086bfb35a7fabc635edeb67a32d1828f","modified":1740671571325},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_12.styl","hash":"27792c767fa345b0dbe735a681c87cf790e19a8b","modified":1740671571324},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_6.styl","hash":"7f6b7d34933921dbabee0937053cb288fcad9647","modified":1740671571326},{"_id":"themes/bamboo1/layout/_partial/comment/beaudar/script.ejs","hash":"58b914569fbc9d5bf706674c1ea4d7a83b5540d1","modified":1740671571268},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_15.styl","hash":"fd9b1e87dfaed5db7d9d7b9dc272a5669056c278","modified":1740671571324},{"_id":"themes/bamboo1/layout/_partial/comment/changyan/layout.ejs","hash":"46192143a90303d8924b3d07d28df116bc833894","modified":1740671571268},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_9.styl","hash":"6cdaa72cab01a2ca483eb7092372bcfcb2dc9b25","modified":1740671571327},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_8.styl","hash":"4ce4323bc8a183533bbb1ab9ea2bf946350e5713","modified":1740671571326},{"_id":"themes/bamboo1/layout/_partial/comment/beaudar/layout.ejs","hash":"52b9a55b6e83bd9a10fc3f66a18be98e3965475b","modified":1740671571268},{"_id":"themes/bamboo1/layout/_partial/comment/giscus/layout.ejs","hash":"a17970930b1064def6f5ad5f67a1afd3ed3169a0","modified":1740671571269},{"_id":"themes/bamboo1/source/css/_tag/coolBtn/coolBtn_7.styl","hash":"d75280def0358da644945744da22f6a5f2abd745","modified":1740671571326},{"_id":"themes/bamboo1/layout/_partial/comment/gitalk/layout.ejs","hash":"8a4c57646ee0d4a4e94d568708fb85a8f9ac97e7","modified":1740671571270},{"_id":"themes/bamboo1/layout/_partial/comment/changyan/script.ejs","hash":"c357b9052564e12754cf21a1cb1debd3bdfe1eac","modified":1740671571269},{"_id":"themes/bamboo1/layout/_partial/comment/giscus/script.ejs","hash":"69ee0d2750ff779f754c8ffe6a5c44960420e2b7","modified":1740671571269},{"_id":"themes/bamboo1/layout/_partial/comment/gitalk/script.ejs","hash":"733947cad238d89c5a5694ecf19a83b1d5648ab9","modified":1740671571270},{"_id":"themes/bamboo1/layout/_partial/comment/gitment/layout.ejs","hash":"353820d6d6aade09cd21b31585afa20485008083","modified":1740671571270},{"_id":"themes/bamboo1/layout/_partial/comment/livere/layout.ejs","hash":"f88b32604056721e658c25f775866a1519e714f2","modified":1740671571271},{"_id":"themes/bamboo1/layout/_partial/comment/livere/script.ejs","hash":"f545bc19b874f684bc4369ef1c6bfc4427b13b6b","modified":1740671571271},{"_id":"themes/bamboo1/layout/_partial/comment/gitment/script.ejs","hash":"1e02cf43a347a612796aa188446605e213e0dd51","modified":1740671571271},{"_id":"themes/bamboo1/layout/_partial/comment/utterance/layout.ejs","hash":"eab867c580f6184d068d5fcc545a763a2919eb16","modified":1740671571272},{"_id":"themes/bamboo1/layout/_partial/comment/twikoo/layout.ejs","hash":"bdfd72b519f3bd8f3f78fd631a8326cbd0b20a98","modified":1740671571272},{"_id":"themes/bamboo1/layout/_partial/comment/twikoo/script.ejs","hash":"c09ef940a9d99d4e567e4891644241dd0ee40135","modified":1740671571272},{"_id":"themes/bamboo1/layout/_partial/comment/utterance/script.ejs","hash":"b8206894169b3e5ad1d38b448db5b9f1e4717987","modified":1740671571273},{"_id":"themes/bamboo1/layout/_partial/comment/valine/layout.ejs","hash":"453fa08c310cef7d00a12bb7cf448aef34c7728a","modified":1740671571273},{"_id":"themes/bamboo1/layout/_partial/comment/waline/layout.ejs","hash":"a82f1c7819cadca142b7f3436957ddce5adf7fa0","modified":1740671571274},{"_id":"themes/bamboo1/layout/_partial/comment/valine/script.ejs","hash":"c39459b0fb46bb1eb49823cc62375f04d3b4a48e","modified":1740671571273},{"_id":"source/img/transformer-notes/pic-1.png","hash":"f6d66e79b8bade7a2b5366ce7fd9a7db04707af1","modified":1741692757020},{"_id":"source/img/transformer-notes/pic-4.png","hash":"ef21731e5c6297dfad18bb907e6e399c3d1070f2","modified":1754709907530},{"_id":"themes/bamboo1/layout/_partial/comment/waline/script.ejs","hash":"ddfc35b05d22d2ad0f5b41444ed47793546f4b9d","modified":1740671571274},{"_id":"themes/bamboo1/source/js/shareJs/fonts/iconfont.svg","hash":"337b4f156f6d8f4beb32c32a3db46fef361cff74","modified":1740671571347},{"_id":"themes/bamboo1/source/js/shareJs/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1740671571346},{"_id":"source/_posts/img/proteinMPNN/p1.png","hash":"e2cac40872bc88771067c039f67baa4c6d28d64a","modified":1761548612536},{"_id":"source/_posts/img/all-in-rag/p2.png","hash":"a7fdfe861c3bca2857dad69d9b076d1ab3231878","modified":1764057349414},{"_id":"source/_posts/img/venusREM/p2.png","hash":"095ab3be1daa0dc443dca1c2a4529ba769cdcfbe","modified":1761291421641},{"_id":"themes/bamboo1/source/js/shareJs/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1740671571347},{"_id":"themes/bamboo1/source/js/shareJs/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1740671571347},{"_id":"source/_posts/img/transformer-notes/pic-1.png","hash":"f6d66e79b8bade7a2b5366ce7fd9a7db04707af1","modified":1741692757020},{"_id":"source/_posts/img/transformer-notes/pic-4.png","hash":"ef21731e5c6297dfad18bb907e6e399c3d1070f2","modified":1754709907530},{"_id":"source/_posts/img/machine-learning-notes/pic-13.png","hash":"59de2b8eb3b6db9d4c564febdf7e3709130787a7","modified":1739453444035},{"_id":"source/_posts/img/machine-learning-notes/pic-15.png","hash":"9f85209eae05833c0d6376d401f45e051023c4d2","modified":1739456947233},{"_id":"source/_posts/img/machine-learning-notes/pic-18.png","hash":"1ad628440b4b5349cc6667348a33c9c97a012eff","modified":1739458743567},{"_id":"source/_posts/img/machine-learning-notes/pic-19.png","hash":"7598a0992232dac91613e65e9dc4fec58dd1c56c","modified":1739459181242},{"_id":"source/_posts/img/machine-learning-notes/pic-21.png","hash":"a8a3382060eab1be1c5a95e90fe7752721dbe801","modified":1739535680777},{"_id":"source/_posts/img/machine-learning-notes/pic-24.png","hash":"40e00390e74ff9cf3aba708c1e9bec5724c396ca","modified":1739542099791},{"_id":"source/_posts/img/machine-learning-notes/pic-29.png","hash":"b5bab6fddb0ad1c79c6d42362ac8a3a0319e6351","modified":1739624989401},{"_id":"source/_posts/img/machine-learning-notes/pic-34.png","hash":"d25dcd2ed03f72135c38a4901e961d5ddda92778","modified":1739947190822},{"_id":"source/_posts/img/machine-learning-notes/pic-33.png","hash":"278a77be72fa2c34cad1ae3ac6d0a492665c78a1","modified":1739946176241},{"_id":"source/_posts/img/machine-learning-notes/pic-7.jpg","hash":"53a93542b958da7e52fe83aba886eb722dd26155","modified":1738910656446},{"_id":"source/_posts/img/machine-learning-notes/pic-31.png","hash":"a15f390cb899248c679527434ec08a5e4b06d6f2","modified":1739888230194},{"_id":"source/img/venusREM/p3.png","hash":"b561f8fea0c38f9033ac8f6f1533dd8a07232be6","modified":1761292384316},{"_id":"source/img/prot2text/fig3.png","hash":"911f6a3786d106acf7c47ac97541562117528b8c","modified":1759133669091},{"_id":"source/img/machine-learning-notes/pic-11.png","hash":"79e3c86dc4e6558bb5449ef6da54ed932bdf820a","modified":1739449524427},{"_id":"source/img/machine-learning-notes/pic-23.png","hash":"5271104e246a1efa46822cf4b653a6dff3406865","modified":1739541957085},{"_id":"source/img/machine-learning-notes/pic-2.png","hash":"51fbf8685ee1e3285b779d04995ba391196612bd","modified":1737897790662},{"_id":"source/img/machine-learning-notes/pic-28.png","hash":"a1ac56f65a0f24d92dfac28adb18004ae483f468","modified":1739624877518},{"_id":"source/img/machine-learning-notes/pic-30.png","hash":"ed3b3c733868949e51401c26cc8c5777ed3d3abf","modified":1739800893470},{"_id":"source/img/machine-learning-notes/pic-5.png","hash":"f26891470930c14cd618f4fd5d1a702aabe5c9cb","modified":1738564587991},{"_id":"themes/bamboo1/source/js/jquery3.5.1.js","hash":"29fa5ad995e9ec866ece1d3d0b698fc556580eee","modified":1740671571341},{"_id":"source/img/transformer-notes/pic-3.png","hash":"3e91798520e0c24d7c03b69b2040cbec73e703a3","modified":1754709361305},{"_id":"source/_posts/img/venusREM/p3.png","hash":"b561f8fea0c38f9033ac8f6f1533dd8a07232be6","modified":1761292384316},{"_id":"source/_posts/img/prot2text/fig3.png","hash":"911f6a3786d106acf7c47ac97541562117528b8c","modified":1759133669091},{"_id":"source/_posts/img/transformer-notes/pic-3.png","hash":"3e91798520e0c24d7c03b69b2040cbec73e703a3","modified":1754709361305},{"_id":"source/_posts/img/machine-learning-notes/pic-11.png","hash":"79e3c86dc4e6558bb5449ef6da54ed932bdf820a","modified":1739449524427},{"_id":"source/_posts/img/machine-learning-notes/pic-2.png","hash":"51fbf8685ee1e3285b779d04995ba391196612bd","modified":1737897790662},{"_id":"source/_posts/img/machine-learning-notes/pic-23.png","hash":"5271104e246a1efa46822cf4b653a6dff3406865","modified":1739541957085},{"_id":"source/_posts/img/machine-learning-notes/pic-28.png","hash":"a1ac56f65a0f24d92dfac28adb18004ae483f468","modified":1739624877518},{"_id":"source/_posts/img/machine-learning-notes/pic-30.png","hash":"ed3b3c733868949e51401c26cc8c5777ed3d3abf","modified":1739800893470},{"_id":"source/_posts/img/machine-learning-notes/pic-5.png","hash":"f26891470930c14cd618f4fd5d1a702aabe5c9cb","modified":1738564587991},{"_id":"source/img/all-in-rag/p1.png","hash":"66afea63665a42f70316fdddfc2ed208cd8c6007","modified":1764056274906},{"_id":"source/img/machine-learning-notes/pic-10.png","hash":"3518538e91cc7fe18a169e78cbc072f68919e9d4","modified":1739023761909},{"_id":"source/img/machine-learning-notes/pic-14.png","hash":"c2edd1d1a4dcacf66c43b53b8e232b7ce944af4d","modified":1739455810944},{"_id":"source/img/machine-learning-notes/pic-12.png","hash":"8a3f3196091822d6483ddee45b713833baa66540","modified":1739453338824},{"_id":"source/img/machine-learning-notes/pic-25.png","hash":"10b8539b73478749b91175ccff0001faafb34182","modified":1739543974084},{"_id":"source/img/machine-learning-notes/pic-38.png","hash":"556b9b932485b4937b1c0dc77ee6d9a24fb25e07","modified":1740307931753},{"_id":"themes/bamboo1/source/js/waline/waline.min.js","hash":"3a17de5f24e0437c3c681b15f147ceef3980736f","modified":1740671571356},{"_id":"themes/bamboo1/source/js/valine/index.js","hash":"d520897b1bd3788aacb672b5cd9ff7ab0c81fc80","modified":1740671571352},{"_id":"themes/bamboo1/source/js/swiper/swiper.min.js","hash":"674fa0bd5973cc8124d6a711c725b119c025da0c","modified":1740671571349},{"_id":"source/_posts/img/all-in-rag/p1.png","hash":"66afea63665a42f70316fdddfc2ed208cd8c6007","modified":1764056274906},{"_id":"source/_posts/img/machine-learning-notes/pic-12.png","hash":"8a3f3196091822d6483ddee45b713833baa66540","modified":1739453338824},{"_id":"source/_posts/img/machine-learning-notes/pic-10.png","hash":"3518538e91cc7fe18a169e78cbc072f68919e9d4","modified":1739023761909},{"_id":"source/_posts/img/machine-learning-notes/pic-14.png","hash":"c2edd1d1a4dcacf66c43b53b8e232b7ce944af4d","modified":1739455810944},{"_id":"source/_posts/img/machine-learning-notes/pic-25.png","hash":"10b8539b73478749b91175ccff0001faafb34182","modified":1739543974084},{"_id":"source/_posts/img/machine-learning-notes/pic-38.png","hash":"556b9b932485b4937b1c0dc77ee6d9a24fb25e07","modified":1740307931753},{"_id":"source/img/protrek/fig2.png","hash":"672226c8d01becfb2ca1ea5a7b77dd51d4c9dc3e","modified":1758873551591},{"_id":"source/img/machine-learning-notes/pic-8.png","hash":"e4d47e8c39f6ff05839c194ea682b2cbee16ae2f","modified":1738910330380},{"_id":"source/_posts/img/protrek/fig2.png","hash":"672226c8d01becfb2ca1ea5a7b77dd51d4c9dc3e","modified":1758873551591},{"_id":"source/_posts/img/machine-learning-notes/pic-8.png","hash":"e4d47e8c39f6ff05839c194ea682b2cbee16ae2f","modified":1738910330380},{"_id":"source/img/machine-learning-notes/pic-32.png","hash":"a7f06d079e104b650620d7e152bcb9074d1066e2","modified":1739945847505},{"_id":"source/img/proteinMPNN/p2.png","hash":"b242d7706ed36b6794d5b64be82956cc9e75d2dd","modified":1761549897450},{"_id":"source/_posts/img/proteinMPNN/p2.png","hash":"b242d7706ed36b6794d5b64be82956cc9e75d2dd","modified":1761549897450},{"_id":"source/_posts/img/machine-learning-notes/pic-32.png","hash":"a7f06d079e104b650620d7e152bcb9074d1066e2","modified":1739945847505},{"_id":"source/img/machine-learning-notes/pic-9.png","hash":"6a99b1212556fc6513864610da7f9a379eb45b28","modified":1737530573994},{"_id":"themes/bamboo1/source/js/vue2.6.11.js","hash":"1159f02f3f7191a5cf4c109734d0268173fab96d","modified":1740671571356},{"_id":"source/_posts/img/machine-learning-notes/pic-9.png","hash":"6a99b1212556fc6513864610da7f9a379eb45b28","modified":1737530573994},{"_id":"source/img/venusREM/p4.png","hash":"bb43bf2bb610906d4f8e8956785232113eb10fb5","modified":1761292406363},{"_id":"source/_posts/img/venusREM/p4.png","hash":"bb43bf2bb610906d4f8e8956785232113eb10fb5","modified":1761292406363},{"_id":"source/img/protrek/fig1.png","hash":"b77336dc1bea62ec3856bd2cb310d8755410dfc7","modified":1758873394835},{"_id":"source/_posts/img/protrek/fig1.png","hash":"b77336dc1bea62ec3856bd2cb310d8755410dfc7","modified":1758873394835},{"_id":"source/img/venusREM/p1.png","hash":"dcfed9e31ed0984b770d7ec15f56b6aca72d4f08","modified":1761226355278},{"_id":"source/img/proteinMPNN/p3.png","hash":"fc47775b73fa2e84d9de69d7a0b903e9381b85cf","modified":1761550586251},{"_id":"source/_posts/img/venusREM/p1.png","hash":"dcfed9e31ed0984b770d7ec15f56b6aca72d4f08","modified":1761226355278},{"_id":"source/_posts/img/proteinMPNN/p3.png","hash":"fc47775b73fa2e84d9de69d7a0b903e9381b85cf","modified":1761550586251},{"_id":"source/img/bg.jpg","hash":"91cb967d8e17bb6304049f800b236e59ae4cc752","modified":1736254693039},{"_id":"source/img/proteinMPNN/p5.png","hash":"e4ce982389981624e09d49509c42829a6635c140","modified":1761553280098},{"_id":"source/_posts/img/proteinMPNN/p5.png","hash":"e4ce982389981624e09d49509c42829a6635c140","modified":1761553280098},{"_id":"source/img/machine-learning-notes/pic-1.png","hash":"c70db3a157a0fe618458426e13e6bd587f7f8397","modified":1737530573974},{"_id":"source/_posts/img/machine-learning-notes/pic-1.png","hash":"c70db3a157a0fe618458426e13e6bd587f7f8397","modified":1737530573974},{"_id":"source/img/proteinMPNN/p4.png","hash":"d34a9a9c4e8c354d43e8cfd8afc0579b56f080f0","modified":1761553082226},{"_id":"source/_posts/img/proteinMPNN/p4.png","hash":"d34a9a9c4e8c354d43e8cfd8afc0579b56f080f0","modified":1761553082226},{"_id":"public/about/index.html","hash":"b610827b58b50cc811120f556af22035aee3d10e","modified":1769396860060},{"_id":"public/out_of_date/ai4chem.html","hash":"5eebf7d27628729f9a2f2b4f11bd371568c02834","modified":1769396860060},{"_id":"public/out_of_date/learning-cpp-notes.html","hash":"9c71a541582d199e03460a50b4253b2376bcc8a9","modified":1769396860060},{"_id":"public/log/index.html","hash":"7298e4b91c56575a8af0f25f801858d9530eb27a","modified":1769396860060},{"_id":"public/out_of_date/cs106l.html","hash":"50037fd858611c74108ac2b5f52f3401b3a47fba","modified":1769396860060},{"_id":"public/2026/01/23/minimind/index.html","hash":"e019687b7600ab47577679b5e737cb410cb92ad8","modified":1769396860060},{"_id":"public/2026/01/21/conditionMPNN/index.html","hash":"0fb2d52b87e4a6756af942591ff474c4162aa826","modified":1769396860060},{"_id":"public/2026/01/13/memery-in-pytorch/index.html","hash":"872e73015909e7eb5466579bc2268df3430f3c86","modified":1769396860060},{"_id":"public/2025/12/10/Quantification/index.html","hash":"873232edce0cbdd97ad0999f6862cc08230083d4","modified":1769396860060},{"_id":"public/2025/11/25/hello-agent/index.html","hash":"4f1d949f6581e5cf06768b2c000386fa0de083dd","modified":1769396860060},{"_id":"public/2025/10/27/proteinMPNN/index.html","hash":"a68a1d936070e380589e6a4f9f3097b0692a0e5f","modified":1769396860060},{"_id":"public/2025/10/23/venusREM/index.html","hash":"2c81da237679e2087f7fe62ec4911ac2b6e931f2","modified":1769396860060},{"_id":"public/2025/10/21/all-in-rag/index.html","hash":"fc92d8f4723e5c93c3f2df11aa0359efe985059a","modified":1769396860060},{"_id":"public/2025/09/29/prot2text/index.html","hash":"840883cce27531c24778d1a6c3dc2bd5e6c5762f","modified":1769396860060},{"_id":"public/2025/09/26/protrek/index.html","hash":"37e6ec15dbe393042c77d2d80875420a233db474","modified":1769396860060},{"_id":"public/2025/07/01/tudui-pytorch/index.html","hash":"4044005ab6c59979c7a60c559a20722006165ed4","modified":1769396860060},{"_id":"public/2025/03/11/transformer-notes/index.html","hash":"05999a577d418299c6d578d68040e0b5fae8ab67","modified":1769396860060},{"_id":"public/2024/01/22/dive-into-deep-learning/index.html","hash":"99faefc840b05ab177f6ec51151c4467e1eb7b5a","modified":1769396860060},{"_id":"public/2023/11/25/machine-learning-notes/index.html","hash":"ec1cf0061edcd6512676817946a4d356c4b6c11a","modified":1769396860060},{"_id":"public/2023/10/22/algorithm-skills/index.html","hash":"b3bc9de2eef476a1cc3db83f394c5fbf3b8fd48c","modified":1769396860060},{"_id":"public/2023/09/13/algorithm-dp/index.html","hash":"365ee214940eead98159e681e94cfa4c6c0e7b5a","modified":1769396860060},{"_id":"public/2023/09/07/algorithm-math/index.html","hash":"5da909a00ab996dde1740c6942c7c8795a48c225","modified":1769396860060},{"_id":"public/2023/08/05/algorithm-graph/index.html","hash":"d54aeb4a5638024e5d74a797fdcb738a20d2df21","modified":1769396860060},{"_id":"public/2023/08/03/algorithm-search/index.html","hash":"82ca908e01adc71eaa1a06e766c9f577dddf939d","modified":1769396860060},{"_id":"public/2023/07/07/algorithm-data-structure/index.html","hash":"372e920401778b53abae60c278cf28695a842292","modified":1769396860060},{"_id":"public/2023/04/27/algorithm-basic/index.html","hash":"f3aa5e53b75317bfafbd3874988c5e3364d75947","modified":1769396860060},{"_id":"public/2023/01/22/hello-world/index.html","hash":"afeaf8b8392469ea1115229cdd60fed0d9ee6ded","modified":1769396860060},{"_id":"public/archives/index.html","hash":"a992814a3bab5c60bb2791964f152d217117ae6c","modified":1769396860060},{"_id":"public/archives/page/2/index.html","hash":"5418c4fb27c00f832e5eb0d8d083ef52639b0734","modified":1769396860060},{"_id":"public/archives/page/3/index.html","hash":"9e830c5afa6e7932fe82611419da05c9e582b3a6","modified":1769396860060},{"_id":"public/archives/2023/index.html","hash":"a215be39b2ca48af7c896cc5464359b36d66a6f8","modified":1769396860060},{"_id":"public/archives/2023/01/index.html","hash":"6845e007453971ee8820832d24a8dd1fb0404d47","modified":1769396860060},{"_id":"public/archives/2023/04/index.html","hash":"a9be77e8b4b935fe4c82fa1ae22a94078d374264","modified":1769396860060},{"_id":"public/archives/2023/07/index.html","hash":"dfb7a09afa9d758bfd20d1b8c9569c5f75ebba47","modified":1769396860060},{"_id":"public/archives/2023/08/index.html","hash":"003e14e7c9a9b23c8665924f3613b85da1e2b208","modified":1769396860060},{"_id":"public/archives/2023/09/index.html","hash":"b517a847d12683fafa600c9deac5ee9978f1a6bc","modified":1769396860060},{"_id":"public/archives/2023/10/index.html","hash":"f467a8de14060d45347685c5909228dd09e602e5","modified":1769396860060},{"_id":"public/archives/2023/11/index.html","hash":"13389ef9a9dac9126cd7b1814677ab7f19a18904","modified":1769396860060},{"_id":"public/archives/2024/index.html","hash":"96955f40b682eb728111cecd15381fe5251f5aad","modified":1769396860060},{"_id":"public/archives/2024/01/index.html","hash":"184166e28dd73ac301b90d64fcfbf7b75020dd68","modified":1769396860060},{"_id":"public/archives/2025/index.html","hash":"9717cf1c33802451c499432334639ca34a82ec3a","modified":1769396860060},{"_id":"public/archives/2025/03/index.html","hash":"5a94bb2a91a02ba5dce2ce5b3f6d17baf3c4a65b","modified":1769396860060},{"_id":"public/archives/2025/07/index.html","hash":"07eedcc5b5dda18efe0c9d4fb73b3d855d7ab53c","modified":1769396860060},{"_id":"public/archives/2025/09/index.html","hash":"eeb2cbac1d37c31abfd66494e6422658170cbeab","modified":1769396860060},{"_id":"public/archives/2025/10/index.html","hash":"6561b4d352b24db70b20134caabd3bf9376120a8","modified":1769396860060},{"_id":"public/archives/2025/11/index.html","hash":"0c617860fec1a999ef739e159e56aeae5fe4b11a","modified":1769396860060},{"_id":"public/archives/2025/12/index.html","hash":"8d011a4b61c9054c45ce091e5c80a34f2a6a4487","modified":1769396860060},{"_id":"public/index.html","hash":"dead9ab427262782b715cdadb11138f2c6671f35","modified":1769396860060},{"_id":"public/archives/2026/index.html","hash":"ce13c04a2cc481232c3671c39588b6ccf97ae086","modified":1769396860060},{"_id":"public/archives/2026/01/index.html","hash":"968b8fb617826d8ba7eb753b42172b958c7194e8","modified":1769396860060},{"_id":"public/page/2/index.html","hash":"aa90431b0d1fd35d429b7d0c142e955129061797","modified":1769396860060},{"_id":"public/page/3/index.html","hash":"dfe8979ac427ccfc50493fb16eda7f3b542d99b3","modified":1769396860060},{"_id":"public/medias/logo.png","hash":"d08165f945567a08bd74d36b1241a0b8f1618536","modified":1769396860060},{"_id":"public/medias/cursor/Horizontal.cur","hash":"c3c5e8485a67b7ab16079a96b53aff7ff52de756","modified":1769396860060},{"_id":"public/favicon.ico","hash":"801ff7b3f358b77a813787a97ef59148eec93fd8","modified":1769396860060},{"_id":"public/js/danmu/close.png","hash":"2c3ed4345f91dc1b74a57b6dcd1e1efa9e279dbb","modified":1769396860060},{"_id":"public/js/shareJs/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1769396860060},{"_id":"public/js/shareJs/fonts/iconfont.svg","hash":"337b4f156f6d8f4beb32c32a3db46fef361cff74","modified":1769396860060},{"_id":"public/js/shareJs/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1769396860060},{"_id":"public/js/shareJs/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1769396860060},{"_id":"public/img/Kaz.jpg","hash":"aa39b601ea6065577374034fd7a112d022ee3980","modified":1769396860060},{"_id":"public/img/favicon.ico","hash":"a3a1b2c8f5bcd3faf1871d57d7923d6b45f35d34","modified":1769396860060},{"_id":"public/img/hello-world/Kaz.jpg","hash":"aa39b601ea6065577374034fd7a112d022ee3980","modified":1769396860060},{"_id":"public/img/prot2text/fig4.png","hash":"5dc86acc0a978c0b797f714ebcf7e7267a32f175","modified":1769396860060},{"_id":"public/img/prot2text/fig2.png","hash":"edf2c023b1b4431bdb9edc638e28a7b0f61b0cba","modified":1769396860060},{"_id":"public/img/prot2text/table1.png","hash":"4b49e14efd1ef70827a9510964eb04b0b2b21625","modified":1769396860060},{"_id":"public/img/prot2text/table2.png","hash":"157d5535b362be68afadd9ffcfb90a4d99764852","modified":1769396860060},{"_id":"public/css/style.css","hash":"9d93cfbfc4026b96d8dd9115f24b44dec3643281","modified":1769396860060},{"_id":"public/js/app.js","hash":"38e8d7ce69449ee7fc28db92f6be88ae26e708b2","modified":1769396860060},{"_id":"public/js/goTop.js","hash":"5bc7779f0d672c503a68b1e091fb3195df7e9815","modified":1769396860060},{"_id":"public/js/activate-power-mode.js","hash":"3d02584da9dd820d1d9a454c5a93a2c37a8e4e42","modified":1769396860060},{"_id":"public/css/animate.min.css","hash":"8411c1c0418521c96d07bcca0d9dbce7e832ccc9","modified":1769396860060},{"_id":"public/js/local_search.js","hash":"475dc0727cb85c22f15f86701dd93c4bf449a438","modified":1769396860060},{"_id":"public/js/ribbon.min.js","hash":"3c8e4d717ca107f3723def1795c8ed62a5f1a8d0","modified":1769396860060},{"_id":"public/js/jquery3.5.1.js","hash":"d2cc8d43ce1c854b1172e42b1209502ad563db83","modified":1769396860060},{"_id":"public/js/wrapImage.js","hash":"d29b7b5f24b1cbf342187096ee47ec29b5146e7c","modified":1769396860060},{"_id":"public/js/aplayer/APlayer@1.10.1.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1769396860060},{"_id":"public/js/bubble/homeBubble.js","hash":"a8635136621c8c54c04462932192a94f314942cb","modified":1769396860060},{"_id":"public/js/bubble/bubble.js","hash":"40cbc57f98407216ba6dc412e2b75e18c036240f","modified":1769396860060},{"_id":"public/js/danmu/jquery.barrager.js","hash":"305d6e93f3de102b5e1e9b1373821c849d8f54cb","modified":1769396860060},{"_id":"public/js/cursor/clicklove.js","hash":"9e8e79d69ad8338761272f86fe5cad0ad5e503cc","modified":1769396860060},{"_id":"public/js/clipboard/clipboard.min.js","hash":"6371ec0a8e242395c7d4d008d2b98e472c9dcc52","modified":1769396860060},{"_id":"public/js/danmu/barrager.css","hash":"3691efec6dd3d554b4a3dd20ef04836459f151a8","modified":1769396860060},{"_id":"public/js/cursor/explosion.min.js","hash":"ed2d0a5ad306a2745b7c8180b69e36b78d4b0698","modified":1769396860060},{"_id":"public/js/cursor/fireworks.js","hash":"6e1e9206549a6a1a4f5a8672a2dc5044a8f691bd","modified":1769396860060},{"_id":"public/js/cursor/text.js","hash":"a015017310e601f1e544cbc4b08c35b8e547c939","modified":1769396860060},{"_id":"public/js/getPhotoOnline/index.js","hash":"f513605485600561123ffae1a70a0eb35cd5c675","modified":1769396860060},{"_id":"public/js/falling/snow.js","hash":"6f4ef88304f874ef8bb8ea54f79b5d97f5a8f2f6","modified":1769396860060},{"_id":"public/js/getSiteOnline/index.js","hash":"8b93e96331bbdcbee0deb33c9aeca6b2dceacb4b","modified":1769396860060},{"_id":"public/js/getTalkOnline/index.js","hash":"58d9601cfd851c83c2eadd4803698171cd2d8b08","modified":1769396860060},{"_id":"public/js/issues/index.js","hash":"e5f7b37f9dd8e966c7a63b8b6da27d53510eddeb","modified":1769396860060},{"_id":"public/js/falling/sakura.js","hash":"ab41921e8f6ea1bedfcc348924574dc0caa20858","modified":1769396860060},{"_id":"public/js/prism/prism-coy.min.css","hash":"fe1246de39c25eaa7ad1b0c997ee530dbdd39ad8","modified":1769396860060},{"_id":"public/js/pjax@0.2.8/index.js","hash":"c9b1e349203e558dbe43665353e88c6eafc7dbcd","modified":1769396860060},{"_id":"public/js/prism/prism-dark.min.css","hash":"a3f604a19e9a46f83a2fde49dfb45782748957ca","modified":1769396860060},{"_id":"public/js/prism/prism-funky.min.css","hash":"0220f68ccda78c2b5d1109e58f3879674c93b587","modified":1769396860060},{"_id":"public/js/prism/prism-okaidia.min.css","hash":"50be6cc15d883ff3fa5d0885fed47241695a986c","modified":1769396860060},{"_id":"public/js/vue2.6.11.js","hash":"e793aa33ef33150eaba3bc02b07455a231f053ad","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-16.png","hash":"5b3c81945f400550dfc7140e20b1a53d27a196c5","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-27.png","hash":"d36f66e7a82d7f1b17fa05b12be35f45d1046928","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-3.png","hash":"7387a4682f742363b8c58677373d7549a9b9c1cf","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-35.png","hash":"ccc02508f63a657179c124d7637397ff9851d6d4","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-4.png","hash":"838d94327bb5086b731c649fdfb2d0ce109c71b0","modified":1769396860060},{"_id":"public/img/transformer-notes/pic-5.png","hash":"4fd2d84d2cf2517575388972a46e3c0c0ef6574e","modified":1769396860060},{"_id":"public/img/prot2text/fig1.png","hash":"0bd29429de98d67f18efa01afe4d235ce9fc3ca1","modified":1769396860060},{"_id":"public/js/shareJs/font.css","hash":"9d909397e4e94f696b7dd90a16481b50cf170362","modified":1769396860060},{"_id":"public/js/prism/prism-solarizedlight.min.css","hash":"927b757cd8030d12953b5c0fa6eed5de15dda8ad","modified":1769396860060},{"_id":"public/js/prism/prism-line-numbers.css","hash":"3b64b50b73729de943ec894c1d6f19115fa81624","modified":1769396860060},{"_id":"public/js/prism/prism-twilight.min.css","hash":"ff4a6e3c4f1cb9bb59ec061656eacb750d238c15","modified":1769396860060},{"_id":"public/js/prism/prism.min.css","hash":"aa405e2bcb571595c822a80f5482454c1536fa52","modified":1769396860060},{"_id":"public/js/shareJs/share.min.css","hash":"573c7dddb465efd5f5a9337bd50a1ed3f8e82cff","modified":1769396860060},{"_id":"public/js/shareJs/social-share.min.js","hash":"efdfa6b695ac6f0dd04cd8153d3e3a1a1edd90c2","modified":1769396860060},{"_id":"public/js/prism/prism-tomorrow.min.css","hash":"7b4247bc4d3b719afe5957779d0e5c8fb716c8ea","modified":1769396860060},{"_id":"public/js/tocbot/tocbot.css","hash":"45e469dffa7b9ebc03f99fd09fb97274cdc5e9b4","modified":1769396860060},{"_id":"public/js/swiper/swiper.animate1.0.3.min.js","hash":"0e48f180ca2f18b787e4b7b6e55ee3b0c6067691","modified":1769396860060},{"_id":"public/js/tocbot/tocbot.min.js","hash":"bc45d3586a21f7e364cd6efe58844932c00cf11c","modified":1769396860060},{"_id":"public/js/swiper/swiper@5.4.1.min.css","hash":"de2263f82e7bf0778f31fd05c53000799f60701a","modified":1769396860060},{"_id":"public/js/utils/index.js","hash":"54c66b0a396cc3743884cdb979e5c400218613ce","modified":1769396860060},{"_id":"public/js/vue-seamless-scroll/index.js","hash":"f2aaf3f9b1ab7362f7cc158e5360cb1d62a57172","modified":1769396860060},{"_id":"public/js/vue-typed-js/index.css","hash":"36a1d2f61d11ab328e349d6a523dd9dea2ec7ee1","modified":1769396860060},{"_id":"public/js/swiper/vue-awesome-swiper.js","hash":"b7a1ab21dfc58272009bfb5cb7ab87b79f5df573","modified":1769396860060},{"_id":"public/js/vue-typed-js/index.js","hash":"0d80f25135de943ccdfdebec23275bd82712fae1","modified":1769396860060},{"_id":"public/js/valine/index.js","hash":"8809117760e0a7ce8dcc3f14b6421a4d415284a6","modified":1769396860060},{"_id":"public/js/waline/waline.min.js","hash":"94f70e622e2a1ab05adb205033a9ddf371c61534","modified":1769396860060},{"_id":"public/js/swiper/swiper.min.js","hash":"a2fe3c0df9196597c283b2f6ffecc1d4d8702245","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-17.png","hash":"28493d22eede9861a75fe2a1d46390b78aa41ae5","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-22.png","hash":"132aaa4f3e413125735dfd913e775837146ebde4","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-20.png","hash":"724d8995131fbaedbf2f05b313862866b53c4e87","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-26.png","hash":"2409d57d65cb3b6583023569b8a5cfda1146ce59","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-36.png","hash":"b02febe362dc4d704c4a266fea335d83107f0bdf","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-37.png","hash":"037b77bcf91352c8ca863cc7da5fd8930850d7f8","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-6.png","hash":"3d1c7fe6c3783781ac279f471bd8db7f4a96f396","modified":1769396860060},{"_id":"public/img/transformer-notes/pic-2.png","hash":"0df6ba77725900dcc7a9ad3e39790f0b8ecc967c","modified":1769396860060},{"_id":"public/img/all-in-rag/p2.png","hash":"a7fdfe861c3bca2857dad69d9b076d1ab3231878","modified":1769396860060},{"_id":"public/img/venusREM/p2.png","hash":"095ab3be1daa0dc443dca1c2a4529ba769cdcfbe","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-13.png","hash":"59de2b8eb3b6db9d4c564febdf7e3709130787a7","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-15.png","hash":"9f85209eae05833c0d6376d401f45e051023c4d2","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-19.png","hash":"7598a0992232dac91613e65e9dc4fec58dd1c56c","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-18.png","hash":"1ad628440b4b5349cc6667348a33c9c97a012eff","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-21.png","hash":"a8a3382060eab1be1c5a95e90fe7752721dbe801","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-24.png","hash":"40e00390e74ff9cf3aba708c1e9bec5724c396ca","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-33.png","hash":"278a77be72fa2c34cad1ae3ac6d0a492665c78a1","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-29.png","hash":"b5bab6fddb0ad1c79c6d42362ac8a3a0319e6351","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-31.png","hash":"a15f390cb899248c679527434ec08a5e4b06d6f2","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-34.png","hash":"d25dcd2ed03f72135c38a4901e961d5ddda92778","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-7.jpg","hash":"53a93542b958da7e52fe83aba886eb722dd26155","modified":1769396860060},{"_id":"public/img/proteinMPNN/p1.png","hash":"e2cac40872bc88771067c039f67baa4c6d28d64a","modified":1769396860060},{"_id":"public/img/transformer-notes/pic-1.png","hash":"f6d66e79b8bade7a2b5366ce7fd9a7db04707af1","modified":1769396860060},{"_id":"public/img/transformer-notes/pic-4.png","hash":"ef21731e5c6297dfad18bb907e6e399c3d1070f2","modified":1769396860060},{"_id":"public/img/venusREM/p3.png","hash":"b561f8fea0c38f9033ac8f6f1533dd8a07232be6","modified":1769396860060},{"_id":"public/img/prot2text/fig3.png","hash":"911f6a3786d106acf7c47ac97541562117528b8c","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-11.png","hash":"79e3c86dc4e6558bb5449ef6da54ed932bdf820a","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-2.png","hash":"51fbf8685ee1e3285b779d04995ba391196612bd","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-23.png","hash":"5271104e246a1efa46822cf4b653a6dff3406865","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-30.png","hash":"ed3b3c733868949e51401c26cc8c5777ed3d3abf","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-28.png","hash":"a1ac56f65a0f24d92dfac28adb18004ae483f468","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-5.png","hash":"f26891470930c14cd618f4fd5d1a702aabe5c9cb","modified":1769396860060},{"_id":"public/img/transformer-notes/pic-3.png","hash":"3e91798520e0c24d7c03b69b2040cbec73e703a3","modified":1769396860060},{"_id":"public/img/all-in-rag/p1.png","hash":"66afea63665a42f70316fdddfc2ed208cd8c6007","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-10.png","hash":"3518538e91cc7fe18a169e78cbc072f68919e9d4","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-12.png","hash":"8a3f3196091822d6483ddee45b713833baa66540","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-14.png","hash":"c2edd1d1a4dcacf66c43b53b8e232b7ce944af4d","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-25.png","hash":"10b8539b73478749b91175ccff0001faafb34182","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-38.png","hash":"556b9b932485b4937b1c0dc77ee6d9a24fb25e07","modified":1769396860060},{"_id":"public/img/protrek/fig2.png","hash":"672226c8d01becfb2ca1ea5a7b77dd51d4c9dc3e","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-8.png","hash":"e4d47e8c39f6ff05839c194ea682b2cbee16ae2f","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-32.png","hash":"a7f06d079e104b650620d7e152bcb9074d1066e2","modified":1769396860060},{"_id":"public/img/proteinMPNN/p2.png","hash":"b242d7706ed36b6794d5b64be82956cc9e75d2dd","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-9.png","hash":"6a99b1212556fc6513864610da7f9a379eb45b28","modified":1769396860060},{"_id":"public/img/venusREM/p4.png","hash":"bb43bf2bb610906d4f8e8956785232113eb10fb5","modified":1769396860060},{"_id":"public/img/protrek/fig1.png","hash":"b77336dc1bea62ec3856bd2cb310d8755410dfc7","modified":1769396860060},{"_id":"public/img/venusREM/p1.png","hash":"dcfed9e31ed0984b770d7ec15f56b6aca72d4f08","modified":1769396860060},{"_id":"public/img/proteinMPNN/p3.png","hash":"fc47775b73fa2e84d9de69d7a0b903e9381b85cf","modified":1769396860060},{"_id":"public/img/bg.jpg","hash":"91cb967d8e17bb6304049f800b236e59ae4cc752","modified":1769396860060},{"_id":"public/img/proteinMPNN/p5.png","hash":"e4ce982389981624e09d49509c42829a6635c140","modified":1769396860060},{"_id":"public/img/machine-learning-notes/pic-1.png","hash":"c70db3a157a0fe618458426e13e6bd587f7f8397","modified":1769396860060},{"_id":"public/img/proteinMPNN/p4.png","hash":"d34a9a9c4e8c354d43e8cfd8afc0579b56f080f0","modified":1769396860060}],"Category":[],"Data":[],"Page":[{"title":"","type":"about","_content":"\n## \n\n[[Email](mailto:1981270473@qq.com)] | [[Gitee](https://gitee.com/huoyu233)] | [[Github](https://github.com/HuoYu233)] | [[Bilibili](https://space.bilibili.com/82505737)]\n\n\n\nResearch InterestNLPLLMsAI4Science\n\n## \n\n- [2025.7-NOW] [ZhangLab](https://github.com/xmuzhanglab)School of Life ScienceXiamen University\n  - DeepSeaMPNN[[Link](https://github.com/HuoYu233/DeepSeaMPNN)]\n\n- [2023.07-2024.04] [](https://www.fzu-urbansensing.com/)\n  - [[Link](https://www.fzu-urbansensing.com/Platforms-Applications/Crowdsensing_Platform/)]\n\n## \n<div>\n<details>\n<b>[Undergraduate]</b>\n<ul>\n  <li>[2025.4] C/C++ A</li>\n  <li>[2025.4] ACM/ICPC</li>\n  <li>[2024.12] C++</li>\n  <li>[2024.7] </li>\n  <li>[2024.5] COMAPs 2024 MCM/ICM Contest Honorable Mention</li>\n  <li>[2024.4] C/C++ A</li>\n  <li>[2024.4] </li>\n</ul>\n<b>[High School]</b>\n<ul>\n  <li>[2021.4] </li>\n  <li>2019.10] </li>\n  <li>[2019.6]  </li>\n</ul>\n</details>\n</div>\n","source":"about/index.md","raw":"---\ntitle: \ntype: about\n---\n\n## \n\n[[Email](mailto:1981270473@qq.com)] | [[Gitee](https://gitee.com/huoyu233)] | [[Github](https://github.com/HuoYu233)] | [[Bilibili](https://space.bilibili.com/82505737)]\n\n\n\nResearch InterestNLPLLMsAI4Science\n\n## \n\n- [2025.7-NOW] [ZhangLab](https://github.com/xmuzhanglab)School of Life ScienceXiamen University\n  - DeepSeaMPNN[[Link](https://github.com/HuoYu233/DeepSeaMPNN)]\n\n- [2023.07-2024.04] [](https://www.fzu-urbansensing.com/)\n  - [[Link](https://www.fzu-urbansensing.com/Platforms-Applications/Crowdsensing_Platform/)]\n\n## \n<div>\n<details>\n<b>[Undergraduate]</b>\n<ul>\n  <li>[2025.4] C/C++ A</li>\n  <li>[2025.4] ACM/ICPC</li>\n  <li>[2024.12] C++</li>\n  <li>[2024.7] </li>\n  <li>[2024.5] COMAPs 2024 MCM/ICM Contest Honorable Mention</li>\n  <li>[2024.4] C/C++ A</li>\n  <li>[2024.4] </li>\n</ul>\n<b>[High School]</b>\n<ul>\n  <li>[2021.4] </li>\n  <li>2019.10] </li>\n  <li>[2019.6]  </li>\n</ul>\n</details>\n</div>\n","date":"2025-12-18T12:17:36.190Z","updated":"2025-12-18T12:17:36.190Z","path":"about/index.html","comments":1,"layout":"page","_id":"cmkul7fey0000ss99a0qmaavs","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>[<a href=\"mailto:1981270473@qq.com\">Email</a>] | [<a href=\"https://gitee.com/huoyu233\">Gitee</a>] | [<a href=\"https://github.com/HuoYu233\">Github</a>] | [<a href=\"https://space.bilibili.com/82505737\">Bilibili</a>]</p>\n<p></p>\n<p>Research InterestNLPLLMsAI4Science</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>[2025.7-NOW] <a href=\"https://github.com/xmuzhanglab\">ZhangLab</a>School of Life ScienceXiamen University</p>\n<ul>\n<li>DeepSeaMPNN[<a href=\"https://github.com/HuoYu233/DeepSeaMPNN\">Link</a>]</li>\n</ul>\n</li>\n<li><p>[2023.07-2024.04] <a href=\"https://www.fzu-urbansensing.com/\"></a></p>\n<ul>\n<li>[<a href=\"https://www.fzu-urbansensing.com/Platforms-Applications/Crowdsensing_Platform/\">Link</a>]</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><div>\n<details>\n<b>[Undergraduate]</b>\n<ul>\n  <li>[2025.4] C/C++ A</li>\n  <li>[2025.4] ACM/ICPC</li>\n  <li>[2024.12] C++</li>\n  <li>[2024.7] </li>\n  <li>[2024.5] COMAPs 2024 MCM/ICM Contest Honorable Mention</li>\n  <li>[2024.4] C/C++ A</li>\n  <li>[2024.4] </li>\n</ul>\n<b>[High School]</b>\n<ul>\n  <li>[2021.4] </li>\n  <li>2019.10] </li>\n  <li>[2019.6]  </li>\n</ul>\n</details>\n</div>\n","excerpt":"","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>[<a href=\"mailto:1981270473@qq.com\">Email</a>] | [<a href=\"https://gitee.com/huoyu233\">Gitee</a>] | [<a href=\"https://github.com/HuoYu233\">Github</a>] | [<a href=\"https://space.bilibili.com/82505737\">Bilibili</a>]</p>\n<p></p>\n<p>Research InterestNLPLLMsAI4Science</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>[2025.7-NOW] <a href=\"https://github.com/xmuzhanglab\">ZhangLab</a>School of Life ScienceXiamen University</p>\n<ul>\n<li>DeepSeaMPNN[<a href=\"https://github.com/HuoYu233/DeepSeaMPNN\">Link</a>]</li>\n</ul>\n</li>\n<li><p>[2023.07-2024.04] <a href=\"https://www.fzu-urbansensing.com/\"></a></p>\n<ul>\n<li>[<a href=\"https://www.fzu-urbansensing.com/Platforms-Applications/Crowdsensing_Platform/\">Link</a>]</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><div>\n<details>\n<b>[Undergraduate]</b>\n<ul>\n  <li>[2025.4] C/C++ A</li>\n  <li>[2025.4] ACM/ICPC</li>\n  <li>[2024.12] C++</li>\n  <li>[2024.7] </li>\n  <li>[2024.5] COMAPs 2024 MCM/ICM Contest Honorable Mention</li>\n  <li>[2024.4] C/C++ A</li>\n  <li>[2024.4] </li>\n</ul>\n<b>[High School]</b>\n<ul>\n  <li>[2021.4] </li>\n  <li>2019.10] </li>\n  <li>[2019.6]  </li>\n</ul>\n</details>\n</div>\n"},{"title":"OptunaLightGBM","mathjax":true,"date":"2025-02-25T12:46:25.000Z","img":"https://img0.baidu.com/it/u=3213989145,974537053&fm=253&fmt=auto&app=120&f=PNG?w=1023&h=362","excerpt":"RT","_content":"# \n\n  \n\n\n\n\n\n199993539 rxnid, Reactant1, Reactant2 , Product , Additive , Solvent , Yield Reactant1 , Reactant2 , Product , Additive , Solvent SMILESYield\n\n****\n\n$R^2$:\n$$\nR^2(y,\\hat{y})=1-\\frac{\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2}\n$$\n\n\n# baseline\n\n1. **** `pandas``scikit-learn``rdkit`\n2. **** `pd.read_csv` \n3. **MorganSMILES**\n\n   \\- rdkitReactant1,Reactant2,Product,Additive,Solvent\n\n1. ****\n\n   \\- `sklearn``RandomForestRegressor``n_estimators`model.fit(x, y)`'./random_forest_model.pkl'`\n\n1. ****\n\n   ` pkl``pickle.load()``model.predict(x)`\n\n## SMILES\n\nSMILES,Simplified Molecular Input Line Entry SystemASCII\n\nSMILESASCIISMILESSMILES\n\nSMILES=#[][Cu+2]+2CuSMLIES\n\nSMILESSMILES\n\nReactant1,Reactant2,Product,Additive,SolventSMILESrdkitSMILES\n\n## Morgan fingerprint\nbit vector0,1\n\n011\n\n\n\n## RDKit\n\nRDkitRDkitrdkit.Chem.rdchem.MolMolSMILES\n\nRDkithttp://www.rdkit.org\nWIN\\MAC\\LinuxpythonJavaC\n\n## \n\nbaseline$R^2 = 0.0745336043830066$0.08\n\n# My model\n\nSMILE\n\n\n\n- \n- \n-  r\n\n**SMILES**\n\n Morgan  **** \n\n-  CNO \n- \n- \n- \n- \n\n-  0  $2^{n}-1$ n\n-  1024  0  1023\n\n****\n\n- \n-  1\n\nOptuna\n\n\n\n\n\nLightGBM\n\n\n\n\n\n****\n\nGBDTRFLightGBMXgBoost\n\n****\n\n\n\n\n\nBest trial:\n  R2: 0.32038588335457874\n  Params: \n    num_leaves: 250\n    learning_rate: 0.04051655617169133\n    max_depth: 17\n    min_data_in_leaf: 10\n    feature_fraction: 0.4350306415682709\n    bagging_fraction: 0.6540225841297226\n    bagging_freq: 1\n    lambda_l1: 0.000524499451410933\n    lambda_l2: 0.01259645970374942\n\nLGBMGBDTLGBMLGBMGBDT20\n\nOptuna  GridSearch \n\n1. ****\n   - **GridSearch**\n   - **Optuna**\n2. ****\n   - **GridSearch**\n   - **Optuna**\n3. ****\n   - **GridSearch**\n   - **Optuna**\n\n\n","source":"out_of_date/ai4chem.md","raw":"---\ntitle: OptunaLightGBM \nmathjax: true\ndate: 2025/2/25 20:46:25\nimg: https://img0.baidu.com/it/u=3213989145,974537053&fm=253&fmt=auto&app=120&f=PNG?w=1023&h=362\nexcerpt: RT\n---\n# \n\n  \n\n\n\n\n\n199993539 rxnid, Reactant1, Reactant2 , Product , Additive , Solvent , Yield Reactant1 , Reactant2 , Product , Additive , Solvent SMILESYield\n\n****\n\n$R^2$:\n$$\nR^2(y,\\hat{y})=1-\\frac{\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2}\n$$\n\n\n# baseline\n\n1. **** `pandas``scikit-learn``rdkit`\n2. **** `pd.read_csv` \n3. **MorganSMILES**\n\n   \\- rdkitReactant1,Reactant2,Product,Additive,Solvent\n\n1. ****\n\n   \\- `sklearn``RandomForestRegressor``n_estimators`model.fit(x, y)`'./random_forest_model.pkl'`\n\n1. ****\n\n   ` pkl``pickle.load()``model.predict(x)`\n\n## SMILES\n\nSMILES,Simplified Molecular Input Line Entry SystemASCII\n\nSMILESASCIISMILESSMILES\n\nSMILES=#[][Cu+2]+2CuSMLIES\n\nSMILESSMILES\n\nReactant1,Reactant2,Product,Additive,SolventSMILESrdkitSMILES\n\n## Morgan fingerprint\nbit vector0,1\n\n011\n\n\n\n## RDKit\n\nRDkitRDkitrdkit.Chem.rdchem.MolMolSMILES\n\nRDkithttp://www.rdkit.org\nWIN\\MAC\\LinuxpythonJavaC\n\n## \n\nbaseline$R^2 = 0.0745336043830066$0.08\n\n# My model\n\nSMILE\n\n\n\n- \n- \n-  r\n\n**SMILES**\n\n Morgan  **** \n\n-  CNO \n- \n- \n- \n- \n\n-  0  $2^{n}-1$ n\n-  1024  0  1023\n\n****\n\n- \n-  1\n\nOptuna\n\n\n\n\n\nLightGBM\n\n\n\n\n\n****\n\nGBDTRFLightGBMXgBoost\n\n****\n\n\n\n\n\nBest trial:\n  R2: 0.32038588335457874\n  Params: \n    num_leaves: 250\n    learning_rate: 0.04051655617169133\n    max_depth: 17\n    min_data_in_leaf: 10\n    feature_fraction: 0.4350306415682709\n    bagging_fraction: 0.6540225841297226\n    bagging_freq: 1\n    lambda_l1: 0.000524499451410933\n    lambda_l2: 0.01259645970374942\n\nLGBMGBDTLGBMLGBMGBDT20\n\nOptuna  GridSearch \n\n1. ****\n   - **GridSearch**\n   - **Optuna**\n2. ****\n   - **GridSearch**\n   - **Optuna**\n3. ****\n   - **GridSearch**\n   - **Optuna**\n\n\n","updated":"2025-03-23T12:31:22.540Z","path":"out_of_date/ai4chem.html","comments":1,"layout":"page","_id":"cmkul7ff10002ss9998280e1k","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>  </p>\n<p></p>\n<p></p>\n<p>199993539 rxnid, Reactant1, Reactant2 , Product , Additive , Solvent , Yield Reactant1 , Reactant2 , Product , Additive , Solvent SMILESYield</p>\n<p><strong></strong></p>\n<p>$R^2$:<br>$$<br>R^2(y,\\hat{y})&#x3D;1-\\frac{\\sum_{i&#x3D;1}^n(y_i-\\hat{y}<em>i)^2}{\\sum</em>{i&#x3D;1}^n(y_i-\\bar{y})^2}<br>$$</p>\n<h1 id=\"baseline\"><a href=\"#baseline\" class=\"headerlink\" title=\"baseline\"></a>baseline</h1><ol>\n<li><p><strong></strong> <code>pandas</code><code>scikit-learn</code><code>rdkit</code></p>\n</li>\n<li><p><strong></strong> <code>pd.read_csv</code> </p>\n</li>\n<li><p><strong>MorganSMILES</strong></p>\n<p>- rdkitReactant1,Reactant2,Product,Additive,Solvent</p>\n</li>\n<li><p><strong></strong></p>\n<p>- <code>sklearn</code><code>RandomForestRegressor</code><code>n_estimators</code>model.fit(x, y)<code>&#39;./random_forest_model.pkl&#39;</code></p>\n</li>\n<li><p><strong></strong></p>\n<p><code> pkl</code><code>pickle.load()</code><code>model.predict(x)</code></p>\n</li>\n</ol>\n<h2 id=\"SMILES\"><a href=\"#SMILES\" class=\"headerlink\" title=\"SMILES\"></a>SMILES</h2><p>SMILES,Simplified Molecular Input Line Entry SystemASCII</p>\n<p>SMILESASCIISMILESSMILES</p>\n<p>SMILES&#x3D;#[][Cu+2]+2CuSMLIES</p>\n<p>SMILESSMILES</p>\n<p>Reactant1,Reactant2,Product,Additive,SolventSMILESrdkitSMILES</p>\n<h2 id=\"Morgan-fingerprint\"><a href=\"#Morgan-fingerprint\" class=\"headerlink\" title=\"Morgan fingerprint\"></a>Morgan fingerprint</h2><p>bit vector0,1</p>\n<p>011</p>\n<p></p>\n<h2 id=\"RDKit\"><a href=\"#RDKit\" class=\"headerlink\" title=\"RDKit\"></a>RDKit</h2><p>RDkitRDkitrdkit.Chem.rdchem.MolMolSMILES</p>\n<p>RDkit<a href=\"http://www.rdkit.org/\">http://www.rdkit.org</a><br>WIN\\MAC\\LinuxpythonJavaC</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>baseline$R^2 &#x3D; 0.0745336043830066$0.08</p>\n<h1 id=\"My-model\"><a href=\"#My-model\" class=\"headerlink\" title=\"My model\"></a>My model</h1><p>SMILE</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li> r</li>\n</ul>\n<p><strong>SMILES</strong></p>\n<p> Morgan  <strong></strong> </p>\n<ul>\n<li><p> CNO </p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p> 0  $2^{n}-1$ n</p>\n</li>\n<li><p> 1024  0  1023</p>\n</li>\n</ul>\n<p><strong></strong></p>\n<ul>\n<li></li>\n<li> 1</li>\n</ul>\n<p>Optuna</p>\n<p></p>\n<p></p>\n<p>LightGBM</p>\n<p></p>\n<p></p>\n<p><strong></strong></p>\n<p>GBDTRFLightGBMXgBoost</p>\n<p><strong></strong></p>\n<p></p>\n<p></p>\n<p>Best trial:<br>  R2: 0.32038588335457874<br>  Params:<br>    num_leaves: 250<br>    learning_rate: 0.04051655617169133<br>    max_depth: 17<br>    min_data_in_leaf: 10<br>    feature_fraction: 0.4350306415682709<br>    bagging_fraction: 0.6540225841297226<br>    bagging_freq: 1<br>    lambda_l1: 0.000524499451410933<br>    lambda_l2: 0.01259645970374942</p>\n<p>LGBMGBDTLGBMLGBMGBDT20</p>\n<p>Optuna  GridSearch </p>\n<ol>\n<li><strong></strong><ul>\n<li><strong>GridSearch</strong></li>\n<li><strong>Optuna</strong></li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li><strong>GridSearch</strong></li>\n<li><strong>Optuna</strong></li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li><strong>GridSearch</strong></li>\n<li><strong>Optuna</strong></li>\n</ul>\n</li>\n</ol>\n<p></p>\n","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>  </p>\n<p></p>\n<p></p>\n<p>199993539 rxnid, Reactant1, Reactant2 , Product , Additive , Solvent , Yield Reactant1 , Reactant2 , Product , Additive , Solvent SMILESYield</p>\n<p><strong></strong></p>\n<p>$R^2$:<br>$$<br>R^2(y,\\hat{y})&#x3D;1-\\frac{\\sum_{i&#x3D;1}^n(y_i-\\hat{y}<em>i)^2}{\\sum</em>{i&#x3D;1}^n(y_i-\\bar{y})^2}<br>$$</p>\n<h1 id=\"baseline\"><a href=\"#baseline\" class=\"headerlink\" title=\"baseline\"></a>baseline</h1><ol>\n<li><p><strong></strong> <code>pandas</code><code>scikit-learn</code><code>rdkit</code></p>\n</li>\n<li><p><strong></strong> <code>pd.read_csv</code> </p>\n</li>\n<li><p><strong>MorganSMILES</strong></p>\n<p>- rdkitReactant1,Reactant2,Product,Additive,Solvent</p>\n</li>\n<li><p><strong></strong></p>\n<p>- <code>sklearn</code><code>RandomForestRegressor</code><code>n_estimators</code>model.fit(x, y)<code>&#39;./random_forest_model.pkl&#39;</code></p>\n</li>\n<li><p><strong></strong></p>\n<p><code> pkl</code><code>pickle.load()</code><code>model.predict(x)</code></p>\n</li>\n</ol>\n<h2 id=\"SMILES\"><a href=\"#SMILES\" class=\"headerlink\" title=\"SMILES\"></a>SMILES</h2><p>SMILES,Simplified Molecular Input Line Entry SystemASCII</p>\n<p>SMILESASCIISMILESSMILES</p>\n<p>SMILES&#x3D;#[][Cu+2]+2CuSMLIES</p>\n<p>SMILESSMILES</p>\n<p>Reactant1,Reactant2,Product,Additive,SolventSMILESrdkitSMILES</p>\n<h2 id=\"Morgan-fingerprint\"><a href=\"#Morgan-fingerprint\" class=\"headerlink\" title=\"Morgan fingerprint\"></a>Morgan fingerprint</h2><p>bit vector0,1</p>\n<p>011</p>\n<p></p>\n<h2 id=\"RDKit\"><a href=\"#RDKit\" class=\"headerlink\" title=\"RDKit\"></a>RDKit</h2><p>RDkitRDkitrdkit.Chem.rdchem.MolMolSMILES</p>\n<p>RDkit<a href=\"http://www.rdkit.org/\">http://www.rdkit.org</a><br>WIN\\MAC\\LinuxpythonJavaC</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>baseline$R^2 &#x3D; 0.0745336043830066$0.08</p>\n<h1 id=\"My-model\"><a href=\"#My-model\" class=\"headerlink\" title=\"My model\"></a>My model</h1><p>SMILE</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li> r</li>\n</ul>\n<p><strong>SMILES</strong></p>\n<p> Morgan  <strong></strong> </p>\n<ul>\n<li><p> CNO </p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p> 0  $2^{n}-1$ n</p>\n</li>\n<li><p> 1024  0  1023</p>\n</li>\n</ul>\n<p><strong></strong></p>\n<ul>\n<li></li>\n<li> 1</li>\n</ul>\n<p>Optuna</p>\n<p></p>\n<p></p>\n<p>LightGBM</p>\n<p></p>\n<p></p>\n<p><strong></strong></p>\n<p>GBDTRFLightGBMXgBoost</p>\n<p><strong></strong></p>\n<p></p>\n<p></p>\n<p>Best trial:<br>  R2: 0.32038588335457874<br>  Params:<br>    num_leaves: 250<br>    learning_rate: 0.04051655617169133<br>    max_depth: 17<br>    min_data_in_leaf: 10<br>    feature_fraction: 0.4350306415682709<br>    bagging_fraction: 0.6540225841297226<br>    bagging_freq: 1<br>    lambda_l1: 0.000524499451410933<br>    lambda_l2: 0.01259645970374942</p>\n<p>LGBMGBDTLGBMLGBMGBDT20</p>\n<p>Optuna  GridSearch </p>\n<ol>\n<li><strong></strong><ul>\n<li><strong>GridSearch</strong></li>\n<li><strong>Optuna</strong></li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li><strong>GridSearch</strong></li>\n<li><strong>Optuna</strong></li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li><strong>GridSearch</strong></li>\n<li><strong>Optuna</strong></li>\n</ul>\n</li>\n</ol>\n<p></p>\n"},{"title":"","type":"log","_content":"- 2025.2.28 `netlify`\n- 2025.1.24 `bamboo`\n- 2025.1.22  `coder`\n- 2024.1.22  `kazovo.cn`\n- 2024.1.22 `tools`\n- 2023.11.10 `mashiro`\n- 2023.10.12 \n- 2023.3.16 `log`\n- 2023.3.15  `Kaze`\n- 2023.2.17 `tools`\n- 2023.2.17 \n- 2023.2.17  `hawyior.top`\n- 2023.2.17 `Hexo``cactus`\n","source":"log/index.md","raw":"---\ntitle: \ntype: log\n---\n- 2025.2.28 `netlify`\n- 2025.1.24 `bamboo`\n- 2025.1.22  `coder`\n- 2024.1.22  `kazovo.cn`\n- 2024.1.22 `tools`\n- 2023.11.10 `mashiro`\n- 2023.10.12 \n- 2023.3.16 `log`\n- 2023.3.15  `Kaze`\n- 2023.2.17 `tools`\n- 2023.2.17 \n- 2023.2.17  `hawyior.top`\n- 2023.2.17 `Hexo``cactus`\n","date":"2025-02-27T16:09:11.623Z","updated":"2025-02-27T16:09:11.623Z","path":"log/index.html","comments":1,"layout":"page","_id":"cmkul7ff30004ss99dakycv3g","content":"<ul>\n<li>2025.2.28 <code>netlify</code></li>\n<li>2025.1.24 <code>bamboo</code></li>\n<li>2025.1.22  <code>coder</code></li>\n<li>2024.1.22  <code>kazovo.cn</code></li>\n<li>2024.1.22 <code>tools</code></li>\n<li>2023.11.10 <code>mashiro</code></li>\n<li>2023.10.12 </li>\n<li>2023.3.16 <code>log</code></li>\n<li>2023.3.15  <code>Kaze</code></li>\n<li>2023.2.17 <code>tools</code></li>\n<li>2023.2.17 </li>\n<li>2023.2.17  <code>hawyior.top</code></li>\n<li>2023.2.17 <code>Hexo</code><code>cactus</code></li>\n</ul>\n","excerpt":"","more":"<ul>\n<li>2025.2.28 <code>netlify</code></li>\n<li>2025.1.24 <code>bamboo</code></li>\n<li>2025.1.22  <code>coder</code></li>\n<li>2024.1.22  <code>kazovo.cn</code></li>\n<li>2024.1.22 <code>tools</code></li>\n<li>2023.11.10 <code>mashiro</code></li>\n<li>2023.10.12 </li>\n<li>2023.3.16 <code>log</code></li>\n<li>2023.3.15  <code>Kaze</code></li>\n<li>2023.2.17 <code>tools</code></li>\n<li>2023.2.17 </li>\n<li>2023.2.17  <code>hawyior.top</code></li>\n<li>2023.2.17 <code>Hexo</code><code>cactus</code></li>\n</ul>\n"},{"title":"0Cpp","mathjax":true,"date":"2025-04-26T12:46:25.000Z","img":"https://i2.hdslb.com/bfs/archive/6487769f0e49718a24c293df29bd840be0ca2e9c.png","excerpt":"RT","_content":"windows: vsc++\n\n# C++\n\n.cpp.h-> #.i.ii -> .s.o.obj -> \n\n## \n\ncppobj\n\nincludeif endif pragma\n\n- include\n- if-endif\n\n.i.obj\n\n## \n\nobjmainLNKC\n\nmain\n\n\n\ninclude\n\n","source":"out_of_date/learning-cpp-notes.md","raw":"---\ntitle: 0Cpp\nmathjax: true\ndate: 2025/4/26 20:46:25\nimg: https://i2.hdslb.com/bfs/archive/6487769f0e49718a24c293df29bd840be0ca2e9c.png\nexcerpt: RT\n---\nwindows: vsc++\n\n# C++\n\n.cpp.h-> #.i.ii -> .s.o.obj -> \n\n## \n\ncppobj\n\nincludeif endif pragma\n\n- include\n- if-endif\n\n.i.obj\n\n## \n\nobjmainLNKC\n\nmain\n\n\n\ninclude\n\n","updated":"2025-05-12T05:45:30.248Z","path":"out_of_date/learning-cpp-notes.html","comments":1,"layout":"page","_id":"cmkul7ff40006ss999ym40wge","content":"<p>windows: vsc++</p>\n<h1 id=\"C-\"><a href=\"#C-\" class=\"headerlink\" title=\"C++\"></a>C++</h1><p>.cpp.h-&gt; #.i.ii -&gt; .s.o.obj -&gt; </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>cppobj</p>\n<p>includeif endif pragma</p>\n<ul>\n<li>include</li>\n<li>if-endif</li>\n</ul>\n<p>.i.obj</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>objmainLNKC</p>\n<p>main</p>\n<p></p>\n<p>include</p>\n","more":"<p>windows: vsc++</p>\n<h1 id=\"C-\"><a href=\"#C-\" class=\"headerlink\" title=\"C++\"></a>C++</h1><p>.cpp.h-&gt; #.i.ii -&gt; .s.o.obj -&gt; </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>cppobj</p>\n<p>includeif endif pragma</p>\n<ul>\n<li>include</li>\n<li>if-endif</li>\n</ul>\n<p>.i.obj</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>objmainLNKC</p>\n<p>main</p>\n<p></p>\n<p>include</p>\n"},{"_content":"- &\n\ncppRust\n\nPythonJSPHP\n\n+JavaC#Lua\n\n- C++\n\n- usingauto\n\n\n\n1. \n\ndouble -> int\n\n```c++\nint num1 = 12.0;\nint num2(12.0);\n```\n\n2. C++11\n\n\n\n```c++\nint num{12.0}; // \n```\n\nvectormap\n\n3. C++17\n\n\n\n`std::tuple`  C++11 \n\n```c++\nstd::tuple<std::string, std::string, std::string> getClassInfo() {\n    std::string className = \"CS106L\";\n\tstd::string buildingName = \"260-113\";\n\tstd::string language = \"C++\";\n    return {className, buildingName, language};\n}\nint main(){\n    auto [className, buildingName, language] = getClassInfo();\n    // \n    auto classInfo = getClassInfo();\n\tstd::string className = std::get<0>(classInfo);\n    std::string buildingName = std::get<1>(classInfo);\n    std::string language = std::get<2>(classInfo);\n}\n```\n\n- &\n\n```c++\nvoid shift(std::vector<std::pair<int, int>> &nums) {\n    for (auto &[num1, num2] : nums) {\n        num1++;\n        num2++;\n    }\n}\n//\nvoid shift(std::vector<std::pair<int, int>> &nums) {\n     for (size_t i = 0; i < nums.size(); i++) {\n         nums[i].first++;\n         nums[i].second++;\n     }\n}\n```\n\n- &\n\n\n\n\n\n- const\n\nconstconst\n\n- \n\n```sh\ng++ -std=c++23 file.cpp -o exename\n```","source":"out_of_date/cs106l.md","raw":"- &\n\ncppRust\n\nPythonJSPHP\n\n+JavaC#Lua\n\n- C++\n\n- usingauto\n\n\n\n1. \n\ndouble -> int\n\n```c++\nint num1 = 12.0;\nint num2(12.0);\n```\n\n2. C++11\n\n\n\n```c++\nint num{12.0}; // \n```\n\nvectormap\n\n3. C++17\n\n\n\n`std::tuple`  C++11 \n\n```c++\nstd::tuple<std::string, std::string, std::string> getClassInfo() {\n    std::string className = \"CS106L\";\n\tstd::string buildingName = \"260-113\";\n\tstd::string language = \"C++\";\n    return {className, buildingName, language};\n}\nint main(){\n    auto [className, buildingName, language] = getClassInfo();\n    // \n    auto classInfo = getClassInfo();\n\tstd::string className = std::get<0>(classInfo);\n    std::string buildingName = std::get<1>(classInfo);\n    std::string language = std::get<2>(classInfo);\n}\n```\n\n- &\n\n```c++\nvoid shift(std::vector<std::pair<int, int>> &nums) {\n    for (auto &[num1, num2] : nums) {\n        num1++;\n        num2++;\n    }\n}\n//\nvoid shift(std::vector<std::pair<int, int>> &nums) {\n     for (size_t i = 0; i < nums.size(); i++) {\n         nums[i].first++;\n         nums[i].second++;\n     }\n}\n```\n\n- &\n\n\n\n\n\n- const\n\nconstconst\n\n- \n\n```sh\ng++ -std=c++23 file.cpp -o exename\n```","date":"2025-08-09T02:30:08.553Z","updated":"2025-04-30T15:21:30.843Z","path":"out_of_date/cs106l.html","title":"","comments":1,"layout":"page","_id":"cmkul7ff40008ss996iwaafhd","content":"<ul>\n<li>&amp;</li>\n</ul>\n<p>cppRust</p>\n<p>PythonJSPHP</p>\n<p>+JavaC#Lua</p>\n<ul>\n<li><p>C++</p>\n</li>\n<li><p>usingauto</p>\n</li>\n</ul>\n<p></p>\n<ol>\n<li></li>\n</ol>\n<p>double -&gt; int</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> num1 = <span class=\"number\">12.0</span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">num2</span><span class=\"params\">(<span class=\"number\">12.0</span>)</span></span>;</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>C++11</li>\n</ol>\n<p></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> num&#123;<span class=\"number\">12.0</span>&#125;; <span class=\"comment\">// </span></span><br></pre></td></tr></table></figure>\n\n<p>vectormap</p>\n<ol start=\"3\">\n<li>C++17</li>\n</ol>\n<p></p>\n<p><code>std::tuple</code>  C++11 </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">std::tuple&lt;std::string, std::string, std::string&gt; <span class=\"title\">getClassInfo</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    std::string className = <span class=\"string\">&quot;CS106L&quot;</span>;</span><br><span class=\"line\">\tstd::string buildingName = <span class=\"string\">&quot;260-113&quot;</span>;</span><br><span class=\"line\">\tstd::string language = <span class=\"string\">&quot;C++&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;className, buildingName, language&#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">auto</span> [className, buildingName, language] = <span class=\"built_in\">getClassInfo</span>();</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">auto</span> classInfo = <span class=\"built_in\">getClassInfo</span>();</span><br><span class=\"line\">\tstd::string className = std::<span class=\"built_in\">get</span>&lt;<span class=\"number\">0</span>&gt;(classInfo);</span><br><span class=\"line\">    std::string buildingName = std::<span class=\"built_in\">get</span>&lt;<span class=\"number\">1</span>&gt;(classInfo);</span><br><span class=\"line\">    std::string language = std::<span class=\"built_in\">get</span>&lt;<span class=\"number\">2</span>&gt;(classInfo);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>&amp;</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">shift</span><span class=\"params\">(std::vector&lt;std::pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt;&gt; &amp;nums)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">auto</span> &amp;[num1, num2] : nums) &#123;</span><br><span class=\"line\">        num1++;</span><br><span class=\"line\">        num2++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">shift</span><span class=\"params\">(std::vector&lt;std::pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt;&gt; &amp;nums)</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"keyword\">for</span> (<span class=\"type\">size_t</span> i = <span class=\"number\">0</span>; i &lt; nums.<span class=\"built_in\">size</span>(); i++) &#123;</span><br><span class=\"line\">         nums[i].first++;</span><br><span class=\"line\">         nums[i].second++;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>&amp;</li>\n</ul>\n<p></p>\n<p></p>\n<ul>\n<li>const</li>\n</ul>\n<p>constconst</p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ -std=c++23 file.cpp -o exename</span><br></pre></td></tr></table></figure>","excerpt":"","more":"<ul>\n<li>&amp;</li>\n</ul>\n<p>cppRust</p>\n<p>PythonJSPHP</p>\n<p>+JavaC#Lua</p>\n<ul>\n<li><p>C++</p>\n</li>\n<li><p>usingauto</p>\n</li>\n</ul>\n<p></p>\n<ol>\n<li></li>\n</ol>\n<p>double -&gt; int</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> num1 = <span class=\"number\">12.0</span>;</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">num2</span><span class=\"params\">(<span class=\"number\">12.0</span>)</span></span>;</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>C++11</li>\n</ol>\n<p></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> num&#123;<span class=\"number\">12.0</span>&#125;; <span class=\"comment\">// </span></span><br></pre></td></tr></table></figure>\n\n<p>vectormap</p>\n<ol start=\"3\">\n<li>C++17</li>\n</ol>\n<p></p>\n<p><code>std::tuple</code>  C++11 </p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">std::tuple&lt;std::string, std::string, std::string&gt; <span class=\"title\">getClassInfo</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    std::string className = <span class=\"string\">&quot;CS106L&quot;</span>;</span><br><span class=\"line\">\tstd::string buildingName = <span class=\"string\">&quot;260-113&quot;</span>;</span><br><span class=\"line\">\tstd::string language = <span class=\"string\">&quot;C++&quot;</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> &#123;className, buildingName, language&#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">auto</span> [className, buildingName, language] = <span class=\"built_in\">getClassInfo</span>();</span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">auto</span> classInfo = <span class=\"built_in\">getClassInfo</span>();</span><br><span class=\"line\">\tstd::string className = std::<span class=\"built_in\">get</span>&lt;<span class=\"number\">0</span>&gt;(classInfo);</span><br><span class=\"line\">    std::string buildingName = std::<span class=\"built_in\">get</span>&lt;<span class=\"number\">1</span>&gt;(classInfo);</span><br><span class=\"line\">    std::string language = std::<span class=\"built_in\">get</span>&lt;<span class=\"number\">2</span>&gt;(classInfo);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>&amp;</li>\n</ul>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">shift</span><span class=\"params\">(std::vector&lt;std::pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt;&gt; &amp;nums)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">auto</span> &amp;[num1, num2] : nums) &#123;</span><br><span class=\"line\">        num1++;</span><br><span class=\"line\">        num2++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">shift</span><span class=\"params\">(std::vector&lt;std::pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt;&gt; &amp;nums)</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"keyword\">for</span> (<span class=\"type\">size_t</span> i = <span class=\"number\">0</span>; i &lt; nums.<span class=\"built_in\">size</span>(); i++) &#123;</span><br><span class=\"line\">         nums[i].first++;</span><br><span class=\"line\">         nums[i].second++;</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>&amp;</li>\n</ul>\n<p></p>\n<p></p>\n<ul>\n<li>const</li>\n</ul>\n<p>constconst</p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">g++ -std=c++23 file.cpp -o exename</span><br></pre></td></tr></table></figure>"}],"Post":[{"title":"Algorithm-Data-Structure","mathjax":true,"date":"2023-07-07T12:46:25.000Z","img":"https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg","excerpt":"","_content":"\n## \n\n`+`****\n\n- \n\n`e[N]`\n\n`ne[N]`-1\n\n```cpp\n// heade[]ne[]nextidx\nint head, e[N], ne[N], idx;\n\n// \nvoid init()\n{\n    head = -1;\n    idx = 0;\n}\n\n// a\nvoid insert(int a)\n{\n    e[idx] = a, ne[idx] = head, head = idx ++ ;\n}\n\n//ak\nvoid insert(int a,int k)\n{\n    e[idx] = a, ne[idx] = ne[k], ne[k] = idx ++ ;\n}\n\n// \nvoid remove()\n{\n    head = ne[head];\n}\n\n// k\nvoid remove(k)\n{\n    ne[k] = ne[ne[k]];\n}\n```\n\n- \n\n\n\n```cpp\n// e[]l[]r[]idx\nint e[N], l[N], r[N], idx;\n\n// \nvoid init()\n{\n    //01\n    r[0] = 1, l[1] = 0;\n    idx = 2;\n}\n\n// ax\nvoid insert(int a, int x)\n{\n    e[idx] = x;\n    l[idx] = a, r[idx] = r[a];\n    l[r[a]] = idx, r[a] = idx ++ ;\n}\n\n// a\nvoid remove(int a)\n{\n    l[r[a]] = l[a];\n    r[l[a]] = r[a];\n}\n```\n\n- \n\nN\n\n## \n\n(FILO)\n\n```cpp\n// tt\nint stk[N], tt = 0;\n\n// \nstk[ ++ tt] = x;\n\n// \ntt -- ;\n\n// \nstk[tt];\n\n//  tt > 0\nif (tt > 0)\n{\n\tnot empty\n}else\n{\n    empty\n}\n```\n\n## \n\n(FIFO)\n\n```cpp\n// hh tt\nint q[N], hh = 0, tt = -1;\n\n// \nq[ ++ tt] = x;\n\n// \nhh ++ ;\n\n// \nq[hh];\n\n//  hh <= tt\nif (hh <= tt)\n{\n\n}\n```\n\n\n\n```cpp\n// hh tt\nint q[N], hh = 0, tt = 0;\n\n// \nq[tt ++ ] = x;\nif (tt == N) tt = 0;\n\n// \nhh ++ ;\nif (hh == N) hh = 0;\n\n// \nq[hh];\n\n// hh != tt\nif (hh != tt)\n{\n\n}\n```\n\n## \n\n//\n\n```cpp\nint tt = 0;\nfor (int i = 1; i <= n; i ++ )\n{\n    while (tt && check(stk[tt], i)) tt -- ;\n    stk[ ++ tt] = i;\n}\n```\n\n## \n\n/\n\n```cpp\nint hh = 0, tt = -1;\nfor (int i = 0; i < n; i ++ )\n{\n    while (hh <= tt && check_out(q[hh])) hh ++ ;  // \n    while (hh <= tt && check(q[tt], i)) tt -- ;\n    q[ ++ tt] = i;\n}\n```\n\n## KMP\n\n$s$,$t$\n\n```cpp\n// s[]p[]nsmp\n//Next\nfor (int i = 2, j = 0; i <= m; i ++ )\n{\n    while (j && p[i] != p[j + 1]) j = ne[j];\n    if (p[i] == p[j + 1]) j ++ ;\n    ne[i] = j;\n}\n\n// \nfor (int i = 1, j = 0; i <= n; i ++ )\n{\n    while (j && s[i] != p[j + 1]) j = ne[j];\n    if (s[i] == p[j + 1]) j ++ ;\n    if (j == m)\n    {\n        j = ne[j];\n        // \n    }\n}\n```\n\n```cpp\ns.find(t) != s.npos\n```\n\n## Trie\n\n\n\n```cpp\nint son[N][26], cnt[N], idx;\n// 0\n// son[][]\n// cnt[]\n\n// \nvoid insert(char *str)\n{\n    int p = 0;\n    for (int i = 0; str[i]; i ++ )\n    {\n        int u = str[i] - 'a';\n        if (!son[p][u]) son[p][u] = ++ idx;\n        p = son[p][u];\n    }\n    cnt[p] ++ ;\n}\n\n// \nint query(char *str)\n{\n    int p = 0;\n    for (int i = 0; str[i]; i ++ )\n    {\n        int u = str[i] - 'a';\n        if (!son[p][u]) return 0;\n        p = son[p][u];\n    }\n    return cnt[p];\n}\n```\n\n[](https://www.acwing.com/problem/content/145/)\n\n[](https://www.acwing.com/problem/content/144/)\n\n## \n\n1. \n2. \n\n$O(1)$\n\n$p[x]$$x$\n\n- \n\n$p[x] = x$\n\n- $x$\n\n```cpp\nwhile(p[x]!=x) x = p[x]\n```\n\n- \n\np[x]xp[y]yp[x]=y\n\n\n\n```cpp\n(1)\n\n    int p[N]; //\n\n    // x+\n    int find(int x)\n    {\n        if (p[x] != x) p[x] = find(p[x]);\n        return p[x];\n    }\n\n    // 1~n\n    for (int i = 1; i <= n; i ++ ) p[i] = i;\n\n    // ab\n    p[find(a)] = find(b);\n\n\n(2)size\n\n    int p[N], size[N];\n    //p[], size[]\n\n    // x\n    int find(int x)\n    {\n        if (p[x] != x) p[x] = find(p[x]);\n        return p[x];\n    }\n\n    // 1~n\n    for (int i = 1; i <= n; i ++ )\n    {\n        p[i] = i;\n        size[i] = 1;\n    }\n\n    // ab\n    size[find(b)] += size[find(a)];\n    p[find(a)] = find(b);\n\n\n(3)\n\n    int p[N], d[N];\n    //p[], d[x]xp[x]\n\n    // x\n    int find(int x)\n    {\n        if (p[x] != x)\n        {\n            int u = find(p[x]);\n            d[x] += d[p[x]];\n            p[x] = u;\n        }\n        return p[x];\n    }\n\n    // 1~n\n    for (int i = 1; i <= n; i ++ )\n    {\n        p[i] = i;\n        d[i] = 0;\n    }\n\n    // ab\n    p[find(a)] = find(b);\n    d[find(a)] = distance; // find(a)\n```\n\n## C++ STL\n\n```cpp\nvector, \n    size()  \n    empty()  \n    clear()  \n    front()/back()\n    push_back()/pop_back()\n    begin()/end()\n    []\n    \n\npair<int, int>\n    first, \n    second, \n    firstsecond\n\nstring\n    size()/length()  \n    empty()\n    clear()\n    substr(())  \n    c_str()  \n\nqueue, \n    size()\n    empty()\n    push()  \n    front()  \n    back()  \n    pop()  \n\npriority_queue, \n    size()\n    empty()\n    push()  \n    top()  \n    pop()  \n    priority_queue<int, vector<int>, greater<int>> q;\n\nstack, \n    size()\n    empty()\n    push()  \n    top()  \n    pop()  \n\ndeque, \n    size()\n    empty()\n    clear()\n    front()/back()\n    push_back()/pop_back()\n    push_front()/pop_front()\n    begin()/end()\n    []\n\nset, map, multiset, multimap, \n    size()\n    empty()\n    clear()\n    begin()/end()\n    ++, --  O(logn)\n\n    set/multiset\n        insert()  \n        find()  \n        count()  \n        erase()\n            (1) xx   O(k + logn)\n            (2) \n        lower_bound()/upper_bound()\n            lower_bound(x)  x\n            upper_bound(x)  x\n    map/multimap\n        insert()  pair\n        erase()  pair\n        find()\n        []  multimap  O(logn)\n        lower_bound()/upper_bound()\n\nunordered_set, unordered_map, unordered_multiset, unordered_multimap, \n     O(1)\n     lower_bound()/upper_bound() ++--\n\nbitset, \n    bitset<10000> s;\n    ~, &, |, ^\n    >>, <<\n    ==, !=\n    []\n\n    count()  1\n\n    any()  1\n    none()  0\n\n    set()  1\n    set(k, v)  kv\n    reset()  0\n    flip()  ~\n    flip(k) k\n```","source":"_posts/algorithm-data-structure.md","raw":"---\ntitle: Algorithm-Data-Structure\nmathjax: true\ndate: 2023/07/07 20:46:25\nimg: https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg\nexcerpt: \n---\n\n## \n\n`+`****\n\n- \n\n`e[N]`\n\n`ne[N]`-1\n\n```cpp\n// heade[]ne[]nextidx\nint head, e[N], ne[N], idx;\n\n// \nvoid init()\n{\n    head = -1;\n    idx = 0;\n}\n\n// a\nvoid insert(int a)\n{\n    e[idx] = a, ne[idx] = head, head = idx ++ ;\n}\n\n//ak\nvoid insert(int a,int k)\n{\n    e[idx] = a, ne[idx] = ne[k], ne[k] = idx ++ ;\n}\n\n// \nvoid remove()\n{\n    head = ne[head];\n}\n\n// k\nvoid remove(k)\n{\n    ne[k] = ne[ne[k]];\n}\n```\n\n- \n\n\n\n```cpp\n// e[]l[]r[]idx\nint e[N], l[N], r[N], idx;\n\n// \nvoid init()\n{\n    //01\n    r[0] = 1, l[1] = 0;\n    idx = 2;\n}\n\n// ax\nvoid insert(int a, int x)\n{\n    e[idx] = x;\n    l[idx] = a, r[idx] = r[a];\n    l[r[a]] = idx, r[a] = idx ++ ;\n}\n\n// a\nvoid remove(int a)\n{\n    l[r[a]] = l[a];\n    r[l[a]] = r[a];\n}\n```\n\n- \n\nN\n\n## \n\n(FILO)\n\n```cpp\n// tt\nint stk[N], tt = 0;\n\n// \nstk[ ++ tt] = x;\n\n// \ntt -- ;\n\n// \nstk[tt];\n\n//  tt > 0\nif (tt > 0)\n{\n\tnot empty\n}else\n{\n    empty\n}\n```\n\n## \n\n(FIFO)\n\n```cpp\n// hh tt\nint q[N], hh = 0, tt = -1;\n\n// \nq[ ++ tt] = x;\n\n// \nhh ++ ;\n\n// \nq[hh];\n\n//  hh <= tt\nif (hh <= tt)\n{\n\n}\n```\n\n\n\n```cpp\n// hh tt\nint q[N], hh = 0, tt = 0;\n\n// \nq[tt ++ ] = x;\nif (tt == N) tt = 0;\n\n// \nhh ++ ;\nif (hh == N) hh = 0;\n\n// \nq[hh];\n\n// hh != tt\nif (hh != tt)\n{\n\n}\n```\n\n## \n\n//\n\n```cpp\nint tt = 0;\nfor (int i = 1; i <= n; i ++ )\n{\n    while (tt && check(stk[tt], i)) tt -- ;\n    stk[ ++ tt] = i;\n}\n```\n\n## \n\n/\n\n```cpp\nint hh = 0, tt = -1;\nfor (int i = 0; i < n; i ++ )\n{\n    while (hh <= tt && check_out(q[hh])) hh ++ ;  // \n    while (hh <= tt && check(q[tt], i)) tt -- ;\n    q[ ++ tt] = i;\n}\n```\n\n## KMP\n\n$s$,$t$\n\n```cpp\n// s[]p[]nsmp\n//Next\nfor (int i = 2, j = 0; i <= m; i ++ )\n{\n    while (j && p[i] != p[j + 1]) j = ne[j];\n    if (p[i] == p[j + 1]) j ++ ;\n    ne[i] = j;\n}\n\n// \nfor (int i = 1, j = 0; i <= n; i ++ )\n{\n    while (j && s[i] != p[j + 1]) j = ne[j];\n    if (s[i] == p[j + 1]) j ++ ;\n    if (j == m)\n    {\n        j = ne[j];\n        // \n    }\n}\n```\n\n```cpp\ns.find(t) != s.npos\n```\n\n## Trie\n\n\n\n```cpp\nint son[N][26], cnt[N], idx;\n// 0\n// son[][]\n// cnt[]\n\n// \nvoid insert(char *str)\n{\n    int p = 0;\n    for (int i = 0; str[i]; i ++ )\n    {\n        int u = str[i] - 'a';\n        if (!son[p][u]) son[p][u] = ++ idx;\n        p = son[p][u];\n    }\n    cnt[p] ++ ;\n}\n\n// \nint query(char *str)\n{\n    int p = 0;\n    for (int i = 0; str[i]; i ++ )\n    {\n        int u = str[i] - 'a';\n        if (!son[p][u]) return 0;\n        p = son[p][u];\n    }\n    return cnt[p];\n}\n```\n\n[](https://www.acwing.com/problem/content/145/)\n\n[](https://www.acwing.com/problem/content/144/)\n\n## \n\n1. \n2. \n\n$O(1)$\n\n$p[x]$$x$\n\n- \n\n$p[x] = x$\n\n- $x$\n\n```cpp\nwhile(p[x]!=x) x = p[x]\n```\n\n- \n\np[x]xp[y]yp[x]=y\n\n\n\n```cpp\n(1)\n\n    int p[N]; //\n\n    // x+\n    int find(int x)\n    {\n        if (p[x] != x) p[x] = find(p[x]);\n        return p[x];\n    }\n\n    // 1~n\n    for (int i = 1; i <= n; i ++ ) p[i] = i;\n\n    // ab\n    p[find(a)] = find(b);\n\n\n(2)size\n\n    int p[N], size[N];\n    //p[], size[]\n\n    // x\n    int find(int x)\n    {\n        if (p[x] != x) p[x] = find(p[x]);\n        return p[x];\n    }\n\n    // 1~n\n    for (int i = 1; i <= n; i ++ )\n    {\n        p[i] = i;\n        size[i] = 1;\n    }\n\n    // ab\n    size[find(b)] += size[find(a)];\n    p[find(a)] = find(b);\n\n\n(3)\n\n    int p[N], d[N];\n    //p[], d[x]xp[x]\n\n    // x\n    int find(int x)\n    {\n        if (p[x] != x)\n        {\n            int u = find(p[x]);\n            d[x] += d[p[x]];\n            p[x] = u;\n        }\n        return p[x];\n    }\n\n    // 1~n\n    for (int i = 1; i <= n; i ++ )\n    {\n        p[i] = i;\n        d[i] = 0;\n    }\n\n    // ab\n    p[find(a)] = find(b);\n    d[find(a)] = distance; // find(a)\n```\n\n## C++ STL\n\n```cpp\nvector, \n    size()  \n    empty()  \n    clear()  \n    front()/back()\n    push_back()/pop_back()\n    begin()/end()\n    []\n    \n\npair<int, int>\n    first, \n    second, \n    firstsecond\n\nstring\n    size()/length()  \n    empty()\n    clear()\n    substr(())  \n    c_str()  \n\nqueue, \n    size()\n    empty()\n    push()  \n    front()  \n    back()  \n    pop()  \n\npriority_queue, \n    size()\n    empty()\n    push()  \n    top()  \n    pop()  \n    priority_queue<int, vector<int>, greater<int>> q;\n\nstack, \n    size()\n    empty()\n    push()  \n    top()  \n    pop()  \n\ndeque, \n    size()\n    empty()\n    clear()\n    front()/back()\n    push_back()/pop_back()\n    push_front()/pop_front()\n    begin()/end()\n    []\n\nset, map, multiset, multimap, \n    size()\n    empty()\n    clear()\n    begin()/end()\n    ++, --  O(logn)\n\n    set/multiset\n        insert()  \n        find()  \n        count()  \n        erase()\n            (1) xx   O(k + logn)\n            (2) \n        lower_bound()/upper_bound()\n            lower_bound(x)  x\n            upper_bound(x)  x\n    map/multimap\n        insert()  pair\n        erase()  pair\n        find()\n        []  multimap  O(logn)\n        lower_bound()/upper_bound()\n\nunordered_set, unordered_map, unordered_multiset, unordered_multimap, \n     O(1)\n     lower_bound()/upper_bound() ++--\n\nbitset, \n    bitset<10000> s;\n    ~, &, |, ^\n    >>, <<\n    ==, !=\n    []\n\n    count()  1\n\n    any()  1\n    none()  0\n\n    set()  1\n    set(k, v)  kv\n    reset()  0\n    flip()  ~\n    flip(k) k\n```","slug":"algorithm-data-structure","published":1,"updated":"2025-02-20T06:45:40.656Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7fez0001ss994u6hboyo","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>+</code><strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<p><code>e[N]</code></p>\n<p><code>ne[N]</code>-1</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// heade[]ne[]nextidx</span></span><br><span class=\"line\"><span class=\"type\">int</span> head, e[N], ne[N], idx;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">init</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    head = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    idx = <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// a</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">insert</span><span class=\"params\">(<span class=\"type\">int</span> a)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    e[idx] = a, ne[idx] = head, head = idx ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//ak</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">insert</span><span class=\"params\">(<span class=\"type\">int</span> a,<span class=\"type\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    e[idx] = a, ne[idx] = ne[k], ne[k] = idx ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">remove</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    head = ne[head];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// k</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">remove</span><span class=\"params\">(k)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ne[k] = ne[ne[k]];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// e[]l[]r[]idx</span></span><br><span class=\"line\"><span class=\"type\">int</span> e[N], l[N], r[N], idx;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">init</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//01</span></span><br><span class=\"line\">    r[<span class=\"number\">0</span>] = <span class=\"number\">1</span>, l[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\">    idx = <span class=\"number\">2</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// ax</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">insert</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    e[idx] = x;</span><br><span class=\"line\">    l[idx] = a, r[idx] = r[a];</span><br><span class=\"line\">    l[r[a]] = idx, r[a] = idx ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// a</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">remove</span><span class=\"params\">(<span class=\"type\">int</span> a)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    l[r[a]] = l[a];</span><br><span class=\"line\">    r[l[a]] = r[a];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p>N</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>(FILO)</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// tt</span></span><br><span class=\"line\"><span class=\"type\">int</span> stk[N], tt = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">stk[ ++ tt] = x;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">tt -- ;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">stk[tt];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//  tt &gt; 0</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (tt &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">not</span> empty</span><br><span class=\"line\">&#125;<span class=\"keyword\">else</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    empty</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>(FIFO)</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// hh tt</span></span><br><span class=\"line\"><span class=\"type\">int</span> q[N], hh = <span class=\"number\">0</span>, tt = <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">q[ ++ tt] = x;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">hh ++ ;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">q[hh];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//  hh &lt;= tt</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (hh &lt;= tt)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// hh tt</span></span><br><span class=\"line\"><span class=\"type\">int</span> q[N], hh = <span class=\"number\">0</span>, tt = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">q[tt ++ ] = x;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (tt == N) tt = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">hh ++ ;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (hh == N) hh = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">q[hh];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// hh != tt</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (hh != tt)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>&#x2F;&#x2F;</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> tt = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (tt &amp;&amp; <span class=\"built_in\">check</span>(stk[tt], i)) tt -- ;</span><br><span class=\"line\">    stk[ ++ tt] = i;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>&#x2F;</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> hh = <span class=\"number\">0</span>, tt = <span class=\"number\">-1</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (hh &lt;= tt &amp;&amp; <span class=\"built_in\">check_out</span>(q[hh])) hh ++ ;  <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (hh &lt;= tt &amp;&amp; <span class=\"built_in\">check</span>(q[tt], i)) tt -- ;</span><br><span class=\"line\">    q[ ++ tt] = i;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"KMP\"><a href=\"#KMP\" class=\"headerlink\" title=\"KMP\"></a>KMP</h2><p>$s$,$t$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// s[]p[]nsmp</span></span><br><span class=\"line\"><span class=\"comment\">//Next</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>, j = <span class=\"number\">0</span>; i &lt;= m; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (j &amp;&amp; p[i] != p[j + <span class=\"number\">1</span>]) j = ne[j];</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p[i] == p[j + <span class=\"number\">1</span>]) j ++ ;</span><br><span class=\"line\">    ne[i] = j;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>, j = <span class=\"number\">0</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (j &amp;&amp; s[i] != p[j + <span class=\"number\">1</span>]) j = ne[j];</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s[i] == p[j + <span class=\"number\">1</span>]) j ++ ;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (j == m)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        j = ne[j];</span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">s.<span class=\"built_in\">find</span>(t) != s.npos</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Trie\"><a href=\"#Trie\" class=\"headerlink\" title=\"Trie\"></a>Trie</h2><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> son[N][<span class=\"number\">26</span>], cnt[N], idx;</span><br><span class=\"line\"><span class=\"comment\">// 0</span></span><br><span class=\"line\"><span class=\"comment\">// son[][]</span></span><br><span class=\"line\"><span class=\"comment\">// cnt[]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">insert</span><span class=\"params\">(<span class=\"type\">char</span> *str)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> p = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; str[i]; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> u = str[i] - <span class=\"string\">&#x27;a&#x27;</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!son[p][u]) son[p][u] = ++ idx;</span><br><span class=\"line\">        p = son[p][u];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    cnt[p] ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">query</span><span class=\"params\">(<span class=\"type\">char</span> *str)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> p = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; str[i]; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> u = str[i] - <span class=\"string\">&#x27;a&#x27;</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!son[p][u]) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        p = son[p][u];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> cnt[p];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://www.acwing.com/problem/content/145/\"></a></p>\n<p><a href=\"https://www.acwing.com/problem/content/144/\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li></li>\n<li></li>\n</ol>\n<p>$O(1)$</p>\n<p>$p[x]$$x$</p>\n<ul>\n<li></li>\n</ul>\n<p>$p[x] &#x3D; x$</p>\n<ul>\n<li>$x$</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span>(p[x]!=x) x = p[x]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p>p[x]xp[y]yp[x]&#x3D;y</p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> p[N]; <span class=\"comment\">//</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// x+</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">find</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p[x] != x) p[x] = <span class=\"built_in\">find</span>(p[x]);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> p[x];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 1~n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ ) p[i] = i;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ab</span></span><br><span class=\"line\">    p[<span class=\"built_in\">find</span>(a)] = <span class=\"built_in\">find</span>(b);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">(<span class=\"number\">2</span>)size</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> p[N], size[N];</span><br><span class=\"line\">    <span class=\"comment\">//p[], size[]</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// x</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">find</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p[x] != x) p[x] = <span class=\"built_in\">find</span>(p[x]);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> p[x];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 1~n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p[i] = i;</span><br><span class=\"line\">        size[i] = <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ab</span></span><br><span class=\"line\">    size[<span class=\"built_in\">find</span>(b)] += size[<span class=\"built_in\">find</span>(a)];</span><br><span class=\"line\">    p[<span class=\"built_in\">find</span>(a)] = <span class=\"built_in\">find</span>(b);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">(<span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> p[N], d[N];</span><br><span class=\"line\">    <span class=\"comment\">//p[], d[x]xp[x]</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// x</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">find</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p[x] != x)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> u = <span class=\"built_in\">find</span>(p[x]);</span><br><span class=\"line\">            d[x] += d[p[x]];</span><br><span class=\"line\">            p[x] = u;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> p[x];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 1~n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p[i] = i;</span><br><span class=\"line\">        d[i] = <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ab</span></span><br><span class=\"line\">    p[<span class=\"built_in\">find</span>(a)] = <span class=\"built_in\">find</span>(b);</span><br><span class=\"line\">    d[<span class=\"built_in\">find</span>(a)] = distance; <span class=\"comment\">// find(a)</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"C-STL\"><a href=\"#C-STL\" class=\"headerlink\" title=\"C++ STL\"></a>C++ STL</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vector, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">clear</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">front</span>()/<span class=\"built_in\">back</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push_back</span>()/<span class=\"built_in\">pop_back</span>()</span><br><span class=\"line\">    <span class=\"built_in\">begin</span>()/<span class=\"built_in\">end</span>()</span><br><span class=\"line\">    []</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt;</span><br><span class=\"line\">    first, </span><br><span class=\"line\">    second, </span><br><span class=\"line\">    firstsecond</span><br><span class=\"line\"></span><br><span class=\"line\">string</span><br><span class=\"line\">    <span class=\"built_in\">size</span>()/<span class=\"built_in\">length</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">clear</span>()</span><br><span class=\"line\">    <span class=\"built_in\">substr</span>(())  </span><br><span class=\"line\">    <span class=\"built_in\">c_str</span>()  </span><br><span class=\"line\"></span><br><span class=\"line\">queue, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">front</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">back</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">pop</span>()  </span><br><span class=\"line\"></span><br><span class=\"line\">priority_queue, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">top</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">pop</span>()  </span><br><span class=\"line\">    priority_queue&lt;<span class=\"type\">int</span>, vector&lt;<span class=\"type\">int</span>&gt;, greater&lt;<span class=\"type\">int</span>&gt;&gt; q;</span><br><span class=\"line\"></span><br><span class=\"line\">stack, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">top</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">pop</span>()  </span><br><span class=\"line\"></span><br><span class=\"line\">deque, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">clear</span>()</span><br><span class=\"line\">    <span class=\"built_in\">front</span>()/<span class=\"built_in\">back</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push_back</span>()/<span class=\"built_in\">pop_back</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push_front</span>()/<span class=\"built_in\">pop_front</span>()</span><br><span class=\"line\">    <span class=\"built_in\">begin</span>()/<span class=\"built_in\">end</span>()</span><br><span class=\"line\">    []</span><br><span class=\"line\"></span><br><span class=\"line\">set, map, multiset, multimap, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">clear</span>()</span><br><span class=\"line\">    <span class=\"built_in\">begin</span>()/<span class=\"built_in\">end</span>()</span><br><span class=\"line\">    ++, --  <span class=\"built_in\">O</span>(logn)</span><br><span class=\"line\"></span><br><span class=\"line\">    set/<span class=\"function\">multiset</span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">insert</span><span class=\"params\">()</span>  </span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">find</span><span class=\"params\">()</span>  </span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">count</span><span class=\"params\">()</span>  </span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">erase</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"params\">(<span class=\"number\">1</span>)</span> xx   <span class=\"title\">O</span><span class=\"params\">(k + logn)</span></span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"params\">(<span class=\"number\">2</span>)</span> </span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">lower_bound</span><span class=\"params\">()</span>/<span class=\"title\">upper_bound</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"title\">lower_bound</span><span class=\"params\">(x)</span>  x</span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"title\">upper_bound</span><span class=\"params\">(x)</span>  x</span></span><br><span class=\"line\"><span class=\"function\">    map/multimap</span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">insert</span><span class=\"params\">()</span>  pair</span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">erase</span><span class=\"params\">()</span>  pair</span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">find</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">        []  multimap  <span class=\"title\">O</span><span class=\"params\">(logn)</span></span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">lower_bound</span><span class=\"params\">()</span>/<span class=\"title\">upper_bound</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\">unordered_set, unordered_map, unordered_multiset, unordered_multimap, </span></span><br><span class=\"line\"><span class=\"function\">     <span class=\"title\">O</span><span class=\"params\">(<span class=\"number\">1</span>)</span></span></span><br><span class=\"line\"><span class=\"function\">     <span class=\"title\">lower_bound</span><span class=\"params\">()</span>/<span class=\"title\">upper_bound</span><span class=\"params\">()</span> ++--</span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\">bitset, </span></span><br><span class=\"line\"><span class=\"function\">    bitset&lt;10000&gt; s</span>;</span><br><span class=\"line\">    ~, &amp;, |, ^</span><br><span class=\"line\">    &gt;&gt;, &lt;&lt;</span><br><span class=\"line\">    ==, !=</span><br><span class=\"line\">    []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">count</span>()  <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">any</span>()  <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"built_in\">none</span>()  <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">set</span>()  <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"built_in\">set</span>(k, v)  kv</span><br><span class=\"line\">    <span class=\"built_in\">reset</span>()  <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"built_in\">flip</span>()  ~</span><br><span class=\"line\">    <span class=\"built_in\">flip</span>(k) k</span><br></pre></td></tr></table></figure>","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>+</code><strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<p><code>e[N]</code></p>\n<p><code>ne[N]</code>-1</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// heade[]ne[]nextidx</span></span><br><span class=\"line\"><span class=\"type\">int</span> head, e[N], ne[N], idx;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">init</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    head = <span class=\"number\">-1</span>;</span><br><span class=\"line\">    idx = <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// a</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">insert</span><span class=\"params\">(<span class=\"type\">int</span> a)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    e[idx] = a, ne[idx] = head, head = idx ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//ak</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">insert</span><span class=\"params\">(<span class=\"type\">int</span> a,<span class=\"type\">int</span> k)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    e[idx] = a, ne[idx] = ne[k], ne[k] = idx ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">remove</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    head = ne[head];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// k</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">remove</span><span class=\"params\">(k)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    ne[k] = ne[ne[k]];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// e[]l[]r[]idx</span></span><br><span class=\"line\"><span class=\"type\">int</span> e[N], l[N], r[N], idx;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">init</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">//01</span></span><br><span class=\"line\">    r[<span class=\"number\">0</span>] = <span class=\"number\">1</span>, l[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\">    idx = <span class=\"number\">2</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// ax</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">insert</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    e[idx] = x;</span><br><span class=\"line\">    l[idx] = a, r[idx] = r[a];</span><br><span class=\"line\">    l[r[a]] = idx, r[a] = idx ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// a</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">remove</span><span class=\"params\">(<span class=\"type\">int</span> a)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    l[r[a]] = l[a];</span><br><span class=\"line\">    r[l[a]] = r[a];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p>N</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>(FILO)</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// tt</span></span><br><span class=\"line\"><span class=\"type\">int</span> stk[N], tt = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">stk[ ++ tt] = x;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">tt -- ;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">stk[tt];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//  tt &gt; 0</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (tt &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">not</span> empty</span><br><span class=\"line\">&#125;<span class=\"keyword\">else</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    empty</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>(FIFO)</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// hh tt</span></span><br><span class=\"line\"><span class=\"type\">int</span> q[N], hh = <span class=\"number\">0</span>, tt = <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">q[ ++ tt] = x;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">hh ++ ;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">q[hh];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//  hh &lt;= tt</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (hh &lt;= tt)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// hh tt</span></span><br><span class=\"line\"><span class=\"type\">int</span> q[N], hh = <span class=\"number\">0</span>, tt = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">q[tt ++ ] = x;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (tt == N) tt = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">hh ++ ;</span><br><span class=\"line\"><span class=\"keyword\">if</span> (hh == N) hh = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">q[hh];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// hh != tt</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (hh != tt)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>&#x2F;&#x2F;</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> tt = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (tt &amp;&amp; <span class=\"built_in\">check</span>(stk[tt], i)) tt -- ;</span><br><span class=\"line\">    stk[ ++ tt] = i;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>&#x2F;</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> hh = <span class=\"number\">0</span>, tt = <span class=\"number\">-1</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (hh &lt;= tt &amp;&amp; <span class=\"built_in\">check_out</span>(q[hh])) hh ++ ;  <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (hh &lt;= tt &amp;&amp; <span class=\"built_in\">check</span>(q[tt], i)) tt -- ;</span><br><span class=\"line\">    q[ ++ tt] = i;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"KMP\"><a href=\"#KMP\" class=\"headerlink\" title=\"KMP\"></a>KMP</h2><p>$s$,$t$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// s[]p[]nsmp</span></span><br><span class=\"line\"><span class=\"comment\">//Next</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>, j = <span class=\"number\">0</span>; i &lt;= m; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (j &amp;&amp; p[i] != p[j + <span class=\"number\">1</span>]) j = ne[j];</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p[i] == p[j + <span class=\"number\">1</span>]) j ++ ;</span><br><span class=\"line\">    ne[i] = j;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>, j = <span class=\"number\">0</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (j &amp;&amp; s[i] != p[j + <span class=\"number\">1</span>]) j = ne[j];</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (s[i] == p[j + <span class=\"number\">1</span>]) j ++ ;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (j == m)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        j = ne[j];</span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">s.<span class=\"built_in\">find</span>(t) != s.npos</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Trie\"><a href=\"#Trie\" class=\"headerlink\" title=\"Trie\"></a>Trie</h2><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> son[N][<span class=\"number\">26</span>], cnt[N], idx;</span><br><span class=\"line\"><span class=\"comment\">// 0</span></span><br><span class=\"line\"><span class=\"comment\">// son[][]</span></span><br><span class=\"line\"><span class=\"comment\">// cnt[]</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">insert</span><span class=\"params\">(<span class=\"type\">char</span> *str)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> p = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; str[i]; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> u = str[i] - <span class=\"string\">&#x27;a&#x27;</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!son[p][u]) son[p][u] = ++ idx;</span><br><span class=\"line\">        p = son[p][u];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    cnt[p] ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">query</span><span class=\"params\">(<span class=\"type\">char</span> *str)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> p = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; str[i]; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> u = str[i] - <span class=\"string\">&#x27;a&#x27;</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!son[p][u]) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">        p = son[p][u];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> cnt[p];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://www.acwing.com/problem/content/145/\"></a></p>\n<p><a href=\"https://www.acwing.com/problem/content/144/\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li></li>\n<li></li>\n</ol>\n<p>$O(1)$</p>\n<p>$p[x]$$x$</p>\n<ul>\n<li></li>\n</ul>\n<p>$p[x] &#x3D; x$</p>\n<ul>\n<li>$x$</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span>(p[x]!=x) x = p[x]</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p>p[x]xp[y]yp[x]&#x3D;y</p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> p[N]; <span class=\"comment\">//</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// x+</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">find</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p[x] != x) p[x] = <span class=\"built_in\">find</span>(p[x]);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> p[x];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 1~n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ ) p[i] = i;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ab</span></span><br><span class=\"line\">    p[<span class=\"built_in\">find</span>(a)] = <span class=\"built_in\">find</span>(b);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">(<span class=\"number\">2</span>)size</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> p[N], size[N];</span><br><span class=\"line\">    <span class=\"comment\">//p[], size[]</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// x</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">find</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p[x] != x) p[x] = <span class=\"built_in\">find</span>(p[x]);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> p[x];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 1~n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p[i] = i;</span><br><span class=\"line\">        size[i] = <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ab</span></span><br><span class=\"line\">    size[<span class=\"built_in\">find</span>(b)] += size[<span class=\"built_in\">find</span>(a)];</span><br><span class=\"line\">    p[<span class=\"built_in\">find</span>(a)] = <span class=\"built_in\">find</span>(b);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">(<span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> p[N], d[N];</span><br><span class=\"line\">    <span class=\"comment\">//p[], d[x]xp[x]</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// x</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">find</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (p[x] != x)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> u = <span class=\"built_in\">find</span>(p[x]);</span><br><span class=\"line\">            d[x] += d[p[x]];</span><br><span class=\"line\">            p[x] = u;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> p[x];</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 1~n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        p[i] = i;</span><br><span class=\"line\">        d[i] = <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// ab</span></span><br><span class=\"line\">    p[<span class=\"built_in\">find</span>(a)] = <span class=\"built_in\">find</span>(b);</span><br><span class=\"line\">    d[<span class=\"built_in\">find</span>(a)] = distance; <span class=\"comment\">// find(a)</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"C-STL\"><a href=\"#C-STL\" class=\"headerlink\" title=\"C++ STL\"></a>C++ STL</h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vector, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">clear</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">front</span>()/<span class=\"built_in\">back</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push_back</span>()/<span class=\"built_in\">pop_back</span>()</span><br><span class=\"line\">    <span class=\"built_in\">begin</span>()/<span class=\"built_in\">end</span>()</span><br><span class=\"line\">    []</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt;</span><br><span class=\"line\">    first, </span><br><span class=\"line\">    second, </span><br><span class=\"line\">    firstsecond</span><br><span class=\"line\"></span><br><span class=\"line\">string</span><br><span class=\"line\">    <span class=\"built_in\">size</span>()/<span class=\"built_in\">length</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">clear</span>()</span><br><span class=\"line\">    <span class=\"built_in\">substr</span>(())  </span><br><span class=\"line\">    <span class=\"built_in\">c_str</span>()  </span><br><span class=\"line\"></span><br><span class=\"line\">queue, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">front</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">back</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">pop</span>()  </span><br><span class=\"line\"></span><br><span class=\"line\">priority_queue, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">top</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">pop</span>()  </span><br><span class=\"line\">    priority_queue&lt;<span class=\"type\">int</span>, vector&lt;<span class=\"type\">int</span>&gt;, greater&lt;<span class=\"type\">int</span>&gt;&gt; q;</span><br><span class=\"line\"></span><br><span class=\"line\">stack, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">top</span>()  </span><br><span class=\"line\">    <span class=\"built_in\">pop</span>()  </span><br><span class=\"line\"></span><br><span class=\"line\">deque, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">clear</span>()</span><br><span class=\"line\">    <span class=\"built_in\">front</span>()/<span class=\"built_in\">back</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push_back</span>()/<span class=\"built_in\">pop_back</span>()</span><br><span class=\"line\">    <span class=\"built_in\">push_front</span>()/<span class=\"built_in\">pop_front</span>()</span><br><span class=\"line\">    <span class=\"built_in\">begin</span>()/<span class=\"built_in\">end</span>()</span><br><span class=\"line\">    []</span><br><span class=\"line\"></span><br><span class=\"line\">set, map, multiset, multimap, </span><br><span class=\"line\">    <span class=\"built_in\">size</span>()</span><br><span class=\"line\">    <span class=\"built_in\">empty</span>()</span><br><span class=\"line\">    <span class=\"built_in\">clear</span>()</span><br><span class=\"line\">    <span class=\"built_in\">begin</span>()/<span class=\"built_in\">end</span>()</span><br><span class=\"line\">    ++, --  <span class=\"built_in\">O</span>(logn)</span><br><span class=\"line\"></span><br><span class=\"line\">    set/<span class=\"function\">multiset</span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">insert</span><span class=\"params\">()</span>  </span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">find</span><span class=\"params\">()</span>  </span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">count</span><span class=\"params\">()</span>  </span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">erase</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"params\">(<span class=\"number\">1</span>)</span> xx   <span class=\"title\">O</span><span class=\"params\">(k + logn)</span></span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"params\">(<span class=\"number\">2</span>)</span> </span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">lower_bound</span><span class=\"params\">()</span>/<span class=\"title\">upper_bound</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"title\">lower_bound</span><span class=\"params\">(x)</span>  x</span></span><br><span class=\"line\"><span class=\"function\">            <span class=\"title\">upper_bound</span><span class=\"params\">(x)</span>  x</span></span><br><span class=\"line\"><span class=\"function\">    map/multimap</span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">insert</span><span class=\"params\">()</span>  pair</span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">erase</span><span class=\"params\">()</span>  pair</span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">find</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">        []  multimap  <span class=\"title\">O</span><span class=\"params\">(logn)</span></span></span><br><span class=\"line\"><span class=\"function\">        <span class=\"title\">lower_bound</span><span class=\"params\">()</span>/<span class=\"title\">upper_bound</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\">unordered_set, unordered_map, unordered_multiset, unordered_multimap, </span></span><br><span class=\"line\"><span class=\"function\">     <span class=\"title\">O</span><span class=\"params\">(<span class=\"number\">1</span>)</span></span></span><br><span class=\"line\"><span class=\"function\">     <span class=\"title\">lower_bound</span><span class=\"params\">()</span>/<span class=\"title\">upper_bound</span><span class=\"params\">()</span> ++--</span></span><br><span class=\"line\"><span class=\"function\"></span></span><br><span class=\"line\"><span class=\"function\">bitset, </span></span><br><span class=\"line\"><span class=\"function\">    bitset&lt;10000&gt; s</span>;</span><br><span class=\"line\">    ~, &amp;, |, ^</span><br><span class=\"line\">    &gt;&gt;, &lt;&lt;</span><br><span class=\"line\">    ==, !=</span><br><span class=\"line\">    []</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">count</span>()  <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">any</span>()  <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"built_in\">none</span>()  <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">set</span>()  <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"built_in\">set</span>(k, v)  kv</span><br><span class=\"line\">    <span class=\"built_in\">reset</span>()  <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"built_in\">flip</span>()  ~</span><br><span class=\"line\">    <span class=\"built_in\">flip</span>(k) k</span><br></pre></td></tr></table></figure>"},{"title":"Algorithm-Basic","mathjax":true,"date":"2023-04-27T12:46:25.000Z","img":"https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg","excerpt":"","_content":"\n# \n\n## \n\n,$O(nlogn)-O(n^2) $\n\n$O(nlogn)$\n\n1. $x$$arr\\left [ l \\right ]$ ,$arr\\left [ r \\right ]$,$arr\\left [ \\frac{l+r}{2} \\right ]$ \n2. $\\le$x$>$x\n   - \n   - $i$$arr[i]$ $>x$\n   - $j$$arr[j]\\le x$\n   - $arr[i]$$arr[j]$\n3. \n\n****\n\n```java\npublic static void quick_sort(int q[], int l, int r){\n    if (l >= r) return;\n    int i = l - 1, j = r + 1, x = q[l + r >> 1];\n    while (i < j){\n        do i ++ ; while (q[i] < x);\n        do j -- ; while (q[j] > x);\n        if (i < j) {\n            int t = q[i];\n            q[i] = q[j];\n            q[j] = t;           \n        }\n    }\n    quick_sort(q, l, j);\n    quick_sort(q, j + 1, r);\n}\n```\n\n## \n\n,$O(nlogn)$\n\n1.  $mid = \\frac{l+r}{2}$\n2. $left$$right$\n3. \n   - $left$$right$\n   - $res$\n   - $left[i]<right[j]$$left[i]$$res$$i$\n   - $left[i]=right[j]$$left[i]$$res$\n\n****\n\n```java\npublic static void merge_sort(int q[], int l, int r){\n    if (l >= r) return;\n    int mid = l + r >> 1;\n\n    merge_sort(q, l, mid);\n    merge_sort(q, mid + 1, r);\n\n    int k = 0, i = l, j = mid + 1;\n\n    while (i <= mid && j <= r)\n        if (q[i] < q[j]) tmp[k ++ ] = q[i ++ ];\n    else tmp[k ++ ] = q[j ++ ];\n\n    while (i <= mid) tmp[k ++ ] = q[i ++ ];\n    while (j <= r) tmp[k ++ ] = q[j ++ ];\n\n    for (i = l, j = 0; i <= r; i ++, j ++ ) q[i] = tmp[j];\n}\n```\n\n# \n\n## \n\n****\n\n- \n- \n- \n\n****\n\n$[l,r]$$check(x)=true$\n\n- \n\n$mid = \\frac{l+r+1}{2}$\n\n$check(mid)=true$ $[mid,r]$\n$l = mid$\n\n$check(mid)=false$ $[l,mid-1]$\n$r = mid-1$\n\n- \n\n$mid = \\frac{l+r}{2}$\n\n$check(mid)=true$ $[l,mid]$\n$r = mid$\n\n$check(mid)=false$ $[mid+1,r]$\n$l=mid+1$\n\n****\n\n```java\npublic static boolean check(int x) {/* ... */} // x\n\n// [l, r][l, mid][mid + 1, r]\npublic static int bsearch_1(int l, int r)\n{\n    while (l < r)\n    {\n        int mid = l + r >> 1;\n        if (check(mid)) r = mid;    // check()mid\n        else l = mid + 1;\n    }\n    return l;\n}\n// [l, r][l, mid - 1][mid, r]\npublic static int bsearch_2(int l, int r)\n{\n    while (l < r)\n    {\n        int mid = l + r + 1 >> 1;\n        if (check(mid)) l = mid;\n        else r = mid - 1;\n    }\n    return l;\n}\n```\n\n$l=mid$ $mid$$+1$\n\n`check`\n\n## \n\n```java\npublic static boolean check(double x) {/* ... */} // x\n\ndouble bsearch_3(double l, double r)\n{\n    final double eps = 1e-6;   \n    // eps \n    //2\n    while (r - l > eps)\n    {\n        double mid = (l + r) / 2;\n        if (check(mid)) r = mid;\n        else l = mid;\n    }\n    return l;\n}\n```\n\n**-2**\n\n$while$`for`100\n\n# \n\n$C++$\n\n\n\n```cpp\n// C = A + B, A >= 0, B >= 0\nvector<int> add(vector<int> &A, vector<int> &B)\n{\n    if (A.size() < B.size()) return add(B, A);\n\n    vector<int> C;\n    int t = 0;\n    for (int i = 0; i < A.size(); i ++ )\n    {\n        t += A[i];\n        if (i < B.size()) t += B[i];\n        C.push_back(t % 10);\n        t /= 10;\n    }\n\n    if (t) C.push_back(t);\n    return C;\n}\n```\n\n## \n\n```cpp\n// C = A - B, A >= B, A >= 0, B >= 0\nvector<int> sub(vector<int> &A, vector<int> &B)\n{\n    vector<int> C;\n    for (int i = 0, t = 0; i < A.size(); i ++ )\n    {\n        t = A[i] - t;\n        if (i < B.size()) t -= B[i];\n        C.push_back((t + 10) % 10);\n        if (t < 0) t = 1;\n        else t = 0;\n    }\n\n    while (C.size() > 1 && C.back() == 0) C.pop_back();\n    return C;\n}\n```\n\n## \n\n```cpp\n// C = A * b, A >= 0, b >= 0\nvector<int> mul(vector<int> &A, int b)\n{\n    vector<int> C;\n\n    int t = 0;\n    for (int i = 0; i < A.size() || t; i ++ )\n    {\n        if (i < A.size()) t += A[i] * b;\n        C.push_back(t % 10);\n        t /= 10;\n    }\n\n    while (C.size() > 1 && C.back() == 0) C.pop_back();\n\n    return C;\n}\n```\n\n## \n\n```cpp\n// A / b = C ... r, A >= 0, b > 0\nvector<int> div(vector<int> &A, int b, int &r)\n{\n    vector<int> C;\n    r = 0;\n    for (int i = A.size() - 1; i >= 0; i -- )\n    {\n        r = r * 10 + A[i];\n        C.push_back(r / b);\n        r %= b;\n    }\n    reverse(C.begin(), C.end());\n    while (C.size() > 1 && C.back() == 0) C.pop_back();\n    return C;\n}\n```\n\n## \n\n```cpp\ncin>>a1>>b1;\nint lena=strlen(a1);\nint lenb=strlen(b1);\nfor(i=1;i<=lena;i++)a[i]=a1[lena-i]-'0';\nfor(i=1;i<=lenb;i++)b[i]=b1[lenb-i]-'0';\nfor(i=1;i<=lenb;i++)\n    for(j=1;j<=lena;j++)\n        c[i+j-1]+=a[j]*b[i];\nfor(i=1;i<lena+lenb;i++)\n    if(c[i]>9)\n    {\n        c[i+1]+=c[i]/10;\n        c[i]%=10;\n    }\nlen=lena+lenb;\nwhile(c[len]==0&&len>1)len--;\n```\n\n# \n\n\n\n## \n\n${a}_1,{a}_2,...,{a}_{n-1},{a}_n$\n\n${S}_i=a_1+a_2+...+a_i$\n\n1$S_0=0$\n\n$S_i$: $S_i = S_{i-1}+a_i$\n\n****\n\n\n\n$[l,r]$\n\n$\\sum_{i=l}^{r}a_i = S_r-S_{l-1}$\n\n## \n\n$\\begin{pmatrix} a_{11}& a_{12} & ... & a_{1j}\\\\ a_{21}& a_{22} & ... & a_{2j} \\\\ ...& ... & ... & ...\\\\ a_{i1}& a_{i2} & ... & a_{ij} \\end{pmatrix}$\n\n$S_{ij}$$a_{ij}$\n\n- $(i,j)$$S_{ij}$\n\n  $S_{ij}=S_{i-1,j}+S_{i,j-1}-S_{i-1,j-1}+a_{i,j}$\n\n- $(x_1,y_1)$$(x_2,y_2)$\n  $S=S_{x_2,y_2}-S_{x_2,y_1-1}-S_{x_1-1,y_2}+S_{x_1-1,y_1-1}$\n\n## \n\n$a_1,a_2,a_3,...,a_i$\n\n$b_1,b_2,b_3,...,b_i$$a_i=b_1+b_2+...+b_i$\n\n$a$$b$$b$$a$\n\n$\\left\\{\\begin{matrix} b_1=a_1\\\\ b_2=a_2-a_1\\\\ b_3=a_3-a_2\\\\ ......\\\\ b_n=a_n-a_{n-1} \\end{matrix}\\right.$\n\n****\n\n$a_1,a_2,a_3,...,a_i$$[l,r]$$a$$c$\n\n$b_l+=c,b_{r+1}-=c$\n\n****\n\n```java\nimport java.util.Scanner;\n\npublic class Diff {\n    public static void main(String[] args) {\n\n        Scanner scanner = new Scanner(System.in);\n        // nk\n        int n = scanner.nextInt();\n        int k = scanner.nextInt();\n\n        // \n        int[] arr = new int[n+1];\n        int[] brr = new int[n+1];\n\n        // arr\n        for (int i = 1; i < n+1; i++) {\n            arr[i] = scanner.nextInt();\n        }\n\n        // brr\n        for (int i = 1; i < n+1; i++){\n            brr[i] = arr[i] - arr[i-1];\n        }\n\n        while (k-- > 0){\n            // arr[l,r]c\n            int l = scanner.nextInt();\n            int r = scanner.nextInt();\n            int c = scanner.nextInt();\n\n            brr[l] += c;\n            brr[r+1] -= c;\n        }\n\n        // ba\n        // arr\n        for (int i = 1; i < n+1; i++) {\n            brr[i] += brr[i-1];\n            //arr[i] = brr[i]+arr[i-1];\n        }\n\n        // \n        for (int i = 1; i < n+1; i++) {\n            System.out.println(brr[i]);\n        }\n\n    }\n}\n```\n\n## \n\n$a_{ij}$,$b_{ij}$\n\n$b_{x1,y1}+=c$\n\n$b_{x2+1,y1}-=c$\n\n$b_{x1,y2+1}-=c$\n\n$b_{x2+1,y2+1}+=c$\n\n# \n\n## \n\n- \n- ****\n\n****\n\n```cpp\nfor(int i=0,j=0;i<n;i++){\n    while(j<i && check(i,j)) j++;\n    //\n}\n```\n\n****\n\n$O(n^2)$$O(n)$\n\nij\n\n[A-B](https://www.luogu.com.cn/problem/P1102)\n\n## \n\n01\n\n8-128~127\n\n### \n\n> \n\n&\n\n```bash\n1&1 //1\n1&0 //0\n0&0 //0\n```\n\n> \n\n|\n\n```bash\n1|1 //1\n1|0 //1\n0|0 //0\n```\n\n> \n\n~1001\n\n```bash\n~1 //11111110\n```\n\n> \n\n0\n\n```bash\na=11;\na<<1;\n0000 1011\n0001 011022\n```\n\n12n2n\n\n> \n\n001\n\n```text\n\na=16;\na>>3;\n0001 0000\n0000 00102\n\nb=32;\na>>3;\n0010 0000\n0000 01004\n\nb=-32;\nb>>3;\n1010 0000\n1000 0100-4\n```\n\n- nk\n\nk0,1,2\n\n1. k`n>>k`\n\n2.  `x&1`\n\n   **n>>k&1**\n\n- lowbit(x)\n\n  x1\n\n  **x&(-x)**\n\n  `-x=(~x+1)`\n\n## \n\n- \n\n- \n\n  - \n\n    - $max$\n\n  - \n\n    - \n\n    **C++**\n\n```cpp\n// \nvoid merge(vector<PII> &segs)\n{\n    vector<PII> res;\n\n    sort(segs.begin(), segs.end());\n\n    int st = -2e9, ed = -2e9;\n    for (auto seg : segs)\n        if (ed < seg.first)\n        {\n            if (st != -2e9) res.push_back({st, ed});\n            st = seg.first, ed = seg.second;\n        }\n        else ed = max(ed, seg.second);\n\n    if (st != -2e9) res.push_back({st, ed});\n\n    segs = res;\n}\n```","source":"_posts/algorithm-basic.md","raw":"---\ntitle: Algorithm-Basic\nmathjax: true\ndate: 2023/4/27 20:46:25\nimg: https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg\nexcerpt: \n---\n\n# \n\n## \n\n,$O(nlogn)-O(n^2) $\n\n$O(nlogn)$\n\n1. $x$$arr\\left [ l \\right ]$ ,$arr\\left [ r \\right ]$,$arr\\left [ \\frac{l+r}{2} \\right ]$ \n2. $\\le$x$>$x\n   - \n   - $i$$arr[i]$ $>x$\n   - $j$$arr[j]\\le x$\n   - $arr[i]$$arr[j]$\n3. \n\n****\n\n```java\npublic static void quick_sort(int q[], int l, int r){\n    if (l >= r) return;\n    int i = l - 1, j = r + 1, x = q[l + r >> 1];\n    while (i < j){\n        do i ++ ; while (q[i] < x);\n        do j -- ; while (q[j] > x);\n        if (i < j) {\n            int t = q[i];\n            q[i] = q[j];\n            q[j] = t;           \n        }\n    }\n    quick_sort(q, l, j);\n    quick_sort(q, j + 1, r);\n}\n```\n\n## \n\n,$O(nlogn)$\n\n1.  $mid = \\frac{l+r}{2}$\n2. $left$$right$\n3. \n   - $left$$right$\n   - $res$\n   - $left[i]<right[j]$$left[i]$$res$$i$\n   - $left[i]=right[j]$$left[i]$$res$\n\n****\n\n```java\npublic static void merge_sort(int q[], int l, int r){\n    if (l >= r) return;\n    int mid = l + r >> 1;\n\n    merge_sort(q, l, mid);\n    merge_sort(q, mid + 1, r);\n\n    int k = 0, i = l, j = mid + 1;\n\n    while (i <= mid && j <= r)\n        if (q[i] < q[j]) tmp[k ++ ] = q[i ++ ];\n    else tmp[k ++ ] = q[j ++ ];\n\n    while (i <= mid) tmp[k ++ ] = q[i ++ ];\n    while (j <= r) tmp[k ++ ] = q[j ++ ];\n\n    for (i = l, j = 0; i <= r; i ++, j ++ ) q[i] = tmp[j];\n}\n```\n\n# \n\n## \n\n****\n\n- \n- \n- \n\n****\n\n$[l,r]$$check(x)=true$\n\n- \n\n$mid = \\frac{l+r+1}{2}$\n\n$check(mid)=true$ $[mid,r]$\n$l = mid$\n\n$check(mid)=false$ $[l,mid-1]$\n$r = mid-1$\n\n- \n\n$mid = \\frac{l+r}{2}$\n\n$check(mid)=true$ $[l,mid]$\n$r = mid$\n\n$check(mid)=false$ $[mid+1,r]$\n$l=mid+1$\n\n****\n\n```java\npublic static boolean check(int x) {/* ... */} // x\n\n// [l, r][l, mid][mid + 1, r]\npublic static int bsearch_1(int l, int r)\n{\n    while (l < r)\n    {\n        int mid = l + r >> 1;\n        if (check(mid)) r = mid;    // check()mid\n        else l = mid + 1;\n    }\n    return l;\n}\n// [l, r][l, mid - 1][mid, r]\npublic static int bsearch_2(int l, int r)\n{\n    while (l < r)\n    {\n        int mid = l + r + 1 >> 1;\n        if (check(mid)) l = mid;\n        else r = mid - 1;\n    }\n    return l;\n}\n```\n\n$l=mid$ $mid$$+1$\n\n`check`\n\n## \n\n```java\npublic static boolean check(double x) {/* ... */} // x\n\ndouble bsearch_3(double l, double r)\n{\n    final double eps = 1e-6;   \n    // eps \n    //2\n    while (r - l > eps)\n    {\n        double mid = (l + r) / 2;\n        if (check(mid)) r = mid;\n        else l = mid;\n    }\n    return l;\n}\n```\n\n**-2**\n\n$while$`for`100\n\n# \n\n$C++$\n\n\n\n```cpp\n// C = A + B, A >= 0, B >= 0\nvector<int> add(vector<int> &A, vector<int> &B)\n{\n    if (A.size() < B.size()) return add(B, A);\n\n    vector<int> C;\n    int t = 0;\n    for (int i = 0; i < A.size(); i ++ )\n    {\n        t += A[i];\n        if (i < B.size()) t += B[i];\n        C.push_back(t % 10);\n        t /= 10;\n    }\n\n    if (t) C.push_back(t);\n    return C;\n}\n```\n\n## \n\n```cpp\n// C = A - B, A >= B, A >= 0, B >= 0\nvector<int> sub(vector<int> &A, vector<int> &B)\n{\n    vector<int> C;\n    for (int i = 0, t = 0; i < A.size(); i ++ )\n    {\n        t = A[i] - t;\n        if (i < B.size()) t -= B[i];\n        C.push_back((t + 10) % 10);\n        if (t < 0) t = 1;\n        else t = 0;\n    }\n\n    while (C.size() > 1 && C.back() == 0) C.pop_back();\n    return C;\n}\n```\n\n## \n\n```cpp\n// C = A * b, A >= 0, b >= 0\nvector<int> mul(vector<int> &A, int b)\n{\n    vector<int> C;\n\n    int t = 0;\n    for (int i = 0; i < A.size() || t; i ++ )\n    {\n        if (i < A.size()) t += A[i] * b;\n        C.push_back(t % 10);\n        t /= 10;\n    }\n\n    while (C.size() > 1 && C.back() == 0) C.pop_back();\n\n    return C;\n}\n```\n\n## \n\n```cpp\n// A / b = C ... r, A >= 0, b > 0\nvector<int> div(vector<int> &A, int b, int &r)\n{\n    vector<int> C;\n    r = 0;\n    for (int i = A.size() - 1; i >= 0; i -- )\n    {\n        r = r * 10 + A[i];\n        C.push_back(r / b);\n        r %= b;\n    }\n    reverse(C.begin(), C.end());\n    while (C.size() > 1 && C.back() == 0) C.pop_back();\n    return C;\n}\n```\n\n## \n\n```cpp\ncin>>a1>>b1;\nint lena=strlen(a1);\nint lenb=strlen(b1);\nfor(i=1;i<=lena;i++)a[i]=a1[lena-i]-'0';\nfor(i=1;i<=lenb;i++)b[i]=b1[lenb-i]-'0';\nfor(i=1;i<=lenb;i++)\n    for(j=1;j<=lena;j++)\n        c[i+j-1]+=a[j]*b[i];\nfor(i=1;i<lena+lenb;i++)\n    if(c[i]>9)\n    {\n        c[i+1]+=c[i]/10;\n        c[i]%=10;\n    }\nlen=lena+lenb;\nwhile(c[len]==0&&len>1)len--;\n```\n\n# \n\n\n\n## \n\n${a}_1,{a}_2,...,{a}_{n-1},{a}_n$\n\n${S}_i=a_1+a_2+...+a_i$\n\n1$S_0=0$\n\n$S_i$: $S_i = S_{i-1}+a_i$\n\n****\n\n\n\n$[l,r]$\n\n$\\sum_{i=l}^{r}a_i = S_r-S_{l-1}$\n\n## \n\n$\\begin{pmatrix} a_{11}& a_{12} & ... & a_{1j}\\\\ a_{21}& a_{22} & ... & a_{2j} \\\\ ...& ... & ... & ...\\\\ a_{i1}& a_{i2} & ... & a_{ij} \\end{pmatrix}$\n\n$S_{ij}$$a_{ij}$\n\n- $(i,j)$$S_{ij}$\n\n  $S_{ij}=S_{i-1,j}+S_{i,j-1}-S_{i-1,j-1}+a_{i,j}$\n\n- $(x_1,y_1)$$(x_2,y_2)$\n  $S=S_{x_2,y_2}-S_{x_2,y_1-1}-S_{x_1-1,y_2}+S_{x_1-1,y_1-1}$\n\n## \n\n$a_1,a_2,a_3,...,a_i$\n\n$b_1,b_2,b_3,...,b_i$$a_i=b_1+b_2+...+b_i$\n\n$a$$b$$b$$a$\n\n$\\left\\{\\begin{matrix} b_1=a_1\\\\ b_2=a_2-a_1\\\\ b_3=a_3-a_2\\\\ ......\\\\ b_n=a_n-a_{n-1} \\end{matrix}\\right.$\n\n****\n\n$a_1,a_2,a_3,...,a_i$$[l,r]$$a$$c$\n\n$b_l+=c,b_{r+1}-=c$\n\n****\n\n```java\nimport java.util.Scanner;\n\npublic class Diff {\n    public static void main(String[] args) {\n\n        Scanner scanner = new Scanner(System.in);\n        // nk\n        int n = scanner.nextInt();\n        int k = scanner.nextInt();\n\n        // \n        int[] arr = new int[n+1];\n        int[] brr = new int[n+1];\n\n        // arr\n        for (int i = 1; i < n+1; i++) {\n            arr[i] = scanner.nextInt();\n        }\n\n        // brr\n        for (int i = 1; i < n+1; i++){\n            brr[i] = arr[i] - arr[i-1];\n        }\n\n        while (k-- > 0){\n            // arr[l,r]c\n            int l = scanner.nextInt();\n            int r = scanner.nextInt();\n            int c = scanner.nextInt();\n\n            brr[l] += c;\n            brr[r+1] -= c;\n        }\n\n        // ba\n        // arr\n        for (int i = 1; i < n+1; i++) {\n            brr[i] += brr[i-1];\n            //arr[i] = brr[i]+arr[i-1];\n        }\n\n        // \n        for (int i = 1; i < n+1; i++) {\n            System.out.println(brr[i]);\n        }\n\n    }\n}\n```\n\n## \n\n$a_{ij}$,$b_{ij}$\n\n$b_{x1,y1}+=c$\n\n$b_{x2+1,y1}-=c$\n\n$b_{x1,y2+1}-=c$\n\n$b_{x2+1,y2+1}+=c$\n\n# \n\n## \n\n- \n- ****\n\n****\n\n```cpp\nfor(int i=0,j=0;i<n;i++){\n    while(j<i && check(i,j)) j++;\n    //\n}\n```\n\n****\n\n$O(n^2)$$O(n)$\n\nij\n\n[A-B](https://www.luogu.com.cn/problem/P1102)\n\n## \n\n01\n\n8-128~127\n\n### \n\n> \n\n&\n\n```bash\n1&1 //1\n1&0 //0\n0&0 //0\n```\n\n> \n\n|\n\n```bash\n1|1 //1\n1|0 //1\n0|0 //0\n```\n\n> \n\n~1001\n\n```bash\n~1 //11111110\n```\n\n> \n\n0\n\n```bash\na=11;\na<<1;\n0000 1011\n0001 011022\n```\n\n12n2n\n\n> \n\n001\n\n```text\n\na=16;\na>>3;\n0001 0000\n0000 00102\n\nb=32;\na>>3;\n0010 0000\n0000 01004\n\nb=-32;\nb>>3;\n1010 0000\n1000 0100-4\n```\n\n- nk\n\nk0,1,2\n\n1. k`n>>k`\n\n2.  `x&1`\n\n   **n>>k&1**\n\n- lowbit(x)\n\n  x1\n\n  **x&(-x)**\n\n  `-x=(~x+1)`\n\n## \n\n- \n\n- \n\n  - \n\n    - $max$\n\n  - \n\n    - \n\n    **C++**\n\n```cpp\n// \nvoid merge(vector<PII> &segs)\n{\n    vector<PII> res;\n\n    sort(segs.begin(), segs.end());\n\n    int st = -2e9, ed = -2e9;\n    for (auto seg : segs)\n        if (ed < seg.first)\n        {\n            if (st != -2e9) res.push_back({st, ed});\n            st = seg.first, ed = seg.second;\n        }\n        else ed = max(ed, seg.second);\n\n    if (st != -2e9) res.push_back({st, ed});\n\n    segs = res;\n}\n```","slug":"algorithm-basic","published":1,"updated":"2025-02-28T03:03:46.487Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff20003ss999s21a15h","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>,$O(nlogn)-O(n^2) $</p>\n<p>$O(nlogn)$</p>\n<ol>\n<li>$x$$arr\\left [ l \\right ]$ ,$arr\\left [ r \\right ]$,$arr\\left [ \\frac{l+r}{2} \\right ]$ </li>\n<li>$\\le$x$&gt;$x<ul>\n<li></li>\n<li>$i$$arr[i]$ $&gt;x$</li>\n<li>$j$$arr[j]\\le x$</li>\n<li>$arr[i]$$arr[j]$</li>\n</ul>\n</li>\n<li></li>\n</ol>\n<p><strong></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">quick_sort</span><span class=\"params\">(<span class=\"type\">int</span> q[], <span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (l &gt;= r) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> l - <span class=\"number\">1</span>, j = r + <span class=\"number\">1</span>, x = q[l + r &gt;&gt; <span class=\"number\">1</span>];</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (i &lt; j)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">do</span> i ++ ; <span class=\"keyword\">while</span> (q[i] &lt; x);</span><br><span class=\"line\">        <span class=\"keyword\">do</span> j -- ; <span class=\"keyword\">while</span> (q[j] &gt; x);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; j) &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> <span class=\"variable\">t</span> <span class=\"operator\">=</span> q[i];</span><br><span class=\"line\">            q[i] = q[j];</span><br><span class=\"line\">            q[j] = t;           </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    quick_sort(q, l, j);</span><br><span class=\"line\">    quick_sort(q, j + <span class=\"number\">1</span>, r);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>,$O(nlogn)$</p>\n<ol>\n<li> $mid &#x3D; \\frac{l+r}{2}$</li>\n<li>$left$$right$</li>\n<li><ul>\n<li>$left$$right$</li>\n<li>$res$</li>\n<li>$left[i]&lt;right[j]$$left[i]$$res$$i$</li>\n<li>$left[i]&#x3D;right[j]$$left[i]$$res$</li>\n</ul>\n</li>\n</ol>\n<p><strong></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">merge_sort</span><span class=\"params\">(<span class=\"type\">int</span> q[], <span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (l &gt;= r) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">mid</span> <span class=\"operator\">=</span> l + r &gt;&gt; <span class=\"number\">1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    merge_sort(q, l, mid);</span><br><span class=\"line\">    merge_sort(q, mid + <span class=\"number\">1</span>, r);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">k</span> <span class=\"operator\">=</span> <span class=\"number\">0</span>, i = l, j = mid + <span class=\"number\">1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (i &lt;= mid &amp;&amp; j &lt;= r)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (q[i] &lt; q[j]) tmp[k ++ ] = q[i ++ ];</span><br><span class=\"line\">    <span class=\"keyword\">else</span> tmp[k ++ ] = q[j ++ ];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (i &lt;= mid) tmp[k ++ ] = q[i ++ ];</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (j &lt;= r) tmp[k ++ ] = q[j ++ ];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (i = l, j = <span class=\"number\">0</span>; i &lt;= r; i ++, j ++ ) q[i] = tmp[j];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p><strong></strong></p>\n<p>$[l,r]$$check(x)&#x3D;true$</p>\n<ul>\n<li></li>\n</ul>\n<p>$mid &#x3D; \\frac{l+r+1}{2}$</p>\n<p>$check(mid)&#x3D;true$ $[mid,r]$<br>$l &#x3D; mid$</p>\n<p>$check(mid)&#x3D;false$ $[l,mid-1]$<br>$r &#x3D; mid-1$</p>\n<ul>\n<li></li>\n</ul>\n<p>$mid &#x3D; \\frac{l+r}{2}$</p>\n<p>$check(mid)&#x3D;true$ $[l,mid]$<br>$r &#x3D; mid$</p>\n<p>$check(mid)&#x3D;false$ $[mid+1,r]$<br>$l&#x3D;mid+1$</p>\n<p><strong></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"type\">boolean</span> <span class=\"title function_\">check</span><span class=\"params\">(<span class=\"type\">int</span> x)</span> &#123;<span class=\"comment\">/* ... */</span>&#125; <span class=\"comment\">// x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// [l, r][l, mid][mid + 1, r]</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">bsearch_1</span><span class=\"params\">(<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (l &lt; r)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> <span class=\"variable\">mid</span> <span class=\"operator\">=</span> l + r &gt;&gt; <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (check(mid)) r = mid;    <span class=\"comment\">// check()mid</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> l = mid + <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// [l, r][l, mid - 1][mid, r]</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">bsearch_2</span><span class=\"params\">(<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (l &lt; r)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> <span class=\"variable\">mid</span> <span class=\"operator\">=</span> l + r + <span class=\"number\">1</span> &gt;&gt; <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (check(mid)) l = mid;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> r = mid - <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>$l&#x3D;mid$ $mid$$+1$</p>\n<p><code>check</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"type\">boolean</span> <span class=\"title function_\">check</span><span class=\"params\">(<span class=\"type\">double</span> x)</span> &#123;<span class=\"comment\">/* ... */</span>&#125; <span class=\"comment\">// x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">double</span> <span class=\"title function_\">bsearch_3</span><span class=\"params\">(<span class=\"type\">double</span> l, <span class=\"type\">double</span> r)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"type\">double</span> <span class=\"variable\">eps</span> <span class=\"operator\">=</span> <span class=\"number\">1e-6</span>;   </span><br><span class=\"line\">    <span class=\"comment\">// eps </span></span><br><span class=\"line\">    <span class=\"comment\">//2</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (r - l &gt; eps)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">double</span> <span class=\"variable\">mid</span> <span class=\"operator\">=</span> (l + r) / <span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (check(mid)) r = mid;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> l = mid;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>-2</strong></p>\n<p>$while$<code>for</code>100</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>$C++$</p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// C = A + B, A &gt;= 0, B &gt;= 0</span></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">add</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; &amp;A, vector&lt;<span class=\"type\">int</span>&gt; &amp;B)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (A.<span class=\"built_in\">size</span>() &lt; B.<span class=\"built_in\">size</span>()) <span class=\"keyword\">return</span> <span class=\"built_in\">add</span>(B, A);</span><br><span class=\"line\"></span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; C;</span><br><span class=\"line\">    <span class=\"type\">int</span> t = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; A.<span class=\"built_in\">size</span>(); i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        t += A[i];</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; B.<span class=\"built_in\">size</span>()) t += B[i];</span><br><span class=\"line\">        C.<span class=\"built_in\">push_back</span>(t % <span class=\"number\">10</span>);</span><br><span class=\"line\">        t /= <span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (t) C.<span class=\"built_in\">push_back</span>(t);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> C;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// C = A - B, A &gt;= B, A &gt;= 0, B &gt;= 0</span></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">sub</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; &amp;A, vector&lt;<span class=\"type\">int</span>&gt; &amp;B)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; C;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>, t = <span class=\"number\">0</span>; i &lt; A.<span class=\"built_in\">size</span>(); i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        t = A[i] - t;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; B.<span class=\"built_in\">size</span>()) t -= B[i];</span><br><span class=\"line\">        C.<span class=\"built_in\">push_back</span>((t + <span class=\"number\">10</span>) % <span class=\"number\">10</span>);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (t &lt; <span class=\"number\">0</span>) t = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> t = <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (C.<span class=\"built_in\">size</span>() &gt; <span class=\"number\">1</span> &amp;&amp; C.<span class=\"built_in\">back</span>() == <span class=\"number\">0</span>) C.<span class=\"built_in\">pop_back</span>();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> C;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// C = A * b, A &gt;= 0, b &gt;= 0</span></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">mul</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; &amp;A, <span class=\"type\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; C;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> t = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; A.<span class=\"built_in\">size</span>() || t; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; A.<span class=\"built_in\">size</span>()) t += A[i] * b;</span><br><span class=\"line\">        C.<span class=\"built_in\">push_back</span>(t % <span class=\"number\">10</span>);</span><br><span class=\"line\">        t /= <span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (C.<span class=\"built_in\">size</span>() &gt; <span class=\"number\">1</span> &amp;&amp; C.<span class=\"built_in\">back</span>() == <span class=\"number\">0</span>) C.<span class=\"built_in\">pop_back</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> C;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// A / b = C ... r, A &gt;= 0, b &gt; 0</span></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">div</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; &amp;A, <span class=\"type\">int</span> b, <span class=\"type\">int</span> &amp;r)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; C;</span><br><span class=\"line\">    r = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = A.<span class=\"built_in\">size</span>() - <span class=\"number\">1</span>; i &gt;= <span class=\"number\">0</span>; i -- )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        r = r * <span class=\"number\">10</span> + A[i];</span><br><span class=\"line\">        C.<span class=\"built_in\">push_back</span>(r / b);</span><br><span class=\"line\">        r %= b;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">reverse</span>(C.<span class=\"built_in\">begin</span>(), C.<span class=\"built_in\">end</span>());</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (C.<span class=\"built_in\">size</span>() &gt; <span class=\"number\">1</span> &amp;&amp; C.<span class=\"built_in\">back</span>() == <span class=\"number\">0</span>) C.<span class=\"built_in\">pop_back</span>();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> C;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cin&gt;&gt;a1&gt;&gt;b1;</span><br><span class=\"line\"><span class=\"type\">int</span> lena=<span class=\"built_in\">strlen</span>(a1);</span><br><span class=\"line\"><span class=\"type\">int</span> lenb=<span class=\"built_in\">strlen</span>(b1);</span><br><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=lena;i++)a[i]=a1[lena-i]-<span class=\"string\">&#x27;0&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=lenb;i++)b[i]=b1[lenb-i]-<span class=\"string\">&#x27;0&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=lenb;i++)</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(j=<span class=\"number\">1</span>;j&lt;=lena;j++)</span><br><span class=\"line\">        c[i+j<span class=\"number\">-1</span>]+=a[j]*b[i];</span><br><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;lena+lenb;i++)</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(c[i]&gt;<span class=\"number\">9</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        c[i<span class=\"number\">+1</span>]+=c[i]/<span class=\"number\">10</span>;</span><br><span class=\"line\">        c[i]%=<span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">len=lena+lenb;</span><br><span class=\"line\"><span class=\"keyword\">while</span>(c[len]==<span class=\"number\">0</span>&amp;&amp;len&gt;<span class=\"number\">1</span>)len--;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>${a}_1,{a}<em>2,,{a}</em>{n-1},{a}_n$</p>\n<p>${S}_i&#x3D;a_1+a_2++a_i$</p>\n<p>1$S_0&#x3D;0$</p>\n<p>$S_i$: $S_i &#x3D; S_{i-1}+a_i$</p>\n<p><strong></strong></p>\n<p></p>\n<p>$[l,r]$</p>\n<p>$\\sum_{i&#x3D;l}^{r}a_i &#x3D; S_r-S_{l-1}$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\begin{pmatrix} a_{11}&amp; a_{12} &amp;  &amp; a_{1j}\\ a_{21}&amp; a_{22} &amp;  &amp; a_{2j} \\ &amp;  &amp;  &amp; \\ a_{i1}&amp; a_{i2} &amp;  &amp; a_{ij} \\end{pmatrix}$</p>\n<p>$S_{ij}$$a_{ij}$</p>\n<ul>\n<li><p>$(i,j)$$S_{ij}$</p>\n<p>$S_{ij}&#x3D;S_{i-1,j}+S_{i,j-1}-S_{i-1,j-1}+a_{i,j}$</p>\n</li>\n<li><p>$(x_1,y_1)$$(x_2,y_2)$<br>$S&#x3D;S_{x_2,y_2}-S_{x_2,y_1-1}-S_{x_1-1,y_2}+S_{x_1-1,y_1-1}$</p>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$a_1,a_2,a_3,,a_i$</p>\n<p>$b_1,b_2,b_3,,b_i$$a_i&#x3D;b_1+b_2++b_i$</p>\n<p>$a$$b$$b$$a$</p>\n<p>$\\left{\\begin{matrix} b_1&#x3D;a_1\\ b_2&#x3D;a_2-a_1\\ b_3&#x3D;a_3-a_2\\ \\ b_n&#x3D;a_n-a_{n-1} \\end{matrix}\\right.$</p>\n<p><strong></strong></p>\n<p>$a_1,a_2,a_3,,a_i$$[l,r]$$a$$c$</p>\n<p>$b_l+&#x3D;c,b_{r+1}-&#x3D;c$</p>\n<p><strong></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> java.util.Scanner;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">Diff</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">main</span><span class=\"params\">(String[] args)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">Scanner</span> <span class=\"variable\">scanner</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Scanner</span>(System.in);</span><br><span class=\"line\">        <span class=\"comment\">// nk</span></span><br><span class=\"line\">        <span class=\"type\">int</span> <span class=\"variable\">n</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\">        <span class=\"type\">int</span> <span class=\"variable\">k</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"type\">int</span>[] arr = <span class=\"keyword\">new</span> <span class=\"title class_\">int</span>[n+<span class=\"number\">1</span>];</span><br><span class=\"line\">        <span class=\"type\">int</span>[] brr = <span class=\"keyword\">new</span> <span class=\"title class_\">int</span>[n+<span class=\"number\">1</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// arr</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> <span class=\"number\">1</span>; i &lt; n+<span class=\"number\">1</span>; i++) &#123;</span><br><span class=\"line\">            arr[i] = scanner.nextInt();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// brr</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> <span class=\"number\">1</span>; i &lt; n+<span class=\"number\">1</span>; i++)&#123;</span><br><span class=\"line\">            brr[i] = arr[i] - arr[i-<span class=\"number\">1</span>];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (k-- &gt; <span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">            <span class=\"comment\">// arr[l,r]c</span></span><br><span class=\"line\">            <span class=\"type\">int</span> <span class=\"variable\">l</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\">            <span class=\"type\">int</span> <span class=\"variable\">r</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\">            <span class=\"type\">int</span> <span class=\"variable\">c</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\"></span><br><span class=\"line\">            brr[l] += c;</span><br><span class=\"line\">            brr[r+<span class=\"number\">1</span>] -= c;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// ba</span></span><br><span class=\"line\">        <span class=\"comment\">// arr</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> <span class=\"number\">1</span>; i &lt; n+<span class=\"number\">1</span>; i++) &#123;</span><br><span class=\"line\">            brr[i] += brr[i-<span class=\"number\">1</span>];</span><br><span class=\"line\">            <span class=\"comment\">//arr[i] = brr[i]+arr[i-1];</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> <span class=\"number\">1</span>; i &lt; n+<span class=\"number\">1</span>; i++) &#123;</span><br><span class=\"line\">            System.out.println(brr[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$a_{ij}$,$b_{ij}$</p>\n<p>$b_{x1,y1}+&#x3D;c$</p>\n<p>$b_{x2+1,y1}-&#x3D;c$</p>\n<p>$b_{x1,y2+1}-&#x3D;c$</p>\n<p>$b_{x2+1,y2+1}+&#x3D;c$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li></li>\n<li><strong></strong></li>\n</ul>\n<p><strong></strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>,j=<span class=\"number\">0</span>;i&lt;n;i++)&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(j&lt;i &amp;&amp; <span class=\"built_in\">check</span>(i,j)) j++;</span><br><span class=\"line\">    <span class=\"comment\">//</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong></strong></p>\n<p>$O(n^2)$$O(n)$</p>\n<p>ij</p>\n<p><a href=\"https://www.luogu.com.cn/problem/P1102\">A-B</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>01</p>\n<p>8-128~127</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><blockquote>\n<p></p>\n</blockquote>\n<p>&amp;</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1&amp;1 //1</span><br><span class=\"line\">1&amp;0 //0</span><br><span class=\"line\">0&amp;0 //0</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p></p>\n</blockquote>\n<p>|</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1|1 //1</span><br><span class=\"line\">1|0 //1</span><br><span class=\"line\">0|0 //0</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p></p>\n</blockquote>\n<p>~1001</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~1 //11111110</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p></p>\n</blockquote>\n<p>0</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=11;</span><br><span class=\"line\">a&lt;&lt;<span class=\"string\">1;</span></span><br><span class=\"line\"><span class=\"string\">0000 1011</span></span><br><span class=\"line\"><span class=\"string\">0001 011022</span></span><br></pre></td></tr></table></figure>\n\n<p>12n2n</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p>001</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">a=16;</span><br><span class=\"line\">a&gt;&gt;3;</span><br><span class=\"line\">0001 0000</span><br><span class=\"line\">0000 00102</span><br><span class=\"line\"></span><br><span class=\"line\">b=32;</span><br><span class=\"line\">a&gt;&gt;3;</span><br><span class=\"line\">0010 0000</span><br><span class=\"line\">0000 01004</span><br><span class=\"line\"></span><br><span class=\"line\">b=-32;</span><br><span class=\"line\">b&gt;&gt;3;</span><br><span class=\"line\">1010 0000</span><br><span class=\"line\">1000 0100-4</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>nk</li>\n</ul>\n<p>k0,1,2</p>\n<ol>\n<li><p>k<code>n&gt;&gt;k</code></p>\n</li>\n<li><p> <code>x&amp;1</code></p>\n<p><strong>n&gt;&gt;k&amp;1</strong></p>\n</li>\n</ol>\n<ul>\n<li><p>lowbit(x)</p>\n<p>x1</p>\n<p><strong>x&amp;(-x)</strong></p>\n<p><code>-x=(~x+1)</code></p>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p></p>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<ul>\n<li>$max$</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n</ul>\n<p><strong>C++</strong></p>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">merge</span><span class=\"params\">(vector&lt;PII&gt; &amp;segs)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;PII&gt; res;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">sort</span>(segs.<span class=\"built_in\">begin</span>(), segs.<span class=\"built_in\">end</span>());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> st = <span class=\"number\">-2e9</span>, ed = <span class=\"number\">-2e9</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">auto</span> seg : segs)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (ed &lt; seg.first)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (st != <span class=\"number\">-2e9</span>) res.<span class=\"built_in\">push_back</span>(&#123;st, ed&#125;);</span><br><span class=\"line\">            st = seg.first, ed = seg.second;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> ed = <span class=\"built_in\">max</span>(ed, seg.second);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (st != <span class=\"number\">-2e9</span>) res.<span class=\"built_in\">push_back</span>(&#123;st, ed&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    segs = res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>,$O(nlogn)-O(n^2) $</p>\n<p>$O(nlogn)$</p>\n<ol>\n<li>$x$$arr\\left [ l \\right ]$ ,$arr\\left [ r \\right ]$,$arr\\left [ \\frac{l+r}{2} \\right ]$ </li>\n<li>$\\le$x$&gt;$x<ul>\n<li></li>\n<li>$i$$arr[i]$ $&gt;x$</li>\n<li>$j$$arr[j]\\le x$</li>\n<li>$arr[i]$$arr[j]$</li>\n</ul>\n</li>\n<li></li>\n</ol>\n<p><strong></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">quick_sort</span><span class=\"params\">(<span class=\"type\">int</span> q[], <span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (l &gt;= r) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> l - <span class=\"number\">1</span>, j = r + <span class=\"number\">1</span>, x = q[l + r &gt;&gt; <span class=\"number\">1</span>];</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (i &lt; j)&#123;</span><br><span class=\"line\">        <span class=\"keyword\">do</span> i ++ ; <span class=\"keyword\">while</span> (q[i] &lt; x);</span><br><span class=\"line\">        <span class=\"keyword\">do</span> j -- ; <span class=\"keyword\">while</span> (q[j] &gt; x);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; j) &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> <span class=\"variable\">t</span> <span class=\"operator\">=</span> q[i];</span><br><span class=\"line\">            q[i] = q[j];</span><br><span class=\"line\">            q[j] = t;           </span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    quick_sort(q, l, j);</span><br><span class=\"line\">    quick_sort(q, j + <span class=\"number\">1</span>, r);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>,$O(nlogn)$</p>\n<ol>\n<li> $mid &#x3D; \\frac{l+r}{2}$</li>\n<li>$left$$right$</li>\n<li><ul>\n<li>$left$$right$</li>\n<li>$res$</li>\n<li>$left[i]&lt;right[j]$$left[i]$$res$$i$</li>\n<li>$left[i]&#x3D;right[j]$$left[i]$$res$</li>\n</ul>\n</li>\n</ol>\n<p><strong></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">merge_sort</span><span class=\"params\">(<span class=\"type\">int</span> q[], <span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (l &gt;= r) <span class=\"keyword\">return</span>;</span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">mid</span> <span class=\"operator\">=</span> l + r &gt;&gt; <span class=\"number\">1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    merge_sort(q, l, mid);</span><br><span class=\"line\">    merge_sort(q, mid + <span class=\"number\">1</span>, r);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> <span class=\"variable\">k</span> <span class=\"operator\">=</span> <span class=\"number\">0</span>, i = l, j = mid + <span class=\"number\">1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (i &lt;= mid &amp;&amp; j &lt;= r)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (q[i] &lt; q[j]) tmp[k ++ ] = q[i ++ ];</span><br><span class=\"line\">    <span class=\"keyword\">else</span> tmp[k ++ ] = q[j ++ ];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (i &lt;= mid) tmp[k ++ ] = q[i ++ ];</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (j &lt;= r) tmp[k ++ ] = q[j ++ ];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (i = l, j = <span class=\"number\">0</span>; i &lt;= r; i ++, j ++ ) q[i] = tmp[j];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p><strong></strong></p>\n<p>$[l,r]$$check(x)&#x3D;true$</p>\n<ul>\n<li></li>\n</ul>\n<p>$mid &#x3D; \\frac{l+r+1}{2}$</p>\n<p>$check(mid)&#x3D;true$ $[mid,r]$<br>$l &#x3D; mid$</p>\n<p>$check(mid)&#x3D;false$ $[l,mid-1]$<br>$r &#x3D; mid-1$</p>\n<ul>\n<li></li>\n</ul>\n<p>$mid &#x3D; \\frac{l+r}{2}$</p>\n<p>$check(mid)&#x3D;true$ $[l,mid]$<br>$r &#x3D; mid$</p>\n<p>$check(mid)&#x3D;false$ $[mid+1,r]$<br>$l&#x3D;mid+1$</p>\n<p><strong></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"type\">boolean</span> <span class=\"title function_\">check</span><span class=\"params\">(<span class=\"type\">int</span> x)</span> &#123;<span class=\"comment\">/* ... */</span>&#125; <span class=\"comment\">// x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// [l, r][l, mid][mid + 1, r]</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">bsearch_1</span><span class=\"params\">(<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (l &lt; r)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> <span class=\"variable\">mid</span> <span class=\"operator\">=</span> l + r &gt;&gt; <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (check(mid)) r = mid;    <span class=\"comment\">// check()mid</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span> l = mid + <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// [l, r][l, mid - 1][mid, r]</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"type\">int</span> <span class=\"title function_\">bsearch_2</span><span class=\"params\">(<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (l &lt; r)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> <span class=\"variable\">mid</span> <span class=\"operator\">=</span> l + r + <span class=\"number\">1</span> &gt;&gt; <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (check(mid)) l = mid;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> r = mid - <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>$l&#x3D;mid$ $mid$$+1$</p>\n<p><code>check</code></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"type\">boolean</span> <span class=\"title function_\">check</span><span class=\"params\">(<span class=\"type\">double</span> x)</span> &#123;<span class=\"comment\">/* ... */</span>&#125; <span class=\"comment\">// x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">double</span> <span class=\"title function_\">bsearch_3</span><span class=\"params\">(<span class=\"type\">double</span> l, <span class=\"type\">double</span> r)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> <span class=\"type\">double</span> <span class=\"variable\">eps</span> <span class=\"operator\">=</span> <span class=\"number\">1e-6</span>;   </span><br><span class=\"line\">    <span class=\"comment\">// eps </span></span><br><span class=\"line\">    <span class=\"comment\">//2</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (r - l &gt; eps)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">double</span> <span class=\"variable\">mid</span> <span class=\"operator\">=</span> (l + r) / <span class=\"number\">2</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (check(mid)) r = mid;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> l = mid;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> l;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>-2</strong></p>\n<p>$while$<code>for</code>100</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>$C++$</p>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// C = A + B, A &gt;= 0, B &gt;= 0</span></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">add</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; &amp;A, vector&lt;<span class=\"type\">int</span>&gt; &amp;B)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (A.<span class=\"built_in\">size</span>() &lt; B.<span class=\"built_in\">size</span>()) <span class=\"keyword\">return</span> <span class=\"built_in\">add</span>(B, A);</span><br><span class=\"line\"></span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; C;</span><br><span class=\"line\">    <span class=\"type\">int</span> t = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; A.<span class=\"built_in\">size</span>(); i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        t += A[i];</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; B.<span class=\"built_in\">size</span>()) t += B[i];</span><br><span class=\"line\">        C.<span class=\"built_in\">push_back</span>(t % <span class=\"number\">10</span>);</span><br><span class=\"line\">        t /= <span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (t) C.<span class=\"built_in\">push_back</span>(t);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> C;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// C = A - B, A &gt;= B, A &gt;= 0, B &gt;= 0</span></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">sub</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; &amp;A, vector&lt;<span class=\"type\">int</span>&gt; &amp;B)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; C;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>, t = <span class=\"number\">0</span>; i &lt; A.<span class=\"built_in\">size</span>(); i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        t = A[i] - t;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; B.<span class=\"built_in\">size</span>()) t -= B[i];</span><br><span class=\"line\">        C.<span class=\"built_in\">push_back</span>((t + <span class=\"number\">10</span>) % <span class=\"number\">10</span>);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (t &lt; <span class=\"number\">0</span>) t = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> t = <span class=\"number\">0</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (C.<span class=\"built_in\">size</span>() &gt; <span class=\"number\">1</span> &amp;&amp; C.<span class=\"built_in\">back</span>() == <span class=\"number\">0</span>) C.<span class=\"built_in\">pop_back</span>();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> C;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// C = A * b, A &gt;= 0, b &gt;= 0</span></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">mul</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; &amp;A, <span class=\"type\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; C;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> t = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; A.<span class=\"built_in\">size</span>() || t; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &lt; A.<span class=\"built_in\">size</span>()) t += A[i] * b;</span><br><span class=\"line\">        C.<span class=\"built_in\">push_back</span>(t % <span class=\"number\">10</span>);</span><br><span class=\"line\">        t /= <span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (C.<span class=\"built_in\">size</span>() &gt; <span class=\"number\">1</span> &amp;&amp; C.<span class=\"built_in\">back</span>() == <span class=\"number\">0</span>) C.<span class=\"built_in\">pop_back</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> C;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// A / b = C ... r, A &gt;= 0, b &gt; 0</span></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">div</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; &amp;A, <span class=\"type\">int</span> b, <span class=\"type\">int</span> &amp;r)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; C;</span><br><span class=\"line\">    r = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = A.<span class=\"built_in\">size</span>() - <span class=\"number\">1</span>; i &gt;= <span class=\"number\">0</span>; i -- )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        r = r * <span class=\"number\">10</span> + A[i];</span><br><span class=\"line\">        C.<span class=\"built_in\">push_back</span>(r / b);</span><br><span class=\"line\">        r %= b;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">reverse</span>(C.<span class=\"built_in\">begin</span>(), C.<span class=\"built_in\">end</span>());</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (C.<span class=\"built_in\">size</span>() &gt; <span class=\"number\">1</span> &amp;&amp; C.<span class=\"built_in\">back</span>() == <span class=\"number\">0</span>) C.<span class=\"built_in\">pop_back</span>();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> C;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cin&gt;&gt;a1&gt;&gt;b1;</span><br><span class=\"line\"><span class=\"type\">int</span> lena=<span class=\"built_in\">strlen</span>(a1);</span><br><span class=\"line\"><span class=\"type\">int</span> lenb=<span class=\"built_in\">strlen</span>(b1);</span><br><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=lena;i++)a[i]=a1[lena-i]-<span class=\"string\">&#x27;0&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=lenb;i++)b[i]=b1[lenb-i]-<span class=\"string\">&#x27;0&#x27;</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;=lenb;i++)</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(j=<span class=\"number\">1</span>;j&lt;=lena;j++)</span><br><span class=\"line\">        c[i+j<span class=\"number\">-1</span>]+=a[j]*b[i];</span><br><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">1</span>;i&lt;lena+lenb;i++)</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(c[i]&gt;<span class=\"number\">9</span>)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        c[i<span class=\"number\">+1</span>]+=c[i]/<span class=\"number\">10</span>;</span><br><span class=\"line\">        c[i]%=<span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">len=lena+lenb;</span><br><span class=\"line\"><span class=\"keyword\">while</span>(c[len]==<span class=\"number\">0</span>&amp;&amp;len&gt;<span class=\"number\">1</span>)len--;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>${a}_1,{a}<em>2,,{a}</em>{n-1},{a}_n$</p>\n<p>${S}_i&#x3D;a_1+a_2++a_i$</p>\n<p>1$S_0&#x3D;0$</p>\n<p>$S_i$: $S_i &#x3D; S_{i-1}+a_i$</p>\n<p><strong></strong></p>\n<p></p>\n<p>$[l,r]$</p>\n<p>$\\sum_{i&#x3D;l}^{r}a_i &#x3D; S_r-S_{l-1}$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$\\begin{pmatrix} a_{11}&amp; a_{12} &amp;  &amp; a_{1j}\\ a_{21}&amp; a_{22} &amp;  &amp; a_{2j} \\ &amp;  &amp;  &amp; \\ a_{i1}&amp; a_{i2} &amp;  &amp; a_{ij} \\end{pmatrix}$</p>\n<p>$S_{ij}$$a_{ij}$</p>\n<ul>\n<li><p>$(i,j)$$S_{ij}$</p>\n<p>$S_{ij}&#x3D;S_{i-1,j}+S_{i,j-1}-S_{i-1,j-1}+a_{i,j}$</p>\n</li>\n<li><p>$(x_1,y_1)$$(x_2,y_2)$<br>$S&#x3D;S_{x_2,y_2}-S_{x_2,y_1-1}-S_{x_1-1,y_2}+S_{x_1-1,y_1-1}$</p>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$a_1,a_2,a_3,,a_i$</p>\n<p>$b_1,b_2,b_3,,b_i$$a_i&#x3D;b_1+b_2++b_i$</p>\n<p>$a$$b$$b$$a$</p>\n<p>$\\left{\\begin{matrix} b_1&#x3D;a_1\\ b_2&#x3D;a_2-a_1\\ b_3&#x3D;a_3-a_2\\ \\ b_n&#x3D;a_n-a_{n-1} \\end{matrix}\\right.$</p>\n<p><strong></strong></p>\n<p>$a_1,a_2,a_3,,a_i$$[l,r]$$a$$c$</p>\n<p>$b_l+&#x3D;c,b_{r+1}-&#x3D;c$</p>\n<p><strong></strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> java.util.Scanner;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">Diff</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">main</span><span class=\"params\">(String[] args)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">Scanner</span> <span class=\"variable\">scanner</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Scanner</span>(System.in);</span><br><span class=\"line\">        <span class=\"comment\">// nk</span></span><br><span class=\"line\">        <span class=\"type\">int</span> <span class=\"variable\">n</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\">        <span class=\"type\">int</span> <span class=\"variable\">k</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"type\">int</span>[] arr = <span class=\"keyword\">new</span> <span class=\"title class_\">int</span>[n+<span class=\"number\">1</span>];</span><br><span class=\"line\">        <span class=\"type\">int</span>[] brr = <span class=\"keyword\">new</span> <span class=\"title class_\">int</span>[n+<span class=\"number\">1</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// arr</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> <span class=\"number\">1</span>; i &lt; n+<span class=\"number\">1</span>; i++) &#123;</span><br><span class=\"line\">            arr[i] = scanner.nextInt();</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// brr</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> <span class=\"number\">1</span>; i &lt; n+<span class=\"number\">1</span>; i++)&#123;</span><br><span class=\"line\">            brr[i] = arr[i] - arr[i-<span class=\"number\">1</span>];</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (k-- &gt; <span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">            <span class=\"comment\">// arr[l,r]c</span></span><br><span class=\"line\">            <span class=\"type\">int</span> <span class=\"variable\">l</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\">            <span class=\"type\">int</span> <span class=\"variable\">r</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\">            <span class=\"type\">int</span> <span class=\"variable\">c</span> <span class=\"operator\">=</span> scanner.nextInt();</span><br><span class=\"line\"></span><br><span class=\"line\">            brr[l] += c;</span><br><span class=\"line\">            brr[r+<span class=\"number\">1</span>] -= c;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// ba</span></span><br><span class=\"line\">        <span class=\"comment\">// arr</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> <span class=\"number\">1</span>; i &lt; n+<span class=\"number\">1</span>; i++) &#123;</span><br><span class=\"line\">            brr[i] += brr[i-<span class=\"number\">1</span>];</span><br><span class=\"line\">            <span class=\"comment\">//arr[i] = brr[i]+arr[i-1];</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> <span class=\"variable\">i</span> <span class=\"operator\">=</span> <span class=\"number\">1</span>; i &lt; n+<span class=\"number\">1</span>; i++) &#123;</span><br><span class=\"line\">            System.out.println(brr[i]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$a_{ij}$,$b_{ij}$</p>\n<p>$b_{x1,y1}+&#x3D;c$</p>\n<p>$b_{x2+1,y1}-&#x3D;c$</p>\n<p>$b_{x1,y2+1}-&#x3D;c$</p>\n<p>$b_{x2+1,y2+1}+&#x3D;c$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li></li>\n<li><strong></strong></li>\n</ul>\n<p><strong></strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">0</span>,j=<span class=\"number\">0</span>;i&lt;n;i++)&#123;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(j&lt;i &amp;&amp; <span class=\"built_in\">check</span>(i,j)) j++;</span><br><span class=\"line\">    <span class=\"comment\">//</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong></strong></p>\n<p>$O(n^2)$$O(n)$</p>\n<p>ij</p>\n<p><a href=\"https://www.luogu.com.cn/problem/P1102\">A-B</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>01</p>\n<p>8-128~127</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><blockquote>\n<p></p>\n</blockquote>\n<p>&amp;</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1&amp;1 //1</span><br><span class=\"line\">1&amp;0 //0</span><br><span class=\"line\">0&amp;0 //0</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p></p>\n</blockquote>\n<p>|</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1|1 //1</span><br><span class=\"line\">1|0 //1</span><br><span class=\"line\">0|0 //0</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p></p>\n</blockquote>\n<p>~1001</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~1 //11111110</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p></p>\n</blockquote>\n<p>0</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a=11;</span><br><span class=\"line\">a&lt;&lt;<span class=\"string\">1;</span></span><br><span class=\"line\"><span class=\"string\">0000 1011</span></span><br><span class=\"line\"><span class=\"string\">0001 011022</span></span><br></pre></td></tr></table></figure>\n\n<p>12n2n</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p>001</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">a=16;</span><br><span class=\"line\">a&gt;&gt;3;</span><br><span class=\"line\">0001 0000</span><br><span class=\"line\">0000 00102</span><br><span class=\"line\"></span><br><span class=\"line\">b=32;</span><br><span class=\"line\">a&gt;&gt;3;</span><br><span class=\"line\">0010 0000</span><br><span class=\"line\">0000 01004</span><br><span class=\"line\"></span><br><span class=\"line\">b=-32;</span><br><span class=\"line\">b&gt;&gt;3;</span><br><span class=\"line\">1010 0000</span><br><span class=\"line\">1000 0100-4</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>nk</li>\n</ul>\n<p>k0,1,2</p>\n<ol>\n<li><p>k<code>n&gt;&gt;k</code></p>\n</li>\n<li><p> <code>x&amp;1</code></p>\n<p><strong>n&gt;&gt;k&amp;1</strong></p>\n</li>\n</ol>\n<ul>\n<li><p>lowbit(x)</p>\n<p>x1</p>\n<p><strong>x&amp;(-x)</strong></p>\n<p><code>-x=(~x+1)</code></p>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p></p>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<ul>\n<li>$max$</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n</ul>\n<p><strong>C++</strong></p>\n</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">merge</span><span class=\"params\">(vector&lt;PII&gt; &amp;segs)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;PII&gt; res;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">sort</span>(segs.<span class=\"built_in\">begin</span>(), segs.<span class=\"built_in\">end</span>());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> st = <span class=\"number\">-2e9</span>, ed = <span class=\"number\">-2e9</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">auto</span> seg : segs)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (ed &lt; seg.first)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (st != <span class=\"number\">-2e9</span>) res.<span class=\"built_in\">push_back</span>(&#123;st, ed&#125;);</span><br><span class=\"line\">            st = seg.first, ed = seg.second;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> ed = <span class=\"built_in\">max</span>(ed, seg.second);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (st != <span class=\"number\">-2e9</span>) res.<span class=\"built_in\">push_back</span>(&#123;st, ed&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">    segs = res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"Algorithm-DP","mathjax":true,"date":"2023-09-13T12:46:25.000Z","img":"https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg","excerpt":"","_content":"\n### \n\n- \n\n  $f[i,j]$\n\n  - \n  - MaxMinCnt\n\n- \n\n  - \n\n### DP\n\n**[](https://www.luogu.com.cn/problem/P1216)**\n\n$O(n^2)$\n\n$f[i,j]$$[i,j]$\n\n$f[1][1] = a[1][1]$\n\n$f[i][j] = max(f[i-1][j-1]+a[i][j], f[i-1][j]+a[i][j])$\n\n**[](https://www.luogu.com.cn/problem/B3637)**\n\n****$O(n^2)$\n\n$f[i]$$i$\n\n$a_i$$a_j$($a_j<a_i$$0 \\le j \\le i-1$)\n\n$f[i] = max(f[j]+1,f[i]),j \\in [0,i-1]$\n\n$g[i]$$j$\n\nhttps://www.luogu.com.cn/record/124595657\n\n****$O(nlogn)$\n\nqi\n\n$q_i>q_{i-1}>...>q_2>q_1$\n\n$a_i$$q_k<=a_i$$f[i] = k+1$$q_k = a_i$\n\nhttps://www.luogu.com.cn/record/133704642\n\n**[](https://www.luogu.com.cn/problem/P1439)**\n\n****$O(n^2)$\n\n$f[i][j]$ij\n\n$a[i],b[j]$\n\n$a[i],b[j]$ ; $a[i]$ $b[j]$ ; $a[j]$$b[j]$ ; $a[i],b[j]$\n\n $f[i-1][j-1] , f[i,j-1] , f[i-1][j] , f[i-1][j-1]+1$\n\n****Max\n\n\n\n$f[i,j] = max(f[i-1,j],f[i,j-1])$\n\n$a[i]==b[j]$,$f[i,j] = max(f[i,j],f[i-1,j-1]+1)$\n\n****$O(nlogn)$\n\n**[](https://www.luogu.com.cn/problem/P2758)**\n\n$f[i,j]$$a[1-i]$$b[1-j]$\n\n\n\n $f[i-1,j]+1$\n\n$f[i,j-1]+1$\n\n$f[i-1,j-1]+1$ $a[i]==b[j]$\n\n### DP\n\n**[](https://www.acwing.com/problem/content/284/)**\n\n$f[i,j]$$i$$j$/\n\n$O(n^3)$\n\n```cpp\nfor(int len=2;len<=n;len++){\n    for(int i=1;i+len-1<=n;i++){\n        int l = i,r = i+len-1;\n        f_max[l][r] = -1e8,f_min[l][r] = 1e8;\n        for(int k=l;k<r;k++){\n            f_max[l][r] = max(f_max[l][r],f_max[l][k]+f_max[k+1][r]+s[r]-s[l-1]);\n            f_min[l][r] = min(f_min[l][r],f_min[l][k]+f_min[k+1][r]+s[r]-s[l-1]);\n        }\n    }\n}\n```\n\n### DP\n\n### DP\n\n**[](https://www.acwing.com/problem/content/340/)**\n\n$n=abcdefg$$i$ $x \\in [0,9]$\n\n$x=1,i=4$\n\n$xxx1yyy$\n\n- $abc>xxx,xxx \\in [000,abc-1], y \\in [000,999]$$abc * 1000$\n\n- $abc<xxx$0\n\n- \n\n  $abc=xxx$\n\n  - $d<1$\n  - $d=1$$yyy \\in [000,efg]$,$efg+1$\n  - $d>1$$yyy \\in [000,999]$,1000\n\n**x=00$xxx \\in [001,abc-1]$**$(abc-1)*1000$\n\n**[](https://www.acwing.com/problem/content/341/)**\n\n### DP\n\n**[](https://www.acwing.com/problem/content/293/)**\n\n$f[i][j]$ij,j\n\n**[Hamilton](https://www.acwing.com/problem/content/93/)**\n\n$f[i][j]$0ji(i)\n\n### DP\n\n**[](https://www.acwing.com/problem/content/287/)**\n\n$f[u][0]$uu\n\n$f[u][1]$uu\n\nu$s_1,s_2,s_3....s_i$\n\n$f[u][0] = \\sum_{1}^{i}max(f[s_i][0],f[s_i][1])$\n\n$f[u][1] = \\sum_{1}^{i}f[s_i][0]$\n\n\n\n### \n\n**[](https://www.luogu.com.cn/problem/P1434)**\n\n$s[i][j]$(i,j)\n\n\n\n\n\n```none\n3 3 \n1 1 3\n2 3 4\n1 1 1\n```\n\n(1,1)1\n\n(1,2)1\n\n(1,3)2((1,3)->(1,2))\n\n(2,1)2((2,1)->(1,1))\n\n(2,2)(2,2)->(2,1)->(1,1)\n\n2,1(2,1)2(2,2)->(2,1),3\n\n### \n\n$n$$v$$v_i$$w_i$$\\sum_{i=1}^{n} v_i \\le v$$w$\n\n#### 01\n\n0/1\n\n$f[i,j] = max(f[i-1,j],f[i-1,j-v_i]+w_i)$\n\n[01](https://www.acwing.com/problem/content/2/)\n\n[](https://www.luogu.com.cn/problem/P1048)\n\n#### \n\n\n\n$f[i,j] = Max(f[i-1,j-v_i \\times k]+w[i] \\times k)$\n\n$k \\subseteq [0,\\frac{j}{v_i}]$\n\n$f[i,j] = Max(f[i-1,j],f[i-1,j-v_i]+w_i,f[i-1,j-2v_i]+2w_i,....,f[i-1][j-kv_i]+kw_i)$\n\n$f[i,j-v_i] = Max(f[i-1][j-v_i],f[i-1][j-2v_i]+w_i,...,f[i-1][j-kv_i]+(k-1)w_i)$\n\n$f[i][j]$$k$$f[i][j-v_i]+w_i$\n\n\n\n$f[i,j] = Max(f[i-1,j],f[i,j-v_i]+w_i)$\n\n[](https://www.acwing.com/problem/content/3/)\n\n#### \n\n\n\n\n\n$f[i,j] = Max(f[i-1,j],f[i-1,j-v_i]+w_i,f[i-1,j-2v_i]+2w_i,....,f[i-1][j-kv_i]+kw_i)$\n\n$k \\subseteq [0,s_i]$\n\n\n\n[1](https://www.acwing.com/problem/content/4/)\n\n****\n\n```cpp\nfor(int i=1;i<=n;i++){\n    int a,b,s;\n    cin>>a>>b>>s;\n    //v w s;\n    int k = 1;\n    while(k<=s){\n        cnt++;\n        v[cnt] = a*k;\n        w[cnt] = b*k;\n        s-=k;\n        k*=2;\n    }\n    if(s>0){\n        cnt++;\n        v[cnt] = a*s;\n        w[cnt] = b*s;\n    }\n}\n```\n\n$cnt$01\n\n```cpp\nn = cnt;\nfor(int i=1;i<=n;i++){\n    for(int j=0;j<=m;j++){\n        f[i][j] = f[i-1][j];\n        if(j>=v[i]) f[i][j] = max(f[i][j],f[i-1][j-v[i]]+w[i]);\n    }\n}\ncout<<f[n][m]<<endl;\n```\n\n[2](https://www.acwing.com/problem/content/5/)\n\n#### \n\n$N$\n\n$f[i][j] = Max(f[i-1,j],f[i-1,j-v_{i,k}]+w_{i,k})$\n\n[](https://www.acwing.com/problem/content/9/)\n\n\n\n","source":"_posts/algorithm-dp.md","raw":"---\ntitle: Algorithm-DP\nmathjax: true\ndate: 2023/09/13 20:46:25\nimg: https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg\nexcerpt: \n---\n\n### \n\n- \n\n  $f[i,j]$\n\n  - \n  - MaxMinCnt\n\n- \n\n  - \n\n### DP\n\n**[](https://www.luogu.com.cn/problem/P1216)**\n\n$O(n^2)$\n\n$f[i,j]$$[i,j]$\n\n$f[1][1] = a[1][1]$\n\n$f[i][j] = max(f[i-1][j-1]+a[i][j], f[i-1][j]+a[i][j])$\n\n**[](https://www.luogu.com.cn/problem/B3637)**\n\n****$O(n^2)$\n\n$f[i]$$i$\n\n$a_i$$a_j$($a_j<a_i$$0 \\le j \\le i-1$)\n\n$f[i] = max(f[j]+1,f[i]),j \\in [0,i-1]$\n\n$g[i]$$j$\n\nhttps://www.luogu.com.cn/record/124595657\n\n****$O(nlogn)$\n\nqi\n\n$q_i>q_{i-1}>...>q_2>q_1$\n\n$a_i$$q_k<=a_i$$f[i] = k+1$$q_k = a_i$\n\nhttps://www.luogu.com.cn/record/133704642\n\n**[](https://www.luogu.com.cn/problem/P1439)**\n\n****$O(n^2)$\n\n$f[i][j]$ij\n\n$a[i],b[j]$\n\n$a[i],b[j]$ ; $a[i]$ $b[j]$ ; $a[j]$$b[j]$ ; $a[i],b[j]$\n\n $f[i-1][j-1] , f[i,j-1] , f[i-1][j] , f[i-1][j-1]+1$\n\n****Max\n\n\n\n$f[i,j] = max(f[i-1,j],f[i,j-1])$\n\n$a[i]==b[j]$,$f[i,j] = max(f[i,j],f[i-1,j-1]+1)$\n\n****$O(nlogn)$\n\n**[](https://www.luogu.com.cn/problem/P2758)**\n\n$f[i,j]$$a[1-i]$$b[1-j]$\n\n\n\n $f[i-1,j]+1$\n\n$f[i,j-1]+1$\n\n$f[i-1,j-1]+1$ $a[i]==b[j]$\n\n### DP\n\n**[](https://www.acwing.com/problem/content/284/)**\n\n$f[i,j]$$i$$j$/\n\n$O(n^3)$\n\n```cpp\nfor(int len=2;len<=n;len++){\n    for(int i=1;i+len-1<=n;i++){\n        int l = i,r = i+len-1;\n        f_max[l][r] = -1e8,f_min[l][r] = 1e8;\n        for(int k=l;k<r;k++){\n            f_max[l][r] = max(f_max[l][r],f_max[l][k]+f_max[k+1][r]+s[r]-s[l-1]);\n            f_min[l][r] = min(f_min[l][r],f_min[l][k]+f_min[k+1][r]+s[r]-s[l-1]);\n        }\n    }\n}\n```\n\n### DP\n\n### DP\n\n**[](https://www.acwing.com/problem/content/340/)**\n\n$n=abcdefg$$i$ $x \\in [0,9]$\n\n$x=1,i=4$\n\n$xxx1yyy$\n\n- $abc>xxx,xxx \\in [000,abc-1], y \\in [000,999]$$abc * 1000$\n\n- $abc<xxx$0\n\n- \n\n  $abc=xxx$\n\n  - $d<1$\n  - $d=1$$yyy \\in [000,efg]$,$efg+1$\n  - $d>1$$yyy \\in [000,999]$,1000\n\n**x=00$xxx \\in [001,abc-1]$**$(abc-1)*1000$\n\n**[](https://www.acwing.com/problem/content/341/)**\n\n### DP\n\n**[](https://www.acwing.com/problem/content/293/)**\n\n$f[i][j]$ij,j\n\n**[Hamilton](https://www.acwing.com/problem/content/93/)**\n\n$f[i][j]$0ji(i)\n\n### DP\n\n**[](https://www.acwing.com/problem/content/287/)**\n\n$f[u][0]$uu\n\n$f[u][1]$uu\n\nu$s_1,s_2,s_3....s_i$\n\n$f[u][0] = \\sum_{1}^{i}max(f[s_i][0],f[s_i][1])$\n\n$f[u][1] = \\sum_{1}^{i}f[s_i][0]$\n\n\n\n### \n\n**[](https://www.luogu.com.cn/problem/P1434)**\n\n$s[i][j]$(i,j)\n\n\n\n\n\n```none\n3 3 \n1 1 3\n2 3 4\n1 1 1\n```\n\n(1,1)1\n\n(1,2)1\n\n(1,3)2((1,3)->(1,2))\n\n(2,1)2((2,1)->(1,1))\n\n(2,2)(2,2)->(2,1)->(1,1)\n\n2,1(2,1)2(2,2)->(2,1),3\n\n### \n\n$n$$v$$v_i$$w_i$$\\sum_{i=1}^{n} v_i \\le v$$w$\n\n#### 01\n\n0/1\n\n$f[i,j] = max(f[i-1,j],f[i-1,j-v_i]+w_i)$\n\n[01](https://www.acwing.com/problem/content/2/)\n\n[](https://www.luogu.com.cn/problem/P1048)\n\n#### \n\n\n\n$f[i,j] = Max(f[i-1,j-v_i \\times k]+w[i] \\times k)$\n\n$k \\subseteq [0,\\frac{j}{v_i}]$\n\n$f[i,j] = Max(f[i-1,j],f[i-1,j-v_i]+w_i,f[i-1,j-2v_i]+2w_i,....,f[i-1][j-kv_i]+kw_i)$\n\n$f[i,j-v_i] = Max(f[i-1][j-v_i],f[i-1][j-2v_i]+w_i,...,f[i-1][j-kv_i]+(k-1)w_i)$\n\n$f[i][j]$$k$$f[i][j-v_i]+w_i$\n\n\n\n$f[i,j] = Max(f[i-1,j],f[i,j-v_i]+w_i)$\n\n[](https://www.acwing.com/problem/content/3/)\n\n#### \n\n\n\n\n\n$f[i,j] = Max(f[i-1,j],f[i-1,j-v_i]+w_i,f[i-1,j-2v_i]+2w_i,....,f[i-1][j-kv_i]+kw_i)$\n\n$k \\subseteq [0,s_i]$\n\n\n\n[1](https://www.acwing.com/problem/content/4/)\n\n****\n\n```cpp\nfor(int i=1;i<=n;i++){\n    int a,b,s;\n    cin>>a>>b>>s;\n    //v w s;\n    int k = 1;\n    while(k<=s){\n        cnt++;\n        v[cnt] = a*k;\n        w[cnt] = b*k;\n        s-=k;\n        k*=2;\n    }\n    if(s>0){\n        cnt++;\n        v[cnt] = a*s;\n        w[cnt] = b*s;\n    }\n}\n```\n\n$cnt$01\n\n```cpp\nn = cnt;\nfor(int i=1;i<=n;i++){\n    for(int j=0;j<=m;j++){\n        f[i][j] = f[i-1][j];\n        if(j>=v[i]) f[i][j] = max(f[i][j],f[i-1][j-v[i]]+w[i]);\n    }\n}\ncout<<f[n][m]<<endl;\n```\n\n[2](https://www.acwing.com/problem/content/5/)\n\n#### \n\n$N$\n\n$f[i][j] = Max(f[i-1,j],f[i-1,j-v_{i,k}]+w_{i,k})$\n\n[](https://www.acwing.com/problem/content/9/)\n\n\n\n","slug":"algorithm-dp","published":1,"updated":"2025-02-28T03:06:38.010Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff30005ss9918ti3ycc","content":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n<p>$f[i,j]$</p>\n<ul>\n<li></li>\n<li>MaxMinCnt</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.luogu.com.cn/problem/P1216\"></a></strong></p>\n<p>$O(n^2)$</p>\n<p>$f[i,j]$$[i,j]$</p>\n<p>$f[1][1] &#x3D; a[1][1]$</p>\n<p>$f[i][j] &#x3D; max(f[i-1][j-1]+a[i][j], f[i-1][j]+a[i][j])$</p>\n<p><strong><a href=\"https://www.luogu.com.cn/problem/B3637\"></a></strong></p>\n<p><strong></strong>$O(n^2)$</p>\n<p>$f[i]$$i$</p>\n<p>$a_i$$a_j$($a_j&lt;a_i$$0 \\le j \\le i-1$)</p>\n<p>$f[i] &#x3D; max(f[j]+1,f[i]),j \\in [0,i-1]$</p>\n<p>$g[i]$$j$</p>\n<p><a href=\"https://www.luogu.com.cn/record/124595657\">https://www.luogu.com.cn/record/124595657</a></p>\n<p><strong></strong>$O(nlogn)$</p>\n<p>qi</p>\n<p>$q_i&gt;q_{i-1}&gt;&gt;q_2&gt;q_1$</p>\n<p>$a_i$$q_k&lt;&#x3D;a_i$$f[i] &#x3D; k+1$$q_k &#x3D; a_i$</p>\n<p><a href=\"https://www.luogu.com.cn/record/133704642\">https://www.luogu.com.cn/record/133704642</a></p>\n<p><strong><a href=\"https://www.luogu.com.cn/problem/P1439\"></a></strong></p>\n<p><strong></strong>$O(n^2)$</p>\n<p>$f[i][j]$ij</p>\n<p>$a[i],b[j]$</p>\n<p>$a[i],b[j]$ ; $a[i]$ $b[j]$ ; $a[j]$$b[j]$ ; $a[i],b[j]$</p>\n<p> $f[i-1][j-1] , f[i,j-1] , f[i-1][j] , f[i-1][j-1]+1$</p>\n<p><strong></strong>Max</p>\n<p></p>\n<p>$f[i,j] &#x3D; max(f[i-1,j],f[i,j-1])$</p>\n<p>$a[i]&#x3D;&#x3D;b[j]$,$f[i,j] &#x3D; max(f[i,j],f[i-1,j-1]+1)$</p>\n<p><strong></strong>$O(nlogn)$</p>\n<p><strong><a href=\"https://www.luogu.com.cn/problem/P2758\"></a></strong></p>\n<p>$f[i,j]$$a[1-i]$$b[1-j]$</p>\n<p></p>\n<p> $f[i-1,j]+1$</p>\n<p>$f[i,j-1]+1$</p>\n<p>$f[i-1,j-1]+1$ $a[i]&#x3D;&#x3D;b[j]$</p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.acwing.com/problem/content/284/\"></a></strong></p>\n<p>$f[i,j]$$i$$j$&#x2F;</p>\n<p>$O(n^3)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"type\">int</span> len=<span class=\"number\">2</span>;len&lt;=n;len++)&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">1</span>;i+len<span class=\"number\">-1</span>&lt;=n;i++)&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> l = i,r = i+len<span class=\"number\">-1</span>;</span><br><span class=\"line\">        f_max[l][r] = <span class=\"number\">-1e8</span>,f_min[l][r] = <span class=\"number\">1e8</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"type\">int</span> k=l;k&lt;r;k++)&#123;</span><br><span class=\"line\">            f_max[l][r] = <span class=\"built_in\">max</span>(f_max[l][r],f_max[l][k]+f_max[k<span class=\"number\">+1</span>][r]+s[r]-s[l<span class=\"number\">-1</span>]);</span><br><span class=\"line\">            f_min[l][r] = <span class=\"built_in\">min</span>(f_min[l][r],f_min[l][k]+f_min[k<span class=\"number\">+1</span>][r]+s[r]-s[l<span class=\"number\">-1</span>]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.acwing.com/problem/content/340/\"></a></strong></p>\n<p>$n&#x3D;abcdefg$$i$ $x \\in [0,9]$</p>\n<p>$x&#x3D;1,i&#x3D;4$</p>\n<p>$xxx1yyy$</p>\n<ul>\n<li><p>$abc&gt;xxx,xxx \\in [000,abc-1], y \\in [000,999]$$abc * 1000$</p>\n</li>\n<li><p>$abc&lt;xxx$0</p>\n</li>\n<li><p></p>\n<p>$abc&#x3D;xxx$</p>\n<ul>\n<li>$d&lt;1$</li>\n<li>$d&#x3D;1$$yyy \\in [000,efg]$,$efg+1$</li>\n<li>$d&gt;1$$yyy \\in [000,999]$,1000</li>\n</ul>\n</li>\n</ul>\n<p>**x&#x3D;00$xxx \\in [001,abc-1]$**$(abc-1)*1000$</p>\n<p><strong><a href=\"https://www.acwing.com/problem/content/341/\"></a></strong></p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.acwing.com/problem/content/293/\"></a></strong></p>\n<p>$f[i][j]$ij,j</p>\n<p><strong><a href=\"https://www.acwing.com/problem/content/93/\">Hamilton</a></strong></p>\n<p>$f[i][j]$0ji(i)</p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.acwing.com/problem/content/287/\"></a></strong></p>\n<p>$f[u][0]$uu</p>\n<p>$f[u][1]$uu</p>\n<p>u$s_1,s_2,s_3.s_i$</p>\n<p>$f[u][0] &#x3D; \\sum_{1}^{i}max(f[s_i][0],f[s_i][1])$</p>\n<p>$f[u][1] &#x3D; \\sum_{1}^{i}f[s_i][0]$</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong><a href=\"https://www.luogu.com.cn/problem/P1434\"></a></strong></p>\n<p>$s[i][j]$(i,j)</p>\n<p></p>\n<p></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3 3 </span><br><span class=\"line\">1 1 3</span><br><span class=\"line\">2 3 4</span><br><span class=\"line\">1 1 1</span><br></pre></td></tr></table></figure>\n\n<p>(1,1)1</p>\n<p>(1,2)1</p>\n<p>(1,3)2((1,3)-&gt;(1,2))</p>\n<p>(2,1)2((2,1)-&gt;(1,1))</p>\n<p>(2,2)(2,2)-&gt;(2,1)-&gt;(1,1)</p>\n<p>2,1(2,1)2(2,2)-&gt;(2,1),3</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$n$$v$$v_i$$w_i$$\\sum_{i&#x3D;1}^{n} v_i \\le v$$w$</p>\n<h4 id=\"01\"><a href=\"#01\" class=\"headerlink\" title=\"01\"></a>01</h4><p>0&#x2F;1</p>\n<p>$f[i,j] &#x3D; max(f[i-1,j],f[i-1,j-v_i]+w_i)$</p>\n<p><a href=\"https://www.acwing.com/problem/content/2/\">01</a></p>\n<p><a href=\"https://www.luogu.com.cn/problem/P1048\"></a></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p>$f[i,j] &#x3D; Max(f[i-1,j-v_i \\times k]+w[i] \\times k)$</p>\n<p>$k \\subseteq [0,\\frac{j}{v_i}]$</p>\n<p>$f[i,j] &#x3D; Max(f[i-1,j],f[i-1,j-v_i]+w_i,f[i-1,j-2v_i]+2w_i,.,f[i-1][j-kv_i]+kw_i)$</p>\n<p>$f[i,j-v_i] &#x3D; Max(f[i-1][j-v_i],f[i-1][j-2v_i]+w_i,,f[i-1][j-kv_i]+(k-1)w_i)$</p>\n<p>$f[i][j]$$k$$f[i][j-v_i]+w_i$</p>\n<p></p>\n<p>$f[i,j] &#x3D; Max(f[i-1,j],f[i,j-v_i]+w_i)$</p>\n<p><a href=\"https://www.acwing.com/problem/content/3/\"></a></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p></p>\n<p>$f[i,j] &#x3D; Max(f[i-1,j],f[i-1,j-v_i]+w_i,f[i-1,j-2v_i]+2w_i,.,f[i-1][j-kv_i]+kw_i)$</p>\n<p>$k \\subseteq [0,s_i]$</p>\n<p></p>\n<p><a href=\"https://www.acwing.com/problem/content/4/\">1</a></p>\n<p><strong></strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">1</span>;i&lt;=n;i++)&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> a,b,s;</span><br><span class=\"line\">    cin&gt;&gt;a&gt;&gt;b&gt;&gt;s;</span><br><span class=\"line\">    <span class=\"comment\">//v w s;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> k = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(k&lt;=s)&#123;</span><br><span class=\"line\">        cnt++;</span><br><span class=\"line\">        v[cnt] = a*k;</span><br><span class=\"line\">        w[cnt] = b*k;</span><br><span class=\"line\">        s-=k;</span><br><span class=\"line\">        k*=<span class=\"number\">2</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(s&gt;<span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">        cnt++;</span><br><span class=\"line\">        v[cnt] = a*s;</span><br><span class=\"line\">        w[cnt] = b*s;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>$cnt$01</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">n = cnt;</span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">1</span>;i&lt;=n;i++)&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> j=<span class=\"number\">0</span>;j&lt;=m;j++)&#123;</span><br><span class=\"line\">        f[i][j] = f[i<span class=\"number\">-1</span>][j];</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j&gt;=v[i]) f[i][j] = <span class=\"built_in\">max</span>(f[i][j],f[i<span class=\"number\">-1</span>][j-v[i]]+w[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">cout&lt;&lt;f[n][m]&lt;&lt;endl;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://www.acwing.com/problem/content/5/\">2</a></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$N$</p>\n<p>$f[i][j] &#x3D; Max(f[i-1,j],f[i-1,j-v_{i,k}]+w_{i,k})$</p>\n<p><a href=\"https://www.acwing.com/problem/content/9/\"></a></p>\n","more":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n<p>$f[i,j]$</p>\n<ul>\n<li></li>\n<li>MaxMinCnt</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.luogu.com.cn/problem/P1216\"></a></strong></p>\n<p>$O(n^2)$</p>\n<p>$f[i,j]$$[i,j]$</p>\n<p>$f[1][1] &#x3D; a[1][1]$</p>\n<p>$f[i][j] &#x3D; max(f[i-1][j-1]+a[i][j], f[i-1][j]+a[i][j])$</p>\n<p><strong><a href=\"https://www.luogu.com.cn/problem/B3637\"></a></strong></p>\n<p><strong></strong>$O(n^2)$</p>\n<p>$f[i]$$i$</p>\n<p>$a_i$$a_j$($a_j&lt;a_i$$0 \\le j \\le i-1$)</p>\n<p>$f[i] &#x3D; max(f[j]+1,f[i]),j \\in [0,i-1]$</p>\n<p>$g[i]$$j$</p>\n<p><a href=\"https://www.luogu.com.cn/record/124595657\">https://www.luogu.com.cn/record/124595657</a></p>\n<p><strong></strong>$O(nlogn)$</p>\n<p>qi</p>\n<p>$q_i&gt;q_{i-1}&gt;&gt;q_2&gt;q_1$</p>\n<p>$a_i$$q_k&lt;&#x3D;a_i$$f[i] &#x3D; k+1$$q_k &#x3D; a_i$</p>\n<p><a href=\"https://www.luogu.com.cn/record/133704642\">https://www.luogu.com.cn/record/133704642</a></p>\n<p><strong><a href=\"https://www.luogu.com.cn/problem/P1439\"></a></strong></p>\n<p><strong></strong>$O(n^2)$</p>\n<p>$f[i][j]$ij</p>\n<p>$a[i],b[j]$</p>\n<p>$a[i],b[j]$ ; $a[i]$ $b[j]$ ; $a[j]$$b[j]$ ; $a[i],b[j]$</p>\n<p> $f[i-1][j-1] , f[i,j-1] , f[i-1][j] , f[i-1][j-1]+1$</p>\n<p><strong></strong>Max</p>\n<p></p>\n<p>$f[i,j] &#x3D; max(f[i-1,j],f[i,j-1])$</p>\n<p>$a[i]&#x3D;&#x3D;b[j]$,$f[i,j] &#x3D; max(f[i,j],f[i-1,j-1]+1)$</p>\n<p><strong></strong>$O(nlogn)$</p>\n<p><strong><a href=\"https://www.luogu.com.cn/problem/P2758\"></a></strong></p>\n<p>$f[i,j]$$a[1-i]$$b[1-j]$</p>\n<p></p>\n<p> $f[i-1,j]+1$</p>\n<p>$f[i,j-1]+1$</p>\n<p>$f[i-1,j-1]+1$ $a[i]&#x3D;&#x3D;b[j]$</p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.acwing.com/problem/content/284/\"></a></strong></p>\n<p>$f[i,j]$$i$$j$&#x2F;</p>\n<p>$O(n^3)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"type\">int</span> len=<span class=\"number\">2</span>;len&lt;=n;len++)&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">1</span>;i+len<span class=\"number\">-1</span>&lt;=n;i++)&#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> l = i,r = i+len<span class=\"number\">-1</span>;</span><br><span class=\"line\">        f_max[l][r] = <span class=\"number\">-1e8</span>,f_min[l][r] = <span class=\"number\">1e8</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"type\">int</span> k=l;k&lt;r;k++)&#123;</span><br><span class=\"line\">            f_max[l][r] = <span class=\"built_in\">max</span>(f_max[l][r],f_max[l][k]+f_max[k<span class=\"number\">+1</span>][r]+s[r]-s[l<span class=\"number\">-1</span>]);</span><br><span class=\"line\">            f_min[l][r] = <span class=\"built_in\">min</span>(f_min[l][r],f_min[l][k]+f_min[k<span class=\"number\">+1</span>][r]+s[r]-s[l<span class=\"number\">-1</span>]);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.acwing.com/problem/content/340/\"></a></strong></p>\n<p>$n&#x3D;abcdefg$$i$ $x \\in [0,9]$</p>\n<p>$x&#x3D;1,i&#x3D;4$</p>\n<p>$xxx1yyy$</p>\n<ul>\n<li><p>$abc&gt;xxx,xxx \\in [000,abc-1], y \\in [000,999]$$abc * 1000$</p>\n</li>\n<li><p>$abc&lt;xxx$0</p>\n</li>\n<li><p></p>\n<p>$abc&#x3D;xxx$</p>\n<ul>\n<li>$d&lt;1$</li>\n<li>$d&#x3D;1$$yyy \\in [000,efg]$,$efg+1$</li>\n<li>$d&gt;1$$yyy \\in [000,999]$,1000</li>\n</ul>\n</li>\n</ul>\n<p>**x&#x3D;00$xxx \\in [001,abc-1]$**$(abc-1)*1000$</p>\n<p><strong><a href=\"https://www.acwing.com/problem/content/341/\"></a></strong></p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.acwing.com/problem/content/293/\"></a></strong></p>\n<p>$f[i][j]$ij,j</p>\n<p><strong><a href=\"https://www.acwing.com/problem/content/93/\">Hamilton</a></strong></p>\n<p>$f[i][j]$0ji(i)</p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p><strong><a href=\"https://www.acwing.com/problem/content/287/\"></a></strong></p>\n<p>$f[u][0]$uu</p>\n<p>$f[u][1]$uu</p>\n<p>u$s_1,s_2,s_3.s_i$</p>\n<p>$f[u][0] &#x3D; \\sum_{1}^{i}max(f[s_i][0],f[s_i][1])$</p>\n<p>$f[u][1] &#x3D; \\sum_{1}^{i}f[s_i][0]$</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong><a href=\"https://www.luogu.com.cn/problem/P1434\"></a></strong></p>\n<p>$s[i][j]$(i,j)</p>\n<p></p>\n<p></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">3 3 </span><br><span class=\"line\">1 1 3</span><br><span class=\"line\">2 3 4</span><br><span class=\"line\">1 1 1</span><br></pre></td></tr></table></figure>\n\n<p>(1,1)1</p>\n<p>(1,2)1</p>\n<p>(1,3)2((1,3)-&gt;(1,2))</p>\n<p>(2,1)2((2,1)-&gt;(1,1))</p>\n<p>(2,2)(2,2)-&gt;(2,1)-&gt;(1,1)</p>\n<p>2,1(2,1)2(2,2)-&gt;(2,1),3</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$n$$v$$v_i$$w_i$$\\sum_{i&#x3D;1}^{n} v_i \\le v$$w$</p>\n<h4 id=\"01\"><a href=\"#01\" class=\"headerlink\" title=\"01\"></a>01</h4><p>0&#x2F;1</p>\n<p>$f[i,j] &#x3D; max(f[i-1,j],f[i-1,j-v_i]+w_i)$</p>\n<p><a href=\"https://www.acwing.com/problem/content/2/\">01</a></p>\n<p><a href=\"https://www.luogu.com.cn/problem/P1048\"></a></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p>$f[i,j] &#x3D; Max(f[i-1,j-v_i \\times k]+w[i] \\times k)$</p>\n<p>$k \\subseteq [0,\\frac{j}{v_i}]$</p>\n<p>$f[i,j] &#x3D; Max(f[i-1,j],f[i-1,j-v_i]+w_i,f[i-1,j-2v_i]+2w_i,.,f[i-1][j-kv_i]+kw_i)$</p>\n<p>$f[i,j-v_i] &#x3D; Max(f[i-1][j-v_i],f[i-1][j-2v_i]+w_i,,f[i-1][j-kv_i]+(k-1)w_i)$</p>\n<p>$f[i][j]$$k$$f[i][j-v_i]+w_i$</p>\n<p></p>\n<p>$f[i,j] &#x3D; Max(f[i-1,j],f[i,j-v_i]+w_i)$</p>\n<p><a href=\"https://www.acwing.com/problem/content/3/\"></a></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p></p>\n<p>$f[i,j] &#x3D; Max(f[i-1,j],f[i-1,j-v_i]+w_i,f[i-1,j-2v_i]+2w_i,.,f[i-1][j-kv_i]+kw_i)$</p>\n<p>$k \\subseteq [0,s_i]$</p>\n<p></p>\n<p><a href=\"https://www.acwing.com/problem/content/4/\">1</a></p>\n<p><strong></strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">1</span>;i&lt;=n;i++)&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> a,b,s;</span><br><span class=\"line\">    cin&gt;&gt;a&gt;&gt;b&gt;&gt;s;</span><br><span class=\"line\">    <span class=\"comment\">//v w s;</span></span><br><span class=\"line\">    <span class=\"type\">int</span> k = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span>(k&lt;=s)&#123;</span><br><span class=\"line\">        cnt++;</span><br><span class=\"line\">        v[cnt] = a*k;</span><br><span class=\"line\">        w[cnt] = b*k;</span><br><span class=\"line\">        s-=k;</span><br><span class=\"line\">        k*=<span class=\"number\">2</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(s&gt;<span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">        cnt++;</span><br><span class=\"line\">        v[cnt] = a*s;</span><br><span class=\"line\">        w[cnt] = b*s;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>$cnt$01</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">n = cnt;</span><br><span class=\"line\"><span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=<span class=\"number\">1</span>;i&lt;=n;i++)&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> j=<span class=\"number\">0</span>;j&lt;=m;j++)&#123;</span><br><span class=\"line\">        f[i][j] = f[i<span class=\"number\">-1</span>][j];</span><br><span class=\"line\">        <span class=\"keyword\">if</span>(j&gt;=v[i]) f[i][j] = <span class=\"built_in\">max</span>(f[i][j],f[i<span class=\"number\">-1</span>][j-v[i]]+w[i]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">cout&lt;&lt;f[n][m]&lt;&lt;endl;</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://www.acwing.com/problem/content/5/\">2</a></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$N$</p>\n<p>$f[i][j] &#x3D; Max(f[i-1,j],f[i-1,j-v_{i,k}]+w_{i,k})$</p>\n<p><a href=\"https://www.acwing.com/problem/content/9/\"></a></p>\n"},{"title":"","mathjax":true,"date":"2025-12-10T12:46:25.000Z","img":"https://digitaloceans.cn/wp-content/uploads/2024/07/image-8-1024x500.png","excerpt":"RethnikFun","_content":"\n\n\n\n","source":"_posts/Quantification.md","raw":"---\ntitle: \nmathjax: true\ndate: 2025/12/10 20:46:25\nimg: https://digitaloceans.cn/wp-content/uploads/2024/07/image-8-1024x500.png\nexcerpt: RethnikFun\n---\n\n\n\n\n","slug":"Quantification","published":1,"updated":"2025-12-10T03:43:01.061Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff40007ss9922zzhn1s","content":"","more":""},{"title":"Algorithm-Math","mathjax":true,"date":"2023-09-07T12:46:25.000Z","img":"https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg","excerpt":"","_content":"\n### \n\n****\n\n#### \n\n$O(\\sqrt n)$\n\n```cpp\nbool is_prime(int x)\n{\n    if (x < 2) return false;\n    for (int i = 2; i <= x / i; i ++ )\n        if (x % i == 0)\n            return false;\n    return true;\n}\n```\n\n#### \n\n```cpp\nN = p1^c1 * p2^c2 * ... *pk^ck\n```\n\n\n\n$(p,c)$\n\n```cpp\nvoid divide(int x)\n{\n    // nsqrt(n)\n    // sqrt(t) O(sqrt(n))\n    for (int i = 2; i <= x / i; i ++ )\n        if (x % i == 0)\n        {\n            int c = 0;\n            while (x % i == 0) x /= i, c ++ ;\n            cout << i << ' ' << c << endl;\n        }\n    if (x > 1) cout << x << ' ' << 1 << endl;\n    cout << endl;\n}\n```\n\n#### \n\n\n\n\n\n$O(nloglogn)$\n\n1-n$\\frac{n}{ln_{}{n}}$\n\n```cpp\nint primes[N], cnt;     // primes[]\nbool st[N];         // st[x]x\n\nvoid get_primes(int n)\n{\n    for (int i = 2; i <= n; i ++ )\n    {\n        if (st[i]) continue;\n        primes[cnt ++ ] = i;\n        for (int j = i + i; j <= n; j += i)\n            st[j] = true;\n    }\n}\n```\n\n#### \n\n$n$\n\n$O(n)$\n\n```cpp\nint primes[N], cnt;     // primes[]\nbool st[N];         // st[x]x\n\nvoid get_primes(int n)\n{\n    for (int i = 2; i <= n; i ++ )\n    {\n        if (!st[i]) primes[cnt ++ ] = i;\n        for (int j = 0; primes[j] <= n / i; j ++ )\n        {\n            st[primes[j] * i] = true;\n            if (i % primes[j] == 0) break; //primes[j]i\n        }\n    }\n}\n```\n\n### \n\n#### \n\n$O(\\sqrt{n})$\n\n```cpp\nvector<int> get_divisors(int x)\n{\n    vector<int> res;\n    for (int i = 1; i <= x / i; i ++ )\n        if (x % i == 0)\n        {\n            res.push_back(i);\n            if (i != x / i) res.push_back(x / i); //push4*4=16\n        }\n    sort(res.begin(), res.end());\n    return res;\n}\n```\n\n#### \n\n N = p1^c1 * p2^c2 *  *pk^ck\n (c1 + 1) * (c2 + 1) *  * (ck + 1)\n (p1^0 + p1^1 +  + p1^c1) *  * (pk^0 + pk^1 +  + pk^ck)\n\n#### \n\n```cpp\nint gcd(int a, int b)\n{\n    return b ? gcd(b, a % b) : a;\n}\n```\n\n`__gcd(int a, int b)`=$\\frac{a  b}{gcd(a,b)}$\n\n### \n\n$\\phi(n)$1-nn\n\n$\\phi(n) = n*(1-\\frac{1}{p_1})*(1-\\frac{1}{p_2})*...*(1-\\frac{1}{p_n})$\n\n```cpp\nint phi(int x)\n{\n    int res = x;\n    for (int i = 2; i <= x / i; i ++ )\n        if (x % i == 0)\n        {\n            res = res / i * (i - 1);\n            while (x % i == 0) x /= i;\n        }\n    if (x > 1) res = res / x * (x - 1);\n\n    return res;\n}\n```\n\n#### \n\n```cpp\nint primes[N], cnt;     // primes[]\nint euler[N];           // \nbool st[N];         // st[x]x\n\n\nvoid get_eulers(int n)\n{\n    euler[1] = 1;\n    for (int i = 2; i <= n; i ++ )\n    {\n        if (!st[i])\n        {\n            primes[cnt ++ ] = i;\n            euler[i] = i - 1;\n        }\n        for (int j = 0; primes[j] <= n / i; j ++ )\n        {\n            int t = primes[j] * i;\n            st[t] = true;\n            if (i % primes[j] == 0)\n            {\n                euler[t] = euler[i] * primes[j];\n                break;\n            }\n            euler[t] = euler[i] * (primes[j] - 1);\n        }\n    }\n}\n```\n\n#### \n\n$a$$n$\n\n$a^{\\phi{(n)}} \\equiv 1 (mod \\ n)$\n\n### \n\n$O(logk)$$a^k mod p$\n\n```cpp\nint qmi(int m, int k, int p)\n{\n    int res = 1 % p, t = m;\n    while (k)\n    {\n        if (k&1) res = res * t % p;\n        t = t * t % p;\n        k >>= 1;\n    }\n    return res;\n}\n```\n\n### \n\n$a,b$$x,y$\n\n$ax+by = gcd(a,b)$\n\n```cpp\n// x, yax + by = gcd(a, b)\nint exgcd(int a, int b, int &x, int &y)\n{\n    if (!b)\n    {\n        x = 1; y = 0;\n        return a;\n    }\n    int d = exgcd(b, a % b, y, x);\n    y -= (a/b) * x;\n    return d;\n}\n```\n\n### \n\n$m_1,m_2,m_3,m_k$\n\n$x \\equiv a_1 (mod \\ m_1)$\n\n$x \\equiv a_2 (mod \\ m_2)$\n\n$...$\n\n$x \\equiv a_k (mod \\ m_k)$\n\n$M = m_1 * m_2*...*m_k$\n\n$M_i = \\frac{M}{m_i}$\n\n$M_i^{-1}$$M_i$$m_i$\n\n$x = a_1M_1M_1^{-1}+a_2M_1M_2^{-1}+...+a_kM_1M_k^{-1}$\n\n### \n\n$O(n^3)$\n\n```cpp\n// a[N][N]\nint gauss()\n{\n    int c, r;\n    for (c = 0, r = 0; c < n; c ++ )\n    {\n        int t = r;\n        for (int i = r; i < n; i ++ )   // \n            if (fabs(a[i][c]) > fabs(a[t][c]))\n                t = i;\n\t\t//eps 1e-6\n        if (fabs(a[t][c]) < eps) continue;\n\n        for (int i = c; i <= n; i ++ ) swap(a[t][i], a[r][i]);      // \n        for (int i = n; i >= c; i -- ) a[r][i] /= a[r][c];      // 1\n        for (int i = r + 1; i < n; i ++ )       // 0\n            if (fabs(a[i][c]) > eps)\n                for (int j = n; j >= c; j -- )\n                    a[i][j] -= a[r][j] * a[i][c];\n\n        r ++ ;\n    }\n\n    if (r < n)\n    {\n        for (int i = r; i < n; i ++ )\n            if (fabs(a[i][n]) > eps)\n                return 2; // \n        return 1; // \n    }\n`\n    for (int i = n - 1; i >= 0; i -- )\n        for (int j = i + 1; j < n; j ++ )\n            //\n            a[i][n] -= a[i][j] * a[j][n];\n\n    return 0; // \n}\n```\n\n### \n\n- $1 \\le b \\le a \\le 2000$  $N^2$\n- $1 \\le b \\le a \\le 10^5$  $NlogN$\n- $1 \\le b \\le a \\le 10^{18}, 1 \\le p \\le 10^5$ Lucas\n- \n\n$C_{n}^{m}=\\frac{n!}{m!(n-m)!} $\n\n#### \n\n```cpp\nLL C(int a,int b){\n    LL res = 1;\n    for(int i=a,j=1;j<=b;i--,j++){\n        res = res*i/j;\n    }\n    return res;\n}\n```\n\n#### \n\n$C_{a}^{b} = C_{a-1}^{b} + C_{a-1}^{b-1}$\n\n```cpp\n// c[a][b] ab\nfor (int i = 0; i < N; i ++ )\n    for (int j = 0; j <= i; j ++ )\n        if (!j) c[i][j] = 1;\n        else c[i][j] = (c[i - 1][j] + c[i - 1][j - 1]) % mod;\n```\n\n#### \n\n```cpp\nfact[N]infact[N]\n\nint qmi(int a, int k, int p)    // \n{\n    int res = 1;\n    while (k)\n    {\n        if (k & 1) res = (LL)res * a % p;\n        a = (LL)a * a % p;\n        k >>= 1;\n    }\n    return res;\n}\n\n// \nfact[0] = infact[0] = 1;\nfor (int i = 1; i < N; i ++ )\n{\n    fact[i] = (LL)fact[i - 1] * i % mod;\n    infact[i] = (LL)infact[i - 1] * qmi(i, mod - 2, mod) % mod;\n}\n```\n\n#### Lucas\n\n```cpp\np 1 <= m <= n\n    C(n, m) = C(n % p, m % p) * C(n / p, m / p) (mod p)\n\nint qmi(int a, int k, int p)  // \n{\n    int res = 1 % p;\n    while (k)\n    {\n        if (k & 1) res = (LL)res * a % p;\n        a = (LL)a * a % p;\n        k >>= 1;\n    }\n    return res;\n}\n\nint C(int a, int b, int p)  // C(a, b)\n{\n    if (a < b) return 0;\n\n    LL x = 1, y = 1;  // xy\n    for (int i = a, j = 1; j <= b; i --, j ++ )\n    {\n        x = (LL)x * i % p;\n        y = (LL) y * j % p;\n    }\n\n    return x * (LL)qmi(y, p - 2, p) % p;\n}\n\nint lucas(LL a, LL b, int p)\n{\n    if (a < p && b < p) return C(a, b, p);\n    return (LL)C(a % p, b % p, p) * lucas(a / p, b / p, p) % p;\n}\n```\n\n#### \n\n```cpp\n\n    1. \n    2.  C(a, b) = a! / b! / (a - b)!  n! p n / p + n / p^2 + n / p^3 + ...\n    3. \n\nint primes[N], cnt;     // \nint sum[N];     // \nbool st[N];     // \n\n\nvoid get_primes(int n)      // \n{\n    for (int i = 2; i <= n; i ++ )\n    {\n        if (!st[i]) primes[cnt ++ ] = i;\n        for (int j = 0; primes[j] <= n / i; j ++ )\n        {\n            st[primes[j] * i] = true;\n            if (i % primes[j] == 0) break;\n        }\n    }\n}\n\n\nint get(int n, int p)       // n\n{\n    int res = 0;\n    while (n)\n    {\n        res += n / p;\n        n /= p;\n    }\n    return res;\n}\n\n\nvector<int> mul(vector<int> a, int b)       // \n{\n    vector<int> c;\n    int t = 0;\n    for (int i = 0; i < a.size(); i ++ )\n    {\n        t += a[i] * b;\n        c.push_back(t % 10);\n        t /= 10;\n    }\n\n    while (t)\n    {\n        c.push_back(t % 10);\n        t /= 10;\n    }\n\n    return c;\n}\n\nget_primes(a);  // \n\nfor (int i = 0; i < cnt; i ++ )     // \n{\n    int p = primes[i];\n    sum[i] = get(a, p) - get(b, p) - get(a - b, p);\n}\n\nvector<int> res;\nres.push_back(1);\n\nfor (int i = 0; i < cnt; i ++ )     // \n    for (int j = 0; j < sum[i]; j ++ )\n        res = mul(res, primes[i]);\n```\n\n### \n\nn0n12n01 Cat(n) = C(2n, n) / (n + 1)","source":"_posts/algorithm-math.md","raw":"---\ntitle: Algorithm-Math\nmathjax: true\ndate: 2023/09/07 20:46:25\nimg: https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg\nexcerpt: \n---\n\n### \n\n****\n\n#### \n\n$O(\\sqrt n)$\n\n```cpp\nbool is_prime(int x)\n{\n    if (x < 2) return false;\n    for (int i = 2; i <= x / i; i ++ )\n        if (x % i == 0)\n            return false;\n    return true;\n}\n```\n\n#### \n\n```cpp\nN = p1^c1 * p2^c2 * ... *pk^ck\n```\n\n\n\n$(p,c)$\n\n```cpp\nvoid divide(int x)\n{\n    // nsqrt(n)\n    // sqrt(t) O(sqrt(n))\n    for (int i = 2; i <= x / i; i ++ )\n        if (x % i == 0)\n        {\n            int c = 0;\n            while (x % i == 0) x /= i, c ++ ;\n            cout << i << ' ' << c << endl;\n        }\n    if (x > 1) cout << x << ' ' << 1 << endl;\n    cout << endl;\n}\n```\n\n#### \n\n\n\n\n\n$O(nloglogn)$\n\n1-n$\\frac{n}{ln_{}{n}}$\n\n```cpp\nint primes[N], cnt;     // primes[]\nbool st[N];         // st[x]x\n\nvoid get_primes(int n)\n{\n    for (int i = 2; i <= n; i ++ )\n    {\n        if (st[i]) continue;\n        primes[cnt ++ ] = i;\n        for (int j = i + i; j <= n; j += i)\n            st[j] = true;\n    }\n}\n```\n\n#### \n\n$n$\n\n$O(n)$\n\n```cpp\nint primes[N], cnt;     // primes[]\nbool st[N];         // st[x]x\n\nvoid get_primes(int n)\n{\n    for (int i = 2; i <= n; i ++ )\n    {\n        if (!st[i]) primes[cnt ++ ] = i;\n        for (int j = 0; primes[j] <= n / i; j ++ )\n        {\n            st[primes[j] * i] = true;\n            if (i % primes[j] == 0) break; //primes[j]i\n        }\n    }\n}\n```\n\n### \n\n#### \n\n$O(\\sqrt{n})$\n\n```cpp\nvector<int> get_divisors(int x)\n{\n    vector<int> res;\n    for (int i = 1; i <= x / i; i ++ )\n        if (x % i == 0)\n        {\n            res.push_back(i);\n            if (i != x / i) res.push_back(x / i); //push4*4=16\n        }\n    sort(res.begin(), res.end());\n    return res;\n}\n```\n\n#### \n\n N = p1^c1 * p2^c2 *  *pk^ck\n (c1 + 1) * (c2 + 1) *  * (ck + 1)\n (p1^0 + p1^1 +  + p1^c1) *  * (pk^0 + pk^1 +  + pk^ck)\n\n#### \n\n```cpp\nint gcd(int a, int b)\n{\n    return b ? gcd(b, a % b) : a;\n}\n```\n\n`__gcd(int a, int b)`=$\\frac{a  b}{gcd(a,b)}$\n\n### \n\n$\\phi(n)$1-nn\n\n$\\phi(n) = n*(1-\\frac{1}{p_1})*(1-\\frac{1}{p_2})*...*(1-\\frac{1}{p_n})$\n\n```cpp\nint phi(int x)\n{\n    int res = x;\n    for (int i = 2; i <= x / i; i ++ )\n        if (x % i == 0)\n        {\n            res = res / i * (i - 1);\n            while (x % i == 0) x /= i;\n        }\n    if (x > 1) res = res / x * (x - 1);\n\n    return res;\n}\n```\n\n#### \n\n```cpp\nint primes[N], cnt;     // primes[]\nint euler[N];           // \nbool st[N];         // st[x]x\n\n\nvoid get_eulers(int n)\n{\n    euler[1] = 1;\n    for (int i = 2; i <= n; i ++ )\n    {\n        if (!st[i])\n        {\n            primes[cnt ++ ] = i;\n            euler[i] = i - 1;\n        }\n        for (int j = 0; primes[j] <= n / i; j ++ )\n        {\n            int t = primes[j] * i;\n            st[t] = true;\n            if (i % primes[j] == 0)\n            {\n                euler[t] = euler[i] * primes[j];\n                break;\n            }\n            euler[t] = euler[i] * (primes[j] - 1);\n        }\n    }\n}\n```\n\n#### \n\n$a$$n$\n\n$a^{\\phi{(n)}} \\equiv 1 (mod \\ n)$\n\n### \n\n$O(logk)$$a^k mod p$\n\n```cpp\nint qmi(int m, int k, int p)\n{\n    int res = 1 % p, t = m;\n    while (k)\n    {\n        if (k&1) res = res * t % p;\n        t = t * t % p;\n        k >>= 1;\n    }\n    return res;\n}\n```\n\n### \n\n$a,b$$x,y$\n\n$ax+by = gcd(a,b)$\n\n```cpp\n// x, yax + by = gcd(a, b)\nint exgcd(int a, int b, int &x, int &y)\n{\n    if (!b)\n    {\n        x = 1; y = 0;\n        return a;\n    }\n    int d = exgcd(b, a % b, y, x);\n    y -= (a/b) * x;\n    return d;\n}\n```\n\n### \n\n$m_1,m_2,m_3,m_k$\n\n$x \\equiv a_1 (mod \\ m_1)$\n\n$x \\equiv a_2 (mod \\ m_2)$\n\n$...$\n\n$x \\equiv a_k (mod \\ m_k)$\n\n$M = m_1 * m_2*...*m_k$\n\n$M_i = \\frac{M}{m_i}$\n\n$M_i^{-1}$$M_i$$m_i$\n\n$x = a_1M_1M_1^{-1}+a_2M_1M_2^{-1}+...+a_kM_1M_k^{-1}$\n\n### \n\n$O(n^3)$\n\n```cpp\n// a[N][N]\nint gauss()\n{\n    int c, r;\n    for (c = 0, r = 0; c < n; c ++ )\n    {\n        int t = r;\n        for (int i = r; i < n; i ++ )   // \n            if (fabs(a[i][c]) > fabs(a[t][c]))\n                t = i;\n\t\t//eps 1e-6\n        if (fabs(a[t][c]) < eps) continue;\n\n        for (int i = c; i <= n; i ++ ) swap(a[t][i], a[r][i]);      // \n        for (int i = n; i >= c; i -- ) a[r][i] /= a[r][c];      // 1\n        for (int i = r + 1; i < n; i ++ )       // 0\n            if (fabs(a[i][c]) > eps)\n                for (int j = n; j >= c; j -- )\n                    a[i][j] -= a[r][j] * a[i][c];\n\n        r ++ ;\n    }\n\n    if (r < n)\n    {\n        for (int i = r; i < n; i ++ )\n            if (fabs(a[i][n]) > eps)\n                return 2; // \n        return 1; // \n    }\n`\n    for (int i = n - 1; i >= 0; i -- )\n        for (int j = i + 1; j < n; j ++ )\n            //\n            a[i][n] -= a[i][j] * a[j][n];\n\n    return 0; // \n}\n```\n\n### \n\n- $1 \\le b \\le a \\le 2000$  $N^2$\n- $1 \\le b \\le a \\le 10^5$  $NlogN$\n- $1 \\le b \\le a \\le 10^{18}, 1 \\le p \\le 10^5$ Lucas\n- \n\n$C_{n}^{m}=\\frac{n!}{m!(n-m)!} $\n\n#### \n\n```cpp\nLL C(int a,int b){\n    LL res = 1;\n    for(int i=a,j=1;j<=b;i--,j++){\n        res = res*i/j;\n    }\n    return res;\n}\n```\n\n#### \n\n$C_{a}^{b} = C_{a-1}^{b} + C_{a-1}^{b-1}$\n\n```cpp\n// c[a][b] ab\nfor (int i = 0; i < N; i ++ )\n    for (int j = 0; j <= i; j ++ )\n        if (!j) c[i][j] = 1;\n        else c[i][j] = (c[i - 1][j] + c[i - 1][j - 1]) % mod;\n```\n\n#### \n\n```cpp\nfact[N]infact[N]\n\nint qmi(int a, int k, int p)    // \n{\n    int res = 1;\n    while (k)\n    {\n        if (k & 1) res = (LL)res * a % p;\n        a = (LL)a * a % p;\n        k >>= 1;\n    }\n    return res;\n}\n\n// \nfact[0] = infact[0] = 1;\nfor (int i = 1; i < N; i ++ )\n{\n    fact[i] = (LL)fact[i - 1] * i % mod;\n    infact[i] = (LL)infact[i - 1] * qmi(i, mod - 2, mod) % mod;\n}\n```\n\n#### Lucas\n\n```cpp\np 1 <= m <= n\n    C(n, m) = C(n % p, m % p) * C(n / p, m / p) (mod p)\n\nint qmi(int a, int k, int p)  // \n{\n    int res = 1 % p;\n    while (k)\n    {\n        if (k & 1) res = (LL)res * a % p;\n        a = (LL)a * a % p;\n        k >>= 1;\n    }\n    return res;\n}\n\nint C(int a, int b, int p)  // C(a, b)\n{\n    if (a < b) return 0;\n\n    LL x = 1, y = 1;  // xy\n    for (int i = a, j = 1; j <= b; i --, j ++ )\n    {\n        x = (LL)x * i % p;\n        y = (LL) y * j % p;\n    }\n\n    return x * (LL)qmi(y, p - 2, p) % p;\n}\n\nint lucas(LL a, LL b, int p)\n{\n    if (a < p && b < p) return C(a, b, p);\n    return (LL)C(a % p, b % p, p) * lucas(a / p, b / p, p) % p;\n}\n```\n\n#### \n\n```cpp\n\n    1. \n    2.  C(a, b) = a! / b! / (a - b)!  n! p n / p + n / p^2 + n / p^3 + ...\n    3. \n\nint primes[N], cnt;     // \nint sum[N];     // \nbool st[N];     // \n\n\nvoid get_primes(int n)      // \n{\n    for (int i = 2; i <= n; i ++ )\n    {\n        if (!st[i]) primes[cnt ++ ] = i;\n        for (int j = 0; primes[j] <= n / i; j ++ )\n        {\n            st[primes[j] * i] = true;\n            if (i % primes[j] == 0) break;\n        }\n    }\n}\n\n\nint get(int n, int p)       // n\n{\n    int res = 0;\n    while (n)\n    {\n        res += n / p;\n        n /= p;\n    }\n    return res;\n}\n\n\nvector<int> mul(vector<int> a, int b)       // \n{\n    vector<int> c;\n    int t = 0;\n    for (int i = 0; i < a.size(); i ++ )\n    {\n        t += a[i] * b;\n        c.push_back(t % 10);\n        t /= 10;\n    }\n\n    while (t)\n    {\n        c.push_back(t % 10);\n        t /= 10;\n    }\n\n    return c;\n}\n\nget_primes(a);  // \n\nfor (int i = 0; i < cnt; i ++ )     // \n{\n    int p = primes[i];\n    sum[i] = get(a, p) - get(b, p) - get(a - b, p);\n}\n\nvector<int> res;\nres.push_back(1);\n\nfor (int i = 0; i < cnt; i ++ )     // \n    for (int j = 0; j < sum[i]; j ++ )\n        res = mul(res, primes[i]);\n```\n\n### \n\nn0n12n01 Cat(n) = C(2n, n) / (n + 1)","slug":"algorithm-math","published":1,"updated":"2025-03-05T03:12:58.052Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff50009ss993b3z3dwg","content":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong></strong></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$O(\\sqrt n)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">is_prime</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (x &lt; <span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= x / i; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (x % i == <span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">N = p1^c1 * p2^c2 * ... *pk^ck</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<p>$(p,c)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">divide</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// nsqrt(n)</span></span><br><span class=\"line\">    <span class=\"comment\">// sqrt(t) O(sqrt(n))</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= x / i; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (x % i == <span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> c = <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (x % i == <span class=\"number\">0</span>) x /= i, c ++ ;</span><br><span class=\"line\">            cout &lt;&lt; i &lt;&lt; <span class=\"string\">&#x27; &#x27;</span> &lt;&lt; c &lt;&lt; endl;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (x &gt; <span class=\"number\">1</span>) cout &lt;&lt; x &lt;&lt; <span class=\"string\">&#x27; &#x27;</span> &lt;&lt; <span class=\"number\">1</span> &lt;&lt; endl;</span><br><span class=\"line\">    cout &lt;&lt; endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p></p>\n<p>$O(nloglogn)$</p>\n<p>1-n$\\frac{n}{ln_{}{n}}$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> primes[N], cnt;     <span class=\"comment\">// primes[]</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];         <span class=\"comment\">// st[x]x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">get_primes</span><span class=\"params\">(<span class=\"type\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (st[i]) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        primes[cnt ++ ] = i;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = i + i; j &lt;= n; j += i)</span><br><span class=\"line\">            st[j] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$n$</p>\n<p>$O(n)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> primes[N], cnt;     <span class=\"comment\">// primes[]</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];         <span class=\"comment\">// st[x]x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">get_primes</span><span class=\"params\">(<span class=\"type\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[i]) primes[cnt ++ ] = i;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; primes[j] &lt;= n / i; j ++ )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            st[primes[j] * i] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i % primes[j] == <span class=\"number\">0</span>) <span class=\"keyword\">break</span>; <span class=\"comment\">//primes[j]i</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$O(\\sqrt{n})$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">get_divisors</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; res;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= x / i; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (x % i == <span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            res.<span class=\"built_in\">push_back</span>(i);</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i != x / i) res.<span class=\"built_in\">push_back</span>(x / i); <span class=\"comment\">//push4*4=16</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"built_in\">sort</span>(res.<span class=\"built_in\">begin</span>(), res.<span class=\"built_in\">end</span>());</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p> N &#x3D; p1^c1 * p2^c2 *  *pk^ck<br> (c1 + 1) * (c2 + 1) *  * (ck + 1)<br> (p1^0 + p1^1 +  + p1^c1) *  * (pk^0 + pk^1 +  + pk^ck)</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">gcd</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> b ? <span class=\"built_in\">gcd</span>(b, a % b) : a;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><code>__gcd(int a, int b)</code>&#x3D;$\\frac{a  b}{gcd(a,b)}$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$\\phi(n)$1-nn</p>\n<p>$\\phi(n) &#x3D; n*(1-\\frac{1}{p_1})<em>(1-\\frac{1}{p_2})</em>*(1-\\frac{1}{p_n})$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">phi</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = x;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= x / i; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (x % i == <span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            res = res / i * (i - <span class=\"number\">1</span>);</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (x % i == <span class=\"number\">0</span>) x /= i;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (x &gt; <span class=\"number\">1</span>) res = res / x * (x - <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> primes[N], cnt;     <span class=\"comment\">// primes[]</span></span><br><span class=\"line\"><span class=\"type\">int</span> euler[N];           <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];         <span class=\"comment\">// st[x]x</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">get_eulers</span><span class=\"params\">(<span class=\"type\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    euler[<span class=\"number\">1</span>] = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            primes[cnt ++ ] = i;</span><br><span class=\"line\">            euler[i] = i - <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; primes[j] &lt;= n / i; j ++ )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> t = primes[j] * i;</span><br><span class=\"line\">            st[t] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i % primes[j] == <span class=\"number\">0</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                euler[t] = euler[i] * primes[j];</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            euler[t] = euler[i] * (primes[j] - <span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$a$$n$</p>\n<p>$a^{\\phi{(n)}} \\equiv 1 (mod \\ n)$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$O(logk)$$a^k mod p$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">qmi</span><span class=\"params\">(<span class=\"type\">int</span> m, <span class=\"type\">int</span> k, <span class=\"type\">int</span> p)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">1</span> % p, t = m;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (k)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (k&amp;<span class=\"number\">1</span>) res = res * t % p;</span><br><span class=\"line\">        t = t * t % p;</span><br><span class=\"line\">        k &gt;&gt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$a,b$$x,y$</p>\n<p>$ax+by &#x3D; gcd(a,b)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// x, yax + by = gcd(a, b)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">exgcd</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b, <span class=\"type\">int</span> &amp;x, <span class=\"type\">int</span> &amp;y)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!b)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        x = <span class=\"number\">1</span>; y = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> a;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"type\">int</span> d = <span class=\"built_in\">exgcd</span>(b, a % b, y, x);</span><br><span class=\"line\">    y -= (a/b) * x;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> d;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$m_1,m_2,m_3,m_k$</p>\n<p>$x \\equiv a_1 (mod \\ m_1)$</p>\n<p>$x \\equiv a_2 (mod \\ m_2)$</p>\n<p>$$</p>\n<p>$x \\equiv a_k (mod \\ m_k)$</p>\n<p>$M &#x3D; m_1 * m_2**m_k$</p>\n<p>$M_i &#x3D; \\frac{M}{m_i}$</p>\n<p>$M_i^{-1}$$M_i$$m_i$</p>\n<p>$x &#x3D; a_1M_1M_1^{-1}+a_2M_1M_2^{-1}++a_kM_1M_k^{-1}$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$O(n^3)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// a[N][N]</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">gauss</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> c, r;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (c = <span class=\"number\">0</span>, r = <span class=\"number\">0</span>; c &lt; n; c ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> t = r;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = r; i &lt; n; i ++ )   <span class=\"comment\">// </span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (<span class=\"built_in\">fabs</span>(a[i][c]) &gt; <span class=\"built_in\">fabs</span>(a[t][c]))</span><br><span class=\"line\">                t = i;</span><br><span class=\"line\">\t\t<span class=\"comment\">//eps 1e-6</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"built_in\">fabs</span>(a[t][c]) &lt; eps) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = c; i &lt;= n; i ++ ) <span class=\"built_in\">swap</span>(a[t][i], a[r][i]);      <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = n; i &gt;= c; i -- ) a[r][i] /= a[r][c];      <span class=\"comment\">// 1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = r + <span class=\"number\">1</span>; i &lt; n; i ++ )       <span class=\"comment\">// 0</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (<span class=\"built_in\">fabs</span>(a[i][c]) &gt; eps)</span><br><span class=\"line\">                <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = n; j &gt;= c; j -- )</span><br><span class=\"line\">                    a[i][j] -= a[r][j] * a[i][c];</span><br><span class=\"line\"></span><br><span class=\"line\">        r ++ ;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (r &lt; n)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = r; i &lt; n; i ++ )</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (<span class=\"built_in\">fabs</span>(a[i][n]) &gt; eps)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"number\">2</span>; <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>; <span class=\"comment\">// </span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">`</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = n - <span class=\"number\">1</span>; i &gt;= <span class=\"number\">0</span>; i -- )</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = i + <span class=\"number\">1</span>; j &lt; n; j ++ )</span><br><span class=\"line\">            <span class=\"comment\">//</span></span><br><span class=\"line\">            a[i][n] -= a[i][j] * a[j][n];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>; <span class=\"comment\">// </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li>$1 \\le b \\le a \\le 2000$  $N^2$</li>\n<li>$1 \\le b \\le a \\le 10^5$  $NlogN$</li>\n<li>$1 \\le b \\le a \\le 10^{18}, 1 \\le p \\le 10^5$ Lucas</li>\n<li></li>\n</ul>\n<p>$C_{n}^{m}&#x3D;\\frac{n!}{m!(n-m)!} $</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">LL <span class=\"title\">C</span><span class=\"params\">(<span class=\"type\">int</span> a,<span class=\"type\">int</span> b)</span></span>&#123;</span><br><span class=\"line\">    LL res = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=a,j=<span class=\"number\">1</span>;j&lt;=b;i--,j++)&#123;</span><br><span class=\"line\">        res = res*i/j;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$C_{a}^{b} &#x3D; C_{a-1}^{b} + C_{a-1}^{b-1}$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// c[a][b] ab</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; N; i ++ )</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; j &lt;= i; j ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!j) c[i][j] = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> c[i][j] = (c[i - <span class=\"number\">1</span>][j] + c[i - <span class=\"number\">1</span>][j - <span class=\"number\">1</span>]) % mod;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fact[N]infact[N]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">qmi</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> k, <span class=\"type\">int</span> p)</span>    <span class=\"comment\">// </span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (k)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (k &amp; <span class=\"number\">1</span>) res = (LL)res * a % p;</span><br><span class=\"line\">        a = (LL)a * a % p;</span><br><span class=\"line\">        k &gt;&gt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">fact[<span class=\"number\">0</span>] = infact[<span class=\"number\">0</span>] = <span class=\"number\">1</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt; N; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    fact[i] = (LL)fact[i - <span class=\"number\">1</span>] * i % mod;</span><br><span class=\"line\">    infact[i] = (LL)infact[i - <span class=\"number\">1</span>] * <span class=\"built_in\">qmi</span>(i, mod - <span class=\"number\">2</span>, mod) % mod;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Lucas\"><a href=\"#Lucas\" class=\"headerlink\" title=\"Lucas\"></a>Lucas</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">p <span class=\"number\">1</span> &lt;= m &lt;= n</span><br><span class=\"line\">    <span class=\"built_in\">C</span>(n, m) = <span class=\"built_in\">C</span>(n % p, m % p) * <span class=\"built_in\">C</span>(n / p, m / p) (mod p)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"built_in\">qmi</span>(<span class=\"type\">int</span> a, <span class=\"type\">int</span> k, <span class=\"type\">int</span> p)  <span class=\"comment\">// </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">1</span> % p;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (k)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (k &amp; <span class=\"number\">1</span>) res = (LL)res * a % p;</span><br><span class=\"line\">        a = (LL)a * a % p;</span><br><span class=\"line\">        k &gt;&gt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">C</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b, <span class=\"type\">int</span> p)</span>  <span class=\"comment\">// C(a, b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (a &lt; b) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    LL x = <span class=\"number\">1</span>, y = <span class=\"number\">1</span>;  <span class=\"comment\">// xy</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = a, j = <span class=\"number\">1</span>; j &lt;= b; i --, j ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        x = (LL)x * i % p;</span><br><span class=\"line\">        y = (LL) y * j % p;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x * (LL)<span class=\"built_in\">qmi</span>(y, p - <span class=\"number\">2</span>, p) % p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">lucas</span><span class=\"params\">(LL a, LL b, <span class=\"type\">int</span> p)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (a &lt; p &amp;&amp; b &lt; p) <span class=\"keyword\">return</span> <span class=\"built_in\">C</span>(a, b, p);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (LL)<span class=\"built_in\">C</span>(a % p, b % p, p) * <span class=\"built_in\">lucas</span>(a / p, b / p, p) % p;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">    <span class=\"number\">1.</span> </span><br><span class=\"line\">    <span class=\"number\">2.</span>  <span class=\"built_in\">C</span>(a, b) = a! / b! / (a - b)!  n! p n / p + n / p^<span class=\"number\">2</span> + n / p^<span class=\"number\">3</span> + ...</span><br><span class=\"line\">    <span class=\"number\">3.</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> primes[N], cnt;     <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> sum[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">get_primes</span><span class=\"params\">(<span class=\"type\">int</span> n)</span>      <span class=\"comment\">// </span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[i]) primes[cnt ++ ] = i;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; primes[j] &lt;= n / i; j ++ )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            st[primes[j] * i] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i % primes[j] == <span class=\"number\">0</span>) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">get</span><span class=\"params\">(<span class=\"type\">int</span> n, <span class=\"type\">int</span> p)</span>       <span class=\"comment\">// n</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (n)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        res += n / p;</span><br><span class=\"line\">        n /= p;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">mul</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; a, <span class=\"type\">int</span> b)</span>       <span class=\"comment\">// </span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; c;</span><br><span class=\"line\">    <span class=\"type\">int</span> t = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; a.<span class=\"built_in\">size</span>(); i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        t += a[i] * b;</span><br><span class=\"line\">        c.<span class=\"built_in\">push_back</span>(t % <span class=\"number\">10</span>);</span><br><span class=\"line\">        t /= <span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (t)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        c.<span class=\"built_in\">push_back</span>(t % <span class=\"number\">10</span>);</span><br><span class=\"line\">        t /= <span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> c;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">get_primes</span>(a);  <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; cnt; i ++ )     <span class=\"comment\">// </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> p = primes[i];</span><br><span class=\"line\">    sum[i] = <span class=\"built_in\">get</span>(a, p) - <span class=\"built_in\">get</span>(b, p) - <span class=\"built_in\">get</span>(a - b, p);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">vector&lt;<span class=\"type\">int</span>&gt; res;</span><br><span class=\"line\">res.<span class=\"built_in\">push_back</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; cnt; i ++ )     <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; j &lt; sum[i]; j ++ )</span><br><span class=\"line\">        res = <span class=\"built_in\">mul</span>(res, primes[i]);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>n0n12n01 Cat(n) &#x3D; C(2n, n) &#x2F; (n + 1)</p>\n","more":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong></strong></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$O(\\sqrt n)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">is_prime</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (x &lt; <span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= x / i; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (x % i == <span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">N = p1^c1 * p2^c2 * ... *pk^ck</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<p>$(p,c)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">divide</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// nsqrt(n)</span></span><br><span class=\"line\">    <span class=\"comment\">// sqrt(t) O(sqrt(n))</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= x / i; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (x % i == <span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> c = <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (x % i == <span class=\"number\">0</span>) x /= i, c ++ ;</span><br><span class=\"line\">            cout &lt;&lt; i &lt;&lt; <span class=\"string\">&#x27; &#x27;</span> &lt;&lt; c &lt;&lt; endl;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (x &gt; <span class=\"number\">1</span>) cout &lt;&lt; x &lt;&lt; <span class=\"string\">&#x27; &#x27;</span> &lt;&lt; <span class=\"number\">1</span> &lt;&lt; endl;</span><br><span class=\"line\">    cout &lt;&lt; endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p></p>\n<p>$O(nloglogn)$</p>\n<p>1-n$\\frac{n}{ln_{}{n}}$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> primes[N], cnt;     <span class=\"comment\">// primes[]</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];         <span class=\"comment\">// st[x]x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">get_primes</span><span class=\"params\">(<span class=\"type\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (st[i]) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        primes[cnt ++ ] = i;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = i + i; j &lt;= n; j += i)</span><br><span class=\"line\">            st[j] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$n$</p>\n<p>$O(n)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> primes[N], cnt;     <span class=\"comment\">// primes[]</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];         <span class=\"comment\">// st[x]x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">get_primes</span><span class=\"params\">(<span class=\"type\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[i]) primes[cnt ++ ] = i;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; primes[j] &lt;= n / i; j ++ )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            st[primes[j] * i] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i % primes[j] == <span class=\"number\">0</span>) <span class=\"keyword\">break</span>; <span class=\"comment\">//primes[j]i</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$O(\\sqrt{n})$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">get_divisors</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; res;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= x / i; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (x % i == <span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            res.<span class=\"built_in\">push_back</span>(i);</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i != x / i) res.<span class=\"built_in\">push_back</span>(x / i); <span class=\"comment\">//push4*4=16</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"built_in\">sort</span>(res.<span class=\"built_in\">begin</span>(), res.<span class=\"built_in\">end</span>());</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p> N &#x3D; p1^c1 * p2^c2 *  *pk^ck<br> (c1 + 1) * (c2 + 1) *  * (ck + 1)<br> (p1^0 + p1^1 +  + p1^c1) *  * (pk^0 + pk^1 +  + pk^ck)</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">gcd</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> b ? <span class=\"built_in\">gcd</span>(b, a % b) : a;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><code>__gcd(int a, int b)</code>&#x3D;$\\frac{a  b}{gcd(a,b)}$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$\\phi(n)$1-nn</p>\n<p>$\\phi(n) &#x3D; n*(1-\\frac{1}{p_1})<em>(1-\\frac{1}{p_2})</em>*(1-\\frac{1}{p_n})$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">phi</span><span class=\"params\">(<span class=\"type\">int</span> x)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = x;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= x / i; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (x % i == <span class=\"number\">0</span>)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            res = res / i * (i - <span class=\"number\">1</span>);</span><br><span class=\"line\">            <span class=\"keyword\">while</span> (x % i == <span class=\"number\">0</span>) x /= i;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (x &gt; <span class=\"number\">1</span>) res = res / x * (x - <span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> primes[N], cnt;     <span class=\"comment\">// primes[]</span></span><br><span class=\"line\"><span class=\"type\">int</span> euler[N];           <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];         <span class=\"comment\">// st[x]x</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">get_eulers</span><span class=\"params\">(<span class=\"type\">int</span> n)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    euler[<span class=\"number\">1</span>] = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            primes[cnt ++ ] = i;</span><br><span class=\"line\">            euler[i] = i - <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; primes[j] &lt;= n / i; j ++ )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> t = primes[j] * i;</span><br><span class=\"line\">            st[t] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i % primes[j] == <span class=\"number\">0</span>)</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                euler[t] = euler[i] * primes[j];</span><br><span class=\"line\">                <span class=\"keyword\">break</span>;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            euler[t] = euler[i] * (primes[j] - <span class=\"number\">1</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$a$$n$</p>\n<p>$a^{\\phi{(n)}} \\equiv 1 (mod \\ n)$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$O(logk)$$a^k mod p$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">qmi</span><span class=\"params\">(<span class=\"type\">int</span> m, <span class=\"type\">int</span> k, <span class=\"type\">int</span> p)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">1</span> % p, t = m;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (k)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (k&amp;<span class=\"number\">1</span>) res = res * t % p;</span><br><span class=\"line\">        t = t * t % p;</span><br><span class=\"line\">        k &gt;&gt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$a,b$$x,y$</p>\n<p>$ax+by &#x3D; gcd(a,b)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// x, yax + by = gcd(a, b)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">exgcd</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b, <span class=\"type\">int</span> &amp;x, <span class=\"type\">int</span> &amp;y)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!b)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        x = <span class=\"number\">1</span>; y = <span class=\"number\">0</span>;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> a;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"type\">int</span> d = <span class=\"built_in\">exgcd</span>(b, a % b, y, x);</span><br><span class=\"line\">    y -= (a/b) * x;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> d;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$m_1,m_2,m_3,m_k$</p>\n<p>$x \\equiv a_1 (mod \\ m_1)$</p>\n<p>$x \\equiv a_2 (mod \\ m_2)$</p>\n<p>$$</p>\n<p>$x \\equiv a_k (mod \\ m_k)$</p>\n<p>$M &#x3D; m_1 * m_2**m_k$</p>\n<p>$M_i &#x3D; \\frac{M}{m_i}$</p>\n<p>$M_i^{-1}$$M_i$$m_i$</p>\n<p>$x &#x3D; a_1M_1M_1^{-1}+a_2M_1M_2^{-1}++a_kM_1M_k^{-1}$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$O(n^3)$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// a[N][N]</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">gauss</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> c, r;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (c = <span class=\"number\">0</span>, r = <span class=\"number\">0</span>; c &lt; n; c ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> t = r;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = r; i &lt; n; i ++ )   <span class=\"comment\">// </span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (<span class=\"built_in\">fabs</span>(a[i][c]) &gt; <span class=\"built_in\">fabs</span>(a[t][c]))</span><br><span class=\"line\">                t = i;</span><br><span class=\"line\">\t\t<span class=\"comment\">//eps 1e-6</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (<span class=\"built_in\">fabs</span>(a[t][c]) &lt; eps) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = c; i &lt;= n; i ++ ) <span class=\"built_in\">swap</span>(a[t][i], a[r][i]);      <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = n; i &gt;= c; i -- ) a[r][i] /= a[r][c];      <span class=\"comment\">// 1</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = r + <span class=\"number\">1</span>; i &lt; n; i ++ )       <span class=\"comment\">// 0</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> (<span class=\"built_in\">fabs</span>(a[i][c]) &gt; eps)</span><br><span class=\"line\">                <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = n; j &gt;= c; j -- )</span><br><span class=\"line\">                    a[i][j] -= a[r][j] * a[i][c];</span><br><span class=\"line\"></span><br><span class=\"line\">        r ++ ;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (r &lt; n)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = r; i &lt; n; i ++ )</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (<span class=\"built_in\">fabs</span>(a[i][n]) &gt; eps)</span><br><span class=\"line\">                <span class=\"keyword\">return</span> <span class=\"number\">2</span>; <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"number\">1</span>; <span class=\"comment\">// </span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">`</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = n - <span class=\"number\">1</span>; i &gt;= <span class=\"number\">0</span>; i -- )</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = i + <span class=\"number\">1</span>; j &lt; n; j ++ )</span><br><span class=\"line\">            <span class=\"comment\">//</span></span><br><span class=\"line\">            a[i][n] -= a[i][j] * a[j][n];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>; <span class=\"comment\">// </span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li>$1 \\le b \\le a \\le 2000$  $N^2$</li>\n<li>$1 \\le b \\le a \\le 10^5$  $NlogN$</li>\n<li>$1 \\le b \\le a \\le 10^{18}, 1 \\le p \\le 10^5$ Lucas</li>\n<li></li>\n</ul>\n<p>$C_{n}^{m}&#x3D;\\frac{n!}{m!(n-m)!} $</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">LL <span class=\"title\">C</span><span class=\"params\">(<span class=\"type\">int</span> a,<span class=\"type\">int</span> b)</span></span>&#123;</span><br><span class=\"line\">    LL res = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"type\">int</span> i=a,j=<span class=\"number\">1</span>;j&lt;=b;i--,j++)&#123;</span><br><span class=\"line\">        res = res*i/j;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$C_{a}^{b} &#x3D; C_{a-1}^{b} + C_{a-1}^{b-1}$</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// c[a][b] ab</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; N; i ++ )</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; j &lt;= i; j ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!j) c[i][j] = <span class=\"number\">1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">else</span> c[i][j] = (c[i - <span class=\"number\">1</span>][j] + c[i - <span class=\"number\">1</span>][j - <span class=\"number\">1</span>]) % mod;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">fact[N]infact[N]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">qmi</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> k, <span class=\"type\">int</span> p)</span>    <span class=\"comment\">// </span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (k)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (k &amp; <span class=\"number\">1</span>) res = (LL)res * a % p;</span><br><span class=\"line\">        a = (LL)a * a % p;</span><br><span class=\"line\">        k &gt;&gt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">fact[<span class=\"number\">0</span>] = infact[<span class=\"number\">0</span>] = <span class=\"number\">1</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt; N; i ++ )</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    fact[i] = (LL)fact[i - <span class=\"number\">1</span>] * i % mod;</span><br><span class=\"line\">    infact[i] = (LL)infact[i - <span class=\"number\">1</span>] * <span class=\"built_in\">qmi</span>(i, mod - <span class=\"number\">2</span>, mod) % mod;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Lucas\"><a href=\"#Lucas\" class=\"headerlink\" title=\"Lucas\"></a>Lucas</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">p <span class=\"number\">1</span> &lt;= m &lt;= n</span><br><span class=\"line\">    <span class=\"built_in\">C</span>(n, m) = <span class=\"built_in\">C</span>(n % p, m % p) * <span class=\"built_in\">C</span>(n / p, m / p) (mod p)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> <span class=\"built_in\">qmi</span>(<span class=\"type\">int</span> a, <span class=\"type\">int</span> k, <span class=\"type\">int</span> p)  <span class=\"comment\">// </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">1</span> % p;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (k)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (k &amp; <span class=\"number\">1</span>) res = (LL)res * a % p;</span><br><span class=\"line\">        a = (LL)a * a % p;</span><br><span class=\"line\">        k &gt;&gt;= <span class=\"number\">1</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">C</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b, <span class=\"type\">int</span> p)</span>  <span class=\"comment\">// C(a, b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (a &lt; b) <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    LL x = <span class=\"number\">1</span>, y = <span class=\"number\">1</span>;  <span class=\"comment\">// xy</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = a, j = <span class=\"number\">1</span>; j &lt;= b; i --, j ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        x = (LL)x * i % p;</span><br><span class=\"line\">        y = (LL) y * j % p;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> x * (LL)<span class=\"built_in\">qmi</span>(y, p - <span class=\"number\">2</span>, p) % p;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">lucas</span><span class=\"params\">(LL a, LL b, <span class=\"type\">int</span> p)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (a &lt; p &amp;&amp; b &lt; p) <span class=\"keyword\">return</span> <span class=\"built_in\">C</span>(a, b, p);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (LL)<span class=\"built_in\">C</span>(a % p, b % p, p) * <span class=\"built_in\">lucas</span>(a / p, b / p, p) % p;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">    <span class=\"number\">1.</span> </span><br><span class=\"line\">    <span class=\"number\">2.</span>  <span class=\"built_in\">C</span>(a, b) = a! / b! / (a - b)!  n! p n / p + n / p^<span class=\"number\">2</span> + n / p^<span class=\"number\">3</span> + ...</span><br><span class=\"line\">    <span class=\"number\">3.</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> primes[N], cnt;     <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> sum[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">get_primes</span><span class=\"params\">(<span class=\"type\">int</span> n)</span>      <span class=\"comment\">// </span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">2</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[i]) primes[cnt ++ ] = i;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; primes[j] &lt;= n / i; j ++ )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            st[primes[j] * i] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i % primes[j] == <span class=\"number\">0</span>) <span class=\"keyword\">break</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">get</span><span class=\"params\">(<span class=\"type\">int</span> n, <span class=\"type\">int</span> p)</span>       <span class=\"comment\">// n</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">while</span> (n)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        res += n / p;</span><br><span class=\"line\">        n /= p;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\">vector&lt;<span class=\"type\">int</span>&gt; <span class=\"title\">mul</span><span class=\"params\">(vector&lt;<span class=\"type\">int</span>&gt; a, <span class=\"type\">int</span> b)</span>       <span class=\"comment\">// </span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    vector&lt;<span class=\"type\">int</span>&gt; c;</span><br><span class=\"line\">    <span class=\"type\">int</span> t = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; a.<span class=\"built_in\">size</span>(); i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        t += a[i] * b;</span><br><span class=\"line\">        c.<span class=\"built_in\">push_back</span>(t % <span class=\"number\">10</span>);</span><br><span class=\"line\">        t /= <span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (t)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        c.<span class=\"built_in\">push_back</span>(t % <span class=\"number\">10</span>);</span><br><span class=\"line\">        t /= <span class=\"number\">10</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> c;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">get_primes</span>(a);  <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; cnt; i ++ )     <span class=\"comment\">// </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> p = primes[i];</span><br><span class=\"line\">    sum[i] = <span class=\"built_in\">get</span>(a, p) - <span class=\"built_in\">get</span>(b, p) - <span class=\"built_in\">get</span>(a - b, p);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">vector&lt;<span class=\"type\">int</span>&gt; res;</span><br><span class=\"line\">res.<span class=\"built_in\">push_back</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; cnt; i ++ )     <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; j &lt; sum[i]; j ++ )</span><br><span class=\"line\">        res = <span class=\"built_in\">mul</span>(res, primes[i]);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>n0n12n01 Cat(n) &#x3D; C(2n, n) &#x2F; (n + 1)</p>\n"},{"title":"Algorithm-Graph","mathjax":true,"date":"2023-08-05T12:46:25.000Z","img":"https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg","excerpt":"","_content":"\n### \n\n$n$$m$\n\n$m$$n^2$$n$\n\n\n\n- \n  - \n    - $dijkstra$ $O(n^2+m)$\n    - $dijkstra$ $O(mlogn)$\n  - \n    - $Bellman-Ford$ $O(nm)$\n    - $SPFA$ $O(m)$$O(nm)$\n- \n  - $floyd$ $O(n^3)$\n\n#### dijkstra\n\n1. $dist[1]=0,dist[i]=+\\infty $st\n2. stttstt\n\n```cpp\nint g[N][N];  // \nint dist[N];  // 1\nbool st[N];   // \n\n// 1n-1\nint dijkstra()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n\n    for (int i = 0; i < n - 1; i ++ )\n    {\n        int t = -1;     // \n        for (int j = 1; j <= n; j ++ )\n            if (!st[j] && (t == -1 || dist[t] > dist[j]))\n                t = j;\n\n        // t\n        for (int j = 1; j <= n; j ++ )\n            dist[j] = min(dist[j], dist[t] + g[t][j]);\n\n        st[t] = true;\n    }\n\n    if (dist[n] == 0x3f3f3f3f) return -1;\n    return dist[n];\n}\n```\n\nm`g[a][b]`\n\n#### dijkstra\n\n\n\n****\n\n```cpp\ntypedef pair<int, int> PII;\n\nint n;      // \nint h[N], w[N], e[N], ne[N], idx;       // \nint dist[N];        // 1\nbool st[N];     // \nvoid add(int a, int b, int c){\n    e[idx] = b, w[idx] = c, ne[idx] = h[a], h[a] = idx++;\n}\n// 1n-1\nint dijkstra()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n    priority_queue<PII, vector<PII>, greater<PII>> heap;\n    heap.push({0, 1});      // firstsecond\n\n    while (heap.size())\n    {\n        auto t = heap.top();\n        heap.pop();\n\n        int ver = t.second, distance = t.first;\n\n        if (st[ver]) continue;\n        st[ver] = true;\n\n        for (int i = h[ver]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (dist[j] > distance + w[i])\n            {\n                dist[j] = distance + w[i];\n                heap.push({dist[j], j});\n            }\n        }\n    }\n\n    if (dist[n] == 0x3f3f3f3f) return -1;\n    return dist[n];\n}\n```\n\n#### Bellman-Ford\n\nndist[b]\n\n```cpp\nint n, m;       // nm\nint dist[N];        // dist[x]1x\n\nstruct Edge     // abw\n{\n    int a, b, w;\n}edges[M];\n\n// 1n1n-1\nint bellman_ford()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n\n    // nn+1\n    for (int i = 0; i < n; i ++ )\n    {\n        for (int j = 0; j < m; j ++ )\n        {\n            int a = edges[j].a, b = edges[j].b, w = edges[j].w;\n            if (dist[b] > dist[a] + w)\n                dist[b] = dist[a] + w;\n        }\n    }\n\n    if (dist[n] > 0x3f3f3f3f / 2) return -1;\n    return dist[n];\n}\n//\ndist[b] <= dist[a] + w\n```\n\n\n\n#### SPFA\n\nBellman-Ford\n\n```cpp\nint n;      // \nint h[N], w[N], e[N], ne[N], idx;       // \nint dist[N];        // 1\nbool st[N];     // \n\n// 1n1n-1\nint spfa()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n\n    queue<int> q;\n    q.push(1);\n    st[1] = true;\n\n    while (q.size())\n    {\n        auto t = q.front();\n        q.pop();\n\n        st[t] = false;\n\n        for (int i = h[t]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (dist[j] > dist[t] + w[i])\n            {\n                dist[j] = dist[t] + w[i];\n                if (!st[j])     // jj\n                {\n                    q.push(j);\n                    st[j] = true;\n                }\n            }\n        }\n    }\n\n    if (dist[n] == 0x3f3f3f3f) return -1;\n    return dist[n];\n}\n```\n\n\n\n****\n\ndist[j] = dist[t] + wcnt[x] (1x)\n\ncnt[x] = cnt[t]+1;\n\ncnt[x] n\n\n```cpp\nint n;      // \nint h[N], w[N], e[N], ne[N], idx;       // \nint dist[N], cnt[N];        // dist[x]1xcnt[x]1x\nbool st[N];     // \n\n// truefalse\nbool spfa()\n{\n    // dist\n    // nn+1\n\n    queue<int> q;\n    for (int i = 1; i <= n; i ++ )\n    {\n        q.push(i);\n        st[i] = true;\n    }\n\n    while (q.size())\n    {\n        auto t = q.front();\n        q.pop();\n\n        st[t] = false;\n\n        for (int i = h[t]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (dist[j] > dist[t] + w[i])\n            {\n                dist[j] = dist[t] + w[i];\n                cnt[j] = cnt[t] + 1;\n                if (cnt[j] >= n) return true;       // 1xn\n                if (!st[j])\n                {\n                    q.push(j);\n                    st[j] = true;\n                }\n            }\n        }\n    }\n\n    return false;\n}\n```\n\n#### Floyd\n\n\n\n```cpp\n\n    for (int i = 1; i <= n; i ++ )\n        for (int j = 1; j <= n; j ++ )\n            if (i == j) d[i][j] = 0;\n            else d[i][j] = INF;\n\n// d[a][b]ab\nvoid floyd()\n{\n    for (int k = 1; k <= n; k ++ )\n        for (int i = 1; i <= n; i ++ )\n            for (int j = 1; j <= n; j ++ )\n                d[i][j] = min(d[i][j], d[i][k] + d[k][j]);\n}\n```\n\n### \n\n#### Prim\n\n\n\n**Prim** $O(n^2)$\n\ndijkstra\n\n```cpp\nint n;      // n\nint g[N][N];        // \nint dist[N];        // \nbool st[N];     // \n\n\n// INF(0x3f3f3f3f), \nint prim()\n{\n    memset(dist, 0x3f, sizeof dist);\n\n    int res = 0;\n    for (int i = 0; i < n; i ++ )\n    {\n        int t = -1;\n        for (int j = 1; j <= n; j ++ )\n            if (!st[j] && (t == -1 || dist[t] > dist[j]))\n                t = j;\n\n        if (i && dist[t] == INF) return INF;\n\n        if (i) res += dist[t];\n        st[t] = true;\n\n        for (int j = 1; j <= n; j ++ ) dist[j] = min(dist[j], g[t][j]);\n    }\n\n    return res;\n}\n```\n\n**Prim** $O(mlogn)$ \n\n#### Kruskal\n\n$O(mlogm)$ \n\n1. \n2. a->b,c abab\n\n```cpp\nint n, m;       // nm\nint p[N];       // \n\nstruct Edge     // \n{\n    int a, b, w;\n\n    bool operator< (const Edge &W)const\n    {\n        return w < W.w;\n    }\n}edges[M];\n\nint find(int x)     // \n{\n    if (p[x] != x) p[x] = find(p[x]);\n    return p[x];\n}\n\nint kruskal()\n{\n    sort(edges, edges + m);\n\n    for (int i = 1; i <= n; i ++ ) p[i] = i;    // \n\n    int res = 0, cnt = 0;\n    for (int i = 0; i < m; i ++ )\n    {\n        int a = edges[i].a, b = edges[i].b, w = edges[i].w;\n\n        a = find(a), b = find(b);\n        if (a != b)     // \n        {\n            p[a] = b;\n            res += w;\n            cnt ++ ;\n        }\n    }\n\n    if (cnt < n - 1) return INF;\n    return res;\n}\n```","source":"_posts/algorithm-graph.md","raw":"---\ntitle: Algorithm-Graph\nmathjax: true\ndate: 2023/08/05 20:46:25\nimg: https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg\nexcerpt: \n---\n\n### \n\n$n$$m$\n\n$m$$n^2$$n$\n\n\n\n- \n  - \n    - $dijkstra$ $O(n^2+m)$\n    - $dijkstra$ $O(mlogn)$\n  - \n    - $Bellman-Ford$ $O(nm)$\n    - $SPFA$ $O(m)$$O(nm)$\n- \n  - $floyd$ $O(n^3)$\n\n#### dijkstra\n\n1. $dist[1]=0,dist[i]=+\\infty $st\n2. stttstt\n\n```cpp\nint g[N][N];  // \nint dist[N];  // 1\nbool st[N];   // \n\n// 1n-1\nint dijkstra()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n\n    for (int i = 0; i < n - 1; i ++ )\n    {\n        int t = -1;     // \n        for (int j = 1; j <= n; j ++ )\n            if (!st[j] && (t == -1 || dist[t] > dist[j]))\n                t = j;\n\n        // t\n        for (int j = 1; j <= n; j ++ )\n            dist[j] = min(dist[j], dist[t] + g[t][j]);\n\n        st[t] = true;\n    }\n\n    if (dist[n] == 0x3f3f3f3f) return -1;\n    return dist[n];\n}\n```\n\nm`g[a][b]`\n\n#### dijkstra\n\n\n\n****\n\n```cpp\ntypedef pair<int, int> PII;\n\nint n;      // \nint h[N], w[N], e[N], ne[N], idx;       // \nint dist[N];        // 1\nbool st[N];     // \nvoid add(int a, int b, int c){\n    e[idx] = b, w[idx] = c, ne[idx] = h[a], h[a] = idx++;\n}\n// 1n-1\nint dijkstra()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n    priority_queue<PII, vector<PII>, greater<PII>> heap;\n    heap.push({0, 1});      // firstsecond\n\n    while (heap.size())\n    {\n        auto t = heap.top();\n        heap.pop();\n\n        int ver = t.second, distance = t.first;\n\n        if (st[ver]) continue;\n        st[ver] = true;\n\n        for (int i = h[ver]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (dist[j] > distance + w[i])\n            {\n                dist[j] = distance + w[i];\n                heap.push({dist[j], j});\n            }\n        }\n    }\n\n    if (dist[n] == 0x3f3f3f3f) return -1;\n    return dist[n];\n}\n```\n\n#### Bellman-Ford\n\nndist[b]\n\n```cpp\nint n, m;       // nm\nint dist[N];        // dist[x]1x\n\nstruct Edge     // abw\n{\n    int a, b, w;\n}edges[M];\n\n// 1n1n-1\nint bellman_ford()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n\n    // nn+1\n    for (int i = 0; i < n; i ++ )\n    {\n        for (int j = 0; j < m; j ++ )\n        {\n            int a = edges[j].a, b = edges[j].b, w = edges[j].w;\n            if (dist[b] > dist[a] + w)\n                dist[b] = dist[a] + w;\n        }\n    }\n\n    if (dist[n] > 0x3f3f3f3f / 2) return -1;\n    return dist[n];\n}\n//\ndist[b] <= dist[a] + w\n```\n\n\n\n#### SPFA\n\nBellman-Ford\n\n```cpp\nint n;      // \nint h[N], w[N], e[N], ne[N], idx;       // \nint dist[N];        // 1\nbool st[N];     // \n\n// 1n1n-1\nint spfa()\n{\n    memset(dist, 0x3f, sizeof dist);\n    dist[1] = 0;\n\n    queue<int> q;\n    q.push(1);\n    st[1] = true;\n\n    while (q.size())\n    {\n        auto t = q.front();\n        q.pop();\n\n        st[t] = false;\n\n        for (int i = h[t]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (dist[j] > dist[t] + w[i])\n            {\n                dist[j] = dist[t] + w[i];\n                if (!st[j])     // jj\n                {\n                    q.push(j);\n                    st[j] = true;\n                }\n            }\n        }\n    }\n\n    if (dist[n] == 0x3f3f3f3f) return -1;\n    return dist[n];\n}\n```\n\n\n\n****\n\ndist[j] = dist[t] + wcnt[x] (1x)\n\ncnt[x] = cnt[t]+1;\n\ncnt[x] n\n\n```cpp\nint n;      // \nint h[N], w[N], e[N], ne[N], idx;       // \nint dist[N], cnt[N];        // dist[x]1xcnt[x]1x\nbool st[N];     // \n\n// truefalse\nbool spfa()\n{\n    // dist\n    // nn+1\n\n    queue<int> q;\n    for (int i = 1; i <= n; i ++ )\n    {\n        q.push(i);\n        st[i] = true;\n    }\n\n    while (q.size())\n    {\n        auto t = q.front();\n        q.pop();\n\n        st[t] = false;\n\n        for (int i = h[t]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            if (dist[j] > dist[t] + w[i])\n            {\n                dist[j] = dist[t] + w[i];\n                cnt[j] = cnt[t] + 1;\n                if (cnt[j] >= n) return true;       // 1xn\n                if (!st[j])\n                {\n                    q.push(j);\n                    st[j] = true;\n                }\n            }\n        }\n    }\n\n    return false;\n}\n```\n\n#### Floyd\n\n\n\n```cpp\n\n    for (int i = 1; i <= n; i ++ )\n        for (int j = 1; j <= n; j ++ )\n            if (i == j) d[i][j] = 0;\n            else d[i][j] = INF;\n\n// d[a][b]ab\nvoid floyd()\n{\n    for (int k = 1; k <= n; k ++ )\n        for (int i = 1; i <= n; i ++ )\n            for (int j = 1; j <= n; j ++ )\n                d[i][j] = min(d[i][j], d[i][k] + d[k][j]);\n}\n```\n\n### \n\n#### Prim\n\n\n\n**Prim** $O(n^2)$\n\ndijkstra\n\n```cpp\nint n;      // n\nint g[N][N];        // \nint dist[N];        // \nbool st[N];     // \n\n\n// INF(0x3f3f3f3f), \nint prim()\n{\n    memset(dist, 0x3f, sizeof dist);\n\n    int res = 0;\n    for (int i = 0; i < n; i ++ )\n    {\n        int t = -1;\n        for (int j = 1; j <= n; j ++ )\n            if (!st[j] && (t == -1 || dist[t] > dist[j]))\n                t = j;\n\n        if (i && dist[t] == INF) return INF;\n\n        if (i) res += dist[t];\n        st[t] = true;\n\n        for (int j = 1; j <= n; j ++ ) dist[j] = min(dist[j], g[t][j]);\n    }\n\n    return res;\n}\n```\n\n**Prim** $O(mlogn)$ \n\n#### Kruskal\n\n$O(mlogm)$ \n\n1. \n2. a->b,c abab\n\n```cpp\nint n, m;       // nm\nint p[N];       // \n\nstruct Edge     // \n{\n    int a, b, w;\n\n    bool operator< (const Edge &W)const\n    {\n        return w < W.w;\n    }\n}edges[M];\n\nint find(int x)     // \n{\n    if (p[x] != x) p[x] = find(p[x]);\n    return p[x];\n}\n\nint kruskal()\n{\n    sort(edges, edges + m);\n\n    for (int i = 1; i <= n; i ++ ) p[i] = i;    // \n\n    int res = 0, cnt = 0;\n    for (int i = 0; i < m; i ++ )\n    {\n        int a = edges[i].a, b = edges[i].b, w = edges[i].w;\n\n        a = find(a), b = find(b);\n        if (a != b)     // \n        {\n            p[a] = b;\n            res += w;\n            cnt ++ ;\n        }\n    }\n\n    if (cnt < n - 1) return INF;\n    return res;\n}\n```","slug":"algorithm-graph","published":1,"updated":"2025-02-28T03:16:48.846Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff5000ass990hvc19dj","content":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$n$$m$</p>\n<p>$m$$n^2$$n$</p>\n<p></p>\n<ul>\n<li><ul>\n<li><ul>\n<li>$dijkstra$ $O(n^2+m)$</li>\n<li>$dijkstra$ $O(mlogn)$</li>\n</ul>\n</li>\n<li><ul>\n<li>$Bellman-Ford$ $O(nm)$</li>\n<li>$SPFA$ $O(m)$$O(nm)$</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><ul>\n<li>$floyd$ $O(n^3)$</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"dijkstra\"><a href=\"#dijkstra\" class=\"headerlink\" title=\"dijkstra\"></a>dijkstra</h4><ol>\n<li>$dist[1]&#x3D;0,dist[i]&#x3D;+\\infty $st</li>\n<li>stttstt</li>\n</ol>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> g[N][N];  <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];  <span class=\"comment\">// 1</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];   <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 1n-1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">dijkstra</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\">    dist[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n - <span class=\"number\">1</span>; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> t = <span class=\"number\">-1</span>;     <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!st[j] &amp;&amp; (t == <span class=\"number\">-1</span> || dist[t] &gt; dist[j]))</span><br><span class=\"line\">                t = j;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// t</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">            dist[j] = <span class=\"built_in\">min</span>(dist[j], dist[t] + g[t][j]);</span><br><span class=\"line\"></span><br><span class=\"line\">        st[t] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (dist[n] == <span class=\"number\">0x3f3f3f3f</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dist[n];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>m<code>g[a][b]</code></p>\n<h4 id=\"dijkstra\"><a href=\"#dijkstra\" class=\"headerlink\" title=\"dijkstra\"></a>dijkstra</h4><p></p>\n<p><strong></strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt; PII;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> n;      <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> h[N], w[N], e[N], ne[N], idx;       <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];        <span class=\"comment\">// 1</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">add</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b, <span class=\"type\">int</span> c)</span></span>&#123;</span><br><span class=\"line\">    e[idx] = b, w[idx] = c, ne[idx] = h[a], h[a] = idx++;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 1n-1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">dijkstra</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\">    dist[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\">    priority_queue&lt;PII, vector&lt;PII&gt;, greater&lt;PII&gt;&gt; heap;</span><br><span class=\"line\">    heap.<span class=\"built_in\">push</span>(&#123;<span class=\"number\">0</span>, <span class=\"number\">1</span>&#125;);      <span class=\"comment\">// firstsecond</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (heap.<span class=\"built_in\">size</span>())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">auto</span> t = heap.<span class=\"built_in\">top</span>();</span><br><span class=\"line\">        heap.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">int</span> ver = t.second, distance = t.first;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (st[ver]) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        st[ver] = <span class=\"literal\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[ver]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dist[j] &gt; distance + w[i])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                dist[j] = distance + w[i];</span><br><span class=\"line\">                heap.<span class=\"built_in\">push</span>(&#123;dist[j], j&#125;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (dist[n] == <span class=\"number\">0x3f3f3f3f</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dist[n];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Bellman-Ford\"><a href=\"#Bellman-Ford\" class=\"headerlink\" title=\"Bellman-Ford\"></a>Bellman-Ford</h4><p>ndist[b]</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n, m;       <span class=\"comment\">// nm</span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];        <span class=\"comment\">// dist[x]1x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">struct</span> <span class=\"title class_\">Edge</span>     <span class=\"comment\">// abw</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> a, b, w;</span><br><span class=\"line\">&#125;edges[M];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 1n1n-1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">bellman_ford</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\">    dist[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// nn+1</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; j &lt; m; j ++ )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> a = edges[j].a, b = edges[j].b, w = edges[j].w;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dist[b] &gt; dist[a] + w)</span><br><span class=\"line\">                dist[b] = dist[a] + w;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (dist[n] &gt; <span class=\"number\">0x3f3f3f3f</span> / <span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dist[n];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\">dist[b] &lt;= dist[a] + w</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<h4 id=\"SPFA\"><a href=\"#SPFA\" class=\"headerlink\" title=\"SPFA\"></a>SPFA</h4><p>Bellman-Ford</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n;      <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> h[N], w[N], e[N], ne[N], idx;       <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];        <span class=\"comment\">// 1</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 1n1n-1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">spfa</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\">    dist[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    queue&lt;<span class=\"type\">int</span>&gt; q;</span><br><span class=\"line\">    q.<span class=\"built_in\">push</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    st[<span class=\"number\">1</span>] = <span class=\"literal\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (q.<span class=\"built_in\">size</span>())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">auto</span> t = q.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">        q.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">        st[t] = <span class=\"literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[t]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dist[j] &gt; dist[t] + w[i])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                dist[j] = dist[t] + w[i];</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!st[j])     <span class=\"comment\">// jj</span></span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    q.<span class=\"built_in\">push</span>(j);</span><br><span class=\"line\">                    st[j] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (dist[n] == <span class=\"number\">0x3f3f3f3f</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dist[n];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<p><strong></strong></p>\n<p>dist[j] &#x3D; dist[t] + wcnt[x] (1x)</p>\n<p>cnt[x] &#x3D; cnt[t]+1;</p>\n<p>cnt[x] n</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n;      <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> h[N], w[N], e[N], ne[N], idx;       <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N], cnt[N];        <span class=\"comment\">// dist[x]1xcnt[x]1x</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// truefalse</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">spfa</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// dist</span></span><br><span class=\"line\">    <span class=\"comment\">// nn+1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    queue&lt;<span class=\"type\">int</span>&gt; q;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        q.<span class=\"built_in\">push</span>(i);</span><br><span class=\"line\">        st[i] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (q.<span class=\"built_in\">size</span>())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">auto</span> t = q.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">        q.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">        st[t] = <span class=\"literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[t]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dist[j] &gt; dist[t] + w[i])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                dist[j] = dist[t] + w[i];</span><br><span class=\"line\">                cnt[j] = cnt[t] + <span class=\"number\">1</span>;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (cnt[j] &gt;= n) <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;       <span class=\"comment\">// 1xn</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!st[j])</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    q.<span class=\"built_in\">push</span>(j);</span><br><span class=\"line\">                    st[j] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Floyd\"><a href=\"#Floyd\" class=\"headerlink\" title=\"Floyd\"></a>Floyd</h4><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i == j) d[i][j] = <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> d[i][j] = INF;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// d[a][b]ab</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">floyd</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> k = <span class=\"number\">1</span>; k &lt;= n; k ++ )</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">                d[i][j] = <span class=\"built_in\">min</span>(d[i][j], d[i][k] + d[k][j]);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"Prim\"><a href=\"#Prim\" class=\"headerlink\" title=\"Prim\"></a>Prim</h4><p></p>\n<p><strong>Prim</strong> $O(n^2)$</p>\n<p>dijkstra</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n;      <span class=\"comment\">// n</span></span><br><span class=\"line\"><span class=\"type\">int</span> g[N][N];        <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];        <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// INF(0x3f3f3f3f), </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">prim</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> t = <span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!st[j] &amp;&amp; (t == <span class=\"number\">-1</span> || dist[t] &gt; dist[j]))</span><br><span class=\"line\">                t = j;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &amp;&amp; dist[t] == INF) <span class=\"keyword\">return</span> INF;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i) res += dist[t];</span><br><span class=\"line\">        st[t] = <span class=\"literal\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ ) dist[j] = <span class=\"built_in\">min</span>(dist[j], g[t][j]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>Prim</strong> $O(mlogn)$ </p>\n<h4 id=\"Kruskal\"><a href=\"#Kruskal\" class=\"headerlink\" title=\"Kruskal\"></a>Kruskal</h4><p>$O(mlogm)$ </p>\n<ol>\n<li></li>\n<li>a-&gt;b,c abab</li>\n</ol>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n, m;       <span class=\"comment\">// nm</span></span><br><span class=\"line\"><span class=\"type\">int</span> p[N];       <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">struct</span> <span class=\"title class_\">Edge</span>     <span class=\"comment\">// </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> a, b, w;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">bool</span> <span class=\"keyword\">operator</span>&lt; (<span class=\"type\">const</span> Edge &amp;W)<span class=\"type\">const</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> w &lt; W.w;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;edges[M];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">find</span><span class=\"params\">(<span class=\"type\">int</span> x)</span>     <span class=\"comment\">// </span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p[x] != x) p[x] = <span class=\"built_in\">find</span>(p[x]);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p[x];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">kruskal</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">sort</span>(edges, edges + m);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ ) p[i] = i;    <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">0</span>, cnt = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; m; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> a = edges[i].a, b = edges[i].b, w = edges[i].w;</span><br><span class=\"line\"></span><br><span class=\"line\">        a = <span class=\"built_in\">find</span>(a), b = <span class=\"built_in\">find</span>(b);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (a != b)     <span class=\"comment\">// </span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            p[a] = b;</span><br><span class=\"line\">            res += w;</span><br><span class=\"line\">            cnt ++ ;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (cnt &lt; n - <span class=\"number\">1</span>) <span class=\"keyword\">return</span> INF;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","more":"<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$n$$m$</p>\n<p>$m$$n^2$$n$</p>\n<p></p>\n<ul>\n<li><ul>\n<li><ul>\n<li>$dijkstra$ $O(n^2+m)$</li>\n<li>$dijkstra$ $O(mlogn)$</li>\n</ul>\n</li>\n<li><ul>\n<li>$Bellman-Ford$ $O(nm)$</li>\n<li>$SPFA$ $O(m)$$O(nm)$</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><ul>\n<li>$floyd$ $O(n^3)$</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"dijkstra\"><a href=\"#dijkstra\" class=\"headerlink\" title=\"dijkstra\"></a>dijkstra</h4><ol>\n<li>$dist[1]&#x3D;0,dist[i]&#x3D;+\\infty $st</li>\n<li>stttstt</li>\n</ol>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> g[N][N];  <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];  <span class=\"comment\">// 1</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];   <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 1n-1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">dijkstra</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\">    dist[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n - <span class=\"number\">1</span>; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> t = <span class=\"number\">-1</span>;     <span class=\"comment\">// </span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!st[j] &amp;&amp; (t == <span class=\"number\">-1</span> || dist[t] &gt; dist[j]))</span><br><span class=\"line\">                t = j;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// t</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">            dist[j] = <span class=\"built_in\">min</span>(dist[j], dist[t] + g[t][j]);</span><br><span class=\"line\"></span><br><span class=\"line\">        st[t] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (dist[n] == <span class=\"number\">0x3f3f3f3f</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dist[n];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>m<code>g[a][b]</code></p>\n<h4 id=\"dijkstra\"><a href=\"#dijkstra\" class=\"headerlink\" title=\"dijkstra\"></a>dijkstra</h4><p></p>\n<p><strong></strong></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt; PII;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"type\">int</span> n;      <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> h[N], w[N], e[N], ne[N], idx;       <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];        <span class=\"comment\">// 1</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">add</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b, <span class=\"type\">int</span> c)</span></span>&#123;</span><br><span class=\"line\">    e[idx] = b, w[idx] = c, ne[idx] = h[a], h[a] = idx++;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 1n-1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">dijkstra</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\">    dist[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\">    priority_queue&lt;PII, vector&lt;PII&gt;, greater&lt;PII&gt;&gt; heap;</span><br><span class=\"line\">    heap.<span class=\"built_in\">push</span>(&#123;<span class=\"number\">0</span>, <span class=\"number\">1</span>&#125;);      <span class=\"comment\">// firstsecond</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (heap.<span class=\"built_in\">size</span>())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">auto</span> t = heap.<span class=\"built_in\">top</span>();</span><br><span class=\"line\">        heap.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"type\">int</span> ver = t.second, distance = t.first;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (st[ver]) <span class=\"keyword\">continue</span>;</span><br><span class=\"line\">        st[ver] = <span class=\"literal\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[ver]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dist[j] &gt; distance + w[i])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                dist[j] = distance + w[i];</span><br><span class=\"line\">                heap.<span class=\"built_in\">push</span>(&#123;dist[j], j&#125;);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (dist[n] == <span class=\"number\">0x3f3f3f3f</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dist[n];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Bellman-Ford\"><a href=\"#Bellman-Ford\" class=\"headerlink\" title=\"Bellman-Ford\"></a>Bellman-Ford</h4><p>ndist[b]</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n, m;       <span class=\"comment\">// nm</span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];        <span class=\"comment\">// dist[x]1x</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">struct</span> <span class=\"title class_\">Edge</span>     <span class=\"comment\">// abw</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> a, b, w;</span><br><span class=\"line\">&#125;edges[M];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 1n1n-1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">bellman_ford</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\">    dist[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// nn+1</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">0</span>; j &lt; m; j ++ )</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> a = edges[j].a, b = edges[j].b, w = edges[j].w;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dist[b] &gt; dist[a] + w)</span><br><span class=\"line\">                dist[b] = dist[a] + w;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (dist[n] &gt; <span class=\"number\">0x3f3f3f3f</span> / <span class=\"number\">2</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dist[n];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\">dist[b] &lt;= dist[a] + w</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<h4 id=\"SPFA\"><a href=\"#SPFA\" class=\"headerlink\" title=\"SPFA\"></a>SPFA</h4><p>Bellman-Ford</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n;      <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> h[N], w[N], e[N], ne[N], idx;       <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];        <span class=\"comment\">// 1</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 1n1n-1</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">spfa</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\">    dist[<span class=\"number\">1</span>] = <span class=\"number\">0</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    queue&lt;<span class=\"type\">int</span>&gt; q;</span><br><span class=\"line\">    q.<span class=\"built_in\">push</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\">    st[<span class=\"number\">1</span>] = <span class=\"literal\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (q.<span class=\"built_in\">size</span>())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">auto</span> t = q.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">        q.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">        st[t] = <span class=\"literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[t]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dist[j] &gt; dist[t] + w[i])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                dist[j] = dist[t] + w[i];</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!st[j])     <span class=\"comment\">// jj</span></span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    q.<span class=\"built_in\">push</span>(j);</span><br><span class=\"line\">                    st[j] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (dist[n] == <span class=\"number\">0x3f3f3f3f</span>) <span class=\"keyword\">return</span> <span class=\"number\">-1</span>;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> dist[n];</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<p><strong></strong></p>\n<p>dist[j] &#x3D; dist[t] + wcnt[x] (1x)</p>\n<p>cnt[x] &#x3D; cnt[t]+1;</p>\n<p>cnt[x] n</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n;      <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> h[N], w[N], e[N], ne[N], idx;       <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N], cnt[N];        <span class=\"comment\">// dist[x]1xcnt[x]1x</span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// truefalse</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">spfa</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// dist</span></span><br><span class=\"line\">    <span class=\"comment\">// nn+1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    queue&lt;<span class=\"type\">int</span>&gt; q;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        q.<span class=\"built_in\">push</span>(i);</span><br><span class=\"line\">        st[i] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (q.<span class=\"built_in\">size</span>())</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">auto</span> t = q.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">        q.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">        st[t] = <span class=\"literal\">false</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[t]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (dist[j] &gt; dist[t] + w[i])</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                dist[j] = dist[t] + w[i];</span><br><span class=\"line\">                cnt[j] = cnt[t] + <span class=\"number\">1</span>;</span><br><span class=\"line\">                <span class=\"keyword\">if</span> (cnt[j] &gt;= n) <span class=\"keyword\">return</span> <span class=\"literal\">true</span>;       <span class=\"comment\">// 1xn</span></span><br><span class=\"line\">                <span class=\"keyword\">if</span> (!st[j])</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    q.<span class=\"built_in\">push</span>(j);</span><br><span class=\"line\">                    st[j] = <span class=\"literal\">true</span>;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">false</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"Floyd\"><a href=\"#Floyd\" class=\"headerlink\" title=\"Floyd\"></a>Floyd</h4><p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (i == j) d[i][j] = <span class=\"number\">0</span>;</span><br><span class=\"line\">            <span class=\"keyword\">else</span> d[i][j] = INF;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// d[a][b]ab</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">floyd</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> k = <span class=\"number\">1</span>; k &lt;= n; k ++ )</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">            <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">                d[i][j] = <span class=\"built_in\">min</span>(d[i][j], d[i][k] + d[k][j]);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"Prim\"><a href=\"#Prim\" class=\"headerlink\" title=\"Prim\"></a>Prim</h4><p></p>\n<p><strong>Prim</strong> $O(n^2)$</p>\n<p>dijkstra</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n;      <span class=\"comment\">// n</span></span><br><span class=\"line\"><span class=\"type\">int</span> g[N][N];        <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">int</span> dist[N];        <span class=\"comment\">// </span></span><br><span class=\"line\"><span class=\"type\">bool</span> st[N];     <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// INF(0x3f3f3f3f), </span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">prim</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">memset</span>(dist, <span class=\"number\">0x3f</span>, <span class=\"keyword\">sizeof</span> dist);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> t = <span class=\"number\">-1</span>;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ )</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (!st[j] &amp;&amp; (t == <span class=\"number\">-1</span> || dist[t] &gt; dist[j]))</span><br><span class=\"line\">                t = j;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i &amp;&amp; dist[t] == INF) <span class=\"keyword\">return</span> INF;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i) res += dist[t];</span><br><span class=\"line\">        st[t] = <span class=\"literal\">true</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> j = <span class=\"number\">1</span>; j &lt;= n; j ++ ) dist[j] = <span class=\"built_in\">min</span>(dist[j], g[t][j]);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>Prim</strong> $O(mlogn)$ </p>\n<h4 id=\"Kruskal\"><a href=\"#Kruskal\" class=\"headerlink\" title=\"Kruskal\"></a>Kruskal</h4><p>$O(mlogm)$ </p>\n<ol>\n<li></li>\n<li>a-&gt;b,c abab</li>\n</ol>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> n, m;       <span class=\"comment\">// nm</span></span><br><span class=\"line\"><span class=\"type\">int</span> p[N];       <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">struct</span> <span class=\"title class_\">Edge</span>     <span class=\"comment\">// </span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> a, b, w;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">bool</span> <span class=\"keyword\">operator</span>&lt; (<span class=\"type\">const</span> Edge &amp;W)<span class=\"type\">const</span></span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> w &lt; W.w;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;edges[M];</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">find</span><span class=\"params\">(<span class=\"type\">int</span> x)</span>     <span class=\"comment\">// </span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (p[x] != x) p[x] = <span class=\"built_in\">find</span>(p[x]);</span><br><span class=\"line\">    <span class=\"keyword\">return</span> p[x];</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">kruskal</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"built_in\">sort</span>(edges, edges + m);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ ) p[i] = i;    <span class=\"comment\">// </span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"type\">int</span> res = <span class=\"number\">0</span>, cnt = <span class=\"number\">0</span>;</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">0</span>; i &lt; m; i ++ )</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> a = edges[i].a, b = edges[i].b, w = edges[i].w;</span><br><span class=\"line\"></span><br><span class=\"line\">        a = <span class=\"built_in\">find</span>(a), b = <span class=\"built_in\">find</span>(b);</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (a != b)     <span class=\"comment\">// </span></span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            p[a] = b;</span><br><span class=\"line\">            res += w;</span><br><span class=\"line\">            cnt ++ ;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (cnt &lt; n - <span class=\"number\">1</span>) <span class=\"keyword\">return</span> INF;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> res;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"},{"title":"-ProteinMPNN","mathjax":true,"date":"2026-01-21T12:46:25.000Z","img":"https://www.researchgate.net/publication/363608659/figure/fig1/AS:11431281127577573@1679077202382/ProteinMPNN-architecture.jpg","excerpt":"SF-MPNN-RL","_content":"\n#### A. \n\n ProteinMPNN **** \n\n- **** N, Ca, C, O Cb \n- ****   \n\n#### B.  (Random Decoding Order)\n\n N  C \n\n- **** ProteinMPNN  \n- **** InferenceBinder design \n\n#### C.  (Training with Noise)\n\n- ****  PDB  0.02 \n- ****  AlphaFold  \n\n#### D.  (Tied Decoding)\n\nTied\n\n- ****  A  1  B  1 Logits \n\n### 3.  (Architecture)\n\nProteinMPNN **-Encoder-Decoder** \n\n- ** (Backbone Encoder):**\n  - \n  - 3 NodeEdge \n  - \n- ** (Sequence Decoder):**\n  -  + Masked sequence\n  - 3  MPNN  \n  - \n\n### 4.  (Experiments & Evaluation)\n\nIn silicoIn vitro\n\n#### A.  (In Silico)\n\n1. ** (Sequence Recovery):** ProteinMPNN  **52.4%** Rosetta  32.9%  \n2. **AlphaFold :**  ProteinMPNN  AlphaFold  AlphaFold pLDDT \n3. **:**  100  1.2  Rosetta  4.3  \n\n#### B.  (Experimental Validation)\n\n ProteinMPNN \"\" \n\n1. ** AlphaFold \"\" (Hallucinations):**\n   - ****  AlphaFold Hallucinations\n   - ****  ProteinMPNN **76%** 73/96 95C \n   - **** RMSD 2.35  \n2. ** (Protein Nanoparticles):**\n   - ****  Rosetta \n   - **** ProteinMPNN  76  13 1.2  RMSD \n3. ** (Functional Design - SH3 Binder):**\n   - ****  Grb2 SH3  Rosetta \n   - **** ProteinMPNN  SH3  \n\n# ProteinMPNN\n\n**B**: Batch size\n\n**L**: Sequence length\n\n**K**: NeighborsK3032\n\n**C**: Hidden dimension128\n\n**V**: Vocab size21+\n\n### 1.  (`featurize` )\n\n PDB \n\n- ****: `batch` ()\n- ****:\n  1.  N, CA, C, O \n  2. Chain `chain_encoding`  `mask`\n  3.  Padding Batch \n- ****:\n  - **`X` ()**: `[B, L, 4, 3]`\n    - 4  (N, Ca, C, O)\n    - 3  (x, y, z) \n  - **`S` ()**: `[B, L]` Loss\n  - **`mask`**: `[B, L]` Padding\n  - **`chain_M`**: `[B, L]`maskedvisible\n\n| ****           | ** (Shape)**    | **** | ****                                  |\n| ---------------------- | ------------------- | ------------ | ----------------------------------------- |\n| **X**                  | `[B, L_max, 4, 3]`  | float32      |  (N, Ca, C, O)                |\n| **S**                  | `[B, L_max]`        | long         |  ( Loss)        |\n| **mask**               | `[B, L_max]`        | float32      | Padding  (1=, 0=)         |\n| **lengths**            | `[B]`               | int32        |                       |\n| **chain_M**            | `[B, L_max]`        | float32      | ****1=/0= |\n| **residue_idx**        | `[B, L_max]`        | long         |  ()                 |\n| **mask_self**          | `[B, L_max, L_max]` | float32      | / ( Loss)     |\n| **chain_encoding_all** | `[B, L_max]`        | long         |  ID (1, 2, 3...)      |\n\n****\n\n**** `residue_idx` \n\n**** `chain_M`  input context Target output design Binder\n\n**** `random.shuffle` \n\n### 2.  (`ProteinFeatures` )\n\nGraph\n\n- ****:\n  1. ** (KNN)**:  CA  `top_k` \n  2. ****: N-Ca, Ca-C  Cb \n  3. ** (Edge Features)**:\n     - ** (RBF)**: N-N, Ca-Ca, C-O  16RBF\n     - ****: Seq differenceChain index\n- ****:\n  -  `X`: `[B, L, 4, 3]`\n  - **`E_idx` ()**: `[B, L, K]` K  L \n  - **`E` ()**: `[B, L, K, C]`\n    -  `self.edge_embedding`  `C`\n\n- ** `E`**:  `[B, L, K, C]`\n- ** `E_idx`**:  `[B, L, K]`\n\n`ProteinFeatures` Node Features**Edge Features**\n\n### 3.  (Gather Functions)\n\n\n\n- **`gather_nodes`**:\n  -  `[B, L, C]`  `[B, L, K]` \n  - : `[B, L, K, C]`\n- **`cat_neighbors_nodes`**:\n  - ********\n\n### 4.  (`EncLayer` )\n\nProteinMPNN **Nodes****Edges**\n\n- ****:\n  1. ****:  `h_V` (), `h_E` (), `h_V_neighbor` ()\n  2. **MLP**: \n  3. **Update Nodes (`h_V`)**:  `K` `torch.sum`\n  4. **Update Edges (`h_E`)**:  MLP \n- **/**:\n  -  `h_V`: `[B, L, C]` (0)\n  -  `h_E`: `[B, L, K, C]` ()\n  -  `h_V`: `[B, L, C]` ()\n  -  `h_E`: `[B, L, K, C]` ()\n\n### 5.  (`DecLayer` )\n\n**Autoregressive**\n\n- ****:\n  1.  Encoder \n  2. ****:  `mask_attend`\n- **/**:\n  -  `h_V`: `[B, L, C]` ()\n  -  `h_E`: `[B, L, K, C]` (Embedding)\n  -  `h_V`: `[B, L, C]`\n\n### 6.  (`ProteinMPNN` )\n\n\n\n#### A. \n\n```python\nE, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\nh_V = torch.zeros(...) # 0\nh_E = self.W_e(E)      # \n```\n\n- `E`: `[B, L, K, C]`\n- `h_V`: `[B, L, C]`\n\n#### B.  (Encoder Loop)\n\n```python\nfor layer in self.encoder_layers:\n    h_V, h_E = layer(h_V, h_E, E_idx, ...)\n```\n\n3 `EncLayer` 3D \n\n#### C.  (Random Decoding Order) - ****\n\n```python\ndecoding_order = torch.argsort(...) \npermutation_matrix_reverse = ...\norder_mask_backward = ...\n```\n\nProteinMPNN  N->C ****\n\n- \n-  `mask_attend` `[B, L, K, 1]` Decoder \n\n#### D. \n\n```python\nh_S = self.W_s(S) #  Embedding [B, L, C]\nh_ES = cat_neighbors_nodes(h_S, h_E, E_idx) # \n```\n\n **Teacher Forcing** `S`  Decoder  mask  `i`  `i` \n\n#### E.  (Decoder Loop)\n\n```python\nfor layer in self.decoder_layers:\n    h_V = layer(h_V, h_ESV, mask)\n```\n\n- `h_ESV` (`h_E`) + (`h_S`)\n-  `mask_bw` (backward mask) \n\n#### F. \n\n```python\nlogits = self.W_out(h_V) # [B, L, 21]\nlog_probs = F.log_softmax(logits, dim=-1)\n```\n\n 21 \n\n### \n\n1. **Input**: `coords [B, L, 4, 3]`\n2. **Features**: `Edges [B, L, K, C]` ()\n3. **Encoder**:\n   - Input: `Nodes [B, L, C]` (zeros), `Edges [B, L, K, C]`\n   - Output: `Nodes [B, L, C]` (), `Edges [B, L, K, C]` ()\n4. **Decoder Prep**:\n   - `Seq Embed [B, L, C]` ()\n   - `Random Mask [B, L, K]` ()\n5. **Decoder**:\n   - Input: `Encoder Nodes`, `Seq Embed + Edges`\n   - Output: `Nodes [B, L, C]` (+)\n6. **Output**: `Logits [B, L, 21]`","source":"_posts/conditionMPNN.md","raw":"---\ntitle: -ProteinMPNN\nmathjax: true\ndate: 2026/01/21 20:46:25\nimg: https://www.researchgate.net/publication/363608659/figure/fig1/AS:11431281127577573@1679077202382/ProteinMPNN-architecture.jpg\nexcerpt: SF-MPNN-RL\n---\n\n#### A. \n\n ProteinMPNN **** \n\n- **** N, Ca, C, O Cb \n- ****   \n\n#### B.  (Random Decoding Order)\n\n N  C \n\n- **** ProteinMPNN  \n- **** InferenceBinder design \n\n#### C.  (Training with Noise)\n\n- ****  PDB  0.02 \n- ****  AlphaFold  \n\n#### D.  (Tied Decoding)\n\nTied\n\n- ****  A  1  B  1 Logits \n\n### 3.  (Architecture)\n\nProteinMPNN **-Encoder-Decoder** \n\n- ** (Backbone Encoder):**\n  - \n  - 3 NodeEdge \n  - \n- ** (Sequence Decoder):**\n  -  + Masked sequence\n  - 3  MPNN  \n  - \n\n### 4.  (Experiments & Evaluation)\n\nIn silicoIn vitro\n\n#### A.  (In Silico)\n\n1. ** (Sequence Recovery):** ProteinMPNN  **52.4%** Rosetta  32.9%  \n2. **AlphaFold :**  ProteinMPNN  AlphaFold  AlphaFold pLDDT \n3. **:**  100  1.2  Rosetta  4.3  \n\n#### B.  (Experimental Validation)\n\n ProteinMPNN \"\" \n\n1. ** AlphaFold \"\" (Hallucinations):**\n   - ****  AlphaFold Hallucinations\n   - ****  ProteinMPNN **76%** 73/96 95C \n   - **** RMSD 2.35  \n2. ** (Protein Nanoparticles):**\n   - ****  Rosetta \n   - **** ProteinMPNN  76  13 1.2  RMSD \n3. ** (Functional Design - SH3 Binder):**\n   - ****  Grb2 SH3  Rosetta \n   - **** ProteinMPNN  SH3  \n\n# ProteinMPNN\n\n**B**: Batch size\n\n**L**: Sequence length\n\n**K**: NeighborsK3032\n\n**C**: Hidden dimension128\n\n**V**: Vocab size21+\n\n### 1.  (`featurize` )\n\n PDB \n\n- ****: `batch` ()\n- ****:\n  1.  N, CA, C, O \n  2. Chain `chain_encoding`  `mask`\n  3.  Padding Batch \n- ****:\n  - **`X` ()**: `[B, L, 4, 3]`\n    - 4  (N, Ca, C, O)\n    - 3  (x, y, z) \n  - **`S` ()**: `[B, L]` Loss\n  - **`mask`**: `[B, L]` Padding\n  - **`chain_M`**: `[B, L]`maskedvisible\n\n| ****           | ** (Shape)**    | **** | ****                                  |\n| ---------------------- | ------------------- | ------------ | ----------------------------------------- |\n| **X**                  | `[B, L_max, 4, 3]`  | float32      |  (N, Ca, C, O)                |\n| **S**                  | `[B, L_max]`        | long         |  ( Loss)        |\n| **mask**               | `[B, L_max]`        | float32      | Padding  (1=, 0=)         |\n| **lengths**            | `[B]`               | int32        |                       |\n| **chain_M**            | `[B, L_max]`        | float32      | ****1=/0= |\n| **residue_idx**        | `[B, L_max]`        | long         |  ()                 |\n| **mask_self**          | `[B, L_max, L_max]` | float32      | / ( Loss)     |\n| **chain_encoding_all** | `[B, L_max]`        | long         |  ID (1, 2, 3...)      |\n\n****\n\n**** `residue_idx` \n\n**** `chain_M`  input context Target output design Binder\n\n**** `random.shuffle` \n\n### 2.  (`ProteinFeatures` )\n\nGraph\n\n- ****:\n  1. ** (KNN)**:  CA  `top_k` \n  2. ****: N-Ca, Ca-C  Cb \n  3. ** (Edge Features)**:\n     - ** (RBF)**: N-N, Ca-Ca, C-O  16RBF\n     - ****: Seq differenceChain index\n- ****:\n  -  `X`: `[B, L, 4, 3]`\n  - **`E_idx` ()**: `[B, L, K]` K  L \n  - **`E` ()**: `[B, L, K, C]`\n    -  `self.edge_embedding`  `C`\n\n- ** `E`**:  `[B, L, K, C]`\n- ** `E_idx`**:  `[B, L, K]`\n\n`ProteinFeatures` Node Features**Edge Features**\n\n### 3.  (Gather Functions)\n\n\n\n- **`gather_nodes`**:\n  -  `[B, L, C]`  `[B, L, K]` \n  - : `[B, L, K, C]`\n- **`cat_neighbors_nodes`**:\n  - ********\n\n### 4.  (`EncLayer` )\n\nProteinMPNN **Nodes****Edges**\n\n- ****:\n  1. ****:  `h_V` (), `h_E` (), `h_V_neighbor` ()\n  2. **MLP**: \n  3. **Update Nodes (`h_V`)**:  `K` `torch.sum`\n  4. **Update Edges (`h_E`)**:  MLP \n- **/**:\n  -  `h_V`: `[B, L, C]` (0)\n  -  `h_E`: `[B, L, K, C]` ()\n  -  `h_V`: `[B, L, C]` ()\n  -  `h_E`: `[B, L, K, C]` ()\n\n### 5.  (`DecLayer` )\n\n**Autoregressive**\n\n- ****:\n  1.  Encoder \n  2. ****:  `mask_attend`\n- **/**:\n  -  `h_V`: `[B, L, C]` ()\n  -  `h_E`: `[B, L, K, C]` (Embedding)\n  -  `h_V`: `[B, L, C]`\n\n### 6.  (`ProteinMPNN` )\n\n\n\n#### A. \n\n```python\nE, E_idx = self.features(X, mask, residue_idx, chain_encoding_all)\nh_V = torch.zeros(...) # 0\nh_E = self.W_e(E)      # \n```\n\n- `E`: `[B, L, K, C]`\n- `h_V`: `[B, L, C]`\n\n#### B.  (Encoder Loop)\n\n```python\nfor layer in self.encoder_layers:\n    h_V, h_E = layer(h_V, h_E, E_idx, ...)\n```\n\n3 `EncLayer` 3D \n\n#### C.  (Random Decoding Order) - ****\n\n```python\ndecoding_order = torch.argsort(...) \npermutation_matrix_reverse = ...\norder_mask_backward = ...\n```\n\nProteinMPNN  N->C ****\n\n- \n-  `mask_attend` `[B, L, K, 1]` Decoder \n\n#### D. \n\n```python\nh_S = self.W_s(S) #  Embedding [B, L, C]\nh_ES = cat_neighbors_nodes(h_S, h_E, E_idx) # \n```\n\n **Teacher Forcing** `S`  Decoder  mask  `i`  `i` \n\n#### E.  (Decoder Loop)\n\n```python\nfor layer in self.decoder_layers:\n    h_V = layer(h_V, h_ESV, mask)\n```\n\n- `h_ESV` (`h_E`) + (`h_S`)\n-  `mask_bw` (backward mask) \n\n#### F. \n\n```python\nlogits = self.W_out(h_V) # [B, L, 21]\nlog_probs = F.log_softmax(logits, dim=-1)\n```\n\n 21 \n\n### \n\n1. **Input**: `coords [B, L, 4, 3]`\n2. **Features**: `Edges [B, L, K, C]` ()\n3. **Encoder**:\n   - Input: `Nodes [B, L, C]` (zeros), `Edges [B, L, K, C]`\n   - Output: `Nodes [B, L, C]` (), `Edges [B, L, K, C]` ()\n4. **Decoder Prep**:\n   - `Seq Embed [B, L, C]` ()\n   - `Random Mask [B, L, K]` ()\n5. **Decoder**:\n   - Input: `Encoder Nodes`, `Seq Embed + Edges`\n   - Output: `Nodes [B, L, C]` (+)\n6. **Output**: `Logits [B, L, 21]`","slug":"conditionMPNN","published":1,"updated":"2026-01-23T07:34:54.027Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff6000bss9901ozalwy","content":"<h4 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A. \"></a>A. </h4><p> ProteinMPNN <strong></strong> </p>\n<ul>\n<li><strong></strong> N, Ca, C, O Cb </li>\n<li><strong></strong>   </li>\n</ul>\n<h4 id=\"B--Random-Decoding-Order\"><a href=\"#B--Random-Decoding-Order\" class=\"headerlink\" title=\"B.  (Random Decoding Order)\"></a>B.  (Random Decoding Order)</h4><p> N  C </p>\n<ul>\n<li><strong></strong> ProteinMPNN  </li>\n<li><strong></strong> InferenceBinder design </li>\n</ul>\n<h4 id=\"C--Training-with-Noise\"><a href=\"#C--Training-with-Noise\" class=\"headerlink\" title=\"C.  (Training with Noise)\"></a>C.  (Training with Noise)</h4><ul>\n<li><strong></strong>  PDB  0.02 </li>\n<li><strong></strong>  AlphaFold  </li>\n</ul>\n<h4 id=\"D--Tied-Decoding\"><a href=\"#D--Tied-Decoding\" class=\"headerlink\" title=\"D.  (Tied Decoding)\"></a>D.  (Tied Decoding)</h4><p>Tied</p>\n<ul>\n<li><strong></strong>  A  1  B  1 Logits </li>\n</ul>\n<h3 id=\"3--Architecture\"><a href=\"#3--Architecture\" class=\"headerlink\" title=\"3.  (Architecture)\"></a>3.  (Architecture)</h3><p>ProteinMPNN <strong>-Encoder-Decoder</strong> </p>\n<ul>\n<li><strong> (Backbone Encoder):</strong><ul>\n<li></li>\n<li>3 NodeEdge </li>\n<li></li>\n</ul>\n</li>\n<li><strong> (Sequence Decoder):</strong><ul>\n<li> + Masked sequence</li>\n<li>3  MPNN  </li>\n<li></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4--Experiments-Evaluation\"><a href=\"#4--Experiments-Evaluation\" class=\"headerlink\" title=\"4.  (Experiments &amp; Evaluation)\"></a>4.  (Experiments &amp; Evaluation)</h3><p>In silicoIn vitro</p>\n<h4 id=\"A--In-Silico\"><a href=\"#A--In-Silico\" class=\"headerlink\" title=\"A.  (In Silico)\"></a>A.  (In Silico)</h4><ol>\n<li><strong> (Sequence Recovery):</strong> ProteinMPNN  **52.4%** Rosetta  32.9%  </li>\n<li><strong>AlphaFold :</strong>  ProteinMPNN  AlphaFold  AlphaFold pLDDT </li>\n<li><strong>:</strong>  100  1.2  Rosetta  4.3  </li>\n</ol>\n<h4 id=\"B--Experimental-Validation\"><a href=\"#B--Experimental-Validation\" class=\"headerlink\" title=\"B.  (Experimental Validation)\"></a>B.  (Experimental Validation)</h4><p> ProteinMPNN  </p>\n<ol>\n<li><strong> AlphaFold  (Hallucinations):</strong><ul>\n<li><strong></strong>  AlphaFold Hallucinations</li>\n<li><strong></strong>  ProteinMPNN <strong>76%</strong> 73&#x2F;96 95C </li>\n<li><strong></strong> RMSD 2.35  </li>\n</ul>\n</li>\n<li><strong> (Protein Nanoparticles):</strong><ul>\n<li><strong></strong>  Rosetta </li>\n<li><strong></strong> ProteinMPNN  76  13 1.2  RMSD </li>\n</ul>\n</li>\n<li><strong> (Functional Design - SH3 Binder):</strong><ul>\n<li><strong></strong>  Grb2 SH3  Rosetta </li>\n<li><strong></strong> ProteinMPNN  SH3  </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"ProteinMPNN\"><a href=\"#ProteinMPNN\" class=\"headerlink\" title=\"ProteinMPNN\"></a>ProteinMPNN</h1><p><strong>B</strong>: Batch size</p>\n<p><strong>L</strong>: Sequence length</p>\n<p><strong>K</strong>: NeighborsK3032</p>\n<p><strong>C</strong>: Hidden dimension128</p>\n<p><strong>V</strong>: Vocab size21+</p>\n<h3 id=\"1--featurize-\"><a href=\"#1--featurize-\" class=\"headerlink\" title=\"1.  (featurize )\"></a>1.  (<code>featurize</code> )</h3><p> PDB </p>\n<ul>\n<li><strong></strong>: <code>batch</code> ()</li>\n<li><strong></strong>:<ol>\n<li> N, CA, C, O </li>\n<li>Chain <code>chain_encoding</code>  <code>mask</code></li>\n<li> Padding Batch </li>\n</ol>\n</li>\n<li><strong></strong>:<ul>\n<li><strong><code>X</code> ()</strong>: <code>[B, L, 4, 3]</code><ul>\n<li>4  (N, Ca, C, O)</li>\n<li>3  (x, y, z) </li>\n</ul>\n</li>\n<li><strong><code>S</code> ()</strong>: <code>[B, L]</code> Loss</li>\n<li><strong><code>mask</code></strong>: <code>[B, L]</code> Padding</li>\n<li><strong><code>chain_M</code></strong>: <code>[B, L]</code>maskedvisible</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong></strong></th>\n<th><strong> (Shape)</strong></th>\n<th><strong></strong></th>\n<th><strong></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>X</strong></td>\n<td><code>[B, L_max, 4, 3]</code></td>\n<td>float32</td>\n<td> (N, Ca, C, O)</td>\n</tr>\n<tr>\n<td><strong>S</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>long</td>\n<td> ( Loss)</td>\n</tr>\n<tr>\n<td><strong>mask</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>float32</td>\n<td>Padding  (1&#x3D;, 0&#x3D;)</td>\n</tr>\n<tr>\n<td><strong>lengths</strong></td>\n<td><code>[B]</code></td>\n<td>int32</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>chain_M</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>float32</td>\n<td><strong></strong>1&#x3D;&#x2F;0&#x3D;</td>\n</tr>\n<tr>\n<td><strong>residue_idx</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>long</td>\n<td> ()</td>\n</tr>\n<tr>\n<td><strong>mask_self</strong></td>\n<td><code>[B, L_max, L_max]</code></td>\n<td>float32</td>\n<td>&#x2F; ( Loss)</td>\n</tr>\n<tr>\n<td><strong>chain_encoding_all</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>long</td>\n<td> ID (1, 2, 3)</td>\n</tr>\n</tbody></table>\n<p><strong></strong></p>\n<p><strong></strong> <code>residue_idx</code> </p>\n<p><strong></strong> <code>chain_M</code>  input context Target output design Binder</p>\n<p><strong></strong> <code>random.shuffle</code> </p>\n<h3 id=\"2--ProteinFeatures-\"><a href=\"#2--ProteinFeatures-\" class=\"headerlink\" title=\"2.  (ProteinFeatures )\"></a>2.  (<code>ProteinFeatures</code> )</h3><p>Graph</p>\n<ul>\n<li><p><strong></strong>:</p>\n<ol>\n<li><strong> (KNN)</strong>:  CA  <code>top_k</code> </li>\n<li><strong></strong>: N-Ca, Ca-C  Cb </li>\n<li><strong> (Edge Features)</strong>:<ul>\n<li><strong> (RBF)</strong>: N-N, Ca-Ca, C-O  16RBF</li>\n<li><strong></strong>: Seq differenceChain index</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p><strong></strong>:</p>\n<ul>\n<li> <code>X</code>: <code>[B, L, 4, 3]</code></li>\n<li><strong><code>E_idx</code> ()</strong>: <code>[B, L, K]</code> K  L </li>\n<li><strong><code>E</code> ()</strong>: <code>[B, L, K, C]</code><ul>\n<li> <code>self.edge_embedding</code>  <code>C</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong> <code>E</code></strong>:  <code>[B, L, K, C]</code></p>\n</li>\n<li><p><strong> <code>E_idx</code></strong>:  <code>[B, L, K]</code></p>\n</li>\n</ul>\n<p><code>ProteinFeatures</code> Node Features<strong>Edge Features</strong></p>\n<h3 id=\"3--Gather-Functions\"><a href=\"#3--Gather-Functions\" class=\"headerlink\" title=\"3.  (Gather Functions)\"></a>3.  (Gather Functions)</h3><p></p>\n<ul>\n<li><strong><code>gather_nodes</code></strong>:<ul>\n<li> <code>[B, L, C]</code>  <code>[B, L, K]</code> </li>\n<li>: <code>[B, L, K, C]</code></li>\n</ul>\n</li>\n<li><strong><code>cat_neighbors_nodes</code></strong>:<ul>\n<li><strong></strong><strong></strong></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4--EncLayer-\"><a href=\"#4--EncLayer-\" class=\"headerlink\" title=\"4.  (EncLayer )\"></a>4.  (<code>EncLayer</code> )</h3><p>ProteinMPNN <strong>Nodes</strong><strong>Edges</strong></p>\n<ul>\n<li><strong></strong>:<ol>\n<li><strong></strong>:  <code>h_V</code> (), <code>h_E</code> (), <code>h_V_neighbor</code> ()</li>\n<li><strong>MLP</strong>: </li>\n<li><strong>Update Nodes (<code>h_V</code>)</strong>:  <code>K</code> <code>torch.sum</code></li>\n<li><strong>Update Edges (<code>h_E</code>)</strong>:  MLP </li>\n</ol>\n</li>\n<li><strong>&#x2F;</strong>:<ul>\n<li> <code>h_V</code>: <code>[B, L, C]</code> (0)</li>\n<li> <code>h_E</code>: <code>[B, L, K, C]</code> ()</li>\n<li> <code>h_V</code>: <code>[B, L, C]</code> ()</li>\n<li> <code>h_E</code>: <code>[B, L, K, C]</code> ()</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"5--DecLayer-\"><a href=\"#5--DecLayer-\" class=\"headerlink\" title=\"5.  (DecLayer )\"></a>5.  (<code>DecLayer</code> )</h3><p><strong>Autoregressive</strong></p>\n<ul>\n<li><strong></strong>:<ol>\n<li> Encoder </li>\n<li><strong></strong>:  <code>mask_attend</code></li>\n</ol>\n</li>\n<li><strong>&#x2F;</strong>:<ul>\n<li> <code>h_V</code>: <code>[B, L, C]</code> ()</li>\n<li> <code>h_E</code>: <code>[B, L, K, C]</code> (Embedding)</li>\n<li> <code>h_V</code>: <code>[B, L, C]</code></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6--ProteinMPNN-\"><a href=\"#6--ProteinMPNN-\" class=\"headerlink\" title=\"6.  (ProteinMPNN )\"></a>6.  (<code>ProteinMPNN</code> )</h3><p></p>\n<h4 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A. \"></a>A. </h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">E, E_idx = <span class=\"variable language_\">self</span>.features(X, mask, residue_idx, chain_encoding_all)</span><br><span class=\"line\">h_V = torch.zeros(...) <span class=\"comment\"># 0</span></span><br><span class=\"line\">h_E = <span class=\"variable language_\">self</span>.W_e(E)      <span class=\"comment\"># </span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>E</code>: <code>[B, L, K, C]</code></li>\n<li><code>h_V</code>: <code>[B, L, C]</code></li>\n</ul>\n<h4 id=\"B--Encoder-Loop\"><a href=\"#B--Encoder-Loop\" class=\"headerlink\" title=\"B.  (Encoder Loop)\"></a>B.  (Encoder Loop)</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> layer <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.encoder_layers:</span><br><span class=\"line\">    h_V, h_E = layer(h_V, h_E, E_idx, ...)</span><br></pre></td></tr></table></figure>\n\n<p>3 <code>EncLayer</code> 3D </p>\n<h4 id=\"C--Random-Decoding-Order-\"><a href=\"#C--Random-Decoding-Order-\" class=\"headerlink\" title=\"C.  (Random Decoding Order) - \"></a>C.  (Random Decoding Order) - <strong></strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">decoding_order = torch.argsort(...) </span><br><span class=\"line\">permutation_matrix_reverse = ...</span><br><span class=\"line\">order_mask_backward = ...</span><br></pre></td></tr></table></figure>\n\n<p>ProteinMPNN  N-&gt;C <strong></strong></p>\n<ul>\n<li></li>\n<li> <code>mask_attend</code> <code>[B, L, K, 1]</code> Decoder </li>\n</ul>\n<h4 id=\"D-\"><a href=\"#D-\" class=\"headerlink\" title=\"D. \"></a>D. </h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">h_S = <span class=\"variable language_\">self</span>.W_s(S) <span class=\"comment\">#  Embedding [B, L, C]</span></span><br><span class=\"line\">h_ES = cat_neighbors_nodes(h_S, h_E, E_idx) <span class=\"comment\"># </span></span><br></pre></td></tr></table></figure>\n\n<p> <strong>Teacher Forcing</strong> <code>S</code>  Decoder  mask  <code>i</code>  <code>i</code> </p>\n<h4 id=\"E--Decoder-Loop\"><a href=\"#E--Decoder-Loop\" class=\"headerlink\" title=\"E.  (Decoder Loop)\"></a>E.  (Decoder Loop)</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> layer <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.decoder_layers:</span><br><span class=\"line\">    h_V = layer(h_V, h_ESV, mask)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>h_ESV</code> (<code>h_E</code>) + (<code>h_S</code>)</li>\n<li> <code>mask_bw</code> (backward mask) </li>\n</ul>\n<h4 id=\"F-\"><a href=\"#F-\" class=\"headerlink\" title=\"F. \"></a>F. </h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">logits = <span class=\"variable language_\">self</span>.W_out(h_V) <span class=\"comment\"># [B, L, 21]</span></span><br><span class=\"line\">log_probs = F.log_softmax(logits, dim=-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<p> 21 </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li><strong>Input</strong>: <code>coords [B, L, 4, 3]</code></li>\n<li><strong>Features</strong>: <code>Edges [B, L, K, C]</code> ()</li>\n<li><strong>Encoder</strong>:<ul>\n<li>Input: <code>Nodes [B, L, C]</code> (zeros), <code>Edges [B, L, K, C]</code></li>\n<li>Output: <code>Nodes [B, L, C]</code> (), <code>Edges [B, L, K, C]</code> ()</li>\n</ul>\n</li>\n<li><strong>Decoder Prep</strong>:<ul>\n<li><code>Seq Embed [B, L, C]</code> ()</li>\n<li><code>Random Mask [B, L, K]</code> ()</li>\n</ul>\n</li>\n<li><strong>Decoder</strong>:<ul>\n<li>Input: <code>Encoder Nodes</code>, <code>Seq Embed + Edges</code></li>\n<li>Output: <code>Nodes [B, L, C]</code> (+)</li>\n</ul>\n</li>\n<li><strong>Output</strong>: <code>Logits [B, L, 21]</code></li>\n</ol>\n","more":"<h4 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A. \"></a>A. </h4><p> ProteinMPNN <strong></strong> </p>\n<ul>\n<li><strong></strong> N, Ca, C, O Cb </li>\n<li><strong></strong>   </li>\n</ul>\n<h4 id=\"B--Random-Decoding-Order\"><a href=\"#B--Random-Decoding-Order\" class=\"headerlink\" title=\"B.  (Random Decoding Order)\"></a>B.  (Random Decoding Order)</h4><p> N  C </p>\n<ul>\n<li><strong></strong> ProteinMPNN  </li>\n<li><strong></strong> InferenceBinder design </li>\n</ul>\n<h4 id=\"C--Training-with-Noise\"><a href=\"#C--Training-with-Noise\" class=\"headerlink\" title=\"C.  (Training with Noise)\"></a>C.  (Training with Noise)</h4><ul>\n<li><strong></strong>  PDB  0.02 </li>\n<li><strong></strong>  AlphaFold  </li>\n</ul>\n<h4 id=\"D--Tied-Decoding\"><a href=\"#D--Tied-Decoding\" class=\"headerlink\" title=\"D.  (Tied Decoding)\"></a>D.  (Tied Decoding)</h4><p>Tied</p>\n<ul>\n<li><strong></strong>  A  1  B  1 Logits </li>\n</ul>\n<h3 id=\"3--Architecture\"><a href=\"#3--Architecture\" class=\"headerlink\" title=\"3.  (Architecture)\"></a>3.  (Architecture)</h3><p>ProteinMPNN <strong>-Encoder-Decoder</strong> </p>\n<ul>\n<li><strong> (Backbone Encoder):</strong><ul>\n<li></li>\n<li>3 NodeEdge </li>\n<li></li>\n</ul>\n</li>\n<li><strong> (Sequence Decoder):</strong><ul>\n<li> + Masked sequence</li>\n<li>3  MPNN  </li>\n<li></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4--Experiments-Evaluation\"><a href=\"#4--Experiments-Evaluation\" class=\"headerlink\" title=\"4.  (Experiments &amp; Evaluation)\"></a>4.  (Experiments &amp; Evaluation)</h3><p>In silicoIn vitro</p>\n<h4 id=\"A--In-Silico\"><a href=\"#A--In-Silico\" class=\"headerlink\" title=\"A.  (In Silico)\"></a>A.  (In Silico)</h4><ol>\n<li><strong> (Sequence Recovery):</strong> ProteinMPNN  **52.4%** Rosetta  32.9%  </li>\n<li><strong>AlphaFold :</strong>  ProteinMPNN  AlphaFold  AlphaFold pLDDT </li>\n<li><strong>:</strong>  100  1.2  Rosetta  4.3  </li>\n</ol>\n<h4 id=\"B--Experimental-Validation\"><a href=\"#B--Experimental-Validation\" class=\"headerlink\" title=\"B.  (Experimental Validation)\"></a>B.  (Experimental Validation)</h4><p> ProteinMPNN  </p>\n<ol>\n<li><strong> AlphaFold  (Hallucinations):</strong><ul>\n<li><strong></strong>  AlphaFold Hallucinations</li>\n<li><strong></strong>  ProteinMPNN <strong>76%</strong> 73&#x2F;96 95C </li>\n<li><strong></strong> RMSD 2.35  </li>\n</ul>\n</li>\n<li><strong> (Protein Nanoparticles):</strong><ul>\n<li><strong></strong>  Rosetta </li>\n<li><strong></strong> ProteinMPNN  76  13 1.2  RMSD </li>\n</ul>\n</li>\n<li><strong> (Functional Design - SH3 Binder):</strong><ul>\n<li><strong></strong>  Grb2 SH3  Rosetta </li>\n<li><strong></strong> ProteinMPNN  SH3  </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"ProteinMPNN\"><a href=\"#ProteinMPNN\" class=\"headerlink\" title=\"ProteinMPNN\"></a>ProteinMPNN</h1><p><strong>B</strong>: Batch size</p>\n<p><strong>L</strong>: Sequence length</p>\n<p><strong>K</strong>: NeighborsK3032</p>\n<p><strong>C</strong>: Hidden dimension128</p>\n<p><strong>V</strong>: Vocab size21+</p>\n<h3 id=\"1--featurize-\"><a href=\"#1--featurize-\" class=\"headerlink\" title=\"1.  (featurize )\"></a>1.  (<code>featurize</code> )</h3><p> PDB </p>\n<ul>\n<li><strong></strong>: <code>batch</code> ()</li>\n<li><strong></strong>:<ol>\n<li> N, CA, C, O </li>\n<li>Chain <code>chain_encoding</code>  <code>mask</code></li>\n<li> Padding Batch </li>\n</ol>\n</li>\n<li><strong></strong>:<ul>\n<li><strong><code>X</code> ()</strong>: <code>[B, L, 4, 3]</code><ul>\n<li>4  (N, Ca, C, O)</li>\n<li>3  (x, y, z) </li>\n</ul>\n</li>\n<li><strong><code>S</code> ()</strong>: <code>[B, L]</code> Loss</li>\n<li><strong><code>mask</code></strong>: <code>[B, L]</code> Padding</li>\n<li><strong><code>chain_M</code></strong>: <code>[B, L]</code>maskedvisible</li>\n</ul>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th><strong></strong></th>\n<th><strong> (Shape)</strong></th>\n<th><strong></strong></th>\n<th><strong></strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>X</strong></td>\n<td><code>[B, L_max, 4, 3]</code></td>\n<td>float32</td>\n<td> (N, Ca, C, O)</td>\n</tr>\n<tr>\n<td><strong>S</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>long</td>\n<td> ( Loss)</td>\n</tr>\n<tr>\n<td><strong>mask</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>float32</td>\n<td>Padding  (1&#x3D;, 0&#x3D;)</td>\n</tr>\n<tr>\n<td><strong>lengths</strong></td>\n<td><code>[B]</code></td>\n<td>int32</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>chain_M</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>float32</td>\n<td><strong></strong>1&#x3D;&#x2F;0&#x3D;</td>\n</tr>\n<tr>\n<td><strong>residue_idx</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>long</td>\n<td> ()</td>\n</tr>\n<tr>\n<td><strong>mask_self</strong></td>\n<td><code>[B, L_max, L_max]</code></td>\n<td>float32</td>\n<td>&#x2F; ( Loss)</td>\n</tr>\n<tr>\n<td><strong>chain_encoding_all</strong></td>\n<td><code>[B, L_max]</code></td>\n<td>long</td>\n<td> ID (1, 2, 3)</td>\n</tr>\n</tbody></table>\n<p><strong></strong></p>\n<p><strong></strong> <code>residue_idx</code> </p>\n<p><strong></strong> <code>chain_M</code>  input context Target output design Binder</p>\n<p><strong></strong> <code>random.shuffle</code> </p>\n<h3 id=\"2--ProteinFeatures-\"><a href=\"#2--ProteinFeatures-\" class=\"headerlink\" title=\"2.  (ProteinFeatures )\"></a>2.  (<code>ProteinFeatures</code> )</h3><p>Graph</p>\n<ul>\n<li><p><strong></strong>:</p>\n<ol>\n<li><strong> (KNN)</strong>:  CA  <code>top_k</code> </li>\n<li><strong></strong>: N-Ca, Ca-C  Cb </li>\n<li><strong> (Edge Features)</strong>:<ul>\n<li><strong> (RBF)</strong>: N-N, Ca-Ca, C-O  16RBF</li>\n<li><strong></strong>: Seq differenceChain index</li>\n</ul>\n</li>\n</ol>\n</li>\n<li><p><strong></strong>:</p>\n<ul>\n<li> <code>X</code>: <code>[B, L, 4, 3]</code></li>\n<li><strong><code>E_idx</code> ()</strong>: <code>[B, L, K]</code> K  L </li>\n<li><strong><code>E</code> ()</strong>: <code>[B, L, K, C]</code><ul>\n<li> <code>self.edge_embedding</code>  <code>C</code></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong> <code>E</code></strong>:  <code>[B, L, K, C]</code></p>\n</li>\n<li><p><strong> <code>E_idx</code></strong>:  <code>[B, L, K]</code></p>\n</li>\n</ul>\n<p><code>ProteinFeatures</code> Node Features<strong>Edge Features</strong></p>\n<h3 id=\"3--Gather-Functions\"><a href=\"#3--Gather-Functions\" class=\"headerlink\" title=\"3.  (Gather Functions)\"></a>3.  (Gather Functions)</h3><p></p>\n<ul>\n<li><strong><code>gather_nodes</code></strong>:<ul>\n<li> <code>[B, L, C]</code>  <code>[B, L, K]</code> </li>\n<li>: <code>[B, L, K, C]</code></li>\n</ul>\n</li>\n<li><strong><code>cat_neighbors_nodes</code></strong>:<ul>\n<li><strong></strong><strong></strong></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"4--EncLayer-\"><a href=\"#4--EncLayer-\" class=\"headerlink\" title=\"4.  (EncLayer )\"></a>4.  (<code>EncLayer</code> )</h3><p>ProteinMPNN <strong>Nodes</strong><strong>Edges</strong></p>\n<ul>\n<li><strong></strong>:<ol>\n<li><strong></strong>:  <code>h_V</code> (), <code>h_E</code> (), <code>h_V_neighbor</code> ()</li>\n<li><strong>MLP</strong>: </li>\n<li><strong>Update Nodes (<code>h_V</code>)</strong>:  <code>K</code> <code>torch.sum</code></li>\n<li><strong>Update Edges (<code>h_E</code>)</strong>:  MLP </li>\n</ol>\n</li>\n<li><strong>&#x2F;</strong>:<ul>\n<li> <code>h_V</code>: <code>[B, L, C]</code> (0)</li>\n<li> <code>h_E</code>: <code>[B, L, K, C]</code> ()</li>\n<li> <code>h_V</code>: <code>[B, L, C]</code> ()</li>\n<li> <code>h_E</code>: <code>[B, L, K, C]</code> ()</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"5--DecLayer-\"><a href=\"#5--DecLayer-\" class=\"headerlink\" title=\"5.  (DecLayer )\"></a>5.  (<code>DecLayer</code> )</h3><p><strong>Autoregressive</strong></p>\n<ul>\n<li><strong></strong>:<ol>\n<li> Encoder </li>\n<li><strong></strong>:  <code>mask_attend</code></li>\n</ol>\n</li>\n<li><strong>&#x2F;</strong>:<ul>\n<li> <code>h_V</code>: <code>[B, L, C]</code> ()</li>\n<li> <code>h_E</code>: <code>[B, L, K, C]</code> (Embedding)</li>\n<li> <code>h_V</code>: <code>[B, L, C]</code></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"6--ProteinMPNN-\"><a href=\"#6--ProteinMPNN-\" class=\"headerlink\" title=\"6.  (ProteinMPNN )\"></a>6.  (<code>ProteinMPNN</code> )</h3><p></p>\n<h4 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A. \"></a>A. </h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">E, E_idx = <span class=\"variable language_\">self</span>.features(X, mask, residue_idx, chain_encoding_all)</span><br><span class=\"line\">h_V = torch.zeros(...) <span class=\"comment\"># 0</span></span><br><span class=\"line\">h_E = <span class=\"variable language_\">self</span>.W_e(E)      <span class=\"comment\"># </span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>E</code>: <code>[B, L, K, C]</code></li>\n<li><code>h_V</code>: <code>[B, L, C]</code></li>\n</ul>\n<h4 id=\"B--Encoder-Loop\"><a href=\"#B--Encoder-Loop\" class=\"headerlink\" title=\"B.  (Encoder Loop)\"></a>B.  (Encoder Loop)</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> layer <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.encoder_layers:</span><br><span class=\"line\">    h_V, h_E = layer(h_V, h_E, E_idx, ...)</span><br></pre></td></tr></table></figure>\n\n<p>3 <code>EncLayer</code> 3D </p>\n<h4 id=\"C--Random-Decoding-Order-\"><a href=\"#C--Random-Decoding-Order-\" class=\"headerlink\" title=\"C.  (Random Decoding Order) - \"></a>C.  (Random Decoding Order) - <strong></strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">decoding_order = torch.argsort(...) </span><br><span class=\"line\">permutation_matrix_reverse = ...</span><br><span class=\"line\">order_mask_backward = ...</span><br></pre></td></tr></table></figure>\n\n<p>ProteinMPNN  N-&gt;C <strong></strong></p>\n<ul>\n<li></li>\n<li> <code>mask_attend</code> <code>[B, L, K, 1]</code> Decoder </li>\n</ul>\n<h4 id=\"D-\"><a href=\"#D-\" class=\"headerlink\" title=\"D. \"></a>D. </h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">h_S = <span class=\"variable language_\">self</span>.W_s(S) <span class=\"comment\">#  Embedding [B, L, C]</span></span><br><span class=\"line\">h_ES = cat_neighbors_nodes(h_S, h_E, E_idx) <span class=\"comment\"># </span></span><br></pre></td></tr></table></figure>\n\n<p> <strong>Teacher Forcing</strong> <code>S</code>  Decoder  mask  <code>i</code>  <code>i</code> </p>\n<h4 id=\"E--Decoder-Loop\"><a href=\"#E--Decoder-Loop\" class=\"headerlink\" title=\"E.  (Decoder Loop)\"></a>E.  (Decoder Loop)</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> layer <span class=\"keyword\">in</span> <span class=\"variable language_\">self</span>.decoder_layers:</span><br><span class=\"line\">    h_V = layer(h_V, h_ESV, mask)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><code>h_ESV</code> (<code>h_E</code>) + (<code>h_S</code>)</li>\n<li> <code>mask_bw</code> (backward mask) </li>\n</ul>\n<h4 id=\"F-\"><a href=\"#F-\" class=\"headerlink\" title=\"F. \"></a>F. </h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">logits = <span class=\"variable language_\">self</span>.W_out(h_V) <span class=\"comment\"># [B, L, 21]</span></span><br><span class=\"line\">log_probs = F.log_softmax(logits, dim=-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<p> 21 </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li><strong>Input</strong>: <code>coords [B, L, 4, 3]</code></li>\n<li><strong>Features</strong>: <code>Edges [B, L, K, C]</code> ()</li>\n<li><strong>Encoder</strong>:<ul>\n<li>Input: <code>Nodes [B, L, C]</code> (zeros), <code>Edges [B, L, K, C]</code></li>\n<li>Output: <code>Nodes [B, L, C]</code> (), <code>Edges [B, L, K, C]</code> ()</li>\n</ul>\n</li>\n<li><strong>Decoder Prep</strong>:<ul>\n<li><code>Seq Embed [B, L, C]</code> ()</li>\n<li><code>Random Mask [B, L, K]</code> ()</li>\n</ul>\n</li>\n<li><strong>Decoder</strong>:<ul>\n<li>Input: <code>Encoder Nodes</code>, <code>Seq Embed + Edges</code></li>\n<li>Output: <code>Nodes [B, L, C]</code> (+)</li>\n</ul>\n</li>\n<li><strong>Output</strong>: <code>Logits [B, L, 21]</code></li>\n</ol>\n"},{"title":"Algorithm-Search","mathjax":true,"date":"2023-08-03T12:46:25.000Z","img":"https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg","excerpt":"","_content":"\n### DFSBFS\n\n- DFS\n\n$Stack$$O(h)$\n\n- BFS\n\n$Queue$$O(2^h)$\n\n****\n\n4\n\n```cpp\nint dx[] = {1,0,-1,0},y = {0,1,0,-1};\n```\n\n\n\n```cpp\nif(i ^ 2 == d) continue;\n```\n\n8\n\n```cpp\nint dx[8] = {-1, -1, -1, 0, 1, 1, 1, 0};\nint dy[8] = {-1, 0, 1, 1, 1, 0, -1, -1};\n```\n\n\n\n```cpp\nif(i ^ 4 == d) continue;\n```\n\n### \n\n\n\n**$a \\to b$**\n\n-  $g[a][b]$\n- $i$\n\n```cpp\n// kkh[k]\nint h[N], e[N], ne[N], idx;\n\n// a->b\nvoid add(int a, int b)\n{\n    e[idx] = b, ne[idx] = h[a], h[a] = idx ++ ;\n}\n\n// \nidx = 0;\nmemset(h, -1, sizeof h);\n```\n\n#### \n\n$O(n+m)$nm\n\n- \n\n```cpp\nint dfs(int u)\n{\n    st[u] = true; // st[u] u\n\n    for (int i = h[u]; i != -1; i = ne[i])\n    {\n        int j = e[i];\n        if (!st[j]) dfs(j);\n    }\n}\n```\n\n- \n\n```cpp\nqueue<int> q;\nst[1] = true; // 1\nq.push(1);\n\nwhile (q.size())\n{\n    int t = q.front();\n    q.pop();\n\n    for (int i = h[t]; i != -1; i = ne[i])\n    {\n        int j = e[i];\n        if (!st[j])\n        {\n            st[j] = true; // j\n            q.push(j);\n        }\n    }\n}\n```\n\n#### \n\n$O(n+m)$nm\n\n\n\n****/\n\n1. 0\n2. $t \\to j$$t \\to j$$t$\n\n```cpp\nbool topsort()\n{\n    int hh = 0, tt = -1;\n\n    // d[i] i\n    for (int i = 1; i <= n; i ++ )\n        if (!d[i])\n            q[ ++ tt] = i;\n\n    while (hh <= tt)\n    {\n        int t = q[hh ++ ];\n\n        for (int i = h[t]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            d[j]--;\n            if (d[j] == 0)\n                q[ ++ tt] = j;\n        }\n    }\n\n    // \n    return tt == n - 1;\n}\n```\n\n**0**","source":"_posts/algorithm-search.md","raw":"---\ntitle: Algorithm-Search\nmathjax: true\ndate: 2023/08/03 20:46:25\nimg: https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg\nexcerpt: \n---\n\n### DFSBFS\n\n- DFS\n\n$Stack$$O(h)$\n\n- BFS\n\n$Queue$$O(2^h)$\n\n****\n\n4\n\n```cpp\nint dx[] = {1,0,-1,0},y = {0,1,0,-1};\n```\n\n\n\n```cpp\nif(i ^ 2 == d) continue;\n```\n\n8\n\n```cpp\nint dx[8] = {-1, -1, -1, 0, 1, 1, 1, 0};\nint dy[8] = {-1, 0, 1, 1, 1, 0, -1, -1};\n```\n\n\n\n```cpp\nif(i ^ 4 == d) continue;\n```\n\n### \n\n\n\n**$a \\to b$**\n\n-  $g[a][b]$\n- $i$\n\n```cpp\n// kkh[k]\nint h[N], e[N], ne[N], idx;\n\n// a->b\nvoid add(int a, int b)\n{\n    e[idx] = b, ne[idx] = h[a], h[a] = idx ++ ;\n}\n\n// \nidx = 0;\nmemset(h, -1, sizeof h);\n```\n\n#### \n\n$O(n+m)$nm\n\n- \n\n```cpp\nint dfs(int u)\n{\n    st[u] = true; // st[u] u\n\n    for (int i = h[u]; i != -1; i = ne[i])\n    {\n        int j = e[i];\n        if (!st[j]) dfs(j);\n    }\n}\n```\n\n- \n\n```cpp\nqueue<int> q;\nst[1] = true; // 1\nq.push(1);\n\nwhile (q.size())\n{\n    int t = q.front();\n    q.pop();\n\n    for (int i = h[t]; i != -1; i = ne[i])\n    {\n        int j = e[i];\n        if (!st[j])\n        {\n            st[j] = true; // j\n            q.push(j);\n        }\n    }\n}\n```\n\n#### \n\n$O(n+m)$nm\n\n\n\n****/\n\n1. 0\n2. $t \\to j$$t \\to j$$t$\n\n```cpp\nbool topsort()\n{\n    int hh = 0, tt = -1;\n\n    // d[i] i\n    for (int i = 1; i <= n; i ++ )\n        if (!d[i])\n            q[ ++ tt] = i;\n\n    while (hh <= tt)\n    {\n        int t = q[hh ++ ];\n\n        for (int i = h[t]; i != -1; i = ne[i])\n        {\n            int j = e[i];\n            d[j]--;\n            if (d[j] == 0)\n                q[ ++ tt] = j;\n        }\n    }\n\n    // \n    return tt == n - 1;\n}\n```\n\n**0**","slug":"algorithm-search","published":1,"updated":"2025-02-28T03:12:34.855Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff6000css99bse772q5","content":"<h3 id=\"DFSBFS\"><a href=\"#DFSBFS\" class=\"headerlink\" title=\"DFSBFS\"></a>DFSBFS</h3><ul>\n<li>DFS</li>\n</ul>\n<p>$Stack$$O(h)$</p>\n<ul>\n<li>BFS</li>\n</ul>\n<p>$Queue$$O(2^h)$</p>\n<p><strong></strong></p>\n<p>4</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> dx[] = &#123;<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">-1</span>,<span class=\"number\">0</span>&#125;,y = &#123;<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">-1</span>&#125;;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(i ^ <span class=\"number\">2</span> == d) <span class=\"keyword\">continue</span>;</span><br></pre></td></tr></table></figure>\n\n<p>8</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> dx[<span class=\"number\">8</span>] = &#123;<span class=\"number\">-1</span>, <span class=\"number\">-1</span>, <span class=\"number\">-1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>&#125;;</span><br><span class=\"line\"><span class=\"type\">int</span> dy[<span class=\"number\">8</span>] = &#123;<span class=\"number\">-1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">-1</span>, <span class=\"number\">-1</span>&#125;;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(i ^ <span class=\"number\">4</span> == d) <span class=\"keyword\">continue</span>;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p><strong>$a \\to b$</strong></p>\n<ul>\n<li> $g[a][b]$</li>\n<li>$i$</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// kkh[k]</span></span><br><span class=\"line\"><span class=\"type\">int</span> h[N], e[N], ne[N], idx;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// a-&gt;b</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">add</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    e[idx] = b, ne[idx] = h[a], h[a] = idx ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">idx = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"built_in\">memset</span>(h, <span class=\"number\">-1</span>, <span class=\"keyword\">sizeof</span> h);</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$O(n+m)$nm</p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"type\">int</span> u)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    st[u] = <span class=\"literal\">true</span>; <span class=\"comment\">// st[u] u</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[u]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[j]) <span class=\"built_in\">dfs</span>(j);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">queue&lt;<span class=\"type\">int</span>&gt; q;</span><br><span class=\"line\">st[<span class=\"number\">1</span>] = <span class=\"literal\">true</span>; <span class=\"comment\">// 1</span></span><br><span class=\"line\">q.<span class=\"built_in\">push</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> (q.<span class=\"built_in\">size</span>())</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> t = q.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">    q.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[t]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[j])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            st[j] = <span class=\"literal\">true</span>; <span class=\"comment\">// j</span></span><br><span class=\"line\">            q.<span class=\"built_in\">push</span>(j);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$O(n+m)$nm</p>\n<p></p>\n<p><strong></strong>&#x2F;</p>\n<ol>\n<li>0</li>\n<li>$t \\to j$$t \\to j$$t$</li>\n</ol>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">topsort</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> hh = <span class=\"number\">0</span>, tt = <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// d[i] i</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!d[i])</span><br><span class=\"line\">            q[ ++ tt] = i;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (hh &lt;= tt)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> t = q[hh ++ ];</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[t]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">            d[j]--;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (d[j] == <span class=\"number\">0</span>)</span><br><span class=\"line\">                q[ ++ tt] = j;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> tt == n - <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>0</strong></p>\n","more":"<h3 id=\"DFSBFS\"><a href=\"#DFSBFS\" class=\"headerlink\" title=\"DFSBFS\"></a>DFSBFS</h3><ul>\n<li>DFS</li>\n</ul>\n<p>$Stack$$O(h)$</p>\n<ul>\n<li>BFS</li>\n</ul>\n<p>$Queue$$O(2^h)$</p>\n<p><strong></strong></p>\n<p>4</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> dx[] = &#123;<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">-1</span>,<span class=\"number\">0</span>&#125;,y = &#123;<span class=\"number\">0</span>,<span class=\"number\">1</span>,<span class=\"number\">0</span>,<span class=\"number\">-1</span>&#125;;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(i ^ <span class=\"number\">2</span> == d) <span class=\"keyword\">continue</span>;</span><br></pre></td></tr></table></figure>\n\n<p>8</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> dx[<span class=\"number\">8</span>] = &#123;<span class=\"number\">-1</span>, <span class=\"number\">-1</span>, <span class=\"number\">-1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>&#125;;</span><br><span class=\"line\"><span class=\"type\">int</span> dy[<span class=\"number\">8</span>] = &#123;<span class=\"number\">-1</span>, <span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, <span class=\"number\">-1</span>, <span class=\"number\">-1</span>&#125;;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(i ^ <span class=\"number\">4</span> == d) <span class=\"keyword\">continue</span>;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p><strong>$a \\to b$</strong></p>\n<ul>\n<li> $g[a][b]$</li>\n<li>$i$</li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// kkh[k]</span></span><br><span class=\"line\"><span class=\"type\">int</span> h[N], e[N], ne[N], idx;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// a-&gt;b</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">void</span> <span class=\"title\">add</span><span class=\"params\">(<span class=\"type\">int</span> a, <span class=\"type\">int</span> b)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    e[idx] = b, ne[idx] = h[a], h[a] = idx ++ ;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// </span></span><br><span class=\"line\">idx = <span class=\"number\">0</span>;</span><br><span class=\"line\"><span class=\"built_in\">memset</span>(h, <span class=\"number\">-1</span>, <span class=\"keyword\">sizeof</span> h);</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$O(n+m)$nm</p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">dfs</span><span class=\"params\">(<span class=\"type\">int</span> u)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    st[u] = <span class=\"literal\">true</span>; <span class=\"comment\">// st[u] u</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[u]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[j]) <span class=\"built_in\">dfs</span>(j);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">queue&lt;<span class=\"type\">int</span>&gt; q;</span><br><span class=\"line\">st[<span class=\"number\">1</span>] = <span class=\"literal\">true</span>; <span class=\"comment\">// 1</span></span><br><span class=\"line\">q.<span class=\"built_in\">push</span>(<span class=\"number\">1</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> (q.<span class=\"built_in\">size</span>())</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> t = q.<span class=\"built_in\">front</span>();</span><br><span class=\"line\">    q.<span class=\"built_in\">pop</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[t]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!st[j])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            st[j] = <span class=\"literal\">true</span>; <span class=\"comment\">// j</span></span><br><span class=\"line\">            q.<span class=\"built_in\">push</span>(j);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>$O(n+m)$nm</p>\n<p></p>\n<p><strong></strong>&#x2F;</p>\n<ol>\n<li>0</li>\n<li>$t \\to j$$t \\to j$$t$</li>\n</ol>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"type\">bool</span> <span class=\"title\">topsort</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> hh = <span class=\"number\">0</span>, tt = <span class=\"number\">-1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// d[i] i</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = <span class=\"number\">1</span>; i &lt;= n; i ++ )</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!d[i])</span><br><span class=\"line\">            q[ ++ tt] = i;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">while</span> (hh &lt;= tt)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"type\">int</span> t = q[hh ++ ];</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"type\">int</span> i = h[t]; i != <span class=\"number\">-1</span>; i = ne[i])</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            <span class=\"type\">int</span> j = e[i];</span><br><span class=\"line\">            d[j]--;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (d[j] == <span class=\"number\">0</span>)</span><br><span class=\"line\">                q[ ++ tt] = j;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// </span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> tt == n - <span class=\"number\">1</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><strong>0</strong></p>\n"},{"title":"DataWhale-Hello-Agent-Notes","mathjax":true,"date":"2025-11-25T12:46:25.000Z","img":"https://datawhalechina.github.io/hello-agents/images/hello-agents.png","excerpt":"DataWhale-Hello-Agent-","_content":"","source":"_posts/hello-agent.md","raw":"---\ntitle: DataWhale-Hello-Agent-Notes\nmathjax: true\ndate: 2025/11/25 20:46:25\nimg: https://datawhalechina.github.io/hello-agents/images/hello-agents.png\nexcerpt: DataWhale-Hello-Agent-\n---","slug":"hello-agent","published":1,"updated":"2025-11-25T09:11:08.775Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff6000dss990c8w3qnj","content":"","more":""},{"title":"Hello World","mathjax":true,"date":"2023-01-22T12:46:25.000Z","img":"https://datawhale-business.oss-cn-hangzhou.aliyuncs.com/23450/dashboard/1736488152304/image.png","excerpt":"halo word","_content":"\n\nlatex\n\n$sin(\\alpha + \\beta)$\n\n\n\n![img](/img/hello-world/Kaz.jpg)\n\n![Transformer](https://datawhale-business.oss-cn-hangzhou.aliyuncs.com/23450/dashboard/1736488152304/image.png)\n\n\n\n```python\nimport torch\n#attention is all u need\nprint(\"Yong shen NB\")\n```\n\n```c++\n#include <iostream>\nusing namespace std;\nint main(){\n    cout<<\"\";\n    pair<int, int> p;\n    int get = [&](int l, int r){\n    \treturn l + r >> 1;  \n    };\n    return 0;\n}\n```\n\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\nmathjax: true\ndate: 2023/1/22 20:46:25\nimg: https://datawhale-business.oss-cn-hangzhou.aliyuncs.com/23450/dashboard/1736488152304/image.png\nexcerpt: halo word\n---\n\n\nlatex\n\n$sin(\\alpha + \\beta)$\n\n\n\n![img](/img/hello-world/Kaz.jpg)\n\n![Transformer](https://datawhale-business.oss-cn-hangzhou.aliyuncs.com/23450/dashboard/1736488152304/image.png)\n\n\n\n```python\nimport torch\n#attention is all u need\nprint(\"Yong shen NB\")\n```\n\n```c++\n#include <iostream>\nusing namespace std;\nint main(){\n    cout<<\"\";\n    pair<int, int> p;\n    int get = [&](int l, int r){\n    \treturn l + r >> 1;  \n    };\n    return 0;\n}\n```\n\n","slug":"hello-world","published":1,"updated":"2025-02-17T12:39:42.971Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff7000ess9920hub048","content":"<p></p>\n<p>latex</p>\n<p>$sin(\\alpha + \\beta)$</p>\n<p></p>\n<p><img src=\"/img/hello-world/Kaz.jpg\" class=\"lazyload placeholder\" data-srcset=\"/img/hello-world/Kaz.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><img src=\"https://datawhale-business.oss-cn-hangzhou.aliyuncs.com/23450/dashboard/1736488152304/image.png\" class=\"lazyload placeholder\" data-srcset=\"https://datawhale-business.oss-cn-hangzhou.aliyuncs.com/23450/dashboard/1736488152304/image.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Transformer\"></p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"comment\">#attention is all u need</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Yong shen NB&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> std;</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    cout&lt;&lt;<span class=\"string\">&quot;&quot;</span>;</span><br><span class=\"line\">    pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt; p;</span><br><span class=\"line\">    <span class=\"type\">int</span> get = [&amp;](<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">return</span> l + r &gt;&gt; <span class=\"number\">1</span>;  </span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n","more":"<p></p>\n<p>latex</p>\n<p>$sin(\\alpha + \\beta)$</p>\n<p></p>\n<p><img src=\"/img/hello-world/Kaz.jpg\" alt=\"img\"></p>\n<p><img src=\"https://datawhale-business.oss-cn-hangzhou.aliyuncs.com/23450/dashboard/1736488152304/image.png\" alt=\"Transformer\"></p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"comment\">#attention is all u need</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Yong shen NB&quot;</span>)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"keyword\">include</span> <span class=\"string\">&lt;iostream&gt;</span></span></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> std;</span><br><span class=\"line\"><span class=\"function\"><span class=\"type\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">    cout&lt;&lt;<span class=\"string\">&quot;&quot;</span>;</span><br><span class=\"line\">    pair&lt;<span class=\"type\">int</span>, <span class=\"type\">int</span>&gt; p;</span><br><span class=\"line\">    <span class=\"type\">int</span> get = [&amp;](<span class=\"type\">int</span> l, <span class=\"type\">int</span> r)&#123;</span><br><span class=\"line\">    \t<span class=\"keyword\">return</span> l + r &gt;&gt; <span class=\"number\">1</span>;  </span><br><span class=\"line\">    &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n"},{"title":"Algorithm-Skills","mathjax":true,"date":"2023-10-22T12:46:25.000Z","img":"https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg","excerpt":"","_content":"\n1s2s$10^7 - 10^8$\n\n\n\n1. $n \\le 30$dfs+dp\n2. $n \\le 100$$O(n^3)$Floyddp\n3. $n \\le 1000$$O(n^2)$dpDijsktraPrimBellman-Ford\n4. $n \\le 10000$$O(n \\sqrt n)$\n5. $n \\le 10^5$$O(nlogn)$sortset/mapheapDijkstraPrimKruskalspfaCDQ\n6. $n \\le 10^6$$O(n)$hashBFSkmpAC$O(nlogn)$sortheapdijkstraprim\n7. $n \\le 10^7$$O(n)$KmpAC\n8. $n \\le 10^9$$O(\\sqrt n)$\n9. $n \\le 10^{18}$$O(nlogn)$dp\n10. $n \\le 10^{1000}$$O((logn)^2)$\n\n\n\n1. long long  20!\n2. int  12!\n3. int => $2^{31}$$2*10^9$\n4. long long => $2^{63}$$9*10^{18}$\n5. float => 38\n6. double => 308\n\nmemset-100x3f-0x3f\n\n0x3f3f3f3f\n\n`cout`\n\n- : `left(right)<<setw()`\n- :`fixed<<setprecision()`\n- `#include <iomanip>`\n\n`cin`\n\n- :`cin.getline(c,N,'\\n')` ccharN'\\n\n\n\n\n```cpp\nstruct s{\n    int a;\n    string b;\n    bool operator< (const s &ss) const{\n        return a < ss.a\n\t}\n}\n```\n\n`string`\n\n```cpp\nstring s = \"I love China\";\ns.substr(start,len); //\nchar c = s.c_str(); //char\nstrstr(s.c_str(),\"love\") //kmp\"love China\"\ns.find(\"China\") //kmp,s.npos\n//int\nstring s = to_string(i);\nint i = stoi(s);\n```","source":"_posts/algorithm-skills.md","raw":"---\ntitle: Algorithm-Skills\nmathjax: true\ndate: 2023/10/22 20:46:25\nimg: https://cdn.acwing.com/media/activity/surface/QQ%E5%9B%BE%E7%89%8720231022233411.jpg\nexcerpt: \n---\n\n1s2s$10^7 - 10^8$\n\n\n\n1. $n \\le 30$dfs+dp\n2. $n \\le 100$$O(n^3)$Floyddp\n3. $n \\le 1000$$O(n^2)$dpDijsktraPrimBellman-Ford\n4. $n \\le 10000$$O(n \\sqrt n)$\n5. $n \\le 10^5$$O(nlogn)$sortset/mapheapDijkstraPrimKruskalspfaCDQ\n6. $n \\le 10^6$$O(n)$hashBFSkmpAC$O(nlogn)$sortheapdijkstraprim\n7. $n \\le 10^7$$O(n)$KmpAC\n8. $n \\le 10^9$$O(\\sqrt n)$\n9. $n \\le 10^{18}$$O(nlogn)$dp\n10. $n \\le 10^{1000}$$O((logn)^2)$\n\n\n\n1. long long  20!\n2. int  12!\n3. int => $2^{31}$$2*10^9$\n4. long long => $2^{63}$$9*10^{18}$\n5. float => 38\n6. double => 308\n\nmemset-100x3f-0x3f\n\n0x3f3f3f3f\n\n`cout`\n\n- : `left(right)<<setw()`\n- :`fixed<<setprecision()`\n- `#include <iomanip>`\n\n`cin`\n\n- :`cin.getline(c,N,'\\n')` ccharN'\\n\n\n\n\n```cpp\nstruct s{\n    int a;\n    string b;\n    bool operator< (const s &ss) const{\n        return a < ss.a\n\t}\n}\n```\n\n`string`\n\n```cpp\nstring s = \"I love China\";\ns.substr(start,len); //\nchar c = s.c_str(); //char\nstrstr(s.c_str(),\"love\") //kmp\"love China\"\ns.find(\"China\") //kmp,s.npos\n//int\nstring s = to_string(i);\nint i = stoi(s);\n```","slug":"algorithm-skills","published":1,"updated":"2025-02-28T03:00:25.621Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff7000fss99apkpbjui","content":"<p>1s2s$10^7 - 10^8$</p>\n<p></p>\n<ol>\n<li>$n \\le 30$dfs+dp</li>\n<li>$n \\le 100$$O(n^3)$Floyddp</li>\n<li>$n \\le 1000$$O(n^2)$dpDijsktraPrimBellman-Ford</li>\n<li>$n \\le 10000$$O(n \\sqrt n)$</li>\n<li>$n \\le 10^5$$O(nlogn)$sortset&#x2F;mapheapDijkstraPrimKruskalspfaCDQ</li>\n<li>$n \\le 10^6$$O(n)$hashBFSkmpAC$O(nlogn)$sortheapdijkstraprim</li>\n<li>$n \\le 10^7$$O(n)$KmpAC</li>\n<li>$n \\le 10^9$$O(\\sqrt n)$</li>\n<li>$n \\le 10^{18}$$O(nlogn)$dp</li>\n<li>$n \\le 10^{1000}$$O((logn)^2)$</li>\n</ol>\n<p></p>\n<ol>\n<li>long long  20!</li>\n<li>int  12!</li>\n<li>int &#x3D;&gt; $2^{31}$$2*10^9$</li>\n<li>long long &#x3D;&gt; $2^{63}$$9*10^{18}$</li>\n<li>float &#x3D;&gt; 38</li>\n<li>double &#x3D;&gt; 308</li>\n</ol>\n<p>memset-100x3f-0x3f</p>\n<p>0x3f3f3f3f</p>\n<p><code>cout</code></p>\n<ul>\n<li>: <code>left(right)&lt;&lt;setw()</code></li>\n<li>:<code>fixed&lt;&lt;setprecision()</code></li>\n<li><code>#include &lt;iomanip&gt;</code></li>\n</ul>\n<p><code>cin</code></p>\n<ul>\n<li>:<code>cin.getline(c,N,&#39;\\n&#39;)</code> ccharN\\n</li>\n</ul>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">struct</span> <span class=\"title class_\">s</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> a;</span><br><span class=\"line\">    string b;</span><br><span class=\"line\">    <span class=\"type\">bool</span> <span class=\"keyword\">operator</span>&lt; (<span class=\"type\">const</span> s &amp;ss) <span class=\"type\">const</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> a &lt; ss.a</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><code>string</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">string s = <span class=\"string\">&quot;I love China&quot;</span>;</span><br><span class=\"line\">s.<span class=\"built_in\">substr</span>(start,len); <span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"type\">char</span> c = s.<span class=\"built_in\">c_str</span>(); <span class=\"comment\">//char</span></span><br><span class=\"line\"><span class=\"built_in\">strstr</span>(s.<span class=\"built_in\">c_str</span>(),<span class=\"string\">&quot;love&quot;</span>) <span class=\"comment\">//kmp&quot;love China&quot;</span></span><br><span class=\"line\">s.<span class=\"built_in\">find</span>(<span class=\"string\">&quot;China&quot;</span>) <span class=\"comment\">//kmp,s.npos</span></span><br><span class=\"line\"><span class=\"comment\">//int</span></span><br><span class=\"line\">string s = <span class=\"built_in\">to_string</span>(i);</span><br><span class=\"line\"><span class=\"type\">int</span> i = <span class=\"built_in\">stoi</span>(s);</span><br></pre></td></tr></table></figure>","more":"<p>1s2s$10^7 - 10^8$</p>\n<p></p>\n<ol>\n<li>$n \\le 30$dfs+dp</li>\n<li>$n \\le 100$$O(n^3)$Floyddp</li>\n<li>$n \\le 1000$$O(n^2)$dpDijsktraPrimBellman-Ford</li>\n<li>$n \\le 10000$$O(n \\sqrt n)$</li>\n<li>$n \\le 10^5$$O(nlogn)$sortset&#x2F;mapheapDijkstraPrimKruskalspfaCDQ</li>\n<li>$n \\le 10^6$$O(n)$hashBFSkmpAC$O(nlogn)$sortheapdijkstraprim</li>\n<li>$n \\le 10^7$$O(n)$KmpAC</li>\n<li>$n \\le 10^9$$O(\\sqrt n)$</li>\n<li>$n \\le 10^{18}$$O(nlogn)$dp</li>\n<li>$n \\le 10^{1000}$$O((logn)^2)$</li>\n</ol>\n<p></p>\n<ol>\n<li>long long  20!</li>\n<li>int  12!</li>\n<li>int &#x3D;&gt; $2^{31}$$2*10^9$</li>\n<li>long long &#x3D;&gt; $2^{63}$$9*10^{18}$</li>\n<li>float &#x3D;&gt; 38</li>\n<li>double &#x3D;&gt; 308</li>\n</ol>\n<p>memset-100x3f-0x3f</p>\n<p>0x3f3f3f3f</p>\n<p><code>cout</code></p>\n<ul>\n<li>: <code>left(right)&lt;&lt;setw()</code></li>\n<li>:<code>fixed&lt;&lt;setprecision()</code></li>\n<li><code>#include &lt;iomanip&gt;</code></li>\n</ul>\n<p><code>cin</code></p>\n<ul>\n<li>:<code>cin.getline(c,N,&#39;\\n&#39;)</code> ccharN\\n</li>\n</ul>\n<p></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">struct</span> <span class=\"title class_\">s</span>&#123;</span><br><span class=\"line\">    <span class=\"type\">int</span> a;</span><br><span class=\"line\">    string b;</span><br><span class=\"line\">    <span class=\"type\">bool</span> <span class=\"keyword\">operator</span>&lt; (<span class=\"type\">const</span> s &amp;ss) <span class=\"type\">const</span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> a &lt; ss.a</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p><code>string</code></p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">string s = <span class=\"string\">&quot;I love China&quot;</span>;</span><br><span class=\"line\">s.<span class=\"built_in\">substr</span>(start,len); <span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"type\">char</span> c = s.<span class=\"built_in\">c_str</span>(); <span class=\"comment\">//char</span></span><br><span class=\"line\"><span class=\"built_in\">strstr</span>(s.<span class=\"built_in\">c_str</span>(),<span class=\"string\">&quot;love&quot;</span>) <span class=\"comment\">//kmp&quot;love China&quot;</span></span><br><span class=\"line\">s.<span class=\"built_in\">find</span>(<span class=\"string\">&quot;China&quot;</span>) <span class=\"comment\">//kmp,s.npos</span></span><br><span class=\"line\"><span class=\"comment\">//int</span></span><br><span class=\"line\">string s = <span class=\"built_in\">to_string</span>(i);</span><br><span class=\"line\"><span class=\"type\">int</span> i = <span class=\"built_in\">stoi</span>(s);</span><br></pre></td></tr></table></figure>"},{"title":"dive-into-deep-learning-notes","mathjax":true,"date":"2024-01-22T12:46:25.000Z","img":"https://zh.d2l.ai/_static/logo-with-text.png","excerpt":"","_content":"# 1. \n\n## 1.1 \n\n`Tensor`numpy`ndarray`\n\nGPUNumPyCPU\n\n \n\n `+``-``*``/``**` \n\n**concatenate \n\n```python\ntorch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)\n```\n\n\n\n```python\ntorch.sum(x)\n```\n\n **broadcasting mechanism \n\n1. \n2. \n\nNumPy`ndarray` torchnumpy\n\n```python\nA = X.numpy()\nB = torch.tensor(A)\n```\n\n1Python`item`Python\n\n```python\na = torch.tensor([3.5])\na, a.item(), float(a), int(a)\n```\n\n## 1.2 \n\n- *Hadamard*\n\n*Hadamard*Hadamard product\n$$\nAB = \\begin{bmatrix} a_{11}b_{11} & a_{12}b_{12} &a_{13}b_{13} \\\\ a_{21}b_{21} & a_{22}b_{22} &a_{23}b_{23} \\\\ a_{31}b_{31}&a_{32}b_{32} &a_{3,3}b_{33} \\end{bmatrix}\n$$\n\n\n\n\n- \n\n  0`axis=0` 00\n\nsum,mean\n\n- \n\n`A` `axis=0``cumsum` \n\n```python\nA.cumsum(axis=0)\n```\n\n- \n\n$x,y$$x^Ty$($<x,y>$)\n$$\nx^Ty = \\sum_{i=1}^{d}x_iy_i\n$$\n\n\n\n\n```python\ntorch.dot(x, y)\n```\n\n- -\n\n$$\nAx = \\begin{bmatrix} a_1^T \\\\ a_2^T \\\\ a_3^T \\end{bmatrix}x = \\begin{bmatrix} a_1^Tx \\\\ a_2^Tx \\\\ a_3^Tx \\end{bmatrix}\n$$\n\n\n\n-`mv`\n\n```python\ntorch.mv(A, x)\n```\n\n- -\n\n$A_i^T$$A$$i$$b_j$$B$$j$\n\nm-`mm`\n$$\nC=AB= \\begin{bmatrix} a_1^T \\\\ a_2^T \\\\ a_3^T \\end{bmatrix}\\begin{bmatrix} b_1 & b_2 & b_3\\\\ \\end{bmatrix} = \\begin{bmatrix} a_1^Tb_1 & a_1^Tb_2 & a_1^Tb_3\\\\ a_2^Tb_1 & a_2^Tb_2 & a_2^Tb_3 \\\\ a_3^Tb_1 & a_3^Tb_2 & a_3^Tb_3 \\end{bmatrix}\n$$\n\n\n```python\ntorch.mm(A, B)\n```\n\n- \n\n$L_2$ $n$$x$$x_1,x_2...x_n$$L_2$**\n\n$||x||_2 = \\sqrt{\\sum_{i=1}^{n}x_i^2}$\n\n```python\nu = torch.tensor([3.0, -4.0])\ntorch.norm(u)\ntensor(5.)\n```\n\n$L_2$$L_1$\n\n$||x||_1 = \\sum_{i=1}^{n}|x_i|$\n\n```python\ntorch.abs(u).sum()\n```\n\n$X$*Frobenius*Frobenius norm\n\n## 1.3 \n\n**gradient f:RnR nx=[x1,x2,,xn] f(x)xn:.\n$$\n\\nabla_\\mathbf{x}f(\\mathbf{x})=\\left[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1},\\frac{\\partial f(\\mathbf{x})}{\\partial x_2},\\ldots,\\frac{\\partial f(\\mathbf{x})}{\\partial x_n}\\right]^\\top\n$$\n\n\n## 1.4 \n\n- \n- \n\n```python\nx = torch.arange(4.0, requires_grad=True) #\ny = 2 * torch.dot(x, x)\nprint(x.grad) # None\ny.backward()\nprint(x.grad == 4 * x) #tensor([True, True, True, True])\n# PyTorch\nx.grad.zero_()\n```\n\n`y``y``x` `y``x`\n\n  \n\n```python\n# backwardgradientself\n# 1\nx.grad.zero_()\ny = x * x\n# y.backward(torch.ones(len(x)))\ny.sum().backward() #ysum\nx.grad # tensor([0., 2., 4., 6.])\n```\n\n `y``x``z``y``x` `z``x``y` `x``y`\n\n`y``u``y` `y` `u``x` `z=u*x``x``u` `z=x*x*x``x`\n\n```python\nx.grad.zero_()\ny = x * x\nu = y.detach() #y\nz = u * x\n\nz.sum().backward()\nx.grad == u # tensor([True, True, True, True])\n```\n\n- \n\n## 1.5 \n\n[TODO]\n\n# 2. \n\n## 2.1 \n\n$\\vec{x} = \\begin{bmatrix} x_1 & x_2 & x_3 & ... \\end{bmatrix}$$\\vec{w} = \\begin{bmatrix} w_1 & w_2 & w_3 & ... \\end{bmatrix}$\n\n$\\hat{y} = Xw+b$\n\n$J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} {(y^i-\\hat{y})}^2$\n\n`SGD(stochastic gradient descent)`\n\n## 2.2 softmax\n\n- **one-hot encoding\n\n   10\n\n![../_images/softmaxreg.svg](https://zh.d2l.ai/_images/softmaxreg.svg)\n\n1   0.5 **calibration\n\nsoftmax1   1\n\n$\\hat{y} = softmax(o)$\n\n\n$$\n\\hat{y}_j = \\frac{exp(o_j)}{\\sum_{k}{exp(o_k)}}\n$$\n\n\n\n\n$argmax\\ \\hat{y}_j = argmax\\ o_j$\n\nsoftmaxsoftmax softmax**linear model\n\n$y$$\\hat{y}$\n\n$l(y,\\hat{y})=-\\sum_{j=q}^{q}y_jlog\\hat{y}_j$\n\n**cross-entropy loss\n\n# 3. \n\n## 3.1 \n\n    $L-1$ **multilayer perceptron*MLP*\n\n\n\n![../_images/mlp.svg](https://zh.d2l.ai/_images/mlp.svg)\n\n**activation function   \n\n- ReLU\n\n$ReLU(x) = max(x,0)$\n\n![../_images/output_mlp_76f463_21_0.svg](https://zh.d2l.ai/_images/output_mlp_76f463_21_0.svg)\n\n- sigmoid\n\n$sigmoid(x)=\\frac{1}{1+exp(-x)}$\n\n![../_images/output_mlp_76f463_51_0.svg](https://zh.d2l.ai/_images/output_mlp_76f463_51_0.svg)\n\n- tanh\n\n$tanh(x) = \\frac{1-exp(-2x)}{1+exp(-2x)}$\n\n![../_images/output_mlp_76f463_81_0.svg](https://zh.d2l.ai/_images/output_mlp_76f463_81_0.svg)\n\n## 3.2 \n\n**training error  **generalization error \n\n   \n\n![../_images/capacity-vs-error.svg](https://zh.d2l.ai/_images/capacity-vs-error.svg)\n\n## 3.3 \n\n **weight decay $L_2$\n\n$f(x)=w^Tx$  $||w||^2$   ** **  $||w||^2$ \n\n**$\\lambda$ \n\n$L(w,b)+\\frac{\\lambda}{2}||w||_2$\n\n$L_2$$L_1$  $L_2$**ridge regression $L_1$ **lasso regression $L_2$   $L_1$  **feature selection\n\n$L_2$\n\n$w = (1-\\alpha\\lambda) w - \\frac{\\alpha}{n}\\sum_{i=1}^{n}(w^Tx^{(i)}+b-y^{(i)})$\n\n**  $\\lambda$$w$ $\\lambda$$w$\n\n`pytorch``weight_decay`weight decay PyTorch `weight_decay`$b$\n\n```python\ntrainer = torch.optim.SGD([\n        {\"params\":net[0].weight,'weight_decay': wd},\n        {\"params\":net[0].bias}], lr=lr)\n# wdlambda\n```\n\n- \n- $L_2$\n- \n- \n\n## 3.4 \n\n    \n\n **unbiased \n\n$\\epsilon~N(0,\\delta^2)$$x$ $x'=x+\\epsilon$ $E(x')=x$\n\n **$p$\n\n$h'= 0 \\ when\\ p=0$\n\n$h'=\\frac{h}{1-p} \\ otherwise$\n\n![../_images/dropout2.svg](https://zh.d2l.ai/_images/dropout2.svg)\n\nAPI`Dropout`  `Dropout` `Dropout`\n\n```python\nnet = nn.Sequential(nn.Flatten(),\n        nn.Linear(784, 256),\n        nn.ReLU(),\n        # dropout\n        nn.Dropout(dropout1),\n        nn.Linear(256, 256),\n        nn.ReLU(),\n        # dropout\n        nn.Dropout(dropout2),\n        nn.Linear(256, 10))\n```\n\n- \n- \n- \n- \n\n## 3.5 \n\n- \n- \n- \n- \n\n\n\n","source":"_posts/dive-into-deep-learning.md","raw":"---\ntitle: dive-into-deep-learning-notes\nmathjax: true\ndate: 2024/1/22 20:46:25\nimg: https://zh.d2l.ai/_static/logo-with-text.png\nexcerpt: \n---\n# 1. \n\n## 1.1 \n\n`Tensor`numpy`ndarray`\n\nGPUNumPyCPU\n\n \n\n `+``-``*``/``**` \n\n**concatenate \n\n```python\ntorch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)\n```\n\n\n\n```python\ntorch.sum(x)\n```\n\n **broadcasting mechanism \n\n1. \n2. \n\nNumPy`ndarray` torchnumpy\n\n```python\nA = X.numpy()\nB = torch.tensor(A)\n```\n\n1Python`item`Python\n\n```python\na = torch.tensor([3.5])\na, a.item(), float(a), int(a)\n```\n\n## 1.2 \n\n- *Hadamard*\n\n*Hadamard*Hadamard product\n$$\nAB = \\begin{bmatrix} a_{11}b_{11} & a_{12}b_{12} &a_{13}b_{13} \\\\ a_{21}b_{21} & a_{22}b_{22} &a_{23}b_{23} \\\\ a_{31}b_{31}&a_{32}b_{32} &a_{3,3}b_{33} \\end{bmatrix}\n$$\n\n\n\n\n- \n\n  0`axis=0` 00\n\nsum,mean\n\n- \n\n`A` `axis=0``cumsum` \n\n```python\nA.cumsum(axis=0)\n```\n\n- \n\n$x,y$$x^Ty$($<x,y>$)\n$$\nx^Ty = \\sum_{i=1}^{d}x_iy_i\n$$\n\n\n\n\n```python\ntorch.dot(x, y)\n```\n\n- -\n\n$$\nAx = \\begin{bmatrix} a_1^T \\\\ a_2^T \\\\ a_3^T \\end{bmatrix}x = \\begin{bmatrix} a_1^Tx \\\\ a_2^Tx \\\\ a_3^Tx \\end{bmatrix}\n$$\n\n\n\n-`mv`\n\n```python\ntorch.mv(A, x)\n```\n\n- -\n\n$A_i^T$$A$$i$$b_j$$B$$j$\n\nm-`mm`\n$$\nC=AB= \\begin{bmatrix} a_1^T \\\\ a_2^T \\\\ a_3^T \\end{bmatrix}\\begin{bmatrix} b_1 & b_2 & b_3\\\\ \\end{bmatrix} = \\begin{bmatrix} a_1^Tb_1 & a_1^Tb_2 & a_1^Tb_3\\\\ a_2^Tb_1 & a_2^Tb_2 & a_2^Tb_3 \\\\ a_3^Tb_1 & a_3^Tb_2 & a_3^Tb_3 \\end{bmatrix}\n$$\n\n\n```python\ntorch.mm(A, B)\n```\n\n- \n\n$L_2$ $n$$x$$x_1,x_2...x_n$$L_2$**\n\n$||x||_2 = \\sqrt{\\sum_{i=1}^{n}x_i^2}$\n\n```python\nu = torch.tensor([3.0, -4.0])\ntorch.norm(u)\ntensor(5.)\n```\n\n$L_2$$L_1$\n\n$||x||_1 = \\sum_{i=1}^{n}|x_i|$\n\n```python\ntorch.abs(u).sum()\n```\n\n$X$*Frobenius*Frobenius norm\n\n## 1.3 \n\n**gradient f:RnR nx=[x1,x2,,xn] f(x)xn:.\n$$\n\\nabla_\\mathbf{x}f(\\mathbf{x})=\\left[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1},\\frac{\\partial f(\\mathbf{x})}{\\partial x_2},\\ldots,\\frac{\\partial f(\\mathbf{x})}{\\partial x_n}\\right]^\\top\n$$\n\n\n## 1.4 \n\n- \n- \n\n```python\nx = torch.arange(4.0, requires_grad=True) #\ny = 2 * torch.dot(x, x)\nprint(x.grad) # None\ny.backward()\nprint(x.grad == 4 * x) #tensor([True, True, True, True])\n# PyTorch\nx.grad.zero_()\n```\n\n`y``y``x` `y``x`\n\n  \n\n```python\n# backwardgradientself\n# 1\nx.grad.zero_()\ny = x * x\n# y.backward(torch.ones(len(x)))\ny.sum().backward() #ysum\nx.grad # tensor([0., 2., 4., 6.])\n```\n\n `y``x``z``y``x` `z``x``y` `x``y`\n\n`y``u``y` `y` `u``x` `z=u*x``x``u` `z=x*x*x``x`\n\n```python\nx.grad.zero_()\ny = x * x\nu = y.detach() #y\nz = u * x\n\nz.sum().backward()\nx.grad == u # tensor([True, True, True, True])\n```\n\n- \n\n## 1.5 \n\n[TODO]\n\n# 2. \n\n## 2.1 \n\n$\\vec{x} = \\begin{bmatrix} x_1 & x_2 & x_3 & ... \\end{bmatrix}$$\\vec{w} = \\begin{bmatrix} w_1 & w_2 & w_3 & ... \\end{bmatrix}$\n\n$\\hat{y} = Xw+b$\n\n$J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} {(y^i-\\hat{y})}^2$\n\n`SGD(stochastic gradient descent)`\n\n## 2.2 softmax\n\n- **one-hot encoding\n\n   10\n\n![../_images/softmaxreg.svg](https://zh.d2l.ai/_images/softmaxreg.svg)\n\n1   0.5 **calibration\n\nsoftmax1   1\n\n$\\hat{y} = softmax(o)$\n\n\n$$\n\\hat{y}_j = \\frac{exp(o_j)}{\\sum_{k}{exp(o_k)}}\n$$\n\n\n\n\n$argmax\\ \\hat{y}_j = argmax\\ o_j$\n\nsoftmaxsoftmax softmax**linear model\n\n$y$$\\hat{y}$\n\n$l(y,\\hat{y})=-\\sum_{j=q}^{q}y_jlog\\hat{y}_j$\n\n**cross-entropy loss\n\n# 3. \n\n## 3.1 \n\n    $L-1$ **multilayer perceptron*MLP*\n\n\n\n![../_images/mlp.svg](https://zh.d2l.ai/_images/mlp.svg)\n\n**activation function   \n\n- ReLU\n\n$ReLU(x) = max(x,0)$\n\n![../_images/output_mlp_76f463_21_0.svg](https://zh.d2l.ai/_images/output_mlp_76f463_21_0.svg)\n\n- sigmoid\n\n$sigmoid(x)=\\frac{1}{1+exp(-x)}$\n\n![../_images/output_mlp_76f463_51_0.svg](https://zh.d2l.ai/_images/output_mlp_76f463_51_0.svg)\n\n- tanh\n\n$tanh(x) = \\frac{1-exp(-2x)}{1+exp(-2x)}$\n\n![../_images/output_mlp_76f463_81_0.svg](https://zh.d2l.ai/_images/output_mlp_76f463_81_0.svg)\n\n## 3.2 \n\n**training error  **generalization error \n\n   \n\n![../_images/capacity-vs-error.svg](https://zh.d2l.ai/_images/capacity-vs-error.svg)\n\n## 3.3 \n\n **weight decay $L_2$\n\n$f(x)=w^Tx$  $||w||^2$   ** **  $||w||^2$ \n\n**$\\lambda$ \n\n$L(w,b)+\\frac{\\lambda}{2}||w||_2$\n\n$L_2$$L_1$  $L_2$**ridge regression $L_1$ **lasso regression $L_2$   $L_1$  **feature selection\n\n$L_2$\n\n$w = (1-\\alpha\\lambda) w - \\frac{\\alpha}{n}\\sum_{i=1}^{n}(w^Tx^{(i)}+b-y^{(i)})$\n\n**  $\\lambda$$w$ $\\lambda$$w$\n\n`pytorch``weight_decay`weight decay PyTorch `weight_decay`$b$\n\n```python\ntrainer = torch.optim.SGD([\n        {\"params\":net[0].weight,'weight_decay': wd},\n        {\"params\":net[0].bias}], lr=lr)\n# wdlambda\n```\n\n- \n- $L_2$\n- \n- \n\n## 3.4 \n\n    \n\n **unbiased \n\n$\\epsilon~N(0,\\delta^2)$$x$ $x'=x+\\epsilon$ $E(x')=x$\n\n **$p$\n\n$h'= 0 \\ when\\ p=0$\n\n$h'=\\frac{h}{1-p} \\ otherwise$\n\n![../_images/dropout2.svg](https://zh.d2l.ai/_images/dropout2.svg)\n\nAPI`Dropout`  `Dropout` `Dropout`\n\n```python\nnet = nn.Sequential(nn.Flatten(),\n        nn.Linear(784, 256),\n        nn.ReLU(),\n        # dropout\n        nn.Dropout(dropout1),\n        nn.Linear(256, 256),\n        nn.ReLU(),\n        # dropout\n        nn.Dropout(dropout2),\n        nn.Linear(256, 10))\n```\n\n- \n- \n- \n- \n\n## 3.5 \n\n- \n- \n- \n- \n\n\n\n","slug":"dive-into-deep-learning","published":1,"updated":"2025-03-03T10:42:18.757Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff7000gss99efmw1c65","content":"<h1 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h1><h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p><code>Tensor</code>numpy<code>ndarray</code></p>\n<p>GPUNumPyCPU</p>\n<p> </p>\n<p> <code>+</code><code>-</code><code>*</code><code>/</code><code>**</code> </p>\n<p><em></em>concatenate </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.cat((X, Y), dim=<span class=\"number\">0</span>), torch.cat((X, Y), dim=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.<span class=\"built_in\">sum</span>(x)</span><br></pre></td></tr></table></figure>\n\n<p> <em></em>broadcasting mechanism </p>\n<ol>\n<li></li>\n<li></li>\n</ol>\n<p>NumPy<code>ndarray</code> torchnumpy</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A = X.numpy()</span><br><span class=\"line\">B = torch.tensor(A)</span><br></pre></td></tr></table></figure>\n\n<p>1Python<code>item</code>Python</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = torch.tensor([<span class=\"number\">3.5</span>])</span><br><span class=\"line\">a, a.item(), <span class=\"built_in\">float</span>(a), <span class=\"built_in\">int</span>(a)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"1-2-\"><a href=\"#1-2-\" class=\"headerlink\" title=\"1.2 \"></a>1.2 </h2><ul>\n<li><em>Hadamard</em></li>\n</ul>\n<p><em>Hadamard</em>Hadamard product<br>$$<br>AB &#x3D; \\begin{bmatrix} a_{11}b_{11} &amp; a_{12}b_{12} &amp;a_{13}b_{13} \\ a_{21}b_{21} &amp; a_{22}b_{22} &amp;a_{23}b_{23} \\ a_{31}b_{31}&amp;a_{32}b_{32} &amp;a_{3,3}b_{33} \\end{bmatrix}<br>$$</p>\n<p></p>\n<ul>\n<li></li>\n</ul>\n<p>  0<code>axis=0</code> 00</p>\n<p>sum,mean</p>\n<ul>\n<li></li>\n</ul>\n<p><code>A</code> <code>axis=0</code><code>cumsum</code> </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A.cumsum(axis=<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p>$x,y$$x^Ty$($&lt;x,y&gt;$)<br>$$<br>x^Ty &#x3D; \\sum_{i&#x3D;1}^{d}x_iy_i<br>$$</p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.dot(x, y)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-</li>\n</ul>\n<p>$$<br>Ax &#x3D; \\begin{bmatrix} a_1^T \\ a_2^T \\ a_3^T \\end{bmatrix}x &#x3D; \\begin{bmatrix} a_1^Tx \\ a_2^Tx \\ a_3^Tx \\end{bmatrix}<br>$$</p>\n<p>-<code>mv</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.mv(A, x)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-</li>\n</ul>\n<p>$A_i^T$$A$$i$$b_j$$B$$j$</p>\n<p>m-<code>mm</code><br>$$<br>C&#x3D;AB&#x3D; \\begin{bmatrix} a_1^T \\ a_2^T \\ a_3^T \\end{bmatrix}\\begin{bmatrix} b_1 &amp; b_2 &amp; b_3\\ \\end{bmatrix} &#x3D; \\begin{bmatrix} a_1^Tb_1 &amp; a_1^Tb_2 &amp; a_1^Tb_3\\ a_2^Tb_1 &amp; a_2^Tb_2 &amp; a_2^Tb_3 \\ a_3^Tb_1 &amp; a_3^Tb_2 &amp; a_3^Tb_3 \\end{bmatrix}<br>$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.mm(A, B)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p>$L_2$ $n$$x$$x_1,x_2x_n$$L_2$<em></em></p>\n<p>$||x||<em>2 &#x3D; \\sqrt{\\sum</em>{i&#x3D;1}^{n}x_i^2}$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">u = torch.tensor([<span class=\"number\">3.0</span>, -<span class=\"number\">4.0</span>])</span><br><span class=\"line\">torch.norm(u)</span><br><span class=\"line\">tensor(<span class=\"number\">5.</span>)</span><br></pre></td></tr></table></figure>\n\n<p>$L_2$$L_1$</p>\n<p>$||x||<em>1 &#x3D; \\sum</em>{i&#x3D;1}^{n}|x_i|$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.<span class=\"built_in\">abs</span>(u).<span class=\"built_in\">sum</span>()</span><br></pre></td></tr></table></figure>\n\n<p>$X$<em>Frobenius</em>Frobenius norm</p>\n<h2 id=\"1-3-\"><a href=\"#1-3-\" class=\"headerlink\" title=\"1.3 \"></a>1.3 </h2><p><em></em>gradient f:RnR nx&#x3D;[x1,x2,,xn] f(x)xn:.<br>$$<br>\\nabla_\\mathbf{x}f(\\mathbf{x})&#x3D;\\left[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1},\\frac{\\partial f(\\mathbf{x})}{\\partial x_2},\\ldots,\\frac{\\partial f(\\mathbf{x})}{\\partial x_n}\\right]^\\top<br>$$</p>\n<h2 id=\"1-4-\"><a href=\"#1-4-\" class=\"headerlink\" title=\"1.4 \"></a>1.4 </h2><ul>\n<li></li>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.arange(<span class=\"number\">4.0</span>, requires_grad=<span class=\"literal\">True</span>) <span class=\"comment\">#</span></span><br><span class=\"line\">y = <span class=\"number\">2</span> * torch.dot(x, x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\"># None</span></span><br><span class=\"line\">y.backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad == <span class=\"number\">4</span> * x) <span class=\"comment\">#tensor([True, True, True, True])</span></span><br><span class=\"line\"><span class=\"comment\"># PyTorch</span></span><br><span class=\"line\">x.grad.zero_()</span><br></pre></td></tr></table></figure>\n\n<p><code>y</code><code>y</code><code>x</code> <code>y</code><code>x</code></p>\n<p>  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># backwardgradientself</span></span><br><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y = x * x</span><br><span class=\"line\"><span class=\"comment\"># y.backward(torch.ones(len(x)))</span></span><br><span class=\"line\">y.<span class=\"built_in\">sum</span>().backward() <span class=\"comment\">#ysum</span></span><br><span class=\"line\">x.grad <span class=\"comment\"># tensor([0., 2., 4., 6.])</span></span><br></pre></td></tr></table></figure>\n\n<p> <code>y</code><code>x</code><code>z</code><code>y</code><code>x</code> <code>z</code><code>x</code><code>y</code> <code>x</code><code>y</code></p>\n<p><code>y</code><code>u</code><code>y</code> <code>y</code> <code>u</code><code>x</code> <code>z=u*x</code><code>x</code><code>u</code> <code>z=x*x*x</code><code>x</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y = x * x</span><br><span class=\"line\">u = y.detach() <span class=\"comment\">#y</span></span><br><span class=\"line\">z = u * x</span><br><span class=\"line\"></span><br><span class=\"line\">z.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\">x.grad == u <span class=\"comment\"># tensor([True, True, True, True])</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<h2 id=\"1-5-\"><a href=\"#1-5-\" class=\"headerlink\" title=\"1.5 \"></a>1.5 </h2><p>[TODO]</p>\n<h1 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h1><h2 id=\"2-1-\"><a href=\"#2-1-\" class=\"headerlink\" title=\"2.1 \"></a>2.1 </h2><p>$\\vec{x} &#x3D; \\begin{bmatrix} x_1 &amp; x_2 &amp; x_3 &amp;  \\end{bmatrix}$$\\vec{w} &#x3D; \\begin{bmatrix} w_1 &amp; w_2 &amp; w_3 &amp;  \\end{bmatrix}$</p>\n<p>$\\hat{y} &#x3D; Xw+b$</p>\n<p>$J(w,b) &#x3D; \\frac{1}{2m} \\sum_{i&#x3D;1}^{m} {(y^i-\\hat{y})}^2$</p>\n<p><code>SGD(stochastic gradient descent)</code></p>\n<h2 id=\"2-2-softmax\"><a href=\"#2-2-softmax\" class=\"headerlink\" title=\"2.2 softmax\"></a>2.2 softmax</h2><ul>\n<li><p><em></em>one-hot encoding</p>\n<p> 10</p>\n</li>\n</ul>\n<p><img src=\"https://zh.d2l.ai/_images/softmaxreg.svg\" class=\"lazyload placeholder\" data-srcset=\"https://zh.d2l.ai/_images/softmaxreg.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"../_images/softmaxreg.svg\"></p>\n<p>1   0.5 <em></em>calibration</p>\n<p>softmax1   1</p>\n<p>$\\hat{y} &#x3D; softmax(o)$</p>\n<p><br>$$<br>\\hat{y}<em>j &#x3D; \\frac{exp(o_j)}{\\sum</em>{k}{exp(o_k)}}<br>$$</p>\n<p></p>\n<p>$argmax\\ \\hat{y}_j &#x3D; argmax\\ o_j$</p>\n<p>softmaxsoftmax softmax<em></em>linear model</p>\n<p>$y$$\\hat{y}$</p>\n<p>$l(y,\\hat{y})&#x3D;-\\sum_{j&#x3D;q}^{q}y_jlog\\hat{y}_j$</p>\n<p><em></em>cross-entropy loss</p>\n<h1 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h1><h2 id=\"3-1-\"><a href=\"#3-1-\" class=\"headerlink\" title=\"3.1 \"></a>3.1 </h2><p>    $L-1$ <em></em>multilayer perceptron<em>MLP</em></p>\n<p></p>\n<p><img src=\"https://zh.d2l.ai/_images/mlp.svg\" class=\"lazyload placeholder\" data-srcset=\"https://zh.d2l.ai/_images/mlp.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"../_images/mlp.svg\"></p>\n<p><em></em>activation function   </p>\n<ul>\n<li>ReLU</li>\n</ul>\n<p>$ReLU(x) &#x3D; max(x,0)$</p>\n<p><img src=\"https://zh.d2l.ai/_images/output_mlp_76f463_21_0.svg\" class=\"lazyload placeholder\" data-srcset=\"https://zh.d2l.ai/_images/output_mlp_76f463_21_0.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"../_images/output_mlp_76f463_21_0.svg\"></p>\n<ul>\n<li>sigmoid</li>\n</ul>\n<p>$sigmoid(x)&#x3D;\\frac{1}{1+exp(-x)}$</p>\n<p><img src=\"https://zh.d2l.ai/_images/output_mlp_76f463_51_0.svg\" class=\"lazyload placeholder\" data-srcset=\"https://zh.d2l.ai/_images/output_mlp_76f463_51_0.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"../_images/output_mlp_76f463_51_0.svg\"></p>\n<ul>\n<li>tanh</li>\n</ul>\n<p>$tanh(x) &#x3D; \\frac{1-exp(-2x)}{1+exp(-2x)}$</p>\n<p><img src=\"https://zh.d2l.ai/_images/output_mlp_76f463_81_0.svg\" class=\"lazyload placeholder\" data-srcset=\"https://zh.d2l.ai/_images/output_mlp_76f463_81_0.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"../_images/output_mlp_76f463_81_0.svg\"></p>\n<h2 id=\"3-2-\"><a href=\"#3-2-\" class=\"headerlink\" title=\"3.2 \"></a>3.2 </h2><p><em></em>training error  <em></em>generalization error </p>\n<p>   </p>\n<p><img src=\"https://zh.d2l.ai/_images/capacity-vs-error.svg\" class=\"lazyload placeholder\" data-srcset=\"https://zh.d2l.ai/_images/capacity-vs-error.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"../_images/capacity-vs-error.svg\"></p>\n<h2 id=\"3-3-\"><a href=\"#3-3-\" class=\"headerlink\" title=\"3.3 \"></a>3.3 </h2><p> <em></em>weight decay $L_2$</p>\n<p>$f(x)&#x3D;w^Tx$  $||w||^2$   <em></em> <em></em>  $||w||^2$ </p>\n<p><em></em>$\\lambda$ </p>\n<p>$L(w,b)+\\frac{\\lambda}{2}||w||_2$</p>\n<p>$L_2$$L_1$  $L_2$<em></em>ridge regression $L_1$ <em></em>lasso regression $L_2$   $L_1$  <em></em>feature selection</p>\n<p>$L_2$</p>\n<p>$w &#x3D; (1-\\alpha\\lambda) w - \\frac{\\alpha}{n}\\sum_{i&#x3D;1}^{n}(w^Tx^{(i)}+b-y^{(i)})$</p>\n<p><em></em>  $\\lambda$$w$ $\\lambda$$w$</p>\n<p><code>pytorch</code><code>weight_decay</code>weight decay PyTorch <code>weight_decay</code>$b$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trainer = torch.optim.SGD([</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;params&quot;</span>:net[<span class=\"number\">0</span>].weight,<span class=\"string\">&#x27;weight_decay&#x27;</span>: wd&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;params&quot;</span>:net[<span class=\"number\">0</span>].bias&#125;], lr=lr)</span><br><span class=\"line\"><span class=\"comment\"># wdlambda</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n<li>$L_2$</li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"3-4-\"><a href=\"#3-4-\" class=\"headerlink\" title=\"3.4 \"></a>3.4 </h2><p>    </p>\n<p> <em></em>unbiased </p>\n<p>$\\epsilon~N(0,\\delta^2)$$x$ $x&#x3D;x+\\epsilon$ $E(x)&#x3D;x$</p>\n<p> <em></em>$p$</p>\n<p>$h&#x3D; 0 \\ when\\ p&#x3D;0$</p>\n<p>$h&#x3D;\\frac{h}{1-p} \\ otherwise$</p>\n<p><img src=\"https://zh.d2l.ai/_images/dropout2.svg\" class=\"lazyload placeholder\" data-srcset=\"https://zh.d2l.ai/_images/dropout2.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"../_images/dropout2.svg\"></p>\n<p>API<code>Dropout</code>  <code>Dropout</code> <code>Dropout</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = nn.Sequential(nn.Flatten(),</span><br><span class=\"line\">        nn.Linear(<span class=\"number\">784</span>, <span class=\"number\">256</span>),</span><br><span class=\"line\">        nn.ReLU(),</span><br><span class=\"line\">        <span class=\"comment\"># dropout</span></span><br><span class=\"line\">        nn.Dropout(dropout1),</span><br><span class=\"line\">        nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">256</span>),</span><br><span class=\"line\">        nn.ReLU(),</span><br><span class=\"line\">        <span class=\"comment\"># dropout</span></span><br><span class=\"line\">        nn.Dropout(dropout2),</span><br><span class=\"line\">        nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"3-5-\"><a href=\"#3-5-\" class=\"headerlink\" title=\"3.5 \"></a>3.5 </h2><ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n","more":"<h1 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h1><h2 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h2><p><code>Tensor</code>numpy<code>ndarray</code></p>\n<p>GPUNumPyCPU</p>\n<p> </p>\n<p> <code>+</code><code>-</code><code>*</code><code>/</code><code>**</code> </p>\n<p><em></em>concatenate </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.cat((X, Y), dim=<span class=\"number\">0</span>), torch.cat((X, Y), dim=<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.<span class=\"built_in\">sum</span>(x)</span><br></pre></td></tr></table></figure>\n\n<p> <em></em>broadcasting mechanism </p>\n<ol>\n<li></li>\n<li></li>\n</ol>\n<p>NumPy<code>ndarray</code> torchnumpy</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A = X.numpy()</span><br><span class=\"line\">B = torch.tensor(A)</span><br></pre></td></tr></table></figure>\n\n<p>1Python<code>item</code>Python</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = torch.tensor([<span class=\"number\">3.5</span>])</span><br><span class=\"line\">a, a.item(), <span class=\"built_in\">float</span>(a), <span class=\"built_in\">int</span>(a)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"1-2-\"><a href=\"#1-2-\" class=\"headerlink\" title=\"1.2 \"></a>1.2 </h2><ul>\n<li><em>Hadamard</em></li>\n</ul>\n<p><em>Hadamard</em>Hadamard product<br>$$<br>AB &#x3D; \\begin{bmatrix} a_{11}b_{11} &amp; a_{12}b_{12} &amp;a_{13}b_{13} \\ a_{21}b_{21} &amp; a_{22}b_{22} &amp;a_{23}b_{23} \\ a_{31}b_{31}&amp;a_{32}b_{32} &amp;a_{3,3}b_{33} \\end{bmatrix}<br>$$</p>\n<p></p>\n<ul>\n<li></li>\n</ul>\n<p>  0<code>axis=0</code> 00</p>\n<p>sum,mean</p>\n<ul>\n<li></li>\n</ul>\n<p><code>A</code> <code>axis=0</code><code>cumsum</code> </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">A.cumsum(axis=<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p>$x,y$$x^Ty$($&lt;x,y&gt;$)<br>$$<br>x^Ty &#x3D; \\sum_{i&#x3D;1}^{d}x_iy_i<br>$$</p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.dot(x, y)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-</li>\n</ul>\n<p>$$<br>Ax &#x3D; \\begin{bmatrix} a_1^T \\ a_2^T \\ a_3^T \\end{bmatrix}x &#x3D; \\begin{bmatrix} a_1^Tx \\ a_2^Tx \\ a_3^Tx \\end{bmatrix}<br>$$</p>\n<p>-<code>mv</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.mv(A, x)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>-</li>\n</ul>\n<p>$A_i^T$$A$$i$$b_j$$B$$j$</p>\n<p>m-<code>mm</code><br>$$<br>C&#x3D;AB&#x3D; \\begin{bmatrix} a_1^T \\ a_2^T \\ a_3^T \\end{bmatrix}\\begin{bmatrix} b_1 &amp; b_2 &amp; b_3\\ \\end{bmatrix} &#x3D; \\begin{bmatrix} a_1^Tb_1 &amp; a_1^Tb_2 &amp; a_1^Tb_3\\ a_2^Tb_1 &amp; a_2^Tb_2 &amp; a_2^Tb_3 \\ a_3^Tb_1 &amp; a_3^Tb_2 &amp; a_3^Tb_3 \\end{bmatrix}<br>$$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.mm(A, B)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<p>$L_2$ $n$$x$$x_1,x_2x_n$$L_2$<em></em></p>\n<p>$||x||<em>2 &#x3D; \\sqrt{\\sum</em>{i&#x3D;1}^{n}x_i^2}$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">u = torch.tensor([<span class=\"number\">3.0</span>, -<span class=\"number\">4.0</span>])</span><br><span class=\"line\">torch.norm(u)</span><br><span class=\"line\">tensor(<span class=\"number\">5.</span>)</span><br></pre></td></tr></table></figure>\n\n<p>$L_2$$L_1$</p>\n<p>$||x||<em>1 &#x3D; \\sum</em>{i&#x3D;1}^{n}|x_i|$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.<span class=\"built_in\">abs</span>(u).<span class=\"built_in\">sum</span>()</span><br></pre></td></tr></table></figure>\n\n<p>$X$<em>Frobenius</em>Frobenius norm</p>\n<h2 id=\"1-3-\"><a href=\"#1-3-\" class=\"headerlink\" title=\"1.3 \"></a>1.3 </h2><p><em></em>gradient f:RnR nx&#x3D;[x1,x2,,xn] f(x)xn:.<br>$$<br>\\nabla_\\mathbf{x}f(\\mathbf{x})&#x3D;\\left[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1},\\frac{\\partial f(\\mathbf{x})}{\\partial x_2},\\ldots,\\frac{\\partial f(\\mathbf{x})}{\\partial x_n}\\right]^\\top<br>$$</p>\n<h2 id=\"1-4-\"><a href=\"#1-4-\" class=\"headerlink\" title=\"1.4 \"></a>1.4 </h2><ul>\n<li></li>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.arange(<span class=\"number\">4.0</span>, requires_grad=<span class=\"literal\">True</span>) <span class=\"comment\">#</span></span><br><span class=\"line\">y = <span class=\"number\">2</span> * torch.dot(x, x)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad) <span class=\"comment\"># None</span></span><br><span class=\"line\">y.backward()</span><br><span class=\"line\"><span class=\"built_in\">print</span>(x.grad == <span class=\"number\">4</span> * x) <span class=\"comment\">#tensor([True, True, True, True])</span></span><br><span class=\"line\"><span class=\"comment\"># PyTorch</span></span><br><span class=\"line\">x.grad.zero_()</span><br></pre></td></tr></table></figure>\n\n<p><code>y</code><code>y</code><code>x</code> <code>y</code><code>x</code></p>\n<p>  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># backwardgradientself</span></span><br><span class=\"line\"><span class=\"comment\"># 1</span></span><br><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y = x * x</span><br><span class=\"line\"><span class=\"comment\"># y.backward(torch.ones(len(x)))</span></span><br><span class=\"line\">y.<span class=\"built_in\">sum</span>().backward() <span class=\"comment\">#ysum</span></span><br><span class=\"line\">x.grad <span class=\"comment\"># tensor([0., 2., 4., 6.])</span></span><br></pre></td></tr></table></figure>\n\n<p> <code>y</code><code>x</code><code>z</code><code>y</code><code>x</code> <code>z</code><code>x</code><code>y</code> <code>x</code><code>y</code></p>\n<p><code>y</code><code>u</code><code>y</code> <code>y</code> <code>u</code><code>x</code> <code>z=u*x</code><code>x</code><code>u</code> <code>z=x*x*x</code><code>x</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x.grad.zero_()</span><br><span class=\"line\">y = x * x</span><br><span class=\"line\">u = y.detach() <span class=\"comment\">#y</span></span><br><span class=\"line\">z = u * x</span><br><span class=\"line\"></span><br><span class=\"line\">z.<span class=\"built_in\">sum</span>().backward()</span><br><span class=\"line\">x.grad == u <span class=\"comment\"># tensor([True, True, True, True])</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<h2 id=\"1-5-\"><a href=\"#1-5-\" class=\"headerlink\" title=\"1.5 \"></a>1.5 </h2><p>[TODO]</p>\n<h1 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h1><h2 id=\"2-1-\"><a href=\"#2-1-\" class=\"headerlink\" title=\"2.1 \"></a>2.1 </h2><p>$\\vec{x} &#x3D; \\begin{bmatrix} x_1 &amp; x_2 &amp; x_3 &amp;  \\end{bmatrix}$$\\vec{w} &#x3D; \\begin{bmatrix} w_1 &amp; w_2 &amp; w_3 &amp;  \\end{bmatrix}$</p>\n<p>$\\hat{y} &#x3D; Xw+b$</p>\n<p>$J(w,b) &#x3D; \\frac{1}{2m} \\sum_{i&#x3D;1}^{m} {(y^i-\\hat{y})}^2$</p>\n<p><code>SGD(stochastic gradient descent)</code></p>\n<h2 id=\"2-2-softmax\"><a href=\"#2-2-softmax\" class=\"headerlink\" title=\"2.2 softmax\"></a>2.2 softmax</h2><ul>\n<li><p><em></em>one-hot encoding</p>\n<p> 10</p>\n</li>\n</ul>\n<p><img src=\"https://zh.d2l.ai/_images/softmaxreg.svg\" alt=\"../_images/softmaxreg.svg\"></p>\n<p>1   0.5 <em></em>calibration</p>\n<p>softmax1   1</p>\n<p>$\\hat{y} &#x3D; softmax(o)$</p>\n<p><br>$$<br>\\hat{y}<em>j &#x3D; \\frac{exp(o_j)}{\\sum</em>{k}{exp(o_k)}}<br>$$</p>\n<p></p>\n<p>$argmax\\ \\hat{y}_j &#x3D; argmax\\ o_j$</p>\n<p>softmaxsoftmax softmax<em></em>linear model</p>\n<p>$y$$\\hat{y}$</p>\n<p>$l(y,\\hat{y})&#x3D;-\\sum_{j&#x3D;q}^{q}y_jlog\\hat{y}_j$</p>\n<p><em></em>cross-entropy loss</p>\n<h1 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h1><h2 id=\"3-1-\"><a href=\"#3-1-\" class=\"headerlink\" title=\"3.1 \"></a>3.1 </h2><p>    $L-1$ <em></em>multilayer perceptron<em>MLP</em></p>\n<p></p>\n<p><img src=\"https://zh.d2l.ai/_images/mlp.svg\" alt=\"../_images/mlp.svg\"></p>\n<p><em></em>activation function   </p>\n<ul>\n<li>ReLU</li>\n</ul>\n<p>$ReLU(x) &#x3D; max(x,0)$</p>\n<p><img src=\"https://zh.d2l.ai/_images/output_mlp_76f463_21_0.svg\" alt=\"../_images/output_mlp_76f463_21_0.svg\"></p>\n<ul>\n<li>sigmoid</li>\n</ul>\n<p>$sigmoid(x)&#x3D;\\frac{1}{1+exp(-x)}$</p>\n<p><img src=\"https://zh.d2l.ai/_images/output_mlp_76f463_51_0.svg\" alt=\"../_images/output_mlp_76f463_51_0.svg\"></p>\n<ul>\n<li>tanh</li>\n</ul>\n<p>$tanh(x) &#x3D; \\frac{1-exp(-2x)}{1+exp(-2x)}$</p>\n<p><img src=\"https://zh.d2l.ai/_images/output_mlp_76f463_81_0.svg\" alt=\"../_images/output_mlp_76f463_81_0.svg\"></p>\n<h2 id=\"3-2-\"><a href=\"#3-2-\" class=\"headerlink\" title=\"3.2 \"></a>3.2 </h2><p><em></em>training error  <em></em>generalization error </p>\n<p>   </p>\n<p><img src=\"https://zh.d2l.ai/_images/capacity-vs-error.svg\" alt=\"../_images/capacity-vs-error.svg\"></p>\n<h2 id=\"3-3-\"><a href=\"#3-3-\" class=\"headerlink\" title=\"3.3 \"></a>3.3 </h2><p> <em></em>weight decay $L_2$</p>\n<p>$f(x)&#x3D;w^Tx$  $||w||^2$   <em></em> <em></em>  $||w||^2$ </p>\n<p><em></em>$\\lambda$ </p>\n<p>$L(w,b)+\\frac{\\lambda}{2}||w||_2$</p>\n<p>$L_2$$L_1$  $L_2$<em></em>ridge regression $L_1$ <em></em>lasso regression $L_2$   $L_1$  <em></em>feature selection</p>\n<p>$L_2$</p>\n<p>$w &#x3D; (1-\\alpha\\lambda) w - \\frac{\\alpha}{n}\\sum_{i&#x3D;1}^{n}(w^Tx^{(i)}+b-y^{(i)})$</p>\n<p><em></em>  $\\lambda$$w$ $\\lambda$$w$</p>\n<p><code>pytorch</code><code>weight_decay</code>weight decay PyTorch <code>weight_decay</code>$b$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">trainer = torch.optim.SGD([</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;params&quot;</span>:net[<span class=\"number\">0</span>].weight,<span class=\"string\">&#x27;weight_decay&#x27;</span>: wd&#125;,</span><br><span class=\"line\">        &#123;<span class=\"string\">&quot;params&quot;</span>:net[<span class=\"number\">0</span>].bias&#125;], lr=lr)</span><br><span class=\"line\"><span class=\"comment\"># wdlambda</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n<li>$L_2$</li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"3-4-\"><a href=\"#3-4-\" class=\"headerlink\" title=\"3.4 \"></a>3.4 </h2><p>    </p>\n<p> <em></em>unbiased </p>\n<p>$\\epsilon~N(0,\\delta^2)$$x$ $x&#x3D;x+\\epsilon$ $E(x)&#x3D;x$</p>\n<p> <em></em>$p$</p>\n<p>$h&#x3D; 0 \\ when\\ p&#x3D;0$</p>\n<p>$h&#x3D;\\frac{h}{1-p} \\ otherwise$</p>\n<p><img src=\"https://zh.d2l.ai/_images/dropout2.svg\" alt=\"../_images/dropout2.svg\"></p>\n<p>API<code>Dropout</code>  <code>Dropout</code> <code>Dropout</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">net = nn.Sequential(nn.Flatten(),</span><br><span class=\"line\">        nn.Linear(<span class=\"number\">784</span>, <span class=\"number\">256</span>),</span><br><span class=\"line\">        nn.ReLU(),</span><br><span class=\"line\">        <span class=\"comment\"># dropout</span></span><br><span class=\"line\">        nn.Dropout(dropout1),</span><br><span class=\"line\">        nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">256</span>),</span><br><span class=\"line\">        nn.ReLU(),</span><br><span class=\"line\">        <span class=\"comment\"># dropout</span></span><br><span class=\"line\">        nn.Dropout(dropout2),</span><br><span class=\"line\">        nn.Linear(<span class=\"number\">256</span>, <span class=\"number\">10</span>))</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"3-5-\"><a href=\"#3-5-\" class=\"headerlink\" title=\"3.5 \"></a>3.5 </h2><ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n"},{"title":"PyTorchGPU","mathjax":true,"date":"2026-01-13T12:46:25.000Z","img":"https://d00.paixin.com/thumbs/1772227/30081205/staff_1024.jpg","excerpt":"CUDA:OUT OF MEMORY","_content":"```bash\nRuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.93 GiB total capacity; 6.00 GiB already allocated; 14.88 MiB free; 6.00 GiB reserved in total by PyTorch)\n```\n\nGPUPyTorchGPUGPU\n\nPyTorchGPU\n\n```python\nimport torch\nfrom torch import nn\n\n# Start recording memory snapshot history\ntorch.cuda.memory._record_memory_history(max_entries=100000)\n\nmodel = nn.Linear(10_000, 50_000, device =\"cuda\")\nfor _ in range(3):\n    inputs = torch.randn(5_000, 10_000, device=\"cuda\")\n    outputs = model(inputs)\n\n# Dump memory snapshot history to a file and stop recording\ntorch.cuda.memory._dump_snapshot(\"profile.pkl\")\ntorch.cuda.memory._record_memory_history(enabled=None)\n```\n\n`profile.pkl`GPUhttps://pytorch.org/memory_viz\n\n`profile.pkl`\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile.png)\n\n\n\n![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile_partitioned.png)\n\n1. 2 GB\n\n   $10000 \\times 50000$ weight $+ 50000$ biases in $float32(4\\ bytes)$=$5 \\times 10^8 \\times 4 bytes = 2GB$\n\n   \n\n2. 200 MB\n\n   $5000 \\times 10000$ elements in $float32(4\\ bytes)=0.2GB$\n\n3. 11 GB\n\n   $5000\\times50000$ elements in $float32(4\\ bytes)=(25\\times10^7)\\times4\\ bytes=1GB$ \n\n4. 2200 MB2`inputs``torch.no_grad()`\n\n5. 1 GB3\n\n6. 2\n\n    forward \n\n   \n\n    forward \n\n7. `output`3`output`\n\n8. 4\n\n9. 5\n\n10. 4\n\n11. `output`5`output`\n\n12. \n\nGPULLM\n\n```python\nimport torch\nfrom transformers import AutoModelForCausalLM\n\n# Start recording memory snapshot history\ntorch.cuda.memory._record_memory_history(max_entries=100000)\n\nmodel = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B\").to(\"cuda\")\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n\nfor _ in range(3):\n    inputs = torch.randint(0, 100, (16, 256), device=\"cuda\")  # Dummy input\n    loss = torch.mean(model(inputs).logits)  # Dummy loss\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n# Dump memory snapshot history to a file and stop recording\ntorch.cuda.memory._dump_snapshot(\"profile.pkl\")\ntorch.cuda.memory._record_memory_history(enabled=None)\n```\n\nGPU8 MB\n\n\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/raw_training_profile.png)\n\n\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile.png)\n\n1. (`model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B\").to(\"cuda\")`)\n\nGPU\n\n2. (`model(inputs)`)\n\n\n\n3. (`loss.backward()`)\n\n\n\n4. (`optimizer.step()`)\n\n\n\n\n\nGPU\n\nGPU $Model Parameters+Optimizer State+Activations$\n\n162\n\n```python\n- inputs = torch.randint(0, 100, (16, 256), device=\"cuda\")  # Dummy input\n+ inputs = torch.randint(0, 100, (2, 256), device=\"cuda\")  # Dummy input\n```\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile_2.png)\n\n$Model Parameters+Optimizer State+Gradients+Optimizer Intermediates$\n\n\n\n- \n\n$Model Parameters+Optimizer State+max(Gradients+Optimizer Intermediates,Activations)$\n\n\n\n$Model Memory=NP$\n\n$N$$P$`float32`4\n\n154\n\n$Model Memory=1.510^94bytes=6GB$\n\n- `AdwmW`\n\n$Optimizer State Size=2NP$\n\n- hook\n\n```python\nimport torch\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B\").to(\"cuda\")\n\nactivation_sizes = []\n\ndef forward_hook(module, input, output):\n    \"\"\"\n    Hook to calculate activation size for each module.\n    \"\"\"\n    if isinstance(output, torch.Tensor):\n        activation_sizes.append(output.numel() * output.element_size())\n    elif isinstance(output, (tuple, list)):\n        for tensor in output:\n            if isinstance(tensor, torch.Tensor):\n                activation_sizes.append(tensor.numel() * tensor.element_size())\n\n# Register hooks for each submodule\nhooks = []\nfor submodule in model.modules():\n    hooks.append(submodule.register_forward_hook(forward_hook))\n\n# Perform a forward pass with a dummy input\ndummy_input = torch.zeros((1, 1), dtype=torch.int64, device=\"cuda\")\nmodel.eval()  # No gradients needed for memory measurement\nwith torch.no_grad():\n    model(dummy_input)\n\n# Clean up hooks\nfor hook in hooks:\n    hook.remove()\n\nprint(sum(activation_sizes))  # Output: 5065216\n```\n\nQwen2.5-1.5Btoken5,065,216$ Activation Memory=ABLP$\n\nAtokenBL\n\n\n\nllm\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/activation_memory_with_global_regression.png)\n\n\n\n$A=4.689410^{4}N+1.849410^6$\n\n\n\n\n\n$Gradients Memory=NP$\n\n\n\n$Optimizer Intermediates Memory=NP$\n\n\n\n$Total Memory=Model Memory+Optimizer State+max(Gradients,Optimizer Intermediates,Activations)$\n\n\n\n- **Model Memory**: $NP$\n- **Optimizer State**: $2NP$\n- **Gradients**: $NP$\n- **Optimizer Intermediates**: $NP$\n- **Activations**:$ ABLP, A=4.689410^{4}N+1.849410^6$\n\n","source":"_posts/memery-in-pytorch.md","raw":"---\ntitle: PyTorchGPU\nmathjax: true\ndate: 2026/1/13 20:46:25\nimg: https://d00.paixin.com/thumbs/1772227/30081205/staff_1024.jpg\nexcerpt: CUDA:OUT OF MEMORY\n---\n```bash\nRuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.93 GiB total capacity; 6.00 GiB already allocated; 14.88 MiB free; 6.00 GiB reserved in total by PyTorch)\n```\n\nGPUPyTorchGPUGPU\n\nPyTorchGPU\n\n```python\nimport torch\nfrom torch import nn\n\n# Start recording memory snapshot history\ntorch.cuda.memory._record_memory_history(max_entries=100000)\n\nmodel = nn.Linear(10_000, 50_000, device =\"cuda\")\nfor _ in range(3):\n    inputs = torch.randn(5_000, 10_000, device=\"cuda\")\n    outputs = model(inputs)\n\n# Dump memory snapshot history to a file and stop recording\ntorch.cuda.memory._dump_snapshot(\"profile.pkl\")\ntorch.cuda.memory._record_memory_history(enabled=None)\n```\n\n`profile.pkl`GPUhttps://pytorch.org/memory_viz\n\n`profile.pkl`\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile.png)\n\n\n\n![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile_partitioned.png)\n\n1. 2 GB\n\n   $10000 \\times 50000$ weight $+ 50000$ biases in $float32(4\\ bytes)$=$5 \\times 10^8 \\times 4 bytes = 2GB$\n\n   \n\n2. 200 MB\n\n   $5000 \\times 10000$ elements in $float32(4\\ bytes)=0.2GB$\n\n3. 11 GB\n\n   $5000\\times50000$ elements in $float32(4\\ bytes)=(25\\times10^7)\\times4\\ bytes=1GB$ \n\n4. 2200 MB2`inputs``torch.no_grad()`\n\n5. 1 GB3\n\n6. 2\n\n    forward \n\n   \n\n    forward \n\n7. `output`3`output`\n\n8. 4\n\n9. 5\n\n10. 4\n\n11. `output`5`output`\n\n12. \n\nGPULLM\n\n```python\nimport torch\nfrom transformers import AutoModelForCausalLM\n\n# Start recording memory snapshot history\ntorch.cuda.memory._record_memory_history(max_entries=100000)\n\nmodel = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B\").to(\"cuda\")\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n\nfor _ in range(3):\n    inputs = torch.randint(0, 100, (16, 256), device=\"cuda\")  # Dummy input\n    loss = torch.mean(model(inputs).logits)  # Dummy loss\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n\n# Dump memory snapshot history to a file and stop recording\ntorch.cuda.memory._dump_snapshot(\"profile.pkl\")\ntorch.cuda.memory._record_memory_history(enabled=None)\n```\n\nGPU8 MB\n\n\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/raw_training_profile.png)\n\n\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile.png)\n\n1. (`model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B\").to(\"cuda\")`)\n\nGPU\n\n2. (`model(inputs)`)\n\n\n\n3. (`loss.backward()`)\n\n\n\n4. (`optimizer.step()`)\n\n\n\n\n\nGPU\n\nGPU $Model Parameters+Optimizer State+Activations$\n\n162\n\n```python\n- inputs = torch.randint(0, 100, (16, 256), device=\"cuda\")  # Dummy input\n+ inputs = torch.randint(0, 100, (2, 256), device=\"cuda\")  # Dummy input\n```\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile_2.png)\n\n$Model Parameters+Optimizer State+Gradients+Optimizer Intermediates$\n\n\n\n- \n\n$Model Parameters+Optimizer State+max(Gradients+Optimizer Intermediates,Activations)$\n\n\n\n$Model Memory=NP$\n\n$N$$P$`float32`4\n\n154\n\n$Model Memory=1.510^94bytes=6GB$\n\n- `AdwmW`\n\n$Optimizer State Size=2NP$\n\n- hook\n\n```python\nimport torch\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B\").to(\"cuda\")\n\nactivation_sizes = []\n\ndef forward_hook(module, input, output):\n    \"\"\"\n    Hook to calculate activation size for each module.\n    \"\"\"\n    if isinstance(output, torch.Tensor):\n        activation_sizes.append(output.numel() * output.element_size())\n    elif isinstance(output, (tuple, list)):\n        for tensor in output:\n            if isinstance(tensor, torch.Tensor):\n                activation_sizes.append(tensor.numel() * tensor.element_size())\n\n# Register hooks for each submodule\nhooks = []\nfor submodule in model.modules():\n    hooks.append(submodule.register_forward_hook(forward_hook))\n\n# Perform a forward pass with a dummy input\ndummy_input = torch.zeros((1, 1), dtype=torch.int64, device=\"cuda\")\nmodel.eval()  # No gradients needed for memory measurement\nwith torch.no_grad():\n    model(dummy_input)\n\n# Clean up hooks\nfor hook in hooks:\n    hook.remove()\n\nprint(sum(activation_sizes))  # Output: 5065216\n```\n\nQwen2.5-1.5Btoken5,065,216$ Activation Memory=ABLP$\n\nAtokenBL\n\n\n\nllm\n\n![](https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/activation_memory_with_global_regression.png)\n\n\n\n$A=4.689410^{4}N+1.849410^6$\n\n\n\n\n\n$Gradients Memory=NP$\n\n\n\n$Optimizer Intermediates Memory=NP$\n\n\n\n$Total Memory=Model Memory+Optimizer State+max(Gradients,Optimizer Intermediates,Activations)$\n\n\n\n- **Model Memory**: $NP$\n- **Optimizer State**: $2NP$\n- **Gradients**: $NP$\n- **Optimizer Intermediates**: $NP$\n- **Activations**:$ ABLP, A=4.689410^{4}N+1.849410^6$\n\n","slug":"memery-in-pytorch","published":1,"updated":"2026-01-14T11:07:34.313Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff8000hss99bpksc6zl","content":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.93 GiB total capacity; 6.00 GiB already allocated; 14.88 MiB free; 6.00 GiB reserved <span class=\"keyword\">in</span> total by PyTorch)</span><br></pre></td></tr></table></figure>\n\n<p>GPUPyTorchGPUGPU</p>\n<p>PyTorchGPU</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Start recording memory snapshot history</span></span><br><span class=\"line\">torch.cuda.memory._record_memory_history(max_entries=<span class=\"number\">100000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model = nn.Linear(<span class=\"number\">10_000</span>, <span class=\"number\">50_000</span>, device =<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">3</span>):</span><br><span class=\"line\">    inputs = torch.randn(<span class=\"number\">5_000</span>, <span class=\"number\">10_000</span>, device=<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\">    outputs = model(inputs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Dump memory snapshot history to a file and stop recording</span></span><br><span class=\"line\">torch.cuda.memory._dump_snapshot(<span class=\"string\">&quot;profile.pkl&quot;</span>)</span><br><span class=\"line\">torch.cuda.memory._record_memory_history(enabled=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><code>profile.pkl</code>GPU<a href=\"https://pytorch.org/memory_viz%E4%B8%8A%E5%8F%AF%E8%A7%86%E5%8C%96%E6%AD%A4%E5%8E%86%E5%8F%B2%E3%80%82\">https://pytorch.org/memory_viz</a></p>\n<p><code>profile.pkl</code></p>\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile.png\" class=\"lazyload placeholder\" data-srcset=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\"></p>\n<p></p>\n<p><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile_partitioned.png\" class=\"lazyload placeholder\" data-srcset=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile_partitioned.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\"></p>\n<ol>\n<li><p>2 GB</p>\n<p>$10000 \\times 50000$ weight $+ 50000$ biases in $float32(4\\ bytes)$&#x3D;$5 \\times 10^8 \\times 4 bytes &#x3D; 2GB$</p>\n<p></p>\n</li>\n<li><p>200 MB</p>\n<p>$5000 \\times 10000$ elements in $float32(4\\ bytes)&#x3D;0.2GB$</p>\n</li>\n<li><p>11 GB</p>\n<p>$5000\\times50000$ elements in $float32(4\\ bytes)&#x3D;(25\\times10^7)\\times4\\ bytes&#x3D;1GB$ </p>\n</li>\n<li><p>2200 MB2<code>inputs</code><code>torch.no_grad()</code></p>\n</li>\n<li><p>1 GB3</p>\n</li>\n<li><p>2</p>\n<p> forward </p>\n<p></p>\n<p> forward </p>\n</li>\n<li><p><code>output</code>3<code>output</code></p>\n</li>\n<li><p>4</p>\n</li>\n<li><p>5</p>\n</li>\n<li><p>4</p>\n</li>\n<li><p><code>output</code>5<code>output</code></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<p>GPULLM</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> AutoModelForCausalLM</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Start recording memory snapshot history</span></span><br><span class=\"line\">torch.cuda.memory._record_memory_history(max_entries=<span class=\"number\">100000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model = AutoModelForCausalLM.from_pretrained(<span class=\"string\">&quot;Qwen/Qwen2.5-1.5B&quot;</span>).to(<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\">optimizer = torch.optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">3</span>):</span><br><span class=\"line\">    inputs = torch.randint(<span class=\"number\">0</span>, <span class=\"number\">100</span>, (<span class=\"number\">16</span>, <span class=\"number\">256</span>), device=<span class=\"string\">&quot;cuda&quot;</span>)  <span class=\"comment\"># Dummy input</span></span><br><span class=\"line\">    loss = torch.mean(model(inputs).logits)  <span class=\"comment\"># Dummy loss</span></span><br><span class=\"line\">    loss.backward()</span><br><span class=\"line\">    optimizer.step()</span><br><span class=\"line\">    optimizer.zero_grad()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Dump memory snapshot history to a file and stop recording</span></span><br><span class=\"line\">torch.cuda.memory._dump_snapshot(<span class=\"string\">&quot;profile.pkl&quot;</span>)</span><br><span class=\"line\">torch.cuda.memory._record_memory_history(enabled=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p>GPU8 MB</p>\n<p></p>\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/raw_training_profile.png\" class=\"lazyload placeholder\" data-srcset=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/raw_training_profile.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\"></p>\n<p></p>\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile.png\" class=\"lazyload placeholder\" data-srcset=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\"></p>\n<ol>\n<li>(<code>model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen2.5-1.5B&quot;).to(&quot;cuda&quot;)</code>)</li>\n</ol>\n<p>GPU</p>\n<ol start=\"2\">\n<li>(<code>model(inputs)</code>)</li>\n</ol>\n<p></p>\n<ol start=\"3\">\n<li>(<code>loss.backward()</code>)</li>\n</ol>\n<p></p>\n<ol start=\"4\">\n<li>(<code>optimizer.step()</code>)</li>\n</ol>\n<p></p>\n<p></p>\n<p>GPU</p>\n<p>GPU $Model Parameters+Optimizer State+Activations$</p>\n<p>162</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- inputs = torch.randint(<span class=\"number\">0</span>, <span class=\"number\">100</span>, (<span class=\"number\">16</span>, <span class=\"number\">256</span>), device=<span class=\"string\">&quot;cuda&quot;</span>)  <span class=\"comment\"># Dummy input</span></span><br><span class=\"line\">+ inputs = torch.randint(<span class=\"number\">0</span>, <span class=\"number\">100</span>, (<span class=\"number\">2</span>, <span class=\"number\">256</span>), device=<span class=\"string\">&quot;cuda&quot;</span>)  <span class=\"comment\"># Dummy input</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile_2.png\" class=\"lazyload placeholder\" data-srcset=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile_2.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\"></p>\n<p>$Model Parameters+Optimizer State+Gradients+Optimizer Intermediates$</p>\n<p></p>\n<ul>\n<li></li>\n</ul>\n<p>$Model Parameters+Optimizer State+max(Gradients+Optimizer Intermediates,Activations)$</p>\n<p></p>\n<p>$Model Memory&#x3D;NP$</p>\n<p>$N$$P$<code>float32</code>4</p>\n<p>154</p>\n<p>$Model Memory&#x3D;1.510^94bytes&#x3D;6GB$</p>\n<ul>\n<li><code>AdwmW</code></li>\n</ul>\n<p>$Optimizer State Size&#x3D;2NP$</p>\n<ul>\n<li>hook</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> AutoModelForCausalLM</span><br><span class=\"line\"></span><br><span class=\"line\">model = AutoModelForCausalLM.from_pretrained(<span class=\"string\">&quot;Qwen/Qwen2.5-1.5B&quot;</span>).to(<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">activation_sizes = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">forward_hook</span>(<span class=\"params\">module, <span class=\"built_in\">input</span>, output</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    Hook to calculate activation size for each module.</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(output, torch.Tensor):</span><br><span class=\"line\">        activation_sizes.append(output.numel() * output.element_size())</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> <span class=\"built_in\">isinstance</span>(output, (<span class=\"built_in\">tuple</span>, <span class=\"built_in\">list</span>)):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tensor <span class=\"keyword\">in</span> output:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(tensor, torch.Tensor):</span><br><span class=\"line\">                activation_sizes.append(tensor.numel() * tensor.element_size())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Register hooks for each submodule</span></span><br><span class=\"line\">hooks = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> submodule <span class=\"keyword\">in</span> model.modules():</span><br><span class=\"line\">    hooks.append(submodule.register_forward_hook(forward_hook))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Perform a forward pass with a dummy input</span></span><br><span class=\"line\">dummy_input = torch.zeros((<span class=\"number\">1</span>, <span class=\"number\">1</span>), dtype=torch.int64, device=<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\">model.<span class=\"built_in\">eval</span>()  <span class=\"comment\"># No gradients needed for memory measurement</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    model(dummy_input)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Clean up hooks</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> hook <span class=\"keyword\">in</span> hooks:</span><br><span class=\"line\">    hook.remove()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">sum</span>(activation_sizes))  <span class=\"comment\"># Output: 5065216</span></span><br></pre></td></tr></table></figure>\n\n<p>Qwen2.5-1.5Btoken5,065,216$ Activation Memory&#x3D;ABLP$</p>\n<p>AtokenBL</p>\n<p></p>\n<p>llm</p>\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/activation_memory_with_global_regression.png\" class=\"lazyload placeholder\" data-srcset=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/activation_memory_with_global_regression.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\"></p>\n<p></p>\n<p>$A&#x3D;4.689410^{4}N+1.849410^6$</p>\n<p></p>\n<p></p>\n<p>$Gradients Memory&#x3D;NP$</p>\n<p></p>\n<p>$Optimizer Intermediates Memory&#x3D;NP$</p>\n<p></p>\n<p>$Total Memory&#x3D;Model Memory+Optimizer State+max(Gradients,Optimizer Intermediates,Activations)$</p>\n<p></p>\n<ul>\n<li><strong>Model Memory</strong>: $NP$</li>\n<li><strong>Optimizer State</strong>: $2NP$</li>\n<li><strong>Gradients</strong>: $NP$</li>\n<li><strong>Optimizer Intermediates</strong>: $NP$</li>\n<li><strong>Activations</strong>:$ ABLP, A&#x3D;4.689410^{4}N+1.849410^6$</li>\n</ul>\n","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.93 GiB total capacity; 6.00 GiB already allocated; 14.88 MiB free; 6.00 GiB reserved <span class=\"keyword\">in</span> total by PyTorch)</span><br></pre></td></tr></table></figure>\n\n<p>GPUPyTorchGPUGPU</p>\n<p>PyTorchGPU</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch <span class=\"keyword\">import</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Start recording memory snapshot history</span></span><br><span class=\"line\">torch.cuda.memory._record_memory_history(max_entries=<span class=\"number\">100000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model = nn.Linear(<span class=\"number\">10_000</span>, <span class=\"number\">50_000</span>, device =<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">3</span>):</span><br><span class=\"line\">    inputs = torch.randn(<span class=\"number\">5_000</span>, <span class=\"number\">10_000</span>, device=<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\">    outputs = model(inputs)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Dump memory snapshot history to a file and stop recording</span></span><br><span class=\"line\">torch.cuda.memory._dump_snapshot(<span class=\"string\">&quot;profile.pkl&quot;</span>)</span><br><span class=\"line\">torch.cuda.memory._record_memory_history(enabled=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><code>profile.pkl</code>GPU<a href=\"https://pytorch.org/memory_viz%E4%B8%8A%E5%8F%AF%E8%A7%86%E5%8C%96%E6%AD%A4%E5%8E%86%E5%8F%B2%E3%80%82\">https://pytorch.org/memory_viz</a></p>\n<p><code>profile.pkl</code></p>\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile.png\"></p>\n<p></p>\n<p><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/simple_profile_partitioned.png\"></p>\n<ol>\n<li><p>2 GB</p>\n<p>$10000 \\times 50000$ weight $+ 50000$ biases in $float32(4\\ bytes)$&#x3D;$5 \\times 10^8 \\times 4 bytes &#x3D; 2GB$</p>\n<p></p>\n</li>\n<li><p>200 MB</p>\n<p>$5000 \\times 10000$ elements in $float32(4\\ bytes)&#x3D;0.2GB$</p>\n</li>\n<li><p>11 GB</p>\n<p>$5000\\times50000$ elements in $float32(4\\ bytes)&#x3D;(25\\times10^7)\\times4\\ bytes&#x3D;1GB$ </p>\n</li>\n<li><p>2200 MB2<code>inputs</code><code>torch.no_grad()</code></p>\n</li>\n<li><p>1 GB3</p>\n</li>\n<li><p>2</p>\n<p> forward </p>\n<p></p>\n<p> forward </p>\n</li>\n<li><p><code>output</code>3<code>output</code></p>\n</li>\n<li><p>4</p>\n</li>\n<li><p>5</p>\n</li>\n<li><p>4</p>\n</li>\n<li><p><code>output</code>5<code>output</code></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<p>GPULLM</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> AutoModelForCausalLM</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Start recording memory snapshot history</span></span><br><span class=\"line\">torch.cuda.memory._record_memory_history(max_entries=<span class=\"number\">100000</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model = AutoModelForCausalLM.from_pretrained(<span class=\"string\">&quot;Qwen/Qwen2.5-1.5B&quot;</span>).to(<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\">optimizer = torch.optim.AdamW(model.parameters(), lr=<span class=\"number\">1e-3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> _ <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">3</span>):</span><br><span class=\"line\">    inputs = torch.randint(<span class=\"number\">0</span>, <span class=\"number\">100</span>, (<span class=\"number\">16</span>, <span class=\"number\">256</span>), device=<span class=\"string\">&quot;cuda&quot;</span>)  <span class=\"comment\"># Dummy input</span></span><br><span class=\"line\">    loss = torch.mean(model(inputs).logits)  <span class=\"comment\"># Dummy loss</span></span><br><span class=\"line\">    loss.backward()</span><br><span class=\"line\">    optimizer.step()</span><br><span class=\"line\">    optimizer.zero_grad()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Dump memory snapshot history to a file and stop recording</span></span><br><span class=\"line\">torch.cuda.memory._dump_snapshot(<span class=\"string\">&quot;profile.pkl&quot;</span>)</span><br><span class=\"line\">torch.cuda.memory._record_memory_history(enabled=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p>GPU8 MB</p>\n<p></p>\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/raw_training_profile.png\"></p>\n<p></p>\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile.png\"></p>\n<ol>\n<li>(<code>model = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen2.5-1.5B&quot;).to(&quot;cuda&quot;)</code>)</li>\n</ol>\n<p>GPU</p>\n<ol start=\"2\">\n<li>(<code>model(inputs)</code>)</li>\n</ol>\n<p></p>\n<ol start=\"3\">\n<li>(<code>loss.backward()</code>)</li>\n</ol>\n<p></p>\n<ol start=\"4\">\n<li>(<code>optimizer.step()</code>)</li>\n</ol>\n<p></p>\n<p></p>\n<p>GPU</p>\n<p>GPU $Model Parameters+Optimizer State+Activations$</p>\n<p>162</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">- inputs = torch.randint(<span class=\"number\">0</span>, <span class=\"number\">100</span>, (<span class=\"number\">16</span>, <span class=\"number\">256</span>), device=<span class=\"string\">&quot;cuda&quot;</span>)  <span class=\"comment\"># Dummy input</span></span><br><span class=\"line\">+ inputs = torch.randint(<span class=\"number\">0</span>, <span class=\"number\">100</span>, (<span class=\"number\">2</span>, <span class=\"number\">256</span>), device=<span class=\"string\">&quot;cuda&quot;</span>)  <span class=\"comment\"># Dummy input</span></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/colorized_training_profile_2.png\"></p>\n<p>$Model Parameters+Optimizer State+Gradients+Optimizer Intermediates$</p>\n<p></p>\n<ul>\n<li></li>\n</ul>\n<p>$Model Parameters+Optimizer State+max(Gradients+Optimizer Intermediates,Activations)$</p>\n<p></p>\n<p>$Model Memory&#x3D;NP$</p>\n<p>$N$$P$<code>float32</code>4</p>\n<p>154</p>\n<p>$Model Memory&#x3D;1.510^94bytes&#x3D;6GB$</p>\n<ul>\n<li><code>AdwmW</code></li>\n</ul>\n<p>$Optimizer State Size&#x3D;2NP$</p>\n<ul>\n<li>hook</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> AutoModelForCausalLM</span><br><span class=\"line\"></span><br><span class=\"line\">model = AutoModelForCausalLM.from_pretrained(<span class=\"string\">&quot;Qwen/Qwen2.5-1.5B&quot;</span>).to(<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">activation_sizes = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">forward_hook</span>(<span class=\"params\">module, <span class=\"built_in\">input</span>, output</span>):</span><br><span class=\"line\">    <span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">    Hook to calculate activation size for each module.</span></span><br><span class=\"line\"><span class=\"string\">    &quot;&quot;&quot;</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(output, torch.Tensor):</span><br><span class=\"line\">        activation_sizes.append(output.numel() * output.element_size())</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> <span class=\"built_in\">isinstance</span>(output, (<span class=\"built_in\">tuple</span>, <span class=\"built_in\">list</span>)):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> tensor <span class=\"keyword\">in</span> output:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(tensor, torch.Tensor):</span><br><span class=\"line\">                activation_sizes.append(tensor.numel() * tensor.element_size())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Register hooks for each submodule</span></span><br><span class=\"line\">hooks = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> submodule <span class=\"keyword\">in</span> model.modules():</span><br><span class=\"line\">    hooks.append(submodule.register_forward_hook(forward_hook))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Perform a forward pass with a dummy input</span></span><br><span class=\"line\">dummy_input = torch.zeros((<span class=\"number\">1</span>, <span class=\"number\">1</span>), dtype=torch.int64, device=<span class=\"string\">&quot;cuda&quot;</span>)</span><br><span class=\"line\">model.<span class=\"built_in\">eval</span>()  <span class=\"comment\"># No gradients needed for memory measurement</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    model(dummy_input)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Clean up hooks</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> hook <span class=\"keyword\">in</span> hooks:</span><br><span class=\"line\">    hook.remove()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">sum</span>(activation_sizes))  <span class=\"comment\"># Output: 5065216</span></span><br></pre></td></tr></table></figure>\n\n<p>Qwen2.5-1.5Btoken5,065,216$ Activation Memory&#x3D;ABLP$</p>\n<p>AtokenBL</p>\n<p></p>\n<p>llm</p>\n<p><img src=\"https://hf-mirror.com/datasets/huggingface/documentation-images/resolve/main/blog/train_memory/activation_memory_with_global_regression.png\"></p>\n<p></p>\n<p>$A&#x3D;4.689410^{4}N+1.849410^6$</p>\n<p></p>\n<p></p>\n<p>$Gradients Memory&#x3D;NP$</p>\n<p></p>\n<p>$Optimizer Intermediates Memory&#x3D;NP$</p>\n<p></p>\n<p>$Total Memory&#x3D;Model Memory+Optimizer State+max(Gradients,Optimizer Intermediates,Activations)$</p>\n<p></p>\n<ul>\n<li><strong>Model Memory</strong>: $NP$</li>\n<li><strong>Optimizer State</strong>: $2NP$</li>\n<li><strong>Gradients</strong>: $NP$</li>\n<li><strong>Optimizer Intermediates</strong>: $NP$</li>\n<li><strong>Activations</strong>:$ ABLP, A&#x3D;4.689410^{4}N+1.849410^6$</li>\n</ul>\n"},{"title":"DataWhale-all-in-Rag-Notes","mathjax":true,"date":"2025-10-21T12:46:25.000Z","img":"https://datawhalechina.github.io/all-in-rag/logo.svg","excerpt":"DataWhale-all-in-Rag-","_content":"\n![](https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1.svg)\n\n\n\n1. **Indexing** PDF/Word\n2. **Retrieval** Context\n3. **Generation** LLM\n\n![](https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1_2.webp)\n\n| ****          |    |\n| ------------------------- | ---------------------------------- |\n| **Hallucination** |        |\n| ****        | /  |\n| ****          |  |\n\n## \n\n| **PyMuPDF4LLM**     | PDFMarkdownOCR+ |  | GPU     |\n| ------------------- | ------------------------------ | ------------------ | --------------------- |\n| **TextLoader**      |                |          |               |\n| **DirectoryLoader** |                |      |         |\n| **Unstructured**    |                  | PDFWordHTML  |     |\n| **FireCrawlLoader** |                    |      |           |\n| **LlamaParse**      | PDF                |  | API   |\n| **Docling**         |                |      | IBM           |\n| **Marker**          | PDFMarkdownGPU          |      | PDF           |\n| **MinerU**          |                  |  | LayoutLMv3+YOLOv8 |\n\n### Unstructured\n\n- PDFWordExcelHTMLMarkdown\n- API\n\n## \n\n Transformer \n\n1. ** (Tokenization)**:  token\n2. ** (Vectorization)**: Transformer ** token** \n3. ** (Pooling)**: `[CLS]`[1](https://datawhalechina.github.io/all-in-rag/#fn-1)token`mean pooling` token ********\n\n``768****\n\n- CharacterTextSplitter\n\n1. ****`CharacterTextSplitter`  `\"\\n\\n\"` `_split_text_with_regex` \n2. **** `_merge_splits`  `chunk_size` `chunk_overlap`\n\n\"\"\n\n- RecursiveCharacterTextSplitter\n\n1. ****: **** `\"\"`\n\n2. \n\n   : \n\n   - ****:  `_good_splits` \n\n   - \n\n     :\n\n     -  `_merge_splits` \n     - \n       - ****:  `_split_text` \n       - ****: \n\n3. ****: \n\n- SemanticChunker\n\n1. ** (Sentence Splitting)**: \n2. ** (Context-Aware Embedding)**:  `SemanticChunker`  `buffer_size` 1 `buffer_size` \n3. ** (Distance Calculation)**: ****\n4. ** (Breakpoint Identification)**: `SemanticChunker`  `percentile`95\n5. ** (Merging into Chunks)**: \n\n** (`breakpoint_threshold_type`)**\n\n`SemanticChunker` \n\n- `percentile` ( - ****):\n  - ****: \n  - ****: `breakpoint_threshold_amount` ( `95`)955%\n- `standard_deviation` ():\n  - ****:  + N * \n  - ****: `breakpoint_threshold_amount` ( `3`)3\n- `interquartile` ():\n  - ****: IQR `Q3 + N * IQR` \n  - ****: `breakpoint_threshold_amount` ( `1.5`)1.5IQR\n- `gradient` ():\n  - ****: \n  - ****: `breakpoint_threshold_amount` ( `95`)\n\n## \n\n[**MTEB (Massive Text Embedding Benchmark)**](https://huggingface.co/spaces/mteb/leaderboard)  Hugging Face \n\n\n\n1. ** (Task)**  RAG  `Retrieval` () \n2. ** (Language)**  RAG\n3. ** (Size)** \n4. ** (Dimensions)** \n5. ** Token  (Max Tokens)** Chunking\n6. ** (Score & Publisher)** \n7. ** (Cost)**  API \n\n## \n\n## \n\n1. **** HNSW, IVFANN\n2. ****\n3. ****` > 2023`\n4. ****\n5. **** AI  LangChain, LlamaIndex\n\n\n\n1. ****\n2. ****HNSWLSHPQ\n3. ****\n4. ****\n\n\n\n- **** Annoy \n- **** LSH\n- **** HNSW\n- **** Faiss  IVF  PQ\n\n## Milvus\n\nhttps://datawhalechina.github.io/all-in-rag/#/chapter3/09_milvus\n\n## \n\n### \n\nRAGLLMLlamaIndex **Sentence Window Retrieval**]LLM\n\n****\n\n### \n\n**Metadata**\n\n- \n- \n- \n- \n- \n\n1. ****\n   - ****Excel1994`Document`1994\n   - ****`Document` `{\"sheet_name\": \"_1994\"}`\n2. ****\n   - ****199419941994 `_1994` \n   - **** `_1994` ****`MetadataFilter` `sheet_name == \"_1994\"` LLM\n\nLlamaIndex [4](https://datawhalechina.github.io/all-in-rag/#fn-4)\n\n## \n\nHybrid Search **Sparse Vectors**  **Dense Vectors** \n\n### (Reciprocal Rank Fusion, RRF)\n\nRRF ****\n\n### \n\n 0-1  `` \n\n `` \n\n## \n\n### \n\nChunksMetadata\n\n**Self-Query Retriever** LangChain\n\n1. ****LLM\n\n2. \n\n   LLM\n\n   - **Query String**\n   - **Metadata Filter**\n\n3. ****\n\n### Cypher\n\nCypher  Neo4j SQL \n\nCypherLLM Cypher LangChain  `GraphCypherQAChain`\n\n1. \n2. LLM Schema Cypher \n3. \n4. () LLM\n\n## Text2SQL\n\n- ****LLM SQL\n- ****LLM  `JOIN`  `WHERE` \n- ****\n\n1. ****LLM `CREATE TABLE` LLM\n2. ****Prompt-SQLLLMLLM\n3. **RAG**RAGFlowDDL\n   - ****\n   - **** `cost` \n   - **** `JOIN``GROUP BY`  Q&ALLMSQL\n4. ** (Error Correction and Reflection)**SQLLLMSQL\n\n## \n\n1. **Query Translation**\n2. **Query Routing**\n\n### \n\n****\n\n- \n\nPrompt LLM \n\n LLM  JSON \n\n- Multi-query\n\n LLM \n\nLangChain  `MultiQueryRetriever`  LLM \n\n- Step-Back Prompting\n\n\n\n\n\n1. **** LLM Step-back Question\n2. ****\n\n![](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_1.webp)\n\n\n\n- HyDE\n\nHypothetical Document Embeddings, HyDE Luyu Gao QueryZilliz [4](https://datawhalechina.github.io/all-in-rag/#fn-4)\n\n![HyDE](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_2.webp)\n\nHyDE LLMHyDE \n\nHyDE \n\n1. **** LLMGPT-3.5\n2. **** Contriever\n3. ****\n\nHyDE \n\n### \n\n**Query Routing**  RAG \n\n\n\n1. ****\n   -  iPhone  -> ****\n   -  -> **SQL**Text-to-SQL\n   - AB -> ****\n2. ****\n   - FAQ  \n   - API   Agent \n3. ****\n   -   Step-by-Step\n   -   \n\n- LLM\n\nLLM\n\n![](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_3.webp)\n\n1. \n2. LLM \n3. \n\n- \n\n LLM \n\n![](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_4.webp)\n\n## \n\n![retrieval](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_1.webp)\n\n### Re-ranking\n\n- RRFReciprocal Rank Fusion\n\n********\n\nRRF \n\n- RankLLM/LLM-based Reranker\n\n![rankllm](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_2.webp)\n\nRankLLM  LLM \n\n LLM  JSON\n\n- Cross-Encoder\n\nCross-EncoderQueryDocument****`[CLS] query [SEP] document [SEP]` Transformer  BERT 0  1 ****\n\n![cross-encoder](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_3.svg)\n\n1. **** 50 \n2. ************ Cross-Encoder \n3. ****-\n4. ****\n\nN\n\n- ColBERT\n\nColBERTContextualized Late Interaction over BERT Cross-Encoder Bi-Encoder****\n\n\n\n1. ****ColBERT QueryDocument Token \n2. **** Token  Token MaxSim\n3. **** Token \n\nColBERT  `[CLS]` \n\n\n\n|          | RRF                | RankLLM                | Cross-Encoder                      | ColBERT            |\n| ------------ | ------------------ | ---------------------- | ---------------------------------- | ------------------ |\n| **** |        | LLM  |  |  |\n| **** |  |  (API )    | N                  |  |\n| **** |        | /            | Query-Doc Pair           | Token            |\n| **** |    |      | Top-K                          | Top-K          |\n\n### Compression\n\nChunks LLM API \n\n\n\n1. ****\n2. ****\n\n### LangChainContextualCompressionRetriever\n\nLangChain  `ContextualCompressionRetriever`  `FAISS.as_retriever()``ContextualCompressionRetriever`  `DocumentCompressor` \n\nLangChain  `DocumentCompressor`\n\n- `LLMChainExtractor`:  LLM Chain \n- `LLMChainFilter`:  LLM\n- `EmbeddingsFilter`: \n\n### Correcting\n\n RAG  LLMHallucination\n\n**Corrective-RAG, C-RAG** \n\nC-RAG  **--** \n\n![C-RAG](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_4.webp)\n\n1. ** (Retrieve)**  RAG \n2. ** (Assess)**  C-RAG  (Retrieval Evaluator) (Correct) (Incorrect) (Ambiguous)\n3. ** (Act)** \n   - **** (Knowledge Refinement) (strips)\n   - **** (Knowledge Searching) (Query Rewriting) Web \n   - **** Web \n\nC-RAG  RAG \n\n LangChain  `langgraph`  RAG \n\n## \n\n### \n\nLLM JSON  XML\n\n- output parsers\n\nLangChain `OutputParsers` LLM \n\n1. **** LLM Prompt\n2. **** LLM  Python \n\nLangChain \n\n- **StrOutputParser** LLM \n- **JsonOutputParser** JSON \n- **PydanticOutputParser** Pydantic \n\n### Function Calling\n\nFunction Calling  API\n\n1. **** JSON Schema\n2. ****\n3. **** `tool_calls` \n4. ******** API\n5. **** API  `role`  `tool` \n6. ****\n\n JSONFunction Calling \n\n- ****\n- ****\n- **** AI Agent LLM  API\n\n## RAG\n\n![RAG Triad](https://datawhalechina.github.io/all-in-rag/chapter6/images/6_1_1.webp)\n\n### RAG\n\n **TruLens**  \n\n1. ** (Context Relevance)**\n   - **** Retriever\n   - **** Query\n   - **** RAG\n2. ** /  (Faithfulness / Groundedness)**\n   - **** \n   - **** \n   - **** LLMLLM\n3. ** (Answer Relevance)**\n   - **** End-to-End\n   - **** \n   - **** \n\n### \n\n- \n\nRAG ** (Context Relevance)\\*** \n\n\n\n![1](/img/all-in-rag/p1.png)\n\n- \n\nRAG ****  **** **** \n\n- \n\n1. ** / :**\n   - \n2. **:**\n   - \n\n- \n\n\n\n**1. **\n\nllm\n\n- **** Claims\n- **** \n\n**2. **\n\n n-gramn\n\n![2](img/all-in-rag/p2.png)\n\nLLM********LLM\n\n### \n\n### LlamaIndex Evaluation\n\n`LlamaIndex Evaluation` **LlamaIndex**RAGRAG****RAG\n\n`LlamaIndex` LLMRAG\n\n1. **** `DatasetGenerator` -`QueryResponseDataset`\n2. ****RAG`QueryEngine`\n3. **** `FaithfulnessEvaluator` `RelevancyEvaluator`\n4. **** `BatchEvalRunner` \n5. ****RAG\n\nLlamaIndex****\n\n- `Faithfulness` (): \n- `Relevancy` (): \n\n****\n\n- `Hit Rate` (): \n- `MRR` (): \n\n### RAGAS\n\nRAGASRAG Assessment**RAG**RAG****RAGRAG`RAGAS` \n\n`RAGAS` `question``answer``context`RAG\n\n1. **** `question``answer`RAG`contexts` `ground_truth``ground_truth`  `context_recall`  `faithfulness` \n2. **** `ragas.evaluate()` \n3. ****\n\n\n\n- `faithfulness`: \n- `context_recall`: `ground_truth`\n- `context_precision`: \n- `answer_relevancy`: \n\n### Phoenix\n\nPhoenix (Arize) **LLM**RAG****LLMTracesPhoenix ****LLMTracing\n\n1. ** (`Instrumentation`)** **OpenTelemetry**RAG `Phoenix` LLM\n2. ** (`Traces`)**RAG`Phoenix` \n3. **UI** `Phoenix` Web\n4. ****UI (`Evals`) \n\n\n\n- ****: RAG\n- ****: \n- ** (`Guardrails`)**: \n- ****: \n- **Arize**: `Phoenix` ArizeRAG\n\n## RAG\n\n![GraphRAG](https://datawhalechina.github.io/all-in-rag/chapter7/images/7_1_1.svg)\n\n RAG \"-\"LLM\n\n****LLM\n\n****RAG\n\n****LLM\"\"\n\n**** RAG \n\n****/\n\n****//\n\n****\n\nRAG\n\n****\"A--B\"LLM\n\n****\n\n****\n\n****\n\n\n\n- ****SchemaOntology\n- ****\n- ****Time-travel Query\n\n### GraphRAG\n\n****  GraphRAG \n\n-  LLM  IE /Normalization\n- \n- Entity Resolution/\n- Neo4j/NebulaGraph/TigerGraph/Neptune\n\n**** \n\n- Entity Linking\n- Cypher\n- \n- GraphRAGLeiden-\n\n GraphRAG  RAG \n\n****  Cypher/Gremlin\n\n**** /\n\n**** \n\n- /\n- \n\nGraphRAG\n\n- GraphRAGMicrosoft\n\n- LightRAG\n- FRAGFlexible RAG\n\n- GraphIRAG (Iterative Knowledge Retrieval)\n\n### \n\nGraphRAG \n\n****\n\n- PrecisionRecallF1Hit Rate@K\n- RAG\n  - Context Precision= \n  - Context Recall= \n  - /Citation/Attribution= \n\n****\n\n- EMF1\n- ROUGE\n- /Faithfulness+\n\n****\n\nLatencyThroughputQPSCostAPIGPU/CPU\n\nGraphRAG\n\n**** GraphRAG HotpotQA2WikiMultihopQA  MuSiQue\n\n****  WebQSP  ComplexWebQuestions (CWQ)\n\n**QA**  KGQAgen-10k\n","source":"_posts/all-in-rag.md","raw":"---\ntitle: DataWhale-all-in-Rag-Notes\nmathjax: true\ndate: 2025/10/21 20:46:25\nimg: https://datawhalechina.github.io/all-in-rag/logo.svg\nexcerpt: DataWhale-all-in-Rag-\n---\n\n![](https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1.svg)\n\n\n\n1. **Indexing** PDF/Word\n2. **Retrieval** Context\n3. **Generation** LLM\n\n![](https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1_2.webp)\n\n| ****          |    |\n| ------------------------- | ---------------------------------- |\n| **Hallucination** |        |\n| ****        | /  |\n| ****          |  |\n\n## \n\n| **PyMuPDF4LLM**     | PDFMarkdownOCR+ |  | GPU     |\n| ------------------- | ------------------------------ | ------------------ | --------------------- |\n| **TextLoader**      |                |          |               |\n| **DirectoryLoader** |                |      |         |\n| **Unstructured**    |                  | PDFWordHTML  |     |\n| **FireCrawlLoader** |                    |      |           |\n| **LlamaParse**      | PDF                |  | API   |\n| **Docling**         |                |      | IBM           |\n| **Marker**          | PDFMarkdownGPU          |      | PDF           |\n| **MinerU**          |                  |  | LayoutLMv3+YOLOv8 |\n\n### Unstructured\n\n- PDFWordExcelHTMLMarkdown\n- API\n\n## \n\n Transformer \n\n1. ** (Tokenization)**:  token\n2. ** (Vectorization)**: Transformer ** token** \n3. ** (Pooling)**: `[CLS]`[1](https://datawhalechina.github.io/all-in-rag/#fn-1)token`mean pooling` token ********\n\n``768****\n\n- CharacterTextSplitter\n\n1. ****`CharacterTextSplitter`  `\"\\n\\n\"` `_split_text_with_regex` \n2. **** `_merge_splits`  `chunk_size` `chunk_overlap`\n\n\"\"\n\n- RecursiveCharacterTextSplitter\n\n1. ****: **** `\"\"`\n\n2. \n\n   : \n\n   - ****:  `_good_splits` \n\n   - \n\n     :\n\n     -  `_merge_splits` \n     - \n       - ****:  `_split_text` \n       - ****: \n\n3. ****: \n\n- SemanticChunker\n\n1. ** (Sentence Splitting)**: \n2. ** (Context-Aware Embedding)**:  `SemanticChunker`  `buffer_size` 1 `buffer_size` \n3. ** (Distance Calculation)**: ****\n4. ** (Breakpoint Identification)**: `SemanticChunker`  `percentile`95\n5. ** (Merging into Chunks)**: \n\n** (`breakpoint_threshold_type`)**\n\n`SemanticChunker` \n\n- `percentile` ( - ****):\n  - ****: \n  - ****: `breakpoint_threshold_amount` ( `95`)955%\n- `standard_deviation` ():\n  - ****:  + N * \n  - ****: `breakpoint_threshold_amount` ( `3`)3\n- `interquartile` ():\n  - ****: IQR `Q3 + N * IQR` \n  - ****: `breakpoint_threshold_amount` ( `1.5`)1.5IQR\n- `gradient` ():\n  - ****: \n  - ****: `breakpoint_threshold_amount` ( `95`)\n\n## \n\n[**MTEB (Massive Text Embedding Benchmark)**](https://huggingface.co/spaces/mteb/leaderboard)  Hugging Face \n\n\n\n1. ** (Task)**  RAG  `Retrieval` () \n2. ** (Language)**  RAG\n3. ** (Size)** \n4. ** (Dimensions)** \n5. ** Token  (Max Tokens)** Chunking\n6. ** (Score & Publisher)** \n7. ** (Cost)**  API \n\n## \n\n## \n\n1. **** HNSW, IVFANN\n2. ****\n3. ****` > 2023`\n4. ****\n5. **** AI  LangChain, LlamaIndex\n\n\n\n1. ****\n2. ****HNSWLSHPQ\n3. ****\n4. ****\n\n\n\n- **** Annoy \n- **** LSH\n- **** HNSW\n- **** Faiss  IVF  PQ\n\n## Milvus\n\nhttps://datawhalechina.github.io/all-in-rag/#/chapter3/09_milvus\n\n## \n\n### \n\nRAGLLMLlamaIndex **Sentence Window Retrieval**]LLM\n\n****\n\n### \n\n**Metadata**\n\n- \n- \n- \n- \n- \n\n1. ****\n   - ****Excel1994`Document`1994\n   - ****`Document` `{\"sheet_name\": \"_1994\"}`\n2. ****\n   - ****199419941994 `_1994` \n   - **** `_1994` ****`MetadataFilter` `sheet_name == \"_1994\"` LLM\n\nLlamaIndex [4](https://datawhalechina.github.io/all-in-rag/#fn-4)\n\n## \n\nHybrid Search **Sparse Vectors**  **Dense Vectors** \n\n### (Reciprocal Rank Fusion, RRF)\n\nRRF ****\n\n### \n\n 0-1  `` \n\n `` \n\n## \n\n### \n\nChunksMetadata\n\n**Self-Query Retriever** LangChain\n\n1. ****LLM\n\n2. \n\n   LLM\n\n   - **Query String**\n   - **Metadata Filter**\n\n3. ****\n\n### Cypher\n\nCypher  Neo4j SQL \n\nCypherLLM Cypher LangChain  `GraphCypherQAChain`\n\n1. \n2. LLM Schema Cypher \n3. \n4. () LLM\n\n## Text2SQL\n\n- ****LLM SQL\n- ****LLM  `JOIN`  `WHERE` \n- ****\n\n1. ****LLM `CREATE TABLE` LLM\n2. ****Prompt-SQLLLMLLM\n3. **RAG**RAGFlowDDL\n   - ****\n   - **** `cost` \n   - **** `JOIN``GROUP BY`  Q&ALLMSQL\n4. ** (Error Correction and Reflection)**SQLLLMSQL\n\n## \n\n1. **Query Translation**\n2. **Query Routing**\n\n### \n\n****\n\n- \n\nPrompt LLM \n\n LLM  JSON \n\n- Multi-query\n\n LLM \n\nLangChain  `MultiQueryRetriever`  LLM \n\n- Step-Back Prompting\n\n\n\n\n\n1. **** LLM Step-back Question\n2. ****\n\n![](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_1.webp)\n\n\n\n- HyDE\n\nHypothetical Document Embeddings, HyDE Luyu Gao QueryZilliz [4](https://datawhalechina.github.io/all-in-rag/#fn-4)\n\n![HyDE](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_2.webp)\n\nHyDE LLMHyDE \n\nHyDE \n\n1. **** LLMGPT-3.5\n2. **** Contriever\n3. ****\n\nHyDE \n\n### \n\n**Query Routing**  RAG \n\n\n\n1. ****\n   -  iPhone  -> ****\n   -  -> **SQL**Text-to-SQL\n   - AB -> ****\n2. ****\n   - FAQ  \n   - API   Agent \n3. ****\n   -   Step-by-Step\n   -   \n\n- LLM\n\nLLM\n\n![](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_3.webp)\n\n1. \n2. LLM \n3. \n\n- \n\n LLM \n\n![](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_4.webp)\n\n## \n\n![retrieval](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_1.webp)\n\n### Re-ranking\n\n- RRFReciprocal Rank Fusion\n\n********\n\nRRF \n\n- RankLLM/LLM-based Reranker\n\n![rankllm](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_2.webp)\n\nRankLLM  LLM \n\n LLM  JSON\n\n- Cross-Encoder\n\nCross-EncoderQueryDocument****`[CLS] query [SEP] document [SEP]` Transformer  BERT 0  1 ****\n\n![cross-encoder](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_3.svg)\n\n1. **** 50 \n2. ************ Cross-Encoder \n3. ****-\n4. ****\n\nN\n\n- ColBERT\n\nColBERTContextualized Late Interaction over BERT Cross-Encoder Bi-Encoder****\n\n\n\n1. ****ColBERT QueryDocument Token \n2. **** Token  Token MaxSim\n3. **** Token \n\nColBERT  `[CLS]` \n\n\n\n|          | RRF                | RankLLM                | Cross-Encoder                      | ColBERT            |\n| ------------ | ------------------ | ---------------------- | ---------------------------------- | ------------------ |\n| **** |        | LLM  |  |  |\n| **** |  |  (API )    | N                  |  |\n| **** |        | /            | Query-Doc Pair           | Token            |\n| **** |    |      | Top-K                          | Top-K          |\n\n### Compression\n\nChunks LLM API \n\n\n\n1. ****\n2. ****\n\n### LangChainContextualCompressionRetriever\n\nLangChain  `ContextualCompressionRetriever`  `FAISS.as_retriever()``ContextualCompressionRetriever`  `DocumentCompressor` \n\nLangChain  `DocumentCompressor`\n\n- `LLMChainExtractor`:  LLM Chain \n- `LLMChainFilter`:  LLM\n- `EmbeddingsFilter`: \n\n### Correcting\n\n RAG  LLMHallucination\n\n**Corrective-RAG, C-RAG** \n\nC-RAG  **--** \n\n![C-RAG](https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_4.webp)\n\n1. ** (Retrieve)**  RAG \n2. ** (Assess)**  C-RAG  (Retrieval Evaluator) (Correct) (Incorrect) (Ambiguous)\n3. ** (Act)** \n   - **** (Knowledge Refinement) (strips)\n   - **** (Knowledge Searching) (Query Rewriting) Web \n   - **** Web \n\nC-RAG  RAG \n\n LangChain  `langgraph`  RAG \n\n## \n\n### \n\nLLM JSON  XML\n\n- output parsers\n\nLangChain `OutputParsers` LLM \n\n1. **** LLM Prompt\n2. **** LLM  Python \n\nLangChain \n\n- **StrOutputParser** LLM \n- **JsonOutputParser** JSON \n- **PydanticOutputParser** Pydantic \n\n### Function Calling\n\nFunction Calling  API\n\n1. **** JSON Schema\n2. ****\n3. **** `tool_calls` \n4. ******** API\n5. **** API  `role`  `tool` \n6. ****\n\n JSONFunction Calling \n\n- ****\n- ****\n- **** AI Agent LLM  API\n\n## RAG\n\n![RAG Triad](https://datawhalechina.github.io/all-in-rag/chapter6/images/6_1_1.webp)\n\n### RAG\n\n **TruLens**  \n\n1. ** (Context Relevance)**\n   - **** Retriever\n   - **** Query\n   - **** RAG\n2. ** /  (Faithfulness / Groundedness)**\n   - **** \n   - **** \n   - **** LLMLLM\n3. ** (Answer Relevance)**\n   - **** End-to-End\n   - **** \n   - **** \n\n### \n\n- \n\nRAG ** (Context Relevance)\\*** \n\n\n\n![1](/img/all-in-rag/p1.png)\n\n- \n\nRAG ****  **** **** \n\n- \n\n1. ** / :**\n   - \n2. **:**\n   - \n\n- \n\n\n\n**1. **\n\nllm\n\n- **** Claims\n- **** \n\n**2. **\n\n n-gramn\n\n![2](img/all-in-rag/p2.png)\n\nLLM********LLM\n\n### \n\n### LlamaIndex Evaluation\n\n`LlamaIndex Evaluation` **LlamaIndex**RAGRAG****RAG\n\n`LlamaIndex` LLMRAG\n\n1. **** `DatasetGenerator` -`QueryResponseDataset`\n2. ****RAG`QueryEngine`\n3. **** `FaithfulnessEvaluator` `RelevancyEvaluator`\n4. **** `BatchEvalRunner` \n5. ****RAG\n\nLlamaIndex****\n\n- `Faithfulness` (): \n- `Relevancy` (): \n\n****\n\n- `Hit Rate` (): \n- `MRR` (): \n\n### RAGAS\n\nRAGASRAG Assessment**RAG**RAG****RAGRAG`RAGAS` \n\n`RAGAS` `question``answer``context`RAG\n\n1. **** `question``answer`RAG`contexts` `ground_truth``ground_truth`  `context_recall`  `faithfulness` \n2. **** `ragas.evaluate()` \n3. ****\n\n\n\n- `faithfulness`: \n- `context_recall`: `ground_truth`\n- `context_precision`: \n- `answer_relevancy`: \n\n### Phoenix\n\nPhoenix (Arize) **LLM**RAG****LLMTracesPhoenix ****LLMTracing\n\n1. ** (`Instrumentation`)** **OpenTelemetry**RAG `Phoenix` LLM\n2. ** (`Traces`)**RAG`Phoenix` \n3. **UI** `Phoenix` Web\n4. ****UI (`Evals`) \n\n\n\n- ****: RAG\n- ****: \n- ** (`Guardrails`)**: \n- ****: \n- **Arize**: `Phoenix` ArizeRAG\n\n## RAG\n\n![GraphRAG](https://datawhalechina.github.io/all-in-rag/chapter7/images/7_1_1.svg)\n\n RAG \"-\"LLM\n\n****LLM\n\n****RAG\n\n****LLM\"\"\n\n**** RAG \n\n****/\n\n****//\n\n****\n\nRAG\n\n****\"A--B\"LLM\n\n****\n\n****\n\n****\n\n\n\n- ****SchemaOntology\n- ****\n- ****Time-travel Query\n\n### GraphRAG\n\n****  GraphRAG \n\n-  LLM  IE /Normalization\n- \n- Entity Resolution/\n- Neo4j/NebulaGraph/TigerGraph/Neptune\n\n**** \n\n- Entity Linking\n- Cypher\n- \n- GraphRAGLeiden-\n\n GraphRAG  RAG \n\n****  Cypher/Gremlin\n\n**** /\n\n**** \n\n- /\n- \n\nGraphRAG\n\n- GraphRAGMicrosoft\n\n- LightRAG\n- FRAGFlexible RAG\n\n- GraphIRAG (Iterative Knowledge Retrieval)\n\n### \n\nGraphRAG \n\n****\n\n- PrecisionRecallF1Hit Rate@K\n- RAG\n  - Context Precision= \n  - Context Recall= \n  - /Citation/Attribution= \n\n****\n\n- EMF1\n- ROUGE\n- /Faithfulness+\n\n****\n\nLatencyThroughputQPSCostAPIGPU/CPU\n\nGraphRAG\n\n**** GraphRAG HotpotQA2WikiMultihopQA  MuSiQue\n\n****  WebQSP  ComplexWebQuestions (CWQ)\n\n**QA**  KGQAgen-10k\n","slug":"all-in-rag","published":1,"updated":"2025-11-25T09:09:40.134Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff8000iss9919yb0krb","content":"<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1.svg\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"\"></p>\n<p></p>\n<ol>\n<li><strong>Indexing</strong> PDF&#x2F;Word</li>\n<li><strong>Retrieval</strong> Context</li>\n<li><strong>Generation</strong> LLM</li>\n</ol>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1_2.webp\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1_2.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"\"></p>\n<table>\n<thead>\n<tr>\n<th><strong></strong></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Hallucination</strong></td>\n<td></td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td>&#x2F;</td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td></td>\n</tr>\n</tbody></table>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><table>\n<thead>\n<tr>\n<th><strong>PyMuPDF4LLM</strong></th>\n<th>PDFMarkdownOCR+</th>\n<th></th>\n<th>GPU</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>TextLoader</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>DirectoryLoader</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Unstructured</strong></td>\n<td></td>\n<td>PDFWordHTML</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>FireCrawlLoader</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>LlamaParse</strong></td>\n<td>PDF</td>\n<td></td>\n<td>API</td>\n</tr>\n<tr>\n<td><strong>Docling</strong></td>\n<td></td>\n<td></td>\n<td>IBM</td>\n</tr>\n<tr>\n<td><strong>Marker</strong></td>\n<td>PDFMarkdownGPU</td>\n<td></td>\n<td>PDF</td>\n</tr>\n<tr>\n<td><strong>MinerU</strong></td>\n<td></td>\n<td></td>\n<td>LayoutLMv3+YOLOv8</td>\n</tr>\n</tbody></table>\n<h3 id=\"Unstructured\"><a href=\"#Unstructured\" class=\"headerlink\" title=\"Unstructured\"></a>Unstructured</h3><ul>\n<li>PDFWordExcelHTMLMarkdown</li>\n<li>API</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Transformer </p>\n<ol>\n<li><strong> (Tokenization)</strong>:  token</li>\n<li><strong> (Vectorization)</strong>: Transformer <strong> token</strong> </li>\n<li><strong> (Pooling)</strong>: <code>[CLS]</code><a href=\"https://datawhalechina.github.io/all-in-rag/#fn-1\">1</a>token<code>mean pooling</code> token <strong></strong><strong></strong></li>\n</ol>\n<p><code></code>768<strong></strong></p>\n<ul>\n<li>CharacterTextSplitter</li>\n</ul>\n<ol>\n<li><strong></strong><code>CharacterTextSplitter</code>  <code>&quot;\\n\\n&quot;</code> <code>_split_text_with_regex</code> </li>\n<li><strong></strong> <code>_merge_splits</code>  <code>chunk_size</code> <code>chunk_overlap</code></li>\n</ol>\n<p></p>\n<ul>\n<li>RecursiveCharacterTextSplitter</li>\n</ul>\n<ol>\n<li><p><strong></strong>: <strong></strong> <code>&quot;&quot;</code></p>\n</li>\n<li><p></p>\n<p>: </p>\n<ul>\n<li><p><strong></strong>:  <code>_good_splits</code> </p>\n</li>\n<li><p></p>\n<p>:</p>\n<ul>\n<li> <code>_merge_splits</code> </li>\n<li><ul>\n<li><strong></strong>:  <code>_split_text</code> </li>\n<li><strong></strong>: </li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong></strong>: </p>\n</li>\n</ol>\n<ul>\n<li>SemanticChunker</li>\n</ul>\n<ol>\n<li><strong> (Sentence Splitting)</strong>: </li>\n<li><strong> (Context-Aware Embedding)</strong>:  <code>SemanticChunker</code>  <code>buffer_size</code> 1 <code>buffer_size</code> </li>\n<li><strong> (Distance Calculation)</strong>: <strong></strong></li>\n<li><strong> (Breakpoint Identification)</strong>: <code>SemanticChunker</code>  <code>percentile</code>95</li>\n<li><strong> (Merging into Chunks)</strong>: </li>\n</ol>\n<p><strong> (<code>breakpoint_threshold_type</code>)</strong></p>\n<p><code>SemanticChunker</code> </p>\n<ul>\n<li><code>percentile</code> ( - <strong></strong>):<ul>\n<li><strong></strong>: </li>\n<li><strong></strong>: <code>breakpoint_threshold_amount</code> ( <code>95</code>)955%</li>\n</ul>\n</li>\n<li><code>standard_deviation</code> ():<ul>\n<li><strong></strong>:  + N * </li>\n<li><strong></strong>: <code>breakpoint_threshold_amount</code> ( <code>3</code>)3</li>\n</ul>\n</li>\n<li><code>interquartile</code> ():<ul>\n<li><strong></strong>: IQR <code>Q3 + N * IQR</code> </li>\n<li><strong></strong>: <code>breakpoint_threshold_amount</code> ( <code>1.5</code>)1.5IQR</li>\n</ul>\n</li>\n<li><code>gradient</code> ():<ul>\n<li><strong></strong>: </li>\n<li><strong></strong>: <code>breakpoint_threshold_amount</code> ( <code>95</code>)</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://huggingface.co/spaces/mteb/leaderboard\"><strong>MTEB (Massive Text Embedding Benchmark)</strong></a>  Hugging Face </p>\n<p></p>\n<ol>\n<li><strong> (Task)</strong>  RAG  <code>Retrieval</code> () </li>\n<li><strong> (Language)</strong>  RAG</li>\n<li><strong> (Size)</strong> </li>\n<li><strong> (Dimensions)</strong> </li>\n<li><strong> Token  (Max Tokens)</strong> Chunking</li>\n<li><strong> (Score &amp; Publisher)</strong> </li>\n<li><strong> (Cost)</strong>  API </li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li><strong></strong> HNSW, IVFANN</li>\n<li><strong></strong></li>\n<li><strong></strong><code> &gt; 2023</code></li>\n<li><strong></strong></li>\n<li><strong></strong> AI  LangChain, LlamaIndex</li>\n</ol>\n<p></p>\n<ol>\n<li><strong></strong></li>\n<li><strong></strong>HNSWLSHPQ</li>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ol>\n<p></p>\n<ul>\n<li><strong></strong> Annoy </li>\n<li><strong></strong> LSH</li>\n<li><strong></strong> HNSW</li>\n<li><strong></strong> Faiss  IVF  PQ</li>\n</ul>\n<h2 id=\"Milvus\"><a href=\"#Milvus\" class=\"headerlink\" title=\"Milvus\"></a>Milvus</h2><p><a href=\"https://datawhalechina.github.io/all-in-rag/#/chapter3/09_milvus\">https://datawhalechina.github.io/all-in-rag/#/chapter3/09_milvus</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>RAGLLMLlamaIndex <strong>Sentence Window Retrieval</strong>]LLM</p>\n<p><strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Metadata</strong></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<ol>\n<li><strong></strong><ul>\n<li><strong></strong>Excel1994<code>Document</code>1994</li>\n<li><strong></strong><code>Document</code> <code>&#123;&quot;sheet_name&quot;: &quot;_1994&quot;&#125;</code></li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li><strong></strong>199419941994 <code>_1994</code> </li>\n<li><strong></strong> <code>_1994</code> <strong></strong><code>MetadataFilter</code> <code>sheet_name == &quot;_1994&quot;</code> LLM</li>\n</ul>\n</li>\n</ol>\n<p>LlamaIndex <a href=\"https://datawhalechina.github.io/all-in-rag/#fn-4\">4</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Hybrid Search <strong>Sparse Vectors</strong>  <strong>Dense Vectors</strong> </p>\n<p>### (Reciprocal Rank Fusion, RRF)</p>\n<p>RRF <strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 0-1  <code></code> </p>\n<p> <code></code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>ChunksMetadata</p>\n<p><strong>Self-Query Retriever</strong> LangChain</p>\n<ol>\n<li><p><strong></strong>LLM</p>\n</li>\n<li><p></p>\n<p>LLM</p>\n<ul>\n<li><strong>Query String</strong></li>\n<li><strong>Metadata Filter</strong></li>\n</ul>\n</li>\n<li><p><strong></strong></p>\n</li>\n</ol>\n<h3 id=\"Cypher\"><a href=\"#Cypher\" class=\"headerlink\" title=\"Cypher\"></a>Cypher</h3><p>Cypher  Neo4j SQL </p>\n<p>CypherLLM Cypher LangChain  <code>GraphCypherQAChain</code></p>\n<ol>\n<li></li>\n<li>LLM Schema Cypher </li>\n<li></li>\n<li>() LLM</li>\n</ol>\n<h2 id=\"Text2SQL\"><a href=\"#Text2SQL\" class=\"headerlink\" title=\"Text2SQL\"></a>Text2SQL</h2><ul>\n<li><strong></strong>LLM SQL</li>\n<li><strong></strong>LLM  <code>JOIN</code>  <code>WHERE</code> </li>\n<li><strong></strong></li>\n</ul>\n<ol>\n<li><strong></strong>LLM <code>CREATE TABLE</code> LLM</li>\n<li><strong></strong>Prompt-SQLLLMLLM</li>\n<li><strong>RAG</strong>RAGFlowDDL<ul>\n<li><strong></strong></li>\n<li><strong></strong> <code>cost</code> </li>\n<li><strong></strong> <code>JOIN</code><code>GROUP BY</code>  Q&amp;ALLMSQL</li>\n</ul>\n</li>\n<li>** (Error Correction and Reflection)**SQLLLMSQL</li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li><strong>Query Translation</strong></li>\n<li><strong>Query Routing</strong></li>\n</ol>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<p>Prompt LLM </p>\n<p> LLM  JSON </p>\n<ul>\n<li>Multi-query</li>\n</ul>\n<p> LLM </p>\n<p>LangChain  <code>MultiQueryRetriever</code>  LLM </p>\n<ul>\n<li>Step-Back Prompting</li>\n</ul>\n<p></p>\n<p></p>\n<ol>\n<li><strong></strong> LLM Step-back Question</li>\n<li><strong></strong></li>\n</ol>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_1.webp\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_1.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"\"></p>\n<p></p>\n<ul>\n<li>HyDE</li>\n</ul>\n<p>Hypothetical Document Embeddings, HyDE Luyu Gao QueryZilliz <a href=\"https://datawhalechina.github.io/all-in-rag/#fn-4\">4</a></p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_2.webp\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_2.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"HyDE\"></p>\n<p>HyDE LLMHyDE </p>\n<p>HyDE </p>\n<ol>\n<li><strong></strong> LLMGPT-3.5</li>\n<li><strong></strong> Contriever</li>\n<li><strong></strong></li>\n</ol>\n<p>HyDE </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Query Routing</strong>  RAG </p>\n<p></p>\n<ol>\n<li><strong></strong><ul>\n<li> iPhone  -&gt; <strong></strong></li>\n<li> -&gt; <strong>SQL</strong>Text-to-SQL</li>\n<li>AB -&gt; <strong></strong></li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li>FAQ  </li>\n<li>API   Agent </li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li>  Step-by-Step</li>\n<li>  </li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>LLM</li>\n</ul>\n<p>LLM</p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_3.webp\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_3.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"\"></p>\n<ol>\n<li></li>\n<li>LLM </li>\n<li></li>\n</ol>\n<ul>\n<li></li>\n</ul>\n<p> LLM </p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_4.webp\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_4.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_1.webp\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_1.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"retrieval\"></p>\n<h3 id=\"Re-ranking\"><a href=\"#Re-ranking\" class=\"headerlink\" title=\"Re-ranking\"></a>Re-ranking</h3><ul>\n<li>RRFReciprocal Rank Fusion</li>\n</ul>\n<p><strong></strong><strong></strong></p>\n<p>RRF </p>\n<ul>\n<li>RankLLM&#x2F;LLM-based Reranker</li>\n</ul>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_2.webp\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_2.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"rankllm\"></p>\n<p>RankLLM  LLM </p>\n<p> LLM  JSON</p>\n<ul>\n<li>Cross-Encoder</li>\n</ul>\n<p>Cross-EncoderQueryDocument<strong></strong><code>[CLS] query [SEP] document [SEP]</code> Transformer  BERT 0  1 <strong></strong></p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_3.svg\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_3.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"cross-encoder\"></p>\n<ol>\n<li><strong></strong> 50 </li>\n<li><strong></strong><strong></strong><strong></strong> Cross-Encoder </li>\n<li><strong></strong>-</li>\n<li><strong></strong></li>\n</ol>\n<p>N</p>\n<ul>\n<li>ColBERT</li>\n</ul>\n<p>ColBERTContextualized Late Interaction over BERT Cross-Encoder Bi-Encoder<strong></strong></p>\n<p></p>\n<ol>\n<li><strong></strong>ColBERT QueryDocument Token </li>\n<li><strong></strong> Token  Token MaxSim</li>\n<li><strong></strong> Token </li>\n</ol>\n<p>ColBERT  <code>[CLS]</code> </p>\n<p></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>RRF</th>\n<th>RankLLM</th>\n<th>Cross-Encoder</th>\n<th>ColBERT</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong></strong></td>\n<td></td>\n<td>LLM </td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td></td>\n<td> (API )</td>\n<td>N</td>\n<td></td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td></td>\n<td>&#x2F;</td>\n<td>Query-Doc Pair</td>\n<td>Token </td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td></td>\n<td></td>\n<td>Top-K </td>\n<td>Top-K </td>\n</tr>\n</tbody></table>\n<h3 id=\"Compression\"><a href=\"#Compression\" class=\"headerlink\" title=\"Compression\"></a>Compression</h3><p>Chunks LLM API </p>\n<p></p>\n<ol>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ol>\n<h3 id=\"LangChainContextualCompressionRetriever\"><a href=\"#LangChainContextualCompressionRetriever\" class=\"headerlink\" title=\"LangChainContextualCompressionRetriever\"></a>LangChainContextualCompressionRetriever</h3><p>LangChain  <code>ContextualCompressionRetriever</code>  <code>FAISS.as_retriever()</code><code>ContextualCompressionRetriever</code>  <code>DocumentCompressor</code> </p>\n<p>LangChain  <code>DocumentCompressor</code></p>\n<ul>\n<li><code>LLMChainExtractor</code>:  LLM Chain </li>\n<li><code>LLMChainFilter</code>:  LLM</li>\n<li><code>EmbeddingsFilter</code>: </li>\n</ul>\n<h3 id=\"Correcting\"><a href=\"#Correcting\" class=\"headerlink\" title=\"Correcting\"></a>Correcting</h3><p> RAG  LLMHallucination</p>\n<p><strong>Corrective-RAG, C-RAG</strong> </p>\n<p>C-RAG  <strong>--</strong> </p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_4.webp\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_4.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"C-RAG\"></p>\n<ol>\n<li><strong> (Retrieve)</strong>  RAG </li>\n<li><strong> (Assess)</strong>  C-RAG  (Retrieval Evaluator) (Correct) (Incorrect) (Ambiguous)</li>\n<li><strong> (Act)</strong> <ul>\n<li><strong></strong> (Knowledge Refinement) (strips)</li>\n<li><strong></strong> (Knowledge Searching) (Query Rewriting) Web </li>\n<li><strong></strong> Web </li>\n</ul>\n</li>\n</ol>\n<p>C-RAG  RAG </p>\n<p> LangChain  <code>langgraph</code>  RAG </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>LLM JSON  XML</p>\n<ul>\n<li>output parsers</li>\n</ul>\n<p>LangChain <code>OutputParsers</code> LLM </p>\n<ol>\n<li><strong></strong> LLM Prompt</li>\n<li><strong></strong> LLM  Python </li>\n</ol>\n<p>LangChain </p>\n<ul>\n<li><strong>StrOutputParser</strong> LLM </li>\n<li><strong>JsonOutputParser</strong> JSON </li>\n<li><strong>PydanticOutputParser</strong> Pydantic </li>\n</ul>\n<h3 id=\"Function-Calling\"><a href=\"#Function-Calling\" class=\"headerlink\" title=\"Function Calling\"></a>Function Calling</h3><p>Function Calling  API</p>\n<ol>\n<li><strong></strong> JSON Schema</li>\n<li><strong></strong></li>\n<li><strong></strong> <code>tool_calls</code> </li>\n<li><strong></strong><strong></strong> API</li>\n<li><strong></strong> API  <code>role</code>  <code>tool</code> </li>\n<li><strong></strong></li>\n</ol>\n<p> JSONFunction Calling </p>\n<ul>\n<li><strong></strong></li>\n<li><strong></strong></li>\n<li><strong></strong> AI Agent LLM  API</li>\n</ul>\n<h2 id=\"RAG\"><a href=\"#RAG\" class=\"headerlink\" title=\"RAG\"></a>RAG</h2><p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter6/images/6_1_1.webp\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter6/images/6_1_1.webp\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"RAG Triad\"></p>\n<h3 id=\"RAG\"><a href=\"#RAG\" class=\"headerlink\" title=\"RAG\"></a>RAG</h3><p> <strong>TruLens</strong>  </p>\n<ol>\n<li><strong> (Context Relevance)</strong><ul>\n<li><strong></strong> Retriever</li>\n<li><strong></strong> Query</li>\n<li><strong></strong> RAG</li>\n</ul>\n</li>\n<li><strong> &#x2F;  (Faithfulness &#x2F; Groundedness)</strong><ul>\n<li><strong></strong> </li>\n<li><strong></strong> </li>\n<li><strong></strong> LLMLLM</li>\n</ul>\n</li>\n<li><strong> (Answer Relevance)</strong><ul>\n<li><strong></strong> End-to-End</li>\n<li><strong></strong> </li>\n<li><strong></strong> </li>\n</ul>\n</li>\n</ol>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n</ul>\n<p>RAG <strong> (Context Relevance)*</strong> </p>\n<p></p>\n<p><img src=\"/img/all-in-rag/p1.png\" class=\"lazyload placeholder\" data-srcset=\"/img/all-in-rag/p1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"1\"></p>\n<ul>\n<li></li>\n</ul>\n<p>RAG <strong></strong>  <strong></strong> <strong></strong> </p>\n<ul>\n<li></li>\n</ul>\n<ol>\n<li><strong> &#x2F; :</strong><ul>\n<li></li>\n</ul>\n</li>\n<li><strong>:</strong><ul>\n<li></li>\n</ul>\n</li>\n</ol>\n<ul>\n<li></li>\n</ul>\n<p></p>\n<p><strong>1. </strong></p>\n<p>llm</p>\n<ul>\n<li><strong></strong> Claims</li>\n<li><strong></strong> </li>\n</ul>\n<p><strong>2. </strong></p>\n<p> n-gramn</p>\n<p><img src=\"/img/all-in-rag/p2.png\" class=\"lazyload placeholder\" data-srcset=\"/img/all-in-rag/p2.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"2\"></p>\n<p>LLM<strong></strong><strong></strong>LLM</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"LlamaIndex-Evaluation\"><a href=\"#LlamaIndex-Evaluation\" class=\"headerlink\" title=\"LlamaIndex Evaluation\"></a>LlamaIndex Evaluation</h3><p><code>LlamaIndex Evaluation</code> <strong>LlamaIndex</strong>RAGRAG<strong></strong>RAG</p>\n<p><code>LlamaIndex</code> LLMRAG</p>\n<ol>\n<li><strong></strong> <code>DatasetGenerator</code> -<code>QueryResponseDataset</code></li>\n<li><strong></strong>RAG<code>QueryEngine</code></li>\n<li><strong></strong> <code>FaithfulnessEvaluator</code> <code>RelevancyEvaluator</code></li>\n<li><strong></strong> <code>BatchEvalRunner</code> </li>\n<li><strong></strong>RAG</li>\n</ol>\n<p>LlamaIndex<strong></strong></p>\n<ul>\n<li><code>Faithfulness</code> (): </li>\n<li><code>Relevancy</code> (): </li>\n</ul>\n<p><strong></strong></p>\n<ul>\n<li><code>Hit Rate</code> (): </li>\n<li><code>MRR</code> (): </li>\n</ul>\n<h3 id=\"RAGAS\"><a href=\"#RAGAS\" class=\"headerlink\" title=\"RAGAS\"></a>RAGAS</h3><p>RAGASRAG Assessment<strong>RAG</strong>RAG<strong></strong>RAGRAG<code>RAGAS</code> </p>\n<p><code>RAGAS</code> <code>question</code><code>answer</code><code>context</code>RAG</p>\n<ol>\n<li><strong></strong> <code>question</code><code>answer</code>RAG<code>contexts</code> <code>ground_truth</code><code>ground_truth</code>  <code>context_recall</code>  <code>faithfulness</code> </li>\n<li><strong></strong> <code>ragas.evaluate()</code> </li>\n<li><strong></strong></li>\n</ol>\n<p></p>\n<ul>\n<li><code>faithfulness</code>: </li>\n<li><code>context_recall</code>: <code>ground_truth</code></li>\n<li><code>context_precision</code>: </li>\n<li><code>answer_relevancy</code>: </li>\n</ul>\n<h3 id=\"Phoenix\"><a href=\"#Phoenix\" class=\"headerlink\" title=\"Phoenix\"></a>Phoenix</h3><p>Phoenix (Arize) <strong>LLM</strong>RAG<strong></strong>LLMTracesPhoenix <strong></strong>LLMTracing</p>\n<ol>\n<li>** (<code>Instrumentation</code>)** <strong>OpenTelemetry</strong>RAG <code>Phoenix</code> LLM</li>\n<li>** (<code>Traces</code>)**RAG<code>Phoenix</code> </li>\n<li><strong>UI</strong> <code>Phoenix</code> Web</li>\n<li><strong></strong>UI (<code>Evals</code>) </li>\n</ol>\n<p></p>\n<ul>\n<li><strong></strong>: RAG</li>\n<li><strong></strong>: </li>\n<li><strong> (<code>Guardrails</code>)</strong>: </li>\n<li><strong></strong>: </li>\n<li><strong>Arize</strong>: <code>Phoenix</code> ArizeRAG</li>\n</ul>\n<h2 id=\"RAG\"><a href=\"#RAG\" class=\"headerlink\" title=\"RAG\"></a>RAG</h2><p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter7/images/7_1_1.svg\" class=\"lazyload placeholder\" data-srcset=\"https://datawhalechina.github.io/all-in-rag/chapter7/images/7_1_1.svg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"GraphRAG\"></p>\n<p> RAG -LLM</p>\n<p><strong></strong>LLM</p>\n<p><strong></strong>RAG</p>\n<p><strong></strong>LLM</p>\n<p><strong></strong> RAG </p>\n<p><strong></strong>&#x2F;</p>\n<p><strong></strong>&#x2F;&#x2F;</p>\n<p><strong></strong></p>\n<p>RAG</p>\n<p><strong></strong>A--BLLM</p>\n<p><strong></strong></p>\n<p><strong></strong></p>\n<p><strong></strong></p>\n<p></p>\n<ul>\n<li><strong></strong>SchemaOntology</li>\n<li><strong></strong></li>\n<li><strong></strong>Time-travel Query</li>\n</ul>\n<h3 id=\"GraphRAG\"><a href=\"#GraphRAG\" class=\"headerlink\" title=\"GraphRAG\"></a>GraphRAG</h3><p><strong></strong>  GraphRAG </p>\n<ul>\n<li> LLM  IE &#x2F;Normalization</li>\n<li></li>\n<li>Entity Resolution&#x2F;</li>\n<li>Neo4j&#x2F;NebulaGraph&#x2F;TigerGraph&#x2F;Neptune</li>\n</ul>\n<p><strong></strong> </p>\n<ul>\n<li>Entity Linking</li>\n<li>Cypher</li>\n<li></li>\n<li>GraphRAGLeiden-</li>\n</ul>\n<p> GraphRAG  RAG </p>\n<p><strong></strong>  Cypher&#x2F;Gremlin</p>\n<p><strong></strong> &#x2F;</p>\n<p><strong></strong> </p>\n<ul>\n<li>&#x2F;</li>\n<li></li>\n</ul>\n<p>GraphRAG</p>\n<ul>\n<li><p>GraphRAGMicrosoft</p>\n</li>\n<li><p>LightRAG</p>\n</li>\n<li><p>FRAGFlexible RAG</p>\n</li>\n<li><p>GraphIRAG (Iterative Knowledge Retrieval)</p>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>GraphRAG </p>\n<p><strong></strong></p>\n<ul>\n<li>PrecisionRecallF1Hit Rate@K</li>\n<li>RAG<ul>\n<li>Context Precision&#x3D; </li>\n<li>Context Recall&#x3D; </li>\n<li>&#x2F;Citation&#x2F;Attribution&#x3D; </li>\n</ul>\n</li>\n</ul>\n<p><strong></strong></p>\n<ul>\n<li>EMF1</li>\n<li>ROUGE</li>\n<li>&#x2F;Faithfulness+</li>\n</ul>\n<p><strong></strong></p>\n<p>LatencyThroughputQPSCostAPIGPU&#x2F;CPU</p>\n<p>GraphRAG</p>\n<p><strong></strong> GraphRAG HotpotQA2WikiMultihopQA  MuSiQue</p>\n<p><strong></strong>  WebQSP  ComplexWebQuestions (CWQ)</p>\n<p><strong>QA</strong>  KGQAgen-10k</p>\n","more":"<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1.svg\" alt=\"\"></p>\n<p></p>\n<ol>\n<li><strong>Indexing</strong> PDF&#x2F;Word</li>\n<li><strong>Retrieval</strong> Context</li>\n<li><strong>Generation</strong> LLM</li>\n</ol>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter1/images/1_1_2.webp\" alt=\"\"></p>\n<table>\n<thead>\n<tr>\n<th><strong></strong></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Hallucination</strong></td>\n<td></td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td>&#x2F;</td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td></td>\n</tr>\n</tbody></table>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><table>\n<thead>\n<tr>\n<th><strong>PyMuPDF4LLM</strong></th>\n<th>PDFMarkdownOCR+</th>\n<th></th>\n<th>GPU</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>TextLoader</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>DirectoryLoader</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Unstructured</strong></td>\n<td></td>\n<td>PDFWordHTML</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>FireCrawlLoader</strong></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong>LlamaParse</strong></td>\n<td>PDF</td>\n<td></td>\n<td>API</td>\n</tr>\n<tr>\n<td><strong>Docling</strong></td>\n<td></td>\n<td></td>\n<td>IBM</td>\n</tr>\n<tr>\n<td><strong>Marker</strong></td>\n<td>PDFMarkdownGPU</td>\n<td></td>\n<td>PDF</td>\n</tr>\n<tr>\n<td><strong>MinerU</strong></td>\n<td></td>\n<td></td>\n<td>LayoutLMv3+YOLOv8</td>\n</tr>\n</tbody></table>\n<h3 id=\"Unstructured\"><a href=\"#Unstructured\" class=\"headerlink\" title=\"Unstructured\"></a>Unstructured</h3><ul>\n<li>PDFWordExcelHTMLMarkdown</li>\n<li>API</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Transformer </p>\n<ol>\n<li><strong> (Tokenization)</strong>:  token</li>\n<li><strong> (Vectorization)</strong>: Transformer <strong> token</strong> </li>\n<li><strong> (Pooling)</strong>: <code>[CLS]</code><a href=\"https://datawhalechina.github.io/all-in-rag/#fn-1\">1</a>token<code>mean pooling</code> token <strong></strong><strong></strong></li>\n</ol>\n<p><code></code>768<strong></strong></p>\n<ul>\n<li>CharacterTextSplitter</li>\n</ul>\n<ol>\n<li><strong></strong><code>CharacterTextSplitter</code>  <code>&quot;\\n\\n&quot;</code> <code>_split_text_with_regex</code> </li>\n<li><strong></strong> <code>_merge_splits</code>  <code>chunk_size</code> <code>chunk_overlap</code></li>\n</ol>\n<p></p>\n<ul>\n<li>RecursiveCharacterTextSplitter</li>\n</ul>\n<ol>\n<li><p><strong></strong>: <strong></strong> <code>&quot;&quot;</code></p>\n</li>\n<li><p></p>\n<p>: </p>\n<ul>\n<li><p><strong></strong>:  <code>_good_splits</code> </p>\n</li>\n<li><p></p>\n<p>:</p>\n<ul>\n<li> <code>_merge_splits</code> </li>\n<li><ul>\n<li><strong></strong>:  <code>_split_text</code> </li>\n<li><strong></strong>: </li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong></strong>: </p>\n</li>\n</ol>\n<ul>\n<li>SemanticChunker</li>\n</ul>\n<ol>\n<li><strong> (Sentence Splitting)</strong>: </li>\n<li><strong> (Context-Aware Embedding)</strong>:  <code>SemanticChunker</code>  <code>buffer_size</code> 1 <code>buffer_size</code> </li>\n<li><strong> (Distance Calculation)</strong>: <strong></strong></li>\n<li><strong> (Breakpoint Identification)</strong>: <code>SemanticChunker</code>  <code>percentile</code>95</li>\n<li><strong> (Merging into Chunks)</strong>: </li>\n</ol>\n<p><strong> (<code>breakpoint_threshold_type</code>)</strong></p>\n<p><code>SemanticChunker</code> </p>\n<ul>\n<li><code>percentile</code> ( - <strong></strong>):<ul>\n<li><strong></strong>: </li>\n<li><strong></strong>: <code>breakpoint_threshold_amount</code> ( <code>95</code>)955%</li>\n</ul>\n</li>\n<li><code>standard_deviation</code> ():<ul>\n<li><strong></strong>:  + N * </li>\n<li><strong></strong>: <code>breakpoint_threshold_amount</code> ( <code>3</code>)3</li>\n</ul>\n</li>\n<li><code>interquartile</code> ():<ul>\n<li><strong></strong>: IQR <code>Q3 + N * IQR</code> </li>\n<li><strong></strong>: <code>breakpoint_threshold_amount</code> ( <code>1.5</code>)1.5IQR</li>\n</ul>\n</li>\n<li><code>gradient</code> ():<ul>\n<li><strong></strong>: </li>\n<li><strong></strong>: <code>breakpoint_threshold_amount</code> ( <code>95</code>)</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://huggingface.co/spaces/mteb/leaderboard\"><strong>MTEB (Massive Text Embedding Benchmark)</strong></a>  Hugging Face </p>\n<p></p>\n<ol>\n<li><strong> (Task)</strong>  RAG  <code>Retrieval</code> () </li>\n<li><strong> (Language)</strong>  RAG</li>\n<li><strong> (Size)</strong> </li>\n<li><strong> (Dimensions)</strong> </li>\n<li><strong> Token  (Max Tokens)</strong> Chunking</li>\n<li><strong> (Score &amp; Publisher)</strong> </li>\n<li><strong> (Cost)</strong>  API </li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li><strong></strong> HNSW, IVFANN</li>\n<li><strong></strong></li>\n<li><strong></strong><code> &gt; 2023</code></li>\n<li><strong></strong></li>\n<li><strong></strong> AI  LangChain, LlamaIndex</li>\n</ol>\n<p></p>\n<ol>\n<li><strong></strong></li>\n<li><strong></strong>HNSWLSHPQ</li>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ol>\n<p></p>\n<ul>\n<li><strong></strong> Annoy </li>\n<li><strong></strong> LSH</li>\n<li><strong></strong> HNSW</li>\n<li><strong></strong> Faiss  IVF  PQ</li>\n</ul>\n<h2 id=\"Milvus\"><a href=\"#Milvus\" class=\"headerlink\" title=\"Milvus\"></a>Milvus</h2><p><a href=\"https://datawhalechina.github.io/all-in-rag/#/chapter3/09_milvus\">https://datawhalechina.github.io/all-in-rag/#/chapter3/09_milvus</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>RAGLLMLlamaIndex <strong>Sentence Window Retrieval</strong>]LLM</p>\n<p><strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Metadata</strong></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<ol>\n<li><strong></strong><ul>\n<li><strong></strong>Excel1994<code>Document</code>1994</li>\n<li><strong></strong><code>Document</code> <code>&#123;&quot;sheet_name&quot;: &quot;_1994&quot;&#125;</code></li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li><strong></strong>199419941994 <code>_1994</code> </li>\n<li><strong></strong> <code>_1994</code> <strong></strong><code>MetadataFilter</code> <code>sheet_name == &quot;_1994&quot;</code> LLM</li>\n</ul>\n</li>\n</ol>\n<p>LlamaIndex <a href=\"https://datawhalechina.github.io/all-in-rag/#fn-4\">4</a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Hybrid Search <strong>Sparse Vectors</strong>  <strong>Dense Vectors</strong> </p>\n<p>### (Reciprocal Rank Fusion, RRF)</p>\n<p>RRF <strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 0-1  <code></code> </p>\n<p> <code></code> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>ChunksMetadata</p>\n<p><strong>Self-Query Retriever</strong> LangChain</p>\n<ol>\n<li><p><strong></strong>LLM</p>\n</li>\n<li><p></p>\n<p>LLM</p>\n<ul>\n<li><strong>Query String</strong></li>\n<li><strong>Metadata Filter</strong></li>\n</ul>\n</li>\n<li><p><strong></strong></p>\n</li>\n</ol>\n<h3 id=\"Cypher\"><a href=\"#Cypher\" class=\"headerlink\" title=\"Cypher\"></a>Cypher</h3><p>Cypher  Neo4j SQL </p>\n<p>CypherLLM Cypher LangChain  <code>GraphCypherQAChain</code></p>\n<ol>\n<li></li>\n<li>LLM Schema Cypher </li>\n<li></li>\n<li>() LLM</li>\n</ol>\n<h2 id=\"Text2SQL\"><a href=\"#Text2SQL\" class=\"headerlink\" title=\"Text2SQL\"></a>Text2SQL</h2><ul>\n<li><strong></strong>LLM SQL</li>\n<li><strong></strong>LLM  <code>JOIN</code>  <code>WHERE</code> </li>\n<li><strong></strong></li>\n</ul>\n<ol>\n<li><strong></strong>LLM <code>CREATE TABLE</code> LLM</li>\n<li><strong></strong>Prompt-SQLLLMLLM</li>\n<li><strong>RAG</strong>RAGFlowDDL<ul>\n<li><strong></strong></li>\n<li><strong></strong> <code>cost</code> </li>\n<li><strong></strong> <code>JOIN</code><code>GROUP BY</code>  Q&amp;ALLMSQL</li>\n</ul>\n</li>\n<li>** (Error Correction and Reflection)**SQLLLMSQL</li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li><strong>Query Translation</strong></li>\n<li><strong>Query Routing</strong></li>\n</ol>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<p>Prompt LLM </p>\n<p> LLM  JSON </p>\n<ul>\n<li>Multi-query</li>\n</ul>\n<p> LLM </p>\n<p>LangChain  <code>MultiQueryRetriever</code>  LLM </p>\n<ul>\n<li>Step-Back Prompting</li>\n</ul>\n<p></p>\n<p></p>\n<ol>\n<li><strong></strong> LLM Step-back Question</li>\n<li><strong></strong></li>\n</ol>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_1.webp\" alt=\"\"></p>\n<p></p>\n<ul>\n<li>HyDE</li>\n</ul>\n<p>Hypothetical Document Embeddings, HyDE Luyu Gao QueryZilliz <a href=\"https://datawhalechina.github.io/all-in-rag/#fn-4\">4</a></p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_2.webp\" alt=\"HyDE\"></p>\n<p>HyDE LLMHyDE </p>\n<p>HyDE </p>\n<ol>\n<li><strong></strong> LLMGPT-3.5</li>\n<li><strong></strong> Contriever</li>\n<li><strong></strong></li>\n</ol>\n<p>HyDE </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Query Routing</strong>  RAG </p>\n<p></p>\n<ol>\n<li><strong></strong><ul>\n<li> iPhone  -&gt; <strong></strong></li>\n<li> -&gt; <strong>SQL</strong>Text-to-SQL</li>\n<li>AB -&gt; <strong></strong></li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li>FAQ  </li>\n<li>API   Agent </li>\n</ul>\n</li>\n<li><strong></strong><ul>\n<li>  Step-by-Step</li>\n<li>  </li>\n</ul>\n</li>\n</ol>\n<ul>\n<li>LLM</li>\n</ul>\n<p>LLM</p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_3.webp\" alt=\"\"></p>\n<ol>\n<li></li>\n<li>LLM </li>\n<li></li>\n</ol>\n<ul>\n<li></li>\n</ul>\n<p> LLM </p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_4_4.webp\" alt=\"\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_1.webp\" alt=\"retrieval\"></p>\n<h3 id=\"Re-ranking\"><a href=\"#Re-ranking\" class=\"headerlink\" title=\"Re-ranking\"></a>Re-ranking</h3><ul>\n<li>RRFReciprocal Rank Fusion</li>\n</ul>\n<p><strong></strong><strong></strong></p>\n<p>RRF </p>\n<ul>\n<li>RankLLM&#x2F;LLM-based Reranker</li>\n</ul>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_2.webp\" alt=\"rankllm\"></p>\n<p>RankLLM  LLM </p>\n<p> LLM  JSON</p>\n<ul>\n<li>Cross-Encoder</li>\n</ul>\n<p>Cross-EncoderQueryDocument<strong></strong><code>[CLS] query [SEP] document [SEP]</code> Transformer  BERT 0  1 <strong></strong></p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_3.svg\" alt=\"cross-encoder\"></p>\n<ol>\n<li><strong></strong> 50 </li>\n<li><strong></strong><strong></strong><strong></strong> Cross-Encoder </li>\n<li><strong></strong>-</li>\n<li><strong></strong></li>\n</ol>\n<p>N</p>\n<ul>\n<li>ColBERT</li>\n</ul>\n<p>ColBERTContextualized Late Interaction over BERT Cross-Encoder Bi-Encoder<strong></strong></p>\n<p></p>\n<ol>\n<li><strong></strong>ColBERT QueryDocument Token </li>\n<li><strong></strong> Token  Token MaxSim</li>\n<li><strong></strong> Token </li>\n</ol>\n<p>ColBERT  <code>[CLS]</code> </p>\n<p></p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>RRF</th>\n<th>RankLLM</th>\n<th>Cross-Encoder</th>\n<th>ColBERT</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong></strong></td>\n<td></td>\n<td>LLM </td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td></td>\n<td> (API )</td>\n<td>N</td>\n<td></td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td></td>\n<td>&#x2F;</td>\n<td>Query-Doc Pair</td>\n<td>Token </td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td></td>\n<td></td>\n<td>Top-K </td>\n<td>Top-K </td>\n</tr>\n</tbody></table>\n<h3 id=\"Compression\"><a href=\"#Compression\" class=\"headerlink\" title=\"Compression\"></a>Compression</h3><p>Chunks LLM API </p>\n<p></p>\n<ol>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ol>\n<h3 id=\"LangChainContextualCompressionRetriever\"><a href=\"#LangChainContextualCompressionRetriever\" class=\"headerlink\" title=\"LangChainContextualCompressionRetriever\"></a>LangChainContextualCompressionRetriever</h3><p>LangChain  <code>ContextualCompressionRetriever</code>  <code>FAISS.as_retriever()</code><code>ContextualCompressionRetriever</code>  <code>DocumentCompressor</code> </p>\n<p>LangChain  <code>DocumentCompressor</code></p>\n<ul>\n<li><code>LLMChainExtractor</code>:  LLM Chain </li>\n<li><code>LLMChainFilter</code>:  LLM</li>\n<li><code>EmbeddingsFilter</code>: </li>\n</ul>\n<h3 id=\"Correcting\"><a href=\"#Correcting\" class=\"headerlink\" title=\"Correcting\"></a>Correcting</h3><p> RAG  LLMHallucination</p>\n<p><strong>Corrective-RAG, C-RAG</strong> </p>\n<p>C-RAG  <strong>--</strong> </p>\n<p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter4/images/4_5_4.webp\" alt=\"C-RAG\"></p>\n<ol>\n<li><strong> (Retrieve)</strong>  RAG </li>\n<li><strong> (Assess)</strong>  C-RAG  (Retrieval Evaluator) (Correct) (Incorrect) (Ambiguous)</li>\n<li><strong> (Act)</strong> <ul>\n<li><strong></strong> (Knowledge Refinement) (strips)</li>\n<li><strong></strong> (Knowledge Searching) (Query Rewriting) Web </li>\n<li><strong></strong> Web </li>\n</ul>\n</li>\n</ol>\n<p>C-RAG  RAG </p>\n<p> LangChain  <code>langgraph</code>  RAG </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>LLM JSON  XML</p>\n<ul>\n<li>output parsers</li>\n</ul>\n<p>LangChain <code>OutputParsers</code> LLM </p>\n<ol>\n<li><strong></strong> LLM Prompt</li>\n<li><strong></strong> LLM  Python </li>\n</ol>\n<p>LangChain </p>\n<ul>\n<li><strong>StrOutputParser</strong> LLM </li>\n<li><strong>JsonOutputParser</strong> JSON </li>\n<li><strong>PydanticOutputParser</strong> Pydantic </li>\n</ul>\n<h3 id=\"Function-Calling\"><a href=\"#Function-Calling\" class=\"headerlink\" title=\"Function Calling\"></a>Function Calling</h3><p>Function Calling  API</p>\n<ol>\n<li><strong></strong> JSON Schema</li>\n<li><strong></strong></li>\n<li><strong></strong> <code>tool_calls</code> </li>\n<li><strong></strong><strong></strong> API</li>\n<li><strong></strong> API  <code>role</code>  <code>tool</code> </li>\n<li><strong></strong></li>\n</ol>\n<p> JSONFunction Calling </p>\n<ul>\n<li><strong></strong></li>\n<li><strong></strong></li>\n<li><strong></strong> AI Agent LLM  API</li>\n</ul>\n<h2 id=\"RAG\"><a href=\"#RAG\" class=\"headerlink\" title=\"RAG\"></a>RAG</h2><p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter6/images/6_1_1.webp\" alt=\"RAG Triad\"></p>\n<h3 id=\"RAG\"><a href=\"#RAG\" class=\"headerlink\" title=\"RAG\"></a>RAG</h3><p> <strong>TruLens</strong>  </p>\n<ol>\n<li><strong> (Context Relevance)</strong><ul>\n<li><strong></strong> Retriever</li>\n<li><strong></strong> Query</li>\n<li><strong></strong> RAG</li>\n</ul>\n</li>\n<li><strong> &#x2F;  (Faithfulness &#x2F; Groundedness)</strong><ul>\n<li><strong></strong> </li>\n<li><strong></strong> </li>\n<li><strong></strong> LLMLLM</li>\n</ul>\n</li>\n<li><strong> (Answer Relevance)</strong><ul>\n<li><strong></strong> End-to-End</li>\n<li><strong></strong> </li>\n<li><strong></strong> </li>\n</ul>\n</li>\n</ol>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li></li>\n</ul>\n<p>RAG <strong> (Context Relevance)*</strong> </p>\n<p></p>\n<p><img src=\"/img/all-in-rag/p1.png\" alt=\"1\"></p>\n<ul>\n<li></li>\n</ul>\n<p>RAG <strong></strong>  <strong></strong> <strong></strong> </p>\n<ul>\n<li></li>\n</ul>\n<ol>\n<li><strong> &#x2F; :</strong><ul>\n<li></li>\n</ul>\n</li>\n<li><strong>:</strong><ul>\n<li></li>\n</ul>\n</li>\n</ol>\n<ul>\n<li></li>\n</ul>\n<p></p>\n<p><strong>1. </strong></p>\n<p>llm</p>\n<ul>\n<li><strong></strong> Claims</li>\n<li><strong></strong> </li>\n</ul>\n<p><strong>2. </strong></p>\n<p> n-gramn</p>\n<p><img src=\"/img/all-in-rag/p2.png\" alt=\"2\"></p>\n<p>LLM<strong></strong><strong></strong>LLM</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"LlamaIndex-Evaluation\"><a href=\"#LlamaIndex-Evaluation\" class=\"headerlink\" title=\"LlamaIndex Evaluation\"></a>LlamaIndex Evaluation</h3><p><code>LlamaIndex Evaluation</code> <strong>LlamaIndex</strong>RAGRAG<strong></strong>RAG</p>\n<p><code>LlamaIndex</code> LLMRAG</p>\n<ol>\n<li><strong></strong> <code>DatasetGenerator</code> -<code>QueryResponseDataset</code></li>\n<li><strong></strong>RAG<code>QueryEngine</code></li>\n<li><strong></strong> <code>FaithfulnessEvaluator</code> <code>RelevancyEvaluator</code></li>\n<li><strong></strong> <code>BatchEvalRunner</code> </li>\n<li><strong></strong>RAG</li>\n</ol>\n<p>LlamaIndex<strong></strong></p>\n<ul>\n<li><code>Faithfulness</code> (): </li>\n<li><code>Relevancy</code> (): </li>\n</ul>\n<p><strong></strong></p>\n<ul>\n<li><code>Hit Rate</code> (): </li>\n<li><code>MRR</code> (): </li>\n</ul>\n<h3 id=\"RAGAS\"><a href=\"#RAGAS\" class=\"headerlink\" title=\"RAGAS\"></a>RAGAS</h3><p>RAGASRAG Assessment<strong>RAG</strong>RAG<strong></strong>RAGRAG<code>RAGAS</code> </p>\n<p><code>RAGAS</code> <code>question</code><code>answer</code><code>context</code>RAG</p>\n<ol>\n<li><strong></strong> <code>question</code><code>answer</code>RAG<code>contexts</code> <code>ground_truth</code><code>ground_truth</code>  <code>context_recall</code>  <code>faithfulness</code> </li>\n<li><strong></strong> <code>ragas.evaluate()</code> </li>\n<li><strong></strong></li>\n</ol>\n<p></p>\n<ul>\n<li><code>faithfulness</code>: </li>\n<li><code>context_recall</code>: <code>ground_truth</code></li>\n<li><code>context_precision</code>: </li>\n<li><code>answer_relevancy</code>: </li>\n</ul>\n<h3 id=\"Phoenix\"><a href=\"#Phoenix\" class=\"headerlink\" title=\"Phoenix\"></a>Phoenix</h3><p>Phoenix (Arize) <strong>LLM</strong>RAG<strong></strong>LLMTracesPhoenix <strong></strong>LLMTracing</p>\n<ol>\n<li>** (<code>Instrumentation</code>)** <strong>OpenTelemetry</strong>RAG <code>Phoenix</code> LLM</li>\n<li>** (<code>Traces</code>)**RAG<code>Phoenix</code> </li>\n<li><strong>UI</strong> <code>Phoenix</code> Web</li>\n<li><strong></strong>UI (<code>Evals</code>) </li>\n</ol>\n<p></p>\n<ul>\n<li><strong></strong>: RAG</li>\n<li><strong></strong>: </li>\n<li><strong> (<code>Guardrails</code>)</strong>: </li>\n<li><strong></strong>: </li>\n<li><strong>Arize</strong>: <code>Phoenix</code> ArizeRAG</li>\n</ul>\n<h2 id=\"RAG\"><a href=\"#RAG\" class=\"headerlink\" title=\"RAG\"></a>RAG</h2><p><img src=\"https://datawhalechina.github.io/all-in-rag/chapter7/images/7_1_1.svg\" alt=\"GraphRAG\"></p>\n<p> RAG -LLM</p>\n<p><strong></strong>LLM</p>\n<p><strong></strong>RAG</p>\n<p><strong></strong>LLM</p>\n<p><strong></strong> RAG </p>\n<p><strong></strong>&#x2F;</p>\n<p><strong></strong>&#x2F;&#x2F;</p>\n<p><strong></strong></p>\n<p>RAG</p>\n<p><strong></strong>A--BLLM</p>\n<p><strong></strong></p>\n<p><strong></strong></p>\n<p><strong></strong></p>\n<p></p>\n<ul>\n<li><strong></strong>SchemaOntology</li>\n<li><strong></strong></li>\n<li><strong></strong>Time-travel Query</li>\n</ul>\n<h3 id=\"GraphRAG\"><a href=\"#GraphRAG\" class=\"headerlink\" title=\"GraphRAG\"></a>GraphRAG</h3><p><strong></strong>  GraphRAG </p>\n<ul>\n<li> LLM  IE &#x2F;Normalization</li>\n<li></li>\n<li>Entity Resolution&#x2F;</li>\n<li>Neo4j&#x2F;NebulaGraph&#x2F;TigerGraph&#x2F;Neptune</li>\n</ul>\n<p><strong></strong> </p>\n<ul>\n<li>Entity Linking</li>\n<li>Cypher</li>\n<li></li>\n<li>GraphRAGLeiden-</li>\n</ul>\n<p> GraphRAG  RAG </p>\n<p><strong></strong>  Cypher&#x2F;Gremlin</p>\n<p><strong></strong> &#x2F;</p>\n<p><strong></strong> </p>\n<ul>\n<li>&#x2F;</li>\n<li></li>\n</ul>\n<p>GraphRAG</p>\n<ul>\n<li><p>GraphRAGMicrosoft</p>\n</li>\n<li><p>LightRAG</p>\n</li>\n<li><p>FRAGFlexible RAG</p>\n</li>\n<li><p>GraphIRAG (Iterative Knowledge Retrieval)</p>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>GraphRAG </p>\n<p><strong></strong></p>\n<ul>\n<li>PrecisionRecallF1Hit Rate@K</li>\n<li>RAG<ul>\n<li>Context Precision&#x3D; </li>\n<li>Context Recall&#x3D; </li>\n<li>&#x2F;Citation&#x2F;Attribution&#x3D; </li>\n</ul>\n</li>\n</ul>\n<p><strong></strong></p>\n<ul>\n<li>EMF1</li>\n<li>ROUGE</li>\n<li>&#x2F;Faithfulness+</li>\n</ul>\n<p><strong></strong></p>\n<p>LatencyThroughputQPSCostAPIGPU&#x2F;CPU</p>\n<p>GraphRAG</p>\n<p><strong></strong> GraphRAG HotpotQA2WikiMultihopQA  MuSiQue</p>\n<p><strong></strong>  WebQSP  ComplexWebQuestions (CWQ)</p>\n<p><strong>QA</strong>  KGQAgen-10k</p>\n"},{"title":"Machine Learning Notes","mathjax":true,"date":"2023-11-25T12:46:25.000Z","img":"https://img2.baidu.com/it/u=1093757134,3274186314&fm=253&fmt=auto&app=120&f=JPEG?w=800&h=500","excerpt":"","_content":"\n# Course 1\n\nxy********\n\nxy************\n\n## \n\n$$\ny^i = wx^i+b\n$$\n\n\n\n$$\nJ(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} {(y^i-\\hat{y})}^2\n$$\n\n$y^i$$\\hat{y}$\n\n- \n- 1/2\n\nlosscost\n\n### \n\n\n\n`learning_rate`$\\alpha$,$\\alpha \\subseteq [0,1]$\n\n$w = w- \\alpha \\frac{\\partial{J(w,b)}}{\\partial{w}}$\n\n$b = b- \\alpha \\frac{\\partial{J(w,b)}}{\\partial{b}}$\n\n- ****\n\n![img](/img/machine-learning-notes/pic-1.png)\n\n$\\alpha$\n\n$\\alpha$\n\n$J(w,b)$$\\alpha$\n\n\n\n$\\frac{\\partial{J(w,b)}}{\\partial{w}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)x^i$\n\n$\\frac{\\partial{J(w,b)}}{\\partial{b}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)$\n\n$f(x^i) = wx^i+b$\n\n\n\n$min(J(w,b))$\n\nbatch gradient descent\n\n### \n\n$n$$\\vec{x} = \\begin{bmatrix} x_1 & x_2 & x_3 & ... \\end{bmatrix}$$\\vec{w} = \\begin{bmatrix} w_1 & w_2 & w_3 & ... \\end{bmatrix}$\n\n$f_{\\vec{w},b}=\\vec{w} \\cdot \\vec{x} +b$\n\n``(dot)\n\n$$\n\\vec{w} \\cdot \\vec{x} = w_1*x_1+w_2*x_2+....+w_n*x_n\n$$\n\n\n****\n\n```python\nf = np.dot(w, x) + b\n```\n\n****\n\n![img](/img/machine-learning-notes/pic-2.png)\n\nPS: $w,b$****\n\n### \n\n \n\n\n\n\n\n- ****$x_{1,scale} = \\frac{x_1}{max}$ $x \\in [0,1]$\n- **Mean Normalization**\n  - $\\mu$\n  - $x_1 = \\frac{x_1-\\mu}{max-min}$\n- **`Z-score`**\n  - $\\sigma$$\\mu$\n  - $x_1 = \\frac{x_1-\\mu}{\\sigma}$\n\n****\n\n1. iteration-loss 2. loss\n\n****0.0013$J(w,b)$$\\alpha$\n\n### \n\n\n\n****$x^q$$f(x)=w_1x^3+w_2x^2+w_1x^1+b$\n\n\n\n## -\n\n\n\n### sigmoid\n\n$(0,1)$\n\n$g(z)= \\frac{1}{1+e^{-z}},z \\subseteq R$\n\n**logistic regression**:\n\n$f_{\\vec{w},b}(\\vec{x})=g(\\vec{w}  \\vec{x}+b) = \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$\n\n1\n\n$f_{\\vec{w},b}(\\vec{x})=P(y=1|\\vec{x};\\vec{w},b)$\n\n### decision boundary\n\n0.5$\\vec{w}  \\vec{x}+b \\ge 0$1$\\vec{w}  \\vec{x}+b <0$0\n\n$\\vec{w}  \\vec{x}+b = 0$\n\n\n\n### \n\n$J(w,b)$****\n\n\n\n$$\nJ(w,b)=\\frac{1}{m}\\sum_{i-1}^{m}L(f_{w,b}(x^{(i)},y^{(i)})\n$$\nLlossJcost\n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-log(f_{w,b}(x^{(i)})) \\quad if\\quad y^{(i)}=1\n$$\n![img](/img/machine-learning-notes/pic-3.png)\n\ny11\n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-log(1-f_{w,b}(x^{(i)})) \\quad if \\quad y^{(i)}=0\n$$\n![img](/img/machine-learning-notes/pic-4.png)\n\ny00 \n\n****                                                                                                                                                                                                                                                                                          \n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))\n$$\n\n\n\n\n$$\nJ(w,b) = -\\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))\n$$\n\n\n\n\n### \n\nJ\n\n$\\frac{\\partial{J(w,b)}}{\\partial{w}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)x^i$\n\n$\\frac{\\partial{J(w,b)}}{\\partial{b}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)$\n\n$f(x^i) = \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$\n\n\n\n### \n\nhigh biashigh variance\n\n![img](/img/machine-learning-notes/pic-5.png)\n\n****\n\n- \n- \n- (Regularization)$w_j$\n\n### \n\n\n\n$$\nJ(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} {(y^i-\\hat{y})}^2 + \\frac{\\lambda}{\\alpha m}\\sum_{j=1}^{n} {w_j}^2\n$$\n\n\n$\\lambda$$\\alpha$\n\n$$\nJ(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} {(y^i-\\hat{y})}^2 + \\frac{\\lambda}{2 m}\\sum_{j=1}^{n} {w_j}^2\n$$\n\n\n$w_j$0\n\n$b$\n\n**$\\lambda$**\n\n- \n\n$J(w,b)$w,b\n\n$$\n\\frac{\\partial{J(w,b)}}{\\partial{w}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)x^i+\\frac{\\lambda}{m}\\sum_{j=1}^{m}{w_j}\n$$\n\n$$\nw = w- \\alpha (\\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)x^i+\\frac{\\lambda}{m}\\sum_{j=1}^{m}{w_j}) = (1-\\alpha \\frac{\\lambda}{m})w+.....\n$$\n\n\n- \n\n$$\nJ(w,b) = -\\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))+ \\frac{\\lambda}{2 m}\\sum_{j=1}^{n} {w_j}^2\n$$\n\n\n\n****\n\n$f(x^i) = \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$\n\n![img](/img/machine-learning-notes/pic-6.png)\n\n# Course 2\n\n## \n\n21****\n\n\n\n\n\n->->\n\n\n\n## \n\n\n\n$\\vec{x}$$\\vec{a}_{i-1}$$\\vec{a}^{[l]}$/\n\n$a_j^{[l]} = g(\\vec{w}_j^{[l]} \\cdot \\vec{a}^{[l-1]} + b_j^{[l]})$\n\n$j$$l$$g(x)$`sigmod`\n\n![img](/img/machine-learning-notes/pic-7.jpg)\n\n$a_j^{[l]}$$\\vec{a}^{[l]}$\n\n![img](/img/machine-learning-notes/pic-8.png)\n\n## (forward prop)\n\n\n\n****\n\n```python\ndef dense(a_in, W, b, g):\n\tunits = W.shape[1] # Ww_j\n\ta_out = np.zeros(units)\n\tfor j in range(units):\n\t\tw = W[:, j]\n\t\tz = np.dot(w, a_in) + b\n\t\ta_out[j] = g(z)\n\treturn a_out\ndef sequential(x):\n    a1 = dense(x, W1, b1)\n    a2 = dense(a1, W2, b2)\n    a3 = dense(a2, W3, b3)\n    f_x = a3\n    return f_x\n```\n\n**TensorFlow/Pytorch)**\n\n## \n\n1. X(****)\n2. ****\n3. ****\n\n\n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))\n$$\n\n\n## \n\n`ReLU``sigmoid`$g(z) = max(0,z)$\n\n![img](/img/machine-learning-notes/pic-9.png)\n\n****\n\ny****\n\n- > sigmoid\n- y> linear\n- y0 > ReLU\n\n****ReLU\n\n`ReLU`\n\n- \n- ReLUx->-,sigmoid\n\n****\n\n\n\nsigmoid\n\n## \n\n**softmax**logistic \n\n$z_1=\\vec{w_1}\\vec{x_1}+b_1$\n\n$a_1=\\frac{e^{z_1}}{e^{z_1}+...+e^{z_n}} = P(y=1|\\vec{x})$\n\nN\n\n$z_i=\\vec{w_1}\\vec{x_i}+b_i$\n\n$$\na_i = \\frac{e^{z_i}}{\\sum_{k=1}^{N} e^{z_i}}=P(y=i|\\vec{x})\n$$\n$a_1+a_2+...+a_N=1$\n\n**softmax**\n\nlogistic\n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))\n$$\n\n\n$a_1 = f_{w,b}(x^{(i)})$$y=1$\n\n$a_2 = 1-f_{w,b}(x^{(i)})$$y=0$\n\n\n\n$loss = -log(a_1)$ $y=1$\n\n$loss = -log(a_2)$ $y=0$\n\nsoftmax\n\n$$\nloss(a_1,a_2,...,a_N,y) = \\left\\{\\begin{matrix} -log(a_1) \\quad if \\quad y=1\\\\ -log(a_2) \\quad if \\quad y=2 \\\\ ... \\\\ -log(a_N) \\quad if \\quad y=N \\end{matrix}\\right.\n$$\n\n\n**softmax**\n\nN\n\n$g(z_1)$$z_1$softmax$z_1 ... z_n$\n\n**softmax**\n\n[](https://blog.csdn.net/muyuu/article/details/122757470)\n\n$log$x0$a_i$\n\n$a_i$\n\n****\n$$\nloss_i=-log(\\frac{e^{z_i}}{e_{z_1}+...+e_{z_N}})\n$$\n\n\n`linear`$a_i$`from_logits=True`\n\n```python\nmodel.compile(loss=SparseCategoricalCrossEntropy(from_logits=True)) #\n```\n\n`from_logits=True`[](https://blog.csdn.net/muyuu/article/details/122762442)\n\n`softmax`\n\n```python\nlogits = model(X)\nf_x = tf.nn.softmax(logits)\n```\n\n****\n\n![img](/img/machine-learning-notes/pic-10.png)\n\nnlogisticy\n\n## \n\n\n\n### AdamAdaptive Moment estimation\n\n\n\n\n\n$\\alpha$\n\n$\\alpha$\n\noptimizer=adam\n\n## \n\n### Convolutional Layer\n\n\n\n- \n- \n\n\n\n \n\n## \n\n### \n\n\n\n7382\n\n\n\n![img](/img/machine-learning-notes/pic-11.png)\n\n**error**\n\n$J_{train}$$J_{test}$\n\nerroraccurate rate\n\n### \n\n$J_{train}$$J_{cv}$$J_{test}$\n\ncross validation**dev set**/validation set\n\n$J_{train}$$J_{cv}$$J_{test}$\n\n622\n\n### ****\n\n![img](/img/machine-learning-notes/pic-12.png)\n\n![img](/img/machine-learning-notes/pic-13.png)\n\n\n\n\n\n****\n\n![img](/img/machine-learning-notes/pic-14.png)\n\n/****/\n\n![img](/img/machine-learning-notes/pic-15.png)\n\n****\n\n![img](/img/machine-learning-notes/pic-16.png)\n\n \n\n![img](/img/machine-learning-notes/pic-17.png)\n\n\n\n![img](/img/machine-learning-notes/pic-18.png)\n\n![img](/img/machine-learning-notes/pic-19.png)\n\n\n\n****\n\n\n\n\n\n\n\n```python\nlayer = Dense(unit=25, activation=\"relu\", kernel_regularizer=L2(0.01))\n```\n\n## \n\n![img](/img/machine-learning-notes/pic-20.png)\n\n## \n\n\n\n## \n\n****\n\nx\n\n****OCR\n\nAI = Code(algorithm/model) + Data\n\n## Transfer Learning\n\n0-91000\n\n![img](/img/machine-learning-notes/pic-21.png)\n\n****(supervised pretraining)****(fine tuning)\n\n\n\nx\n\n![img](/img/machine-learning-notes/pic-22.png)\n\n## \n\n![img](/img/machine-learning-notes/pic-23.png)\n\n\n\n![img](/img/machine-learning-notes/pic-24.png)\n\nMLOps(Machine Learning operations)\n\n## \n\n## \n\n********\n\n**(precision)****(recall)**\n\n![img](/img/machine-learning-notes/pic-25.png)\n\n\n\n\n\ny=1logistic0.5\n\ny=1logistic0.5\n\nthresholdprecisionrecall\n\nF1 score\n\n$F1 score = \\frac{1}{\\frac{1}{2}(\\frac{1}{P}+\\frac{1}{R})} = 2\\frac{PR}{P+R}$\n\n## \n\n\n\n![img](/img/machine-learning-notes/pic-26.png)\n\n****\n\n- \n\n\n\n- \n\n100%\n\n\n\n\n\n\n\n### purity\n\n$p_1$$p_0 = 1 - p_1$\n\n$H(p_1)=-p_1log_2(p_1)-p_0log_2(p_0) = -p_1log_2(p_1)-(1-p_1)log_2(1-p_1)$\n\n$0log(0) = 0$\n\n![img](/img/machine-learning-notes/pic-27.png)\n\n### Information Gain\n\n\n\n$H(p)$\n\n\n\n![img](/img/machine-learning-notes/pic-28.png)\n\n\n\n![img](/img/machine-learning-notes/pic-29.png)\n\npw/\n\n### \n\n\n\n\n\n\n\n\n\n- 100%\n- \n- \n- \n\n\n\n### (One Hot Encoding)\n\nkk0/1\n\n\n\n### \n\n\n\n109\n\n\n\n### \n\n(Variance)\n\nw/\n\n\n\n\n\n## \n\nTree Ensemble\n\n### \n\nnn\n\n### Random Forest\n\nmb100m\n\nbBagged Decision Tree\n\nn$k < n$n$k = \\sqrt{n}$\n\n### XGBoosteXtreme Gradient Boosting\n\n$\\frac{1}{m}$\n\n\n\n- \n- \n- \n- \n\n### \n\n\n\n- \n- \n- \n- \n\n\n\n- \n- \n- +\n\n- \n\n# Course 3\n\n\n\n- \n  - \n  - \n- \n- \n\n## \n\n\n\n### K-means\n\nK$\\mu_1 ,\\mu_2... \\mu_k$$\\mu$\n\n- centroid\n- \n- K-means\n\n```bash\nRepeat{\n\tfor i = 1 to m\n\t\tc_i x_i1-k\n\t\t// min_k ||x_i - u_k||\n\tfor i = 1 to k\n\t\tu_k\n\t\t\n}\n```\n\n### \n\n![img](/img/machine-learning-notes/pic-30.png)\n\n$c^{(i)}$$x^{(i)}$1-k\n\n$u_k$k\n\n$\\mu _{c^{(i)}}$$x^{(i)}$\n\n****\n\nDistortion Function\n\n### \n\n$K<m$\n\nK$\\mu_1 ,\\mu_2... \\mu_k$\n\n```bash\nfor i = 1 to 100{\n\t\n\tc_i, u_i\n\tJ\n}\nJi501000\n```\n\n### \n\n**Elbow Method**\n\nK\n\nK\n\n## \n\n### Density estimation\n\n$p(x)$x$x_{test}$$p$$p(x_{test})<\\epsilon$anomaly\n\n### \n\nGaussian Distribution(Normal Distribution)\n\n$p(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{\\frac{-(x-\\mu)}{2\\sigma^2}^2}$\n\n$\\mu$$\\sigma$\n\n![img](/img/machine-learning-notes/pic-31.png)\n\n### \n\n$\\vec{x}$$\\vec{x} = [x_1, x_2 ... x_n]$\n\n$$\np(\\vec{x}) = p(x_1;\\mu_1,\\sigma_1^2) * p(x_2;\\mu_2,\\sigma_2^2) *...* p(x_n;\\mu_n,\\sigma_n^2) = \\prod_{j=1}^np(x_j;\\mu_j,\\sigma_j^2)\n$$\n\n\n### \n\ncv0/1$\\epsilon$cv\n\n****\n\n$x_1...x_m$$p(x)$\n\nyepsilon10\n\nPrecisionRecallF1$\\epsilon$\n\n### \n\n\n\n\n\n### \n\n\n\n- cv\n- cv\n\n## \n\n$r(i,j) = 1$ji\n\n$y^{(i,j)}$ji\n\n$w^{(j)}, b^{(j)}$j\n\n$x^{(i)}$i\n\nji$w^{(j)} \\cdot x^{(i)}+b^{(j)}$\n\n$m^{(j)}$j\n\n$w^{(j)}, b^{(j)}$\n\n$$\n\\min_{w^{(j)}b^{(j)}}J\\left(w^{(j)},b^{(j)}\\right)=\\frac{1}{2m^{(j)}}\\sum_{(i:r(i,j)=1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}+\\frac{\\lambda}{2m^{(j)}}\\sum_{k=1}^{n}\\left(w_{k}^{(j)}\\right)^{2}\n$$\n\n\n$w^{(1)},b^{(1)},w^{(2)},b^{(2)},...,w^{(n_u)},b^{(n_u)}$\n\n$$\n\\left.\\mathrm{J}\\left(\n\\begin{array}\n{cc}{w^{(1)},} & {...,w^{(n_{u})}} \\\\\n{b^{(1)},} & {...,b^{(n_{u})}}\n\\end{array}\\right.\\right)=\\frac{1}{2}\\sum_{j=1}^{n_{u}}\\sum_{i:r(i,j)=1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}\\quad+\\frac{\\lambda}{2}\\sum_{j=1}^{n_{u}}\\sum_{k=1}^{n}\\left(w_{k}^{(j)}\\right)^{2}\n$$\n\n\n### \n\n$w^{(j)}, b^{(j)}$\n\n$$\n\\mathrm{J}(x^{(i)})=\\frac{1}{2}\\sum_{j:r(i,j)=1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-{y^{(i,j)}}\\right)^{2}+\\frac{\\lambda}{2}\\sum_{k=1}^{n}\\left(x_{k}^{(i)}\\right)^{2}\n$$\n\n\n$x^{(1)},x^{(2)},...,x^{(n_m)}$\n\n$$\n\\mathrm{J}\\left(x^{(1)},x^{(2)},...,x^{(n_{m})}\\right)=\\frac{1}{2}\\sum_{i=1}^{n_{m}}\\sum_{j:r(i,j)=1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}+\\frac{\\lambda}{2}\\sum_{i=1}^{n_{m}}\\sum_{k=1}^{n}\\left(x_{k}^{(i)}\\right)^{2}\n$$\n\n\nw,b\n\n![img](/img/machine-learning-notes/pic-32.png)\n\nwbx\n\n![img](/img/machine-learning-notes/pic-33.png)\n\n[](https://blog.csdn.net/zhu_xian_gang/article/details/130243870)\n\n### \n\n1-\n\n0-\n\n?-\n\n$y^{(i,j)}=1$$g(w^{(j)} \\cdot x^{(i)}+ b^{(i)})$glogistic\n\n![img](/img/machine-learning-notes/pic-34.png)\n\n### \n\n**Mean Normalization**\n\n- $\\mu$\n- $x_1 = \\frac{x_1-\\mu}{max-min}$\n\n$\\mu_i$$u$\n\nji\n\n$w^{(j)} \\cdot x^{(i)}+ b^{(i)} + \\mu_i$\n\n0\n\n### \n\n$i$$x^{(i)}$$k$$x^{(k)}$$x^{(i)}$\n\n$\\sum_{l=1}^n(x_l^{(k)} - x_l^{(i)})^2$\n\n$||x^{(k)} - x^{(i)}||^2$\n\n### \n\n****\n\n- \n- \n\n****\n\n### \n\n\n\n\n\n$v^{(j)}$$v^{(i)}$\n\nv\n\nuser networkmovie network\n\n\n\n$$\nJ=\\sum_{(i,j):r(i,j)=1}\\left(v_{u}^{(j)}\\cdot v_{m}^{(i)}-y^{(i,j)}\\right)^{2}+\\text{NN regularization term}\n$$\n\n\ni$||v^{(k)} - v^{(i)}||^2$\n\n### Retrieval and Ranking\n\n\n\n103top10top20\n\n\n\n\n\n## \n\nReinforcement LearningRLAgentEnvironmentRewardTrial and Error\n\n\n\n### \n\n\n\n$\\gamma$10.9,0.99\n\n$\\text{Return} = R_1 + \\gamma R_2 + \\gamma^2R_3+...$\n\n### \n\nstatea\n\n$\\pi(s) = a$sa\n\n### \n\nMarkov Decision Process(MDP)\n\n![img](/img/machine-learning-notes/pic-35.png)\n\n### -\n\nState-action value functionQ-function,Q*,Optimal Q function\n\n$Q(s,a)$sa\n\ns$max_aQ(s,a)$\n\ns$max_aQ(s,a)$\n\n### Bellman\n\n$s$:\n\n$a$:\n\n$R(s)$:\n\n$s'$:a\n\n$a'$:s'\n\n$Q(s,a) = R(s)+\\gamma max_{a'}Q(s',a')$\n\nR(s)\n\ns'\n\n$\\text{Return} = R_1 + \\gamma R_2 + \\gamma^2R_3+... = R_1 + \\gamma[R_2 + \\gamma R_3+...]$\n\n### \n\n\n\n\n\n$\\text{Return} = \\text{Average}(R_1 + \\gamma R_2 + \\gamma^2R_3+...) = \\text{E}(R_1 + \\gamma R_2 + \\gamma^2R_3+...)$\n\nBellman Equation\n\n$Q(s,a) = R(s)+\\gamma \\text{E} [max_{a'}Q(s',a')]$\n\n### \n\n\n\nxyz\n\n\n\n### \n\n![img](/img/machine-learning-notes/pic-36.png)\n\n$Q(s,a)$\n\n\n\n$(s,a,R(s),s')$\n\n10k $(s,a,R(s),s')$Replay Buffer\n\n\n\n\t10k$x=(s,a)$$y = R(s)+\\gamma max_{a'}Q(s',a')$\n\n\t$Q_{new}$$Q_{new}(s,a) \\approx y$\n\n$Q=Q_{new}$\n\nQQ\n\n****\n\n- \n\n\n\n![img](/img/machine-learning-notes/pic-37.png)\n\n- $\\epsilon$\n\nQaQ\n\n0.95Qgreedyexploitation0.05exploration\n\nepsilonepsilone\n\n- $mini-batch$\n\n\n\n![img](/img/machine-learning-notes/pic-38.png)\n\n1000\n\n1000wb10001000\n\n10k\n\n- \n\n$Q=Q_{new}$$w,b$$w_{new},b_{new}$\n\n\n$$\nw = 0.01w_{new} + 0.99w\n$$\n\n$$\nb = 0.01b_{new} + 0.99b\n$$\n\n\n","source":"_posts/machine-learning-notes.md","raw":"---\ntitle: Machine Learning Notes\nmathjax: true\ndate: 2023/11/25 20:46:25\nimg: https://img2.baidu.com/it/u=1093757134,3274186314&fm=253&fmt=auto&app=120&f=JPEG?w=800&h=500\nexcerpt: \n---\n\n# Course 1\n\nxy********\n\nxy************\n\n## \n\n$$\ny^i = wx^i+b\n$$\n\n\n\n$$\nJ(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} {(y^i-\\hat{y})}^2\n$$\n\n$y^i$$\\hat{y}$\n\n- \n- 1/2\n\nlosscost\n\n### \n\n\n\n`learning_rate`$\\alpha$,$\\alpha \\subseteq [0,1]$\n\n$w = w- \\alpha \\frac{\\partial{J(w,b)}}{\\partial{w}}$\n\n$b = b- \\alpha \\frac{\\partial{J(w,b)}}{\\partial{b}}$\n\n- ****\n\n![img](/img/machine-learning-notes/pic-1.png)\n\n$\\alpha$\n\n$\\alpha$\n\n$J(w,b)$$\\alpha$\n\n\n\n$\\frac{\\partial{J(w,b)}}{\\partial{w}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)x^i$\n\n$\\frac{\\partial{J(w,b)}}{\\partial{b}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)$\n\n$f(x^i) = wx^i+b$\n\n\n\n$min(J(w,b))$\n\nbatch gradient descent\n\n### \n\n$n$$\\vec{x} = \\begin{bmatrix} x_1 & x_2 & x_3 & ... \\end{bmatrix}$$\\vec{w} = \\begin{bmatrix} w_1 & w_2 & w_3 & ... \\end{bmatrix}$\n\n$f_{\\vec{w},b}=\\vec{w} \\cdot \\vec{x} +b$\n\n``(dot)\n\n$$\n\\vec{w} \\cdot \\vec{x} = w_1*x_1+w_2*x_2+....+w_n*x_n\n$$\n\n\n****\n\n```python\nf = np.dot(w, x) + b\n```\n\n****\n\n![img](/img/machine-learning-notes/pic-2.png)\n\nPS: $w,b$****\n\n### \n\n \n\n\n\n\n\n- ****$x_{1,scale} = \\frac{x_1}{max}$ $x \\in [0,1]$\n- **Mean Normalization**\n  - $\\mu$\n  - $x_1 = \\frac{x_1-\\mu}{max-min}$\n- **`Z-score`**\n  - $\\sigma$$\\mu$\n  - $x_1 = \\frac{x_1-\\mu}{\\sigma}$\n\n****\n\n1. iteration-loss 2. loss\n\n****0.0013$J(w,b)$$\\alpha$\n\n### \n\n\n\n****$x^q$$f(x)=w_1x^3+w_2x^2+w_1x^1+b$\n\n\n\n## -\n\n\n\n### sigmoid\n\n$(0,1)$\n\n$g(z)= \\frac{1}{1+e^{-z}},z \\subseteq R$\n\n**logistic regression**:\n\n$f_{\\vec{w},b}(\\vec{x})=g(\\vec{w}  \\vec{x}+b) = \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$\n\n1\n\n$f_{\\vec{w},b}(\\vec{x})=P(y=1|\\vec{x};\\vec{w},b)$\n\n### decision boundary\n\n0.5$\\vec{w}  \\vec{x}+b \\ge 0$1$\\vec{w}  \\vec{x}+b <0$0\n\n$\\vec{w}  \\vec{x}+b = 0$\n\n\n\n### \n\n$J(w,b)$****\n\n\n\n$$\nJ(w,b)=\\frac{1}{m}\\sum_{i-1}^{m}L(f_{w,b}(x^{(i)},y^{(i)})\n$$\nLlossJcost\n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-log(f_{w,b}(x^{(i)})) \\quad if\\quad y^{(i)}=1\n$$\n![img](/img/machine-learning-notes/pic-3.png)\n\ny11\n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-log(1-f_{w,b}(x^{(i)})) \\quad if \\quad y^{(i)}=0\n$$\n![img](/img/machine-learning-notes/pic-4.png)\n\ny00 \n\n****                                                                                                                                                                                                                                                                                          \n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))\n$$\n\n\n\n\n$$\nJ(w,b) = -\\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))\n$$\n\n\n\n\n### \n\nJ\n\n$\\frac{\\partial{J(w,b)}}{\\partial{w}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)x^i$\n\n$\\frac{\\partial{J(w,b)}}{\\partial{b}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)$\n\n$f(x^i) = \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$\n\n\n\n### \n\nhigh biashigh variance\n\n![img](/img/machine-learning-notes/pic-5.png)\n\n****\n\n- \n- \n- (Regularization)$w_j$\n\n### \n\n\n\n$$\nJ(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} {(y^i-\\hat{y})}^2 + \\frac{\\lambda}{\\alpha m}\\sum_{j=1}^{n} {w_j}^2\n$$\n\n\n$\\lambda$$\\alpha$\n\n$$\nJ(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m} {(y^i-\\hat{y})}^2 + \\frac{\\lambda}{2 m}\\sum_{j=1}^{n} {w_j}^2\n$$\n\n\n$w_j$0\n\n$b$\n\n**$\\lambda$**\n\n- \n\n$J(w,b)$w,b\n\n$$\n\\frac{\\partial{J(w,b)}}{\\partial{w}} = \\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)x^i+\\frac{\\lambda}{m}\\sum_{j=1}^{m}{w_j}\n$$\n\n$$\nw = w- \\alpha (\\frac{1}{m} \\sum_{i=1}^{m} (f(x^i)-y^i)x^i+\\frac{\\lambda}{m}\\sum_{j=1}^{m}{w_j}) = (1-\\alpha \\frac{\\lambda}{m})w+.....\n$$\n\n\n- \n\n$$\nJ(w,b) = -\\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))+ \\frac{\\lambda}{2 m}\\sum_{j=1}^{n} {w_j}^2\n$$\n\n\n\n****\n\n$f(x^i) = \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$\n\n![img](/img/machine-learning-notes/pic-6.png)\n\n# Course 2\n\n## \n\n21****\n\n\n\n\n\n->->\n\n\n\n## \n\n\n\n$\\vec{x}$$\\vec{a}_{i-1}$$\\vec{a}^{[l]}$/\n\n$a_j^{[l]} = g(\\vec{w}_j^{[l]} \\cdot \\vec{a}^{[l-1]} + b_j^{[l]})$\n\n$j$$l$$g(x)$`sigmod`\n\n![img](/img/machine-learning-notes/pic-7.jpg)\n\n$a_j^{[l]}$$\\vec{a}^{[l]}$\n\n![img](/img/machine-learning-notes/pic-8.png)\n\n## (forward prop)\n\n\n\n****\n\n```python\ndef dense(a_in, W, b, g):\n\tunits = W.shape[1] # Ww_j\n\ta_out = np.zeros(units)\n\tfor j in range(units):\n\t\tw = W[:, j]\n\t\tz = np.dot(w, a_in) + b\n\t\ta_out[j] = g(z)\n\treturn a_out\ndef sequential(x):\n    a1 = dense(x, W1, b1)\n    a2 = dense(a1, W2, b2)\n    a3 = dense(a2, W3, b3)\n    f_x = a3\n    return f_x\n```\n\n**TensorFlow/Pytorch)**\n\n## \n\n1. X(****)\n2. ****\n3. ****\n\n\n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))\n$$\n\n\n## \n\n`ReLU``sigmoid`$g(z) = max(0,z)$\n\n![img](/img/machine-learning-notes/pic-9.png)\n\n****\n\ny****\n\n- > sigmoid\n- y> linear\n- y0 > ReLU\n\n****ReLU\n\n`ReLU`\n\n- \n- ReLUx->-,sigmoid\n\n****\n\n\n\nsigmoid\n\n## \n\n**softmax**logistic \n\n$z_1=\\vec{w_1}\\vec{x_1}+b_1$\n\n$a_1=\\frac{e^{z_1}}{e^{z_1}+...+e^{z_n}} = P(y=1|\\vec{x})$\n\nN\n\n$z_i=\\vec{w_1}\\vec{x_i}+b_i$\n\n$$\na_i = \\frac{e^{z_i}}{\\sum_{k=1}^{N} e^{z_i}}=P(y=i|\\vec{x})\n$$\n$a_1+a_2+...+a_N=1$\n\n**softmax**\n\nlogistic\n\n$$\nL(f_{w,b}(x^{(i)},y^{(i)})=-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))\n$$\n\n\n$a_1 = f_{w,b}(x^{(i)})$$y=1$\n\n$a_2 = 1-f_{w,b}(x^{(i)})$$y=0$\n\n\n\n$loss = -log(a_1)$ $y=1$\n\n$loss = -log(a_2)$ $y=0$\n\nsoftmax\n\n$$\nloss(a_1,a_2,...,a_N,y) = \\left\\{\\begin{matrix} -log(a_1) \\quad if \\quad y=1\\\\ -log(a_2) \\quad if \\quad y=2 \\\\ ... \\\\ -log(a_N) \\quad if \\quad y=N \\end{matrix}\\right.\n$$\n\n\n**softmax**\n\nN\n\n$g(z_1)$$z_1$softmax$z_1 ... z_n$\n\n**softmax**\n\n[](https://blog.csdn.net/muyuu/article/details/122757470)\n\n$log$x0$a_i$\n\n$a_i$\n\n****\n$$\nloss_i=-log(\\frac{e^{z_i}}{e_{z_1}+...+e_{z_N}})\n$$\n\n\n`linear`$a_i$`from_logits=True`\n\n```python\nmodel.compile(loss=SparseCategoricalCrossEntropy(from_logits=True)) #\n```\n\n`from_logits=True`[](https://blog.csdn.net/muyuu/article/details/122762442)\n\n`softmax`\n\n```python\nlogits = model(X)\nf_x = tf.nn.softmax(logits)\n```\n\n****\n\n![img](/img/machine-learning-notes/pic-10.png)\n\nnlogisticy\n\n## \n\n\n\n### AdamAdaptive Moment estimation\n\n\n\n\n\n$\\alpha$\n\n$\\alpha$\n\noptimizer=adam\n\n## \n\n### Convolutional Layer\n\n\n\n- \n- \n\n\n\n \n\n## \n\n### \n\n\n\n7382\n\n\n\n![img](/img/machine-learning-notes/pic-11.png)\n\n**error**\n\n$J_{train}$$J_{test}$\n\nerroraccurate rate\n\n### \n\n$J_{train}$$J_{cv}$$J_{test}$\n\ncross validation**dev set**/validation set\n\n$J_{train}$$J_{cv}$$J_{test}$\n\n622\n\n### ****\n\n![img](/img/machine-learning-notes/pic-12.png)\n\n![img](/img/machine-learning-notes/pic-13.png)\n\n\n\n\n\n****\n\n![img](/img/machine-learning-notes/pic-14.png)\n\n/****/\n\n![img](/img/machine-learning-notes/pic-15.png)\n\n****\n\n![img](/img/machine-learning-notes/pic-16.png)\n\n \n\n![img](/img/machine-learning-notes/pic-17.png)\n\n\n\n![img](/img/machine-learning-notes/pic-18.png)\n\n![img](/img/machine-learning-notes/pic-19.png)\n\n\n\n****\n\n\n\n\n\n\n\n```python\nlayer = Dense(unit=25, activation=\"relu\", kernel_regularizer=L2(0.01))\n```\n\n## \n\n![img](/img/machine-learning-notes/pic-20.png)\n\n## \n\n\n\n## \n\n****\n\nx\n\n****OCR\n\nAI = Code(algorithm/model) + Data\n\n## Transfer Learning\n\n0-91000\n\n![img](/img/machine-learning-notes/pic-21.png)\n\n****(supervised pretraining)****(fine tuning)\n\n\n\nx\n\n![img](/img/machine-learning-notes/pic-22.png)\n\n## \n\n![img](/img/machine-learning-notes/pic-23.png)\n\n\n\n![img](/img/machine-learning-notes/pic-24.png)\n\nMLOps(Machine Learning operations)\n\n## \n\n## \n\n********\n\n**(precision)****(recall)**\n\n![img](/img/machine-learning-notes/pic-25.png)\n\n\n\n\n\ny=1logistic0.5\n\ny=1logistic0.5\n\nthresholdprecisionrecall\n\nF1 score\n\n$F1 score = \\frac{1}{\\frac{1}{2}(\\frac{1}{P}+\\frac{1}{R})} = 2\\frac{PR}{P+R}$\n\n## \n\n\n\n![img](/img/machine-learning-notes/pic-26.png)\n\n****\n\n- \n\n\n\n- \n\n100%\n\n\n\n\n\n\n\n### purity\n\n$p_1$$p_0 = 1 - p_1$\n\n$H(p_1)=-p_1log_2(p_1)-p_0log_2(p_0) = -p_1log_2(p_1)-(1-p_1)log_2(1-p_1)$\n\n$0log(0) = 0$\n\n![img](/img/machine-learning-notes/pic-27.png)\n\n### Information Gain\n\n\n\n$H(p)$\n\n\n\n![img](/img/machine-learning-notes/pic-28.png)\n\n\n\n![img](/img/machine-learning-notes/pic-29.png)\n\npw/\n\n### \n\n\n\n\n\n\n\n\n\n- 100%\n- \n- \n- \n\n\n\n### (One Hot Encoding)\n\nkk0/1\n\n\n\n### \n\n\n\n109\n\n\n\n### \n\n(Variance)\n\nw/\n\n\n\n\n\n## \n\nTree Ensemble\n\n### \n\nnn\n\n### Random Forest\n\nmb100m\n\nbBagged Decision Tree\n\nn$k < n$n$k = \\sqrt{n}$\n\n### XGBoosteXtreme Gradient Boosting\n\n$\\frac{1}{m}$\n\n\n\n- \n- \n- \n- \n\n### \n\n\n\n- \n- \n- \n- \n\n\n\n- \n- \n- +\n\n- \n\n# Course 3\n\n\n\n- \n  - \n  - \n- \n- \n\n## \n\n\n\n### K-means\n\nK$\\mu_1 ,\\mu_2... \\mu_k$$\\mu$\n\n- centroid\n- \n- K-means\n\n```bash\nRepeat{\n\tfor i = 1 to m\n\t\tc_i x_i1-k\n\t\t// min_k ||x_i - u_k||\n\tfor i = 1 to k\n\t\tu_k\n\t\t\n}\n```\n\n### \n\n![img](/img/machine-learning-notes/pic-30.png)\n\n$c^{(i)}$$x^{(i)}$1-k\n\n$u_k$k\n\n$\\mu _{c^{(i)}}$$x^{(i)}$\n\n****\n\nDistortion Function\n\n### \n\n$K<m$\n\nK$\\mu_1 ,\\mu_2... \\mu_k$\n\n```bash\nfor i = 1 to 100{\n\t\n\tc_i, u_i\n\tJ\n}\nJi501000\n```\n\n### \n\n**Elbow Method**\n\nK\n\nK\n\n## \n\n### Density estimation\n\n$p(x)$x$x_{test}$$p$$p(x_{test})<\\epsilon$anomaly\n\n### \n\nGaussian Distribution(Normal Distribution)\n\n$p(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{\\frac{-(x-\\mu)}{2\\sigma^2}^2}$\n\n$\\mu$$\\sigma$\n\n![img](/img/machine-learning-notes/pic-31.png)\n\n### \n\n$\\vec{x}$$\\vec{x} = [x_1, x_2 ... x_n]$\n\n$$\np(\\vec{x}) = p(x_1;\\mu_1,\\sigma_1^2) * p(x_2;\\mu_2,\\sigma_2^2) *...* p(x_n;\\mu_n,\\sigma_n^2) = \\prod_{j=1}^np(x_j;\\mu_j,\\sigma_j^2)\n$$\n\n\n### \n\ncv0/1$\\epsilon$cv\n\n****\n\n$x_1...x_m$$p(x)$\n\nyepsilon10\n\nPrecisionRecallF1$\\epsilon$\n\n### \n\n\n\n\n\n### \n\n\n\n- cv\n- cv\n\n## \n\n$r(i,j) = 1$ji\n\n$y^{(i,j)}$ji\n\n$w^{(j)}, b^{(j)}$j\n\n$x^{(i)}$i\n\nji$w^{(j)} \\cdot x^{(i)}+b^{(j)}$\n\n$m^{(j)}$j\n\n$w^{(j)}, b^{(j)}$\n\n$$\n\\min_{w^{(j)}b^{(j)}}J\\left(w^{(j)},b^{(j)}\\right)=\\frac{1}{2m^{(j)}}\\sum_{(i:r(i,j)=1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}+\\frac{\\lambda}{2m^{(j)}}\\sum_{k=1}^{n}\\left(w_{k}^{(j)}\\right)^{2}\n$$\n\n\n$w^{(1)},b^{(1)},w^{(2)},b^{(2)},...,w^{(n_u)},b^{(n_u)}$\n\n$$\n\\left.\\mathrm{J}\\left(\n\\begin{array}\n{cc}{w^{(1)},} & {...,w^{(n_{u})}} \\\\\n{b^{(1)},} & {...,b^{(n_{u})}}\n\\end{array}\\right.\\right)=\\frac{1}{2}\\sum_{j=1}^{n_{u}}\\sum_{i:r(i,j)=1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}\\quad+\\frac{\\lambda}{2}\\sum_{j=1}^{n_{u}}\\sum_{k=1}^{n}\\left(w_{k}^{(j)}\\right)^{2}\n$$\n\n\n### \n\n$w^{(j)}, b^{(j)}$\n\n$$\n\\mathrm{J}(x^{(i)})=\\frac{1}{2}\\sum_{j:r(i,j)=1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-{y^{(i,j)}}\\right)^{2}+\\frac{\\lambda}{2}\\sum_{k=1}^{n}\\left(x_{k}^{(i)}\\right)^{2}\n$$\n\n\n$x^{(1)},x^{(2)},...,x^{(n_m)}$\n\n$$\n\\mathrm{J}\\left(x^{(1)},x^{(2)},...,x^{(n_{m})}\\right)=\\frac{1}{2}\\sum_{i=1}^{n_{m}}\\sum_{j:r(i,j)=1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}+\\frac{\\lambda}{2}\\sum_{i=1}^{n_{m}}\\sum_{k=1}^{n}\\left(x_{k}^{(i)}\\right)^{2}\n$$\n\n\nw,b\n\n![img](/img/machine-learning-notes/pic-32.png)\n\nwbx\n\n![img](/img/machine-learning-notes/pic-33.png)\n\n[](https://blog.csdn.net/zhu_xian_gang/article/details/130243870)\n\n### \n\n1-\n\n0-\n\n?-\n\n$y^{(i,j)}=1$$g(w^{(j)} \\cdot x^{(i)}+ b^{(i)})$glogistic\n\n![img](/img/machine-learning-notes/pic-34.png)\n\n### \n\n**Mean Normalization**\n\n- $\\mu$\n- $x_1 = \\frac{x_1-\\mu}{max-min}$\n\n$\\mu_i$$u$\n\nji\n\n$w^{(j)} \\cdot x^{(i)}+ b^{(i)} + \\mu_i$\n\n0\n\n### \n\n$i$$x^{(i)}$$k$$x^{(k)}$$x^{(i)}$\n\n$\\sum_{l=1}^n(x_l^{(k)} - x_l^{(i)})^2$\n\n$||x^{(k)} - x^{(i)}||^2$\n\n### \n\n****\n\n- \n- \n\n****\n\n### \n\n\n\n\n\n$v^{(j)}$$v^{(i)}$\n\nv\n\nuser networkmovie network\n\n\n\n$$\nJ=\\sum_{(i,j):r(i,j)=1}\\left(v_{u}^{(j)}\\cdot v_{m}^{(i)}-y^{(i,j)}\\right)^{2}+\\text{NN regularization term}\n$$\n\n\ni$||v^{(k)} - v^{(i)}||^2$\n\n### Retrieval and Ranking\n\n\n\n103top10top20\n\n\n\n\n\n## \n\nReinforcement LearningRLAgentEnvironmentRewardTrial and Error\n\n\n\n### \n\n\n\n$\\gamma$10.9,0.99\n\n$\\text{Return} = R_1 + \\gamma R_2 + \\gamma^2R_3+...$\n\n### \n\nstatea\n\n$\\pi(s) = a$sa\n\n### \n\nMarkov Decision Process(MDP)\n\n![img](/img/machine-learning-notes/pic-35.png)\n\n### -\n\nState-action value functionQ-function,Q*,Optimal Q function\n\n$Q(s,a)$sa\n\ns$max_aQ(s,a)$\n\ns$max_aQ(s,a)$\n\n### Bellman\n\n$s$:\n\n$a$:\n\n$R(s)$:\n\n$s'$:a\n\n$a'$:s'\n\n$Q(s,a) = R(s)+\\gamma max_{a'}Q(s',a')$\n\nR(s)\n\ns'\n\n$\\text{Return} = R_1 + \\gamma R_2 + \\gamma^2R_3+... = R_1 + \\gamma[R_2 + \\gamma R_3+...]$\n\n### \n\n\n\n\n\n$\\text{Return} = \\text{Average}(R_1 + \\gamma R_2 + \\gamma^2R_3+...) = \\text{E}(R_1 + \\gamma R_2 + \\gamma^2R_3+...)$\n\nBellman Equation\n\n$Q(s,a) = R(s)+\\gamma \\text{E} [max_{a'}Q(s',a')]$\n\n### \n\n\n\nxyz\n\n\n\n### \n\n![img](/img/machine-learning-notes/pic-36.png)\n\n$Q(s,a)$\n\n\n\n$(s,a,R(s),s')$\n\n10k $(s,a,R(s),s')$Replay Buffer\n\n\n\n\t10k$x=(s,a)$$y = R(s)+\\gamma max_{a'}Q(s',a')$\n\n\t$Q_{new}$$Q_{new}(s,a) \\approx y$\n\n$Q=Q_{new}$\n\nQQ\n\n****\n\n- \n\n\n\n![img](/img/machine-learning-notes/pic-37.png)\n\n- $\\epsilon$\n\nQaQ\n\n0.95Qgreedyexploitation0.05exploration\n\nepsilonepsilone\n\n- $mini-batch$\n\n\n\n![img](/img/machine-learning-notes/pic-38.png)\n\n1000\n\n1000wb10001000\n\n10k\n\n- \n\n$Q=Q_{new}$$w,b$$w_{new},b_{new}$\n\n\n$$\nw = 0.01w_{new} + 0.99w\n$$\n\n$$\nb = 0.01b_{new} + 0.99b\n$$\n\n\n","slug":"machine-learning-notes","published":1,"updated":"2025-02-28T02:56:54.489Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff8000jss991ow01et2","content":"<h1 id=\"Course-1\"><a href=\"#Course-1\" class=\"headerlink\" title=\"Course 1\"></a>Course 1</h1><p>xy<strong></strong><strong></strong></p>\n<p>xy<strong></strong><strong></strong><strong></strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$$<br>y^i &#x3D; wx^i+b<br>$$</p>\n<p></p>\n<p>$$<br>J(w,b) &#x3D; \\frac{1}{2m} \\sum_{i&#x3D;1}^{m} {(y^i-\\hat{y})}^2<br>$$</p>\n<p>$y^i$$\\hat{y}$</p>\n<ul>\n<li></li>\n<li>1&#x2F;2</li>\n</ul>\n<p>losscost</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p><code>learning_rate</code>$\\alpha$,$\\alpha \\subseteq [0,1]$</p>\n<p>$w &#x3D; w- \\alpha \\frac{\\partial{J(w,b)}}{\\partial{w}}$</p>\n<p>$b &#x3D; b- \\alpha \\frac{\\partial{J(w,b)}}{\\partial{b}}$</p>\n<ul>\n<li><strong></strong></li>\n</ul>\n<p><img src=\"/img/machine-learning-notes/pic-1.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>$\\alpha$</p>\n<p>$\\alpha$</p>\n<p>$J(w,b)$$\\alpha$</p>\n<p></p>\n<p>$\\frac{\\partial{J(w,b)}}{\\partial{w}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i$</p>\n<p>$\\frac{\\partial{J(w,b)}}{\\partial{b}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)$</p>\n<p>$f(x^i) &#x3D; wx^i+b$</p>\n<p></p>\n<p>$min(J(w,b))$</p>\n<p>batch gradient descent</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$n$$\\vec{x} &#x3D; \\begin{bmatrix} x_1 &amp; x_2 &amp; x_3 &amp;  \\end{bmatrix}$$\\vec{w} &#x3D; \\begin{bmatrix} w_1 &amp; w_2 &amp; w_3 &amp;  \\end{bmatrix}$</p>\n<p>$f_{\\vec{w},b}&#x3D;\\vec{w} \\cdot \\vec{x} +b$</p>\n<p><code></code>(dot)</p>\n<p>$$<br>\\vec{w} \\cdot \\vec{x} &#x3D; w_1<em>x_1+w_2</em>x_2+.+w_n*x_n<br>$$</p>\n<p><strong></strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f = np.dot(w, x) + b</span><br></pre></td></tr></table></figure>\n\n<p><strong></strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-2.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-2.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>PS: $w,b$<strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> </p>\n<p></p>\n<p></p>\n<ul>\n<li><strong></strong>$x_{1,scale} &#x3D; \\frac{x_1}{max}$ $x \\in [0,1]$</li>\n<li><strong>Mean Normalization</strong><ul>\n<li>$\\mu$</li>\n<li>$x_1 &#x3D; \\frac{x_1-\\mu}{max-min}$</li>\n</ul>\n</li>\n<li><strong><code>Z-score</code></strong><ul>\n<li>$\\sigma$$\\mu$</li>\n<li>$x_1 &#x3D; \\frac{x_1-\\mu}{\\sigma}$</li>\n</ul>\n</li>\n</ul>\n<p><strong></strong></p>\n<ol>\n<li>iteration-loss 2. loss</li>\n</ol>\n<p><strong></strong>0.0013$J(w,b)$$\\alpha$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p><strong></strong>$x^q$$f(x)&#x3D;w_1x^3+w_2x^2+w_1x^1+b$</p>\n<p></p>\n<h2 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"-\"></a>-</h2><p></p>\n<h3 id=\"sigmoid\"><a href=\"#sigmoid\" class=\"headerlink\" title=\"sigmoid\"></a>sigmoid</h3><p>$(0,1)$</p>\n<p>$g(z)&#x3D; \\frac{1}{1+e^{-z}},z \\subseteq R$</p>\n<p><strong>logistic regression</strong>:</p>\n<p>$f_{\\vec{w},b}(\\vec{x})&#x3D;g(\\vec{w}  \\vec{x}+b) &#x3D; \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$</p>\n<p>1</p>\n<p>$f_{\\vec{w},b}(\\vec{x})&#x3D;P(y&#x3D;1|\\vec{x};\\vec{w},b)$</p>\n<h3 id=\"decision-boundary\"><a href=\"#decision-boundary\" class=\"headerlink\" title=\"decision boundary\"></a>decision boundary</h3><p>0.5$\\vec{w}  \\vec{x}+b \\ge 0$1$\\vec{w}  \\vec{x}+b &lt;0$0</p>\n<p>$\\vec{w}  \\vec{x}+b &#x3D; 0$</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$J(w,b)$<strong></strong></p>\n<p></p>\n<p>$$<br>J(w,b)&#x3D;\\frac{1}{m}\\sum_{i-1}^{m}L(f_{w,b}(x^{(i)},y^{(i)})<br>$$<br>LlossJcost</p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-log(f_{w,b}(x^{(i)})) \\quad if\\quad y^{(i)}&#x3D;1<br>$$<br><img src=\"/img/machine-learning-notes/pic-3.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-3.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>y11</p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-log(1-f_{w,b}(x^{(i)})) \\quad if \\quad y^{(i)}&#x3D;0<br>$$<br><img src=\"/img/machine-learning-notes/pic-4.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-4.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>y00 </p>\n<p><strong></strong>                                                                                                                                                                                                                                                                                          </p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))<br>$$</p>\n<p></p>\n<p>$$<br>J(w,b) &#x3D; -\\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))<br>$$</p>\n<p></p>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p>J</p>\n<p>$\\frac{\\partial{J(w,b)}}{\\partial{w}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i$</p>\n<p>$\\frac{\\partial{J(w,b)}}{\\partial{b}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)$</p>\n<p>$f(x^i) &#x3D; \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>high biashigh variance</p>\n<p><img src=\"/img/machine-learning-notes/pic-5.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-5.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><strong></strong></p>\n<ul>\n<li></li>\n<li></li>\n<li>(Regularization)$w_j$</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>$$<br>J(w,b) &#x3D; \\frac{1}{2m} \\sum_{i&#x3D;1}^{m} {(y^i-\\hat{y})}^2 + \\frac{\\lambda}{\\alpha m}\\sum_{j&#x3D;1}^{n} {w_j}^2<br>$$</p>\n<p>$\\lambda$$\\alpha$</p>\n<p>$$<br>J(w,b) &#x3D; \\frac{1}{2m} \\sum_{i&#x3D;1}^{m} {(y^i-\\hat{y})}^2 + \\frac{\\lambda}{2 m}\\sum_{j&#x3D;1}^{n} {w_j}^2<br>$$</p>\n<p>$w_j$0</p>\n<p>$b$</p>\n<p>**$\\lambda$**</p>\n<ul>\n<li></li>\n</ul>\n<p>$J(w,b)$w,b</p>\n<p>$$<br>\\frac{\\partial{J(w,b)}}{\\partial{w}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i+\\frac{\\lambda}{m}\\sum_{j&#x3D;1}^{m}{w_j}<br>$$</p>\n<p>$$<br>w &#x3D; w- \\alpha (\\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i+\\frac{\\lambda}{m}\\sum_{j&#x3D;1}^{m}{w_j}) &#x3D; (1-\\alpha \\frac{\\lambda}{m})w+..<br>$$</p>\n<ul>\n<li></li>\n</ul>\n<p>$$<br>J(w,b) &#x3D; -\\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))+ \\frac{\\lambda}{2 m}\\sum_{j&#x3D;1}^{n} {w_j}^2<br>$$</p>\n<p><strong></strong></p>\n<p>$f(x^i) &#x3D; \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$</p>\n<p><img src=\"/img/machine-learning-notes/pic-6.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-6.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h1 id=\"Course-2\"><a href=\"#Course-2\" class=\"headerlink\" title=\"Course 2\"></a>Course 2</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>21<strong></strong></p>\n<p></p>\n<p></p>\n<p>-&gt;-&gt;</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>$\\vec{x}$$\\vec{a}_{i-1}$$\\vec{a}^{[l]}$&#x2F;</p>\n<p>$a_j^{[l]} &#x3D; g(\\vec{w}_j^{[l]} \\cdot \\vec{a}^{[l-1]} + b_j^{[l]})$</p>\n<p>$j$$l$$g(x)$<code>sigmod</code></p>\n<p><img src=\"/img/machine-learning-notes/pic-7.jpg\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-7.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>$a_j^{[l]}$$\\vec{a}^{[l]}$</p>\n<p><img src=\"/img/machine-learning-notes/pic-8.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-8.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h2 id=\"-forward-prop\"><a href=\"#-forward-prop\" class=\"headerlink\" title=\"(forward prop)\"></a>(forward prop)</h2><p></p>\n<p><strong></strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">dense</span>(<span class=\"params\">a_in, W, b, g</span>):</span><br><span class=\"line\">\tunits = W.shape[<span class=\"number\">1</span>] <span class=\"comment\"># Ww_j</span></span><br><span class=\"line\">\ta_out = np.zeros(units)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(units):</span><br><span class=\"line\">\t\tw = W[:, j]</span><br><span class=\"line\">\t\tz = np.dot(w, a_in) + b</span><br><span class=\"line\">\t\ta_out[j] = g(z)</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> a_out</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sequential</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    a1 = dense(x, W1, b1)</span><br><span class=\"line\">    a2 = dense(a1, W2, b2)</span><br><span class=\"line\">    a3 = dense(a2, W3, b3)</span><br><span class=\"line\">    f_x = a3</span><br><span class=\"line\">    <span class=\"keyword\">return</span> f_x</span><br></pre></td></tr></table></figure>\n\n<p><strong>TensorFlow&#x2F;Pytorch)</strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>X(<strong></strong>)</li>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ol>\n<p></p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))<br>$$<br></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>ReLU</code><code>sigmoid</code>$g(z) &#x3D; max(0,z)$</p>\n<p><img src=\"/img/machine-learning-notes/pic-9.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-9.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><strong></strong></p>\n<p>y<strong></strong></p>\n<ul>\n<li>&gt; sigmoid</li>\n<li>y&gt; linear</li>\n<li>y0 &gt; ReLU</li>\n</ul>\n<p><strong></strong>ReLU</p>\n<p><code>ReLU</code></p>\n<ul>\n<li></li>\n<li>ReLUx-&gt;-,sigmoid</li>\n</ul>\n<p><strong></strong></p>\n<p></p>\n<p>sigmoid</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong>softmax</strong>logistic </p>\n<p>$z_1&#x3D;\\vec{w_1}\\vec{x_1}+b_1$</p>\n<p>$a_1&#x3D;\\frac{e^{z_1}}{e^{z_1}++e^{z_n}} &#x3D; P(y&#x3D;1|\\vec{x})$</p>\n<p>N</p>\n<p>$z_i&#x3D;\\vec{w_1}\\vec{x_i}+b_i$</p>\n<p>$$<br>a_i &#x3D; \\frac{e^{z_i}}{\\sum_{k&#x3D;1}^{N} e^{z_i}}&#x3D;P(y&#x3D;i|\\vec{x})<br>$$<br>$a_1+a_2++a_N&#x3D;1$</p>\n<p><strong>softmax</strong></p>\n<p>logistic</p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))<br>$$</p>\n<p>$a_1 &#x3D; f_{w,b}(x^{(i)})$$y&#x3D;1$</p>\n<p>$a_2 &#x3D; 1-f_{w,b}(x^{(i)})$$y&#x3D;0$</p>\n<p></p>\n<p>$loss &#x3D; -log(a_1)$ $y&#x3D;1$</p>\n<p>$loss &#x3D; -log(a_2)$ $y&#x3D;0$</p>\n<p>softmax</p>\n<p>$$<br>loss(a_1,a_2,,a_N,y) &#x3D; \\left{\\begin{matrix} -log(a_1) \\quad if \\quad y&#x3D;1\\ -log(a_2) \\quad if \\quad y&#x3D;2 \\  \\ -log(a_N) \\quad if \\quad y&#x3D;N \\end{matrix}\\right.<br>$$</p>\n<p><strong>softmax</strong></p>\n<p>N</p>\n<p>$g(z_1)$$z_1$softmax$z_1  z_n$</p>\n<p><strong>softmax</strong></p>\n<p><a href=\"https://blog.csdn.net/muyuu/article/details/122757470\"></a></p>\n<p>$log$x0$a_i$</p>\n<p>$a_i$</p>\n<p><strong></strong><br>$$<br>loss_i&#x3D;-log(\\frac{e^{z_i}}{e_{z_1}++e_{z_N}})<br>$$</p>\n<p><code>linear</code>$a_i$<code>from_logits=True</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model.<span class=\"built_in\">compile</span>(loss=SparseCategoricalCrossEntropy(from_logits=<span class=\"literal\">True</span>)) <span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n<p><code>from_logits=True</code><a href=\"https://blog.csdn.net/muyuu/article/details/122762442\"></a></p>\n<p><code>softmax</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">logits = model(X)</span><br><span class=\"line\">f_x = tf.nn.softmax(logits)</span><br></pre></td></tr></table></figure>\n\n<p><strong></strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-10.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-10.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>nlogisticy</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"AdamAdaptive-Moment-estimation\"><a href=\"#AdamAdaptive-Moment-estimation\" class=\"headerlink\" title=\"AdamAdaptive Moment estimation\"></a>AdamAdaptive Moment estimation</h3><p></p>\n<p></p>\n<p>$\\alpha$</p>\n<p>$\\alpha$</p>\n<p>optimizer&#x3D;adam</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Convolutional-Layer\"><a href=\"#Convolutional-Layer\" class=\"headerlink\" title=\"Convolutional Layer\"></a>Convolutional Layer</h3><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<p> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>7382</p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-11.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-11.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><strong>error</strong></p>\n<p>$J_{train}$$J_{test}$</p>\n<p>erroraccurate rate</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$J_{train}$$J_{cv}$$J_{test}$</p>\n<p>cross validation<strong>dev set</strong>&#x2F;validation set</p>\n<p>$J_{train}$$J_{cv}$$J_{test}$</p>\n<p>622</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><strong></strong></h3><p><img src=\"/img/machine-learning-notes/pic-12.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-12.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><img src=\"/img/machine-learning-notes/pic-13.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-13.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p></p>\n<p></p>\n<p><strong></strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-14.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-14.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>&#x2F;<strong></strong>&#x2F;</p>\n<p><img src=\"/img/machine-learning-notes/pic-15.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-15.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><strong></strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-16.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-16.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p> </p>\n<p><img src=\"/img/machine-learning-notes/pic-17.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-17.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-18.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-18.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><img src=\"/img/machine-learning-notes/pic-19.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-19.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p></p>\n<p><strong></strong></p>\n<p></p>\n<p></p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">layer = Dense(unit=<span class=\"number\">25</span>, activation=<span class=\"string\">&quot;relu&quot;</span>, kernel_regularizer=L2(<span class=\"number\">0.01</span>))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><img src=\"/img/machine-learning-notes/pic-20.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-20.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong></p>\n<p>x</p>\n<p><strong></strong>OCR</p>\n<p>AI &#x3D; Code(algorithm&#x2F;model) + Data</p>\n<h2 id=\"Transfer-Learning\"><a href=\"#Transfer-Learning\" class=\"headerlink\" title=\"Transfer Learning\"></a>Transfer Learning</h2><p>0-91000</p>\n<p><img src=\"/img/machine-learning-notes/pic-21.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-21.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><strong></strong>(supervised pretraining)<strong></strong>(fine tuning)</p>\n<p></p>\n<p>x</p>\n<p><img src=\"/img/machine-learning-notes/pic-22.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-22.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><img src=\"/img/machine-learning-notes/pic-23.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-23.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-24.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-24.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>MLOps(Machine Learning operations)</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong><strong></strong></p>\n<p><strong>(precision)<strong></strong>(recall)</strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-25.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-25.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p></p>\n<p></p>\n<p>y&#x3D;1logistic0.5</p>\n<p>y&#x3D;1logistic0.5</p>\n<p>thresholdprecisionrecall</p>\n<p>F1 score</p>\n<p>$F1 score &#x3D; \\frac{1}{\\frac{1}{2}(\\frac{1}{P}+\\frac{1}{R})} &#x3D; 2\\frac{PR}{P+R}$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p><img src=\"/img/machine-learning-notes/pic-26.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-26.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<p></p>\n<ul>\n<li></li>\n</ul>\n<p>100%</p>\n<p></p>\n<p></p>\n<p></p>\n<h3 id=\"purity\"><a href=\"#purity\" class=\"headerlink\" title=\"purity\"></a>purity</h3><p>$p_1$$p_0 &#x3D; 1 - p_1$</p>\n<p>$H(p_1)&#x3D;-p_1log_2(p_1)-p_0log_2(p_0) &#x3D; -p_1log_2(p_1)-(1-p_1)log_2(1-p_1)$</p>\n<p>$0log(0) &#x3D; 0$</p>\n<p><img src=\"/img/machine-learning-notes/pic-27.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-27.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h3 id=\"Information-Gain\"><a href=\"#Information-Gain\" class=\"headerlink\" title=\"Information Gain\"></a>Information Gain</h3><p></p>\n<p>$H(p)$</p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-28.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-28.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-29.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-29.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>pw&#x2F;</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<p></p>\n<p></p>\n<ul>\n<li>100%</li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<h3 id=\"-One-Hot-Encoding\"><a href=\"#-One-Hot-Encoding\" class=\"headerlink\" title=\"(One Hot Encoding)\"></a>(One Hot Encoding)</h3><p>kk0&#x2F;1</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>109</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>(Variance)</p>\n<p>w&#x2F;</p>\n<p></p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Tree Ensemble</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>nn</p>\n<h3 id=\"Random-Forest\"><a href=\"#Random-Forest\" class=\"headerlink\" title=\"Random Forest\"></a>Random Forest</h3><p>mb100m</p>\n<p>bBagged Decision Tree</p>\n<p>n$k &lt; n$n$k &#x3D; \\sqrt{n}$</p>\n<h3 id=\"XGBoosteXtreme-Gradient-Boosting\"><a href=\"#XGBoosteXtreme-Gradient-Boosting\" class=\"headerlink\" title=\"XGBoosteXtreme Gradient Boosting\"></a>XGBoosteXtreme Gradient Boosting</h3><p>$\\frac{1}{m}$</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<ul>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>+</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n<h1 id=\"Course-3\"><a href=\"#Course-3\" class=\"headerlink\" title=\"Course 3\"></a>Course 3</h1><p></p>\n<ul>\n<li><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"K-means\"><a href=\"#K-means\" class=\"headerlink\" title=\"K-means\"></a>K-means</h3><p>K$\\mu_1 ,\\mu_2 \\mu_k$$\\mu$</p>\n<ul>\n<li>centroid</li>\n<li></li>\n<li>K-means</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Repeat&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i = 1 to m</span><br><span class=\"line\">\t\tc_i x_i1-k</span><br><span class=\"line\">\t\t// min_k ||x_i - u_k||</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i = 1 to k</span><br><span class=\"line\">\t\tu_k</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/img/machine-learning-notes/pic-30.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-30.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>$c^{(i)}$$x^{(i)}$1-k</p>\n<p>$u_k$k</p>\n<p>$\\mu _{c^{(i)}}$$x^{(i)}$</p>\n<p><strong></strong></p>\n<p>Distortion Function</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$K&lt;m$</p>\n<p>K$\\mu_1 ,\\mu_2 \\mu_k$</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i = 1 to 100&#123;</span><br><span class=\"line\">\t</span><br><span class=\"line\">\tc_i, u_i</span><br><span class=\"line\">\tJ</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">Ji501000</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Elbow Method</strong></p>\n<p>K</p>\n<p>K</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Density-estimation\"><a href=\"#Density-estimation\" class=\"headerlink\" title=\"Density estimation\"></a>Density estimation</h3><p>$p(x)$x$x_{test}$$p$$p(x_{test})&lt;\\epsilon$anomaly</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Gaussian Distribution(Normal Distribution)</p>\n<p>$p(x)&#x3D;\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{\\frac{-(x-\\mu)}{2\\sigma^2}^2}$</p>\n<p>$\\mu$$\\sigma$</p>\n<p><img src=\"/img/machine-learning-notes/pic-31.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-31.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$\\vec{x}$$\\vec{x} &#x3D; [x_1, x_2  x_n]$</p>\n<p>$$<br>p(\\vec{x}) &#x3D; p(x_1;\\mu_1,\\sigma_1^2) * p(x_2;\\mu_2,\\sigma_2^2) <em></em> p(x_n;\\mu_n,\\sigma_n^2) &#x3D; \\prod_{j&#x3D;1}^np(x_j;\\mu_j,\\sigma_j^2)<br>$$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>cv0&#x2F;1$\\epsilon$cv</p>\n<p><strong></strong></p>\n<p>$x_1x_m$$p(x)$</p>\n<p>yepsilon10</p>\n<p>PrecisionRecallF1$\\epsilon$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li>cv</li>\n<li>cv</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$r(i,j) &#x3D; 1$ji</p>\n<p>$y^{(i,j)}$ji</p>\n<p>$w^{(j)}, b^{(j)}$j</p>\n<p>$x^{(i)}$i</p>\n<p>ji$w^{(j)} \\cdot x^{(i)}+b^{(j)}$</p>\n<p>$m^{(j)}$j</p>\n<p>$w^{(j)}, b^{(j)}$</p>\n<p>$$<br>\\min_{w^{(j)}b^{(j)}}J\\left(w^{(j)},b^{(j)}\\right)&#x3D;\\frac{1}{2m^{(j)}}\\sum_{(i:r(i,j)&#x3D;1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}+\\frac{\\lambda}{2m^{(j)}}\\sum_{k&#x3D;1}^{n}\\left(w_{k}^{(j)}\\right)^{2}<br>$$</p>\n<p>$w^{(1)},b^{(1)},w^{(2)},b^{(2)},,w^{(n_u)},b^{(n_u)}$</p>\n<p>$$<br>\\left.\\mathrm{J}\\left(<br>\\begin{array}<br>{cc}{w^{(1)},} &amp; {,w^{(n_{u})}} \\<br>{b^{(1)},} &amp; {,b^{(n_{u})}}<br>\\end{array}\\right.\\right)&#x3D;\\frac{1}{2}\\sum_{j&#x3D;1}^{n_{u}}\\sum_{i:r(i,j)&#x3D;1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}\\quad+\\frac{\\lambda}{2}\\sum_{j&#x3D;1}^{n_{u}}\\sum_{k&#x3D;1}^{n}\\left(w_{k}^{(j)}\\right)^{2}<br>$$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$w^{(j)}, b^{(j)}$</p>\n<p>$$<br>\\mathrm{J}(x^{(i)})&#x3D;\\frac{1}{2}\\sum_{j:r(i,j)&#x3D;1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-{y^{(i,j)}}\\right)^{2}+\\frac{\\lambda}{2}\\sum_{k&#x3D;1}^{n}\\left(x_{k}^{(i)}\\right)^{2}<br>$$</p>\n<p>$x^{(1)},x^{(2)},,x^{(n_m)}$</p>\n<p>$$<br>\\mathrm{J}\\left(x^{(1)},x^{(2)},,x^{(n_{m})}\\right)&#x3D;\\frac{1}{2}\\sum_{i&#x3D;1}^{n_{m}}\\sum_{j:r(i,j)&#x3D;1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}+\\frac{\\lambda}{2}\\sum_{i&#x3D;1}^{n_{m}}\\sum_{k&#x3D;1}^{n}\\left(x_{k}^{(i)}\\right)^{2}<br>$$</p>\n<p>w,b</p>\n<p><img src=\"/img/machine-learning-notes/pic-32.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-32.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>wbx</p>\n<p><img src=\"/img/machine-learning-notes/pic-33.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-33.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p><a href=\"https://blog.csdn.net/zhu_xian_gang/article/details/130243870\"></a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>1-</p>\n<p>0-</p>\n<p>?-</p>\n<p>$y^{(i,j)}&#x3D;1$$g(w^{(j)} \\cdot x^{(i)}+ b^{(i)})$glogistic</p>\n<p><img src=\"/img/machine-learning-notes/pic-34.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-34.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Mean Normalization</strong></p>\n<ul>\n<li>$\\mu$</li>\n<li>$x_1 &#x3D; \\frac{x_1-\\mu}{max-min}$</li>\n</ul>\n<p>$\\mu_i$$u$</p>\n<p>ji</p>\n<p>$w^{(j)} \\cdot x^{(i)}+ b^{(i)} + \\mu_i$</p>\n<p>0</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$i$$x^{(i)}$$k$$x^{(k)}$$x^{(i)}$</p>\n<p>$\\sum_{l&#x3D;1}^n(x_l^{(k)} - x_l^{(i)})^2$</p>\n<p>$||x^{(k)} - x^{(i)}||^2$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong></strong></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p><strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<p>$v^{(j)}$$v^{(i)}$</p>\n<p>v</p>\n<p>user networkmovie network</p>\n<p></p>\n<p>$$<br>J&#x3D;\\sum_{(i,j):r(i,j)&#x3D;1}\\left(v_{u}^{(j)}\\cdot v_{m}^{(i)}-y^{(i,j)}\\right)^{2}+\\text{NN regularization term}<br>$$</p>\n<p>i$||v^{(k)} - v^{(i)}||^2$</p>\n<h3 id=\"Retrieval-and-Ranking\"><a href=\"#Retrieval-and-Ranking\" class=\"headerlink\" title=\"Retrieval and Ranking\"></a>Retrieval and Ranking</h3><p></p>\n<p>103top10top20</p>\n<p></p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Reinforcement LearningRLAgentEnvironmentRewardTrial and Error</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>$\\gamma$10.9,0.99</p>\n<p>$\\text{Return} &#x3D; R_1 + \\gamma R_2 + \\gamma^2R_3+$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>statea</p>\n<p>$\\pi(s) &#x3D; a$sa</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Markov Decision Process(MDP)</p>\n<p><img src=\"/img/machine-learning-notes/pic-35.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-35.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"-\"></a>-</h3><p>State-action value functionQ-function,Q*,Optimal Q function</p>\n<p>$Q(s,a)$sa</p>\n<p>s$max_aQ(s,a)$</p>\n<p>s$max_aQ(s,a)$</p>\n<h3 id=\"Bellman\"><a href=\"#Bellman\" class=\"headerlink\" title=\"Bellman\"></a>Bellman</h3><p>$s$:</p>\n<p>$a$:</p>\n<p>$R(s)$:</p>\n<p>$s$:a</p>\n<p>$a$:s</p>\n<p>$Q(s,a) &#x3D; R(s)+\\gamma max_{a}Q(s,a)$</p>\n<p>R(s)</p>\n<p>s</p>\n<p>$\\text{Return} &#x3D; R_1 + \\gamma R_2 + \\gamma^2R_3+ &#x3D; R_1 + \\gamma[R_2 + \\gamma R_3+]$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<p>$\\text{Return} &#x3D; \\text{Average}(R_1 + \\gamma R_2 + \\gamma^2R_3+) &#x3D; \\text{E}(R_1 + \\gamma R_2 + \\gamma^2R_3+)$</p>\n<p>Bellman Equation</p>\n<p>$Q(s,a) &#x3D; R(s)+\\gamma \\text{E} [max_{a}Q(s,a)]$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>xyz</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/img/machine-learning-notes/pic-36.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-36.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>$Q(s,a)$</p>\n<p></p>\n<p>$(s,a,R(s),s)$</p>\n<p>10k $(s,a,R(s),s)$Replay Buffer</p>\n<p></p>\n<p>\t10k$x&#x3D;(s,a)$$y &#x3D; R(s)+\\gamma max_{a}Q(s,a)$</p>\n<p>\t$Q_{new}$$Q_{new}(s,a) \\approx y$</p>\n<p>$Q&#x3D;Q_{new}$</p>\n<p>QQ</p>\n<p><strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-37.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-37.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<ul>\n<li>$\\epsilon$</li>\n</ul>\n<p>QaQ</p>\n<p>0.95Qgreedyexploitation0.05exploration</p>\n<p>epsilonepsilone</p>\n<ul>\n<li>$mini-batch$</li>\n</ul>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-38.png\" class=\"lazyload placeholder\" data-srcset=\"/img/machine-learning-notes/pic-38.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p>1000</p>\n<p>1000wb10001000</p>\n<p>10k</p>\n<ul>\n<li></li>\n</ul>\n<p>$Q&#x3D;Q_{new}$$w,b$$w_{new},b_{new}$</p>\n<p><br>$$<br>w &#x3D; 0.01w_{new} + 0.99w<br>$$</p>\n<p>$$<br>b &#x3D; 0.01b_{new} + 0.99b<br>$$</p>\n<p></p>\n","more":"<h1 id=\"Course-1\"><a href=\"#Course-1\" class=\"headerlink\" title=\"Course 1\"></a>Course 1</h1><p>xy<strong></strong><strong></strong></p>\n<p>xy<strong></strong><strong></strong><strong></strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$$<br>y^i &#x3D; wx^i+b<br>$$</p>\n<p></p>\n<p>$$<br>J(w,b) &#x3D; \\frac{1}{2m} \\sum_{i&#x3D;1}^{m} {(y^i-\\hat{y})}^2<br>$$</p>\n<p>$y^i$$\\hat{y}$</p>\n<ul>\n<li></li>\n<li>1&#x2F;2</li>\n</ul>\n<p>losscost</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p><code>learning_rate</code>$\\alpha$,$\\alpha \\subseteq [0,1]$</p>\n<p>$w &#x3D; w- \\alpha \\frac{\\partial{J(w,b)}}{\\partial{w}}$</p>\n<p>$b &#x3D; b- \\alpha \\frac{\\partial{J(w,b)}}{\\partial{b}}$</p>\n<ul>\n<li><strong></strong></li>\n</ul>\n<p><img src=\"/img/machine-learning-notes/pic-1.png\" alt=\"img\"></p>\n<p>$\\alpha$</p>\n<p>$\\alpha$</p>\n<p>$J(w,b)$$\\alpha$</p>\n<p></p>\n<p>$\\frac{\\partial{J(w,b)}}{\\partial{w}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i$</p>\n<p>$\\frac{\\partial{J(w,b)}}{\\partial{b}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)$</p>\n<p>$f(x^i) &#x3D; wx^i+b$</p>\n<p></p>\n<p>$min(J(w,b))$</p>\n<p>batch gradient descent</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$n$$\\vec{x} &#x3D; \\begin{bmatrix} x_1 &amp; x_2 &amp; x_3 &amp;  \\end{bmatrix}$$\\vec{w} &#x3D; \\begin{bmatrix} w_1 &amp; w_2 &amp; w_3 &amp;  \\end{bmatrix}$</p>\n<p>$f_{\\vec{w},b}&#x3D;\\vec{w} \\cdot \\vec{x} +b$</p>\n<p><code></code>(dot)</p>\n<p>$$<br>\\vec{w} \\cdot \\vec{x} &#x3D; w_1<em>x_1+w_2</em>x_2+.+w_n*x_n<br>$$</p>\n<p><strong></strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">f = np.dot(w, x) + b</span><br></pre></td></tr></table></figure>\n\n<p><strong></strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-2.png\" alt=\"img\"></p>\n<p>PS: $w,b$<strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> </p>\n<p></p>\n<p></p>\n<ul>\n<li><strong></strong>$x_{1,scale} &#x3D; \\frac{x_1}{max}$ $x \\in [0,1]$</li>\n<li><strong>Mean Normalization</strong><ul>\n<li>$\\mu$</li>\n<li>$x_1 &#x3D; \\frac{x_1-\\mu}{max-min}$</li>\n</ul>\n</li>\n<li><strong><code>Z-score</code></strong><ul>\n<li>$\\sigma$$\\mu$</li>\n<li>$x_1 &#x3D; \\frac{x_1-\\mu}{\\sigma}$</li>\n</ul>\n</li>\n</ul>\n<p><strong></strong></p>\n<ol>\n<li>iteration-loss 2. loss</li>\n</ol>\n<p><strong></strong>0.0013$J(w,b)$$\\alpha$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p><strong></strong>$x^q$$f(x)&#x3D;w_1x^3+w_2x^2+w_1x^1+b$</p>\n<p></p>\n<h2 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"-\"></a>-</h2><p></p>\n<h3 id=\"sigmoid\"><a href=\"#sigmoid\" class=\"headerlink\" title=\"sigmoid\"></a>sigmoid</h3><p>$(0,1)$</p>\n<p>$g(z)&#x3D; \\frac{1}{1+e^{-z}},z \\subseteq R$</p>\n<p><strong>logistic regression</strong>:</p>\n<p>$f_{\\vec{w},b}(\\vec{x})&#x3D;g(\\vec{w}  \\vec{x}+b) &#x3D; \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$</p>\n<p>1</p>\n<p>$f_{\\vec{w},b}(\\vec{x})&#x3D;P(y&#x3D;1|\\vec{x};\\vec{w},b)$</p>\n<h3 id=\"decision-boundary\"><a href=\"#decision-boundary\" class=\"headerlink\" title=\"decision boundary\"></a>decision boundary</h3><p>0.5$\\vec{w}  \\vec{x}+b \\ge 0$1$\\vec{w}  \\vec{x}+b &lt;0$0</p>\n<p>$\\vec{w}  \\vec{x}+b &#x3D; 0$</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$J(w,b)$<strong></strong></p>\n<p></p>\n<p>$$<br>J(w,b)&#x3D;\\frac{1}{m}\\sum_{i-1}^{m}L(f_{w,b}(x^{(i)},y^{(i)})<br>$$<br>LlossJcost</p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-log(f_{w,b}(x^{(i)})) \\quad if\\quad y^{(i)}&#x3D;1<br>$$<br><img src=\"/img/machine-learning-notes/pic-3.png\" alt=\"img\"></p>\n<p>y11</p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-log(1-f_{w,b}(x^{(i)})) \\quad if \\quad y^{(i)}&#x3D;0<br>$$<br><img src=\"/img/machine-learning-notes/pic-4.png\" alt=\"img\"></p>\n<p>y00 </p>\n<p><strong></strong>                                                                                                                                                                                                                                                                                          </p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))<br>$$</p>\n<p></p>\n<p>$$<br>J(w,b) &#x3D; -\\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))<br>$$</p>\n<p></p>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><p>J</p>\n<p>$\\frac{\\partial{J(w,b)}}{\\partial{w}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i$</p>\n<p>$\\frac{\\partial{J(w,b)}}{\\partial{b}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)$</p>\n<p>$f(x^i) &#x3D; \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>high biashigh variance</p>\n<p><img src=\"/img/machine-learning-notes/pic-5.png\" alt=\"img\"></p>\n<p><strong></strong></p>\n<ul>\n<li></li>\n<li></li>\n<li>(Regularization)$w_j$</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>$$<br>J(w,b) &#x3D; \\frac{1}{2m} \\sum_{i&#x3D;1}^{m} {(y^i-\\hat{y})}^2 + \\frac{\\lambda}{\\alpha m}\\sum_{j&#x3D;1}^{n} {w_j}^2<br>$$</p>\n<p>$\\lambda$$\\alpha$</p>\n<p>$$<br>J(w,b) &#x3D; \\frac{1}{2m} \\sum_{i&#x3D;1}^{m} {(y^i-\\hat{y})}^2 + \\frac{\\lambda}{2 m}\\sum_{j&#x3D;1}^{n} {w_j}^2<br>$$</p>\n<p>$w_j$0</p>\n<p>$b$</p>\n<p>**$\\lambda$**</p>\n<ul>\n<li></li>\n</ul>\n<p>$J(w,b)$w,b</p>\n<p>$$<br>\\frac{\\partial{J(w,b)}}{\\partial{w}} &#x3D; \\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i+\\frac{\\lambda}{m}\\sum_{j&#x3D;1}^{m}{w_j}<br>$$</p>\n<p>$$<br>w &#x3D; w- \\alpha (\\frac{1}{m} \\sum_{i&#x3D;1}^{m} (f(x^i)-y^i)x^i+\\frac{\\lambda}{m}\\sum_{j&#x3D;1}^{m}{w_j}) &#x3D; (1-\\alpha \\frac{\\lambda}{m})w+..<br>$$</p>\n<ul>\n<li></li>\n</ul>\n<p>$$<br>J(w,b) &#x3D; -\\frac{1}{m} (y^{(i)} log(f_{w,b}(x^{(i)})) + (1-y^{(i)})log(1-f_{w,b}(x^{(i)})))+ \\frac{\\lambda}{2 m}\\sum_{j&#x3D;1}^{n} {w_j}^2<br>$$</p>\n<p><strong></strong></p>\n<p>$f(x^i) &#x3D; \\frac{1}{1+e^{-(\\vec{w}  \\vec{x}+b)}}$</p>\n<p><img src=\"/img/machine-learning-notes/pic-6.png\" alt=\"img\"></p>\n<h1 id=\"Course-2\"><a href=\"#Course-2\" class=\"headerlink\" title=\"Course 2\"></a>Course 2</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>21<strong></strong></p>\n<p></p>\n<p></p>\n<p>-&gt;-&gt;</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>$\\vec{x}$$\\vec{a}_{i-1}$$\\vec{a}^{[l]}$&#x2F;</p>\n<p>$a_j^{[l]} &#x3D; g(\\vec{w}_j^{[l]} \\cdot \\vec{a}^{[l-1]} + b_j^{[l]})$</p>\n<p>$j$$l$$g(x)$<code>sigmod</code></p>\n<p><img src=\"/img/machine-learning-notes/pic-7.jpg\" alt=\"img\"></p>\n<p>$a_j^{[l]}$$\\vec{a}^{[l]}$</p>\n<p><img src=\"/img/machine-learning-notes/pic-8.png\" alt=\"img\"></p>\n<h2 id=\"-forward-prop\"><a href=\"#-forward-prop\" class=\"headerlink\" title=\"(forward prop)\"></a>(forward prop)</h2><p></p>\n<p><strong></strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">dense</span>(<span class=\"params\">a_in, W, b, g</span>):</span><br><span class=\"line\">\tunits = W.shape[<span class=\"number\">1</span>] <span class=\"comment\"># Ww_j</span></span><br><span class=\"line\">\ta_out = np.zeros(units)</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(units):</span><br><span class=\"line\">\t\tw = W[:, j]</span><br><span class=\"line\">\t\tz = np.dot(w, a_in) + b</span><br><span class=\"line\">\t\ta_out[j] = g(z)</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> a_out</span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sequential</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    a1 = dense(x, W1, b1)</span><br><span class=\"line\">    a2 = dense(a1, W2, b2)</span><br><span class=\"line\">    a3 = dense(a2, W3, b3)</span><br><span class=\"line\">    f_x = a3</span><br><span class=\"line\">    <span class=\"keyword\">return</span> f_x</span><br></pre></td></tr></table></figure>\n\n<p><strong>TensorFlow&#x2F;Pytorch)</strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>X(<strong></strong>)</li>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ol>\n<p></p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))<br>$$<br></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><code>ReLU</code><code>sigmoid</code>$g(z) &#x3D; max(0,z)$</p>\n<p><img src=\"/img/machine-learning-notes/pic-9.png\" alt=\"img\"></p>\n<p><strong></strong></p>\n<p>y<strong></strong></p>\n<ul>\n<li>&gt; sigmoid</li>\n<li>y&gt; linear</li>\n<li>y0 &gt; ReLU</li>\n</ul>\n<p><strong></strong>ReLU</p>\n<p><code>ReLU</code></p>\n<ul>\n<li></li>\n<li>ReLUx-&gt;-,sigmoid</li>\n</ul>\n<p><strong></strong></p>\n<p></p>\n<p>sigmoid</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong>softmax</strong>logistic </p>\n<p>$z_1&#x3D;\\vec{w_1}\\vec{x_1}+b_1$</p>\n<p>$a_1&#x3D;\\frac{e^{z_1}}{e^{z_1}++e^{z_n}} &#x3D; P(y&#x3D;1|\\vec{x})$</p>\n<p>N</p>\n<p>$z_i&#x3D;\\vec{w_1}\\vec{x_i}+b_i$</p>\n<p>$$<br>a_i &#x3D; \\frac{e^{z_i}}{\\sum_{k&#x3D;1}^{N} e^{z_i}}&#x3D;P(y&#x3D;i|\\vec{x})<br>$$<br>$a_1+a_2++a_N&#x3D;1$</p>\n<p><strong>softmax</strong></p>\n<p>logistic</p>\n<p>$$<br>L(f_{w,b}(x^{(i)},y^{(i)})&#x3D;-y^{(i)} log(f_{w,b}(x^{(i)})) - (1-y^{(i)})log(1-f_{w,b}(x^{(i)}))<br>$$</p>\n<p>$a_1 &#x3D; f_{w,b}(x^{(i)})$$y&#x3D;1$</p>\n<p>$a_2 &#x3D; 1-f_{w,b}(x^{(i)})$$y&#x3D;0$</p>\n<p></p>\n<p>$loss &#x3D; -log(a_1)$ $y&#x3D;1$</p>\n<p>$loss &#x3D; -log(a_2)$ $y&#x3D;0$</p>\n<p>softmax</p>\n<p>$$<br>loss(a_1,a_2,,a_N,y) &#x3D; \\left{\\begin{matrix} -log(a_1) \\quad if \\quad y&#x3D;1\\ -log(a_2) \\quad if \\quad y&#x3D;2 \\  \\ -log(a_N) \\quad if \\quad y&#x3D;N \\end{matrix}\\right.<br>$$</p>\n<p><strong>softmax</strong></p>\n<p>N</p>\n<p>$g(z_1)$$z_1$softmax$z_1  z_n$</p>\n<p><strong>softmax</strong></p>\n<p><a href=\"https://blog.csdn.net/muyuu/article/details/122757470\"></a></p>\n<p>$log$x0$a_i$</p>\n<p>$a_i$</p>\n<p><strong></strong><br>$$<br>loss_i&#x3D;-log(\\frac{e^{z_i}}{e_{z_1}++e_{z_N}})<br>$$</p>\n<p><code>linear</code>$a_i$<code>from_logits=True</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model.<span class=\"built_in\">compile</span>(loss=SparseCategoricalCrossEntropy(from_logits=<span class=\"literal\">True</span>)) <span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n<p><code>from_logits=True</code><a href=\"https://blog.csdn.net/muyuu/article/details/122762442\"></a></p>\n<p><code>softmax</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">logits = model(X)</span><br><span class=\"line\">f_x = tf.nn.softmax(logits)</span><br></pre></td></tr></table></figure>\n\n<p><strong></strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-10.png\" alt=\"img\"></p>\n<p>nlogisticy</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"AdamAdaptive-Moment-estimation\"><a href=\"#AdamAdaptive-Moment-estimation\" class=\"headerlink\" title=\"AdamAdaptive Moment estimation\"></a>AdamAdaptive Moment estimation</h3><p></p>\n<p></p>\n<p>$\\alpha$</p>\n<p>$\\alpha$</p>\n<p>optimizer&#x3D;adam</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Convolutional-Layer\"><a href=\"#Convolutional-Layer\" class=\"headerlink\" title=\"Convolutional Layer\"></a>Convolutional Layer</h3><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<p> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>7382</p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-11.png\" alt=\"img\"></p>\n<p><strong>error</strong></p>\n<p>$J_{train}$$J_{test}$</p>\n<p>erroraccurate rate</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$J_{train}$$J_{cv}$$J_{test}$</p>\n<p>cross validation<strong>dev set</strong>&#x2F;validation set</p>\n<p>$J_{train}$$J_{cv}$$J_{test}$</p>\n<p>622</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><strong></strong></h3><p><img src=\"/img/machine-learning-notes/pic-12.png\" alt=\"img\"></p>\n<p><img src=\"/img/machine-learning-notes/pic-13.png\" alt=\"img\"></p>\n<p></p>\n<p></p>\n<p><strong></strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-14.png\" alt=\"img\"></p>\n<p>&#x2F;<strong></strong>&#x2F;</p>\n<p><img src=\"/img/machine-learning-notes/pic-15.png\" alt=\"img\"></p>\n<p><strong></strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-16.png\" alt=\"img\"></p>\n<p> </p>\n<p><img src=\"/img/machine-learning-notes/pic-17.png\" alt=\"img\"></p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-18.png\" alt=\"img\"></p>\n<p><img src=\"/img/machine-learning-notes/pic-19.png\" alt=\"img\"></p>\n<p></p>\n<p><strong></strong></p>\n<p></p>\n<p></p>\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">layer = Dense(unit=<span class=\"number\">25</span>, activation=<span class=\"string\">&quot;relu&quot;</span>, kernel_regularizer=L2(<span class=\"number\">0.01</span>))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><img src=\"/img/machine-learning-notes/pic-20.png\" alt=\"img\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong></p>\n<p>x</p>\n<p><strong></strong>OCR</p>\n<p>AI &#x3D; Code(algorithm&#x2F;model) + Data</p>\n<h2 id=\"Transfer-Learning\"><a href=\"#Transfer-Learning\" class=\"headerlink\" title=\"Transfer Learning\"></a>Transfer Learning</h2><p>0-91000</p>\n<p><img src=\"/img/machine-learning-notes/pic-21.png\" alt=\"img\"></p>\n<p><strong></strong>(supervised pretraining)<strong></strong>(fine tuning)</p>\n<p></p>\n<p>x</p>\n<p><img src=\"/img/machine-learning-notes/pic-22.png\" alt=\"img\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><img src=\"/img/machine-learning-notes/pic-23.png\" alt=\"img\"></p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-24.png\" alt=\"img\"></p>\n<p>MLOps(Machine Learning operations)</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong><strong></strong></p>\n<p><strong>(precision)<strong></strong>(recall)</strong></p>\n<p><img src=\"/img/machine-learning-notes/pic-25.png\" alt=\"img\"></p>\n<p></p>\n<p></p>\n<p>y&#x3D;1logistic0.5</p>\n<p>y&#x3D;1logistic0.5</p>\n<p>thresholdprecisionrecall</p>\n<p>F1 score</p>\n<p>$F1 score &#x3D; \\frac{1}{\\frac{1}{2}(\\frac{1}{P}+\\frac{1}{R})} &#x3D; 2\\frac{PR}{P+R}$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p><img src=\"/img/machine-learning-notes/pic-26.png\" alt=\"img\"></p>\n<p><strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<p></p>\n<ul>\n<li></li>\n</ul>\n<p>100%</p>\n<p></p>\n<p></p>\n<p></p>\n<h3 id=\"purity\"><a href=\"#purity\" class=\"headerlink\" title=\"purity\"></a>purity</h3><p>$p_1$$p_0 &#x3D; 1 - p_1$</p>\n<p>$H(p_1)&#x3D;-p_1log_2(p_1)-p_0log_2(p_0) &#x3D; -p_1log_2(p_1)-(1-p_1)log_2(1-p_1)$</p>\n<p>$0log(0) &#x3D; 0$</p>\n<p><img src=\"/img/machine-learning-notes/pic-27.png\" alt=\"img\"></p>\n<h3 id=\"Information-Gain\"><a href=\"#Information-Gain\" class=\"headerlink\" title=\"Information Gain\"></a>Information Gain</h3><p></p>\n<p>$H(p)$</p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-28.png\" alt=\"img\"></p>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-29.png\" alt=\"img\"></p>\n<p>pw&#x2F;</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<p></p>\n<p></p>\n<ul>\n<li>100%</li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<h3 id=\"-One-Hot-Encoding\"><a href=\"#-One-Hot-Encoding\" class=\"headerlink\" title=\"(One Hot Encoding)\"></a>(One Hot Encoding)</h3><p>kk0&#x2F;1</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>109</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>(Variance)</p>\n<p>w&#x2F;</p>\n<p></p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Tree Ensemble</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>nn</p>\n<h3 id=\"Random-Forest\"><a href=\"#Random-Forest\" class=\"headerlink\" title=\"Random Forest\"></a>Random Forest</h3><p>mb100m</p>\n<p>bBagged Decision Tree</p>\n<p>n$k &lt; n$n$k &#x3D; \\sqrt{n}$</p>\n<h3 id=\"XGBoosteXtreme-Gradient-Boosting\"><a href=\"#XGBoosteXtreme-Gradient-Boosting\" class=\"headerlink\" title=\"XGBoosteXtreme Gradient Boosting\"></a>XGBoosteXtreme Gradient Boosting</h3><p>$\\frac{1}{m}$</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<ul>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>+</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n<h1 id=\"Course-3\"><a href=\"#Course-3\" class=\"headerlink\" title=\"Course 3\"></a>Course 3</h1><p></p>\n<ul>\n<li><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li></li>\n<li></li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"K-means\"><a href=\"#K-means\" class=\"headerlink\" title=\"K-means\"></a>K-means</h3><p>K$\\mu_1 ,\\mu_2 \\mu_k$$\\mu$</p>\n<ul>\n<li>centroid</li>\n<li></li>\n<li>K-means</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Repeat&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i = 1 to m</span><br><span class=\"line\">\t\tc_i x_i1-k</span><br><span class=\"line\">\t\t// min_k ||x_i - u_k||</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i = 1 to k</span><br><span class=\"line\">\t\tu_k</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/img/machine-learning-notes/pic-30.png\" alt=\"img\"></p>\n<p>$c^{(i)}$$x^{(i)}$1-k</p>\n<p>$u_k$k</p>\n<p>$\\mu _{c^{(i)}}$$x^{(i)}$</p>\n<p><strong></strong></p>\n<p>Distortion Function</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$K&lt;m$</p>\n<p>K$\\mu_1 ,\\mu_2 \\mu_k$</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> i = 1 to 100&#123;</span><br><span class=\"line\">\t</span><br><span class=\"line\">\tc_i, u_i</span><br><span class=\"line\">\tJ</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">Ji501000</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Elbow Method</strong></p>\n<p>K</p>\n<p>K</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Density-estimation\"><a href=\"#Density-estimation\" class=\"headerlink\" title=\"Density estimation\"></a>Density estimation</h3><p>$p(x)$x$x_{test}$$p$$p(x_{test})&lt;\\epsilon$anomaly</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Gaussian Distribution(Normal Distribution)</p>\n<p>$p(x)&#x3D;\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{\\frac{-(x-\\mu)}{2\\sigma^2}^2}$</p>\n<p>$\\mu$$\\sigma$</p>\n<p><img src=\"/img/machine-learning-notes/pic-31.png\" alt=\"img\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$\\vec{x}$$\\vec{x} &#x3D; [x_1, x_2  x_n]$</p>\n<p>$$<br>p(\\vec{x}) &#x3D; p(x_1;\\mu_1,\\sigma_1^2) * p(x_2;\\mu_2,\\sigma_2^2) <em></em> p(x_n;\\mu_n,\\sigma_n^2) &#x3D; \\prod_{j&#x3D;1}^np(x_j;\\mu_j,\\sigma_j^2)<br>$$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>cv0&#x2F;1$\\epsilon$cv</p>\n<p><strong></strong></p>\n<p>$x_1x_m$$p(x)$</p>\n<p>yepsilon10</p>\n<p>PrecisionRecallF1$\\epsilon$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<ul>\n<li>cv</li>\n<li>cv</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$r(i,j) &#x3D; 1$ji</p>\n<p>$y^{(i,j)}$ji</p>\n<p>$w^{(j)}, b^{(j)}$j</p>\n<p>$x^{(i)}$i</p>\n<p>ji$w^{(j)} \\cdot x^{(i)}+b^{(j)}$</p>\n<p>$m^{(j)}$j</p>\n<p>$w^{(j)}, b^{(j)}$</p>\n<p>$$<br>\\min_{w^{(j)}b^{(j)}}J\\left(w^{(j)},b^{(j)}\\right)&#x3D;\\frac{1}{2m^{(j)}}\\sum_{(i:r(i,j)&#x3D;1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}+\\frac{\\lambda}{2m^{(j)}}\\sum_{k&#x3D;1}^{n}\\left(w_{k}^{(j)}\\right)^{2}<br>$$</p>\n<p>$w^{(1)},b^{(1)},w^{(2)},b^{(2)},,w^{(n_u)},b^{(n_u)}$</p>\n<p>$$<br>\\left.\\mathrm{J}\\left(<br>\\begin{array}<br>{cc}{w^{(1)},} &amp; {,w^{(n_{u})}} \\<br>{b^{(1)},} &amp; {,b^{(n_{u})}}<br>\\end{array}\\right.\\right)&#x3D;\\frac{1}{2}\\sum_{j&#x3D;1}^{n_{u}}\\sum_{i:r(i,j)&#x3D;1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}\\quad+\\frac{\\lambda}{2}\\sum_{j&#x3D;1}^{n_{u}}\\sum_{k&#x3D;1}^{n}\\left(w_{k}^{(j)}\\right)^{2}<br>$$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$w^{(j)}, b^{(j)}$</p>\n<p>$$<br>\\mathrm{J}(x^{(i)})&#x3D;\\frac{1}{2}\\sum_{j:r(i,j)&#x3D;1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-{y^{(i,j)}}\\right)^{2}+\\frac{\\lambda}{2}\\sum_{k&#x3D;1}^{n}\\left(x_{k}^{(i)}\\right)^{2}<br>$$</p>\n<p>$x^{(1)},x^{(2)},,x^{(n_m)}$</p>\n<p>$$<br>\\mathrm{J}\\left(x^{(1)},x^{(2)},,x^{(n_{m})}\\right)&#x3D;\\frac{1}{2}\\sum_{i&#x3D;1}^{n_{m}}\\sum_{j:r(i,j)&#x3D;1}\\left(w^{(j)}\\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\\right)^{2}+\\frac{\\lambda}{2}\\sum_{i&#x3D;1}^{n_{m}}\\sum_{k&#x3D;1}^{n}\\left(x_{k}^{(i)}\\right)^{2}<br>$$</p>\n<p>w,b</p>\n<p><img src=\"/img/machine-learning-notes/pic-32.png\" alt=\"img\"></p>\n<p>wbx</p>\n<p><img src=\"/img/machine-learning-notes/pic-33.png\" alt=\"img\"></p>\n<p><a href=\"https://blog.csdn.net/zhu_xian_gang/article/details/130243870\"></a></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>1-</p>\n<p>0-</p>\n<p>?-</p>\n<p>$y^{(i,j)}&#x3D;1$$g(w^{(j)} \\cdot x^{(i)}+ b^{(i)})$glogistic</p>\n<p><img src=\"/img/machine-learning-notes/pic-34.png\" alt=\"img\"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Mean Normalization</strong></p>\n<ul>\n<li>$\\mu$</li>\n<li>$x_1 &#x3D; \\frac{x_1-\\mu}{max-min}$</li>\n</ul>\n<p>$\\mu_i$$u$</p>\n<p>ji</p>\n<p>$w^{(j)} \\cdot x^{(i)}+ b^{(i)} + \\mu_i$</p>\n<p>0</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>$i$$x^{(i)}$$k$$x^{(k)}$$x^{(i)}$</p>\n<p>$\\sum_{l&#x3D;1}^n(x_l^{(k)} - x_l^{(i)})^2$</p>\n<p>$||x^{(k)} - x^{(i)}||^2$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong></strong></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p><strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<p>$v^{(j)}$$v^{(i)}$</p>\n<p>v</p>\n<p>user networkmovie network</p>\n<p></p>\n<p>$$<br>J&#x3D;\\sum_{(i,j):r(i,j)&#x3D;1}\\left(v_{u}^{(j)}\\cdot v_{m}^{(i)}-y^{(i,j)}\\right)^{2}+\\text{NN regularization term}<br>$$</p>\n<p>i$||v^{(k)} - v^{(i)}||^2$</p>\n<h3 id=\"Retrieval-and-Ranking\"><a href=\"#Retrieval-and-Ranking\" class=\"headerlink\" title=\"Retrieval and Ranking\"></a>Retrieval and Ranking</h3><p></p>\n<p>103top10top20</p>\n<p></p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>Reinforcement LearningRLAgentEnvironmentRewardTrial and Error</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>$\\gamma$10.9,0.99</p>\n<p>$\\text{Return} &#x3D; R_1 + \\gamma R_2 + \\gamma^2R_3+$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>statea</p>\n<p>$\\pi(s) &#x3D; a$sa</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Markov Decision Process(MDP)</p>\n<p><img src=\"/img/machine-learning-notes/pic-35.png\" alt=\"img\"></p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"-\"></a>-</h3><p>State-action value functionQ-function,Q*,Optimal Q function</p>\n<p>$Q(s,a)$sa</p>\n<p>s$max_aQ(s,a)$</p>\n<p>s$max_aQ(s,a)$</p>\n<h3 id=\"Bellman\"><a href=\"#Bellman\" class=\"headerlink\" title=\"Bellman\"></a>Bellman</h3><p>$s$:</p>\n<p>$a$:</p>\n<p>$R(s)$:</p>\n<p>$s$:a</p>\n<p>$a$:s</p>\n<p>$Q(s,a) &#x3D; R(s)+\\gamma max_{a}Q(s,a)$</p>\n<p>R(s)</p>\n<p>s</p>\n<p>$\\text{Return} &#x3D; R_1 + \\gamma R_2 + \\gamma^2R_3+ &#x3D; R_1 + \\gamma[R_2 + \\gamma R_3+]$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<p>$\\text{Return} &#x3D; \\text{Average}(R_1 + \\gamma R_2 + \\gamma^2R_3+) &#x3D; \\text{E}(R_1 + \\gamma R_2 + \\gamma^2R_3+)$</p>\n<p>Bellman Equation</p>\n<p>$Q(s,a) &#x3D; R(s)+\\gamma \\text{E} [max_{a}Q(s,a)]$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p>xyz</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><img src=\"/img/machine-learning-notes/pic-36.png\" alt=\"img\"></p>\n<p>$Q(s,a)$</p>\n<p></p>\n<p>$(s,a,R(s),s)$</p>\n<p>10k $(s,a,R(s),s)$Replay Buffer</p>\n<p></p>\n<p>\t10k$x&#x3D;(s,a)$$y &#x3D; R(s)+\\gamma max_{a}Q(s,a)$</p>\n<p>\t$Q_{new}$$Q_{new}(s,a) \\approx y$</p>\n<p>$Q&#x3D;Q_{new}$</p>\n<p>QQ</p>\n<p><strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-37.png\" alt=\"img\"></p>\n<ul>\n<li>$\\epsilon$</li>\n</ul>\n<p>QaQ</p>\n<p>0.95Qgreedyexploitation0.05exploration</p>\n<p>epsilonepsilone</p>\n<ul>\n<li>$mini-batch$</li>\n</ul>\n<p></p>\n<p><img src=\"/img/machine-learning-notes/pic-38.png\" alt=\"img\"></p>\n<p>1000</p>\n<p>1000wb10001000</p>\n<p>10k</p>\n<ul>\n<li></li>\n</ul>\n<p>$Q&#x3D;Q_{new}$$w,b$$w_{new},b_{new}$</p>\n<p><br>$$<br>w &#x3D; 0.01w_{new} + 0.99w<br>$$</p>\n<p>$$<br>b &#x3D; 0.01b_{new} + 0.99b<br>$$</p>\n<p></p>\n"},{"title":"Prot2Text","mathjax":true,"date":"2025-09-29T12:46:25.000Z","img":"https://github.com/hadi-abdine/Prot2Text/raw/master/Prot2Text.drawio.png","excerpt":"","_content":"![Architecture of the proposed Prot2Text framework for predicting protein function descriptions in free text. The model leverages a multimodal approach that integrates protein sequence, structure, and textual annotations. The EncoderDecoder framework forms the backbone of the model, with the encoder component utilizing a relational graph convolution network (RGCN) to process the protein graphs, and an ESM model to process the protein sequence. A cross-attention mechanism facilitates the exchange of relevant information between the graph-encoded and the sequence-encoded vectors, creating a fused representation synthesizing the structural and textual aspects. The decoder component employs a pre-trained GPT-2 model, to generate detailed and accurate protein descriptions from the fused protein representation. By combining the power of Graph Neural Networks and Large Language Models, Prot2Text enables a holistic representation of protein function, facilitating the generation of comprehensive protein descriptions.](./img/prot2text/fig1.png)\n\n## Expectation\n\n- RGCN is not pre-trained\n- Learning about BLEURouge-1Rouge-2 Rouge-L  and Bert score\n- Use the seq-structure-function pair dataset for Protein function task\n\n## Method\n\n### Graph Construction\n\n>  AlphaFold  3D  $G = V,E,R$ $V = [N] := {1,...,N }$ $E  V  V$ R  u  $x_u  R^d$  $i = v u$  $e_i  R$  3D \n\n `u`  $x_u$\n\n- **** \n- **** \n\n\n\n\n\n****\n\n `i`  `i+1`\n\n- ****\n- \n\n****\n\n3D-10\n\n- ****\n- \n\n****\n\n--\n\n- ****\n- \n\n### Graph Encoding\n\n G  $h_G  R_{d_{out}}$ RGCN $N_ru$  u  r $ N_ru = {v :(v,u)  E_r}$$ E_r$  r  GNN  k \n\n$x_i^k=\\sigma\\left(W_{root}^k\\cdot x_i^{k-1}+\\sum_{r\\in{R}}\\sum_{j\\in{N}_r(i)}\\frac{1}{|N_r(i)|}W_r^k\\cdot x_j^{k-1}\\right)$\n\n$W_k$k$W_r^k$$r$$k$$()$$ReLU$GNNK\n\n$h_G=\\frac{1}{N}\\sum_{i=1}^Nx_i^K$\n\n $h_G$ \n\n### Sequence Encoding\n\n $P_S$ ESM2-35MESM2  transformer  ESM ESM ESM $ H_S^0  R^{Nd_{out}} $\n\n$ H_S^0=ESM(P_S)W_p$\n\n$W_p$$W_p \\in R^{d_{esm}  d_{out}}$\n\n### MultiModal Fusion\n\n $H_S^0$$h_G$  $H_S^k$  $h_G$ $H_S^{k+1}$\n\n$H_S^{k+1}=(H_S^k+1_nh_GW_V^k)W_O^k$\n\n $W_V^k $ $W_O^k$ $k$ $1_n $ n1 transformer \n\n### Text Generation\n\n Transformer GPT-2 GPT-2 Transformer GPT2 CLM 256 \n\n### Dataset\n\n Prot2Text  256690 AlphaFold accession ID  SwissProt   UniProtKB  2016 2022 04  SwissProt  568363 1  AlphaFold  ID  AlphaFoldDB2345CD-HIT24831541724 203//CD-HIT  40%6PubMed AlphaFoldDB .PDB AlphaFoldDB  4\n\n### Baseline\n\n Prot2Text  RGCNESM  Transformer RGCN+ESM **** RGCN  vanilla-Transformer  Prot2Text  vanilla-Transformer  ESM2 ESM vanilla-Transformer ESM2-35M\n\n### Metrics\n\n BLEU Score  ngram BLEU  Rouge-1Rouge-2  Rouge-L BERT ScoreTransformer BioBERTLARGE-cased v1.1   BERT \n\n### Result\n\n 1  vanillaTransformerESM2-35M  RGCN RGCN  vanilla-Transformer  RGCN + ESM2-35 GPT-2 vanilla-Transformer RGCN RGCN  BLEU  vanillaTransformer  5  BERT  vanillaTransformer  3  RGCN  ESM2-35M  vanilla-Transformer Transformer ESM2-35M  16  BLEU  18  Rouge-L  ESM2-35M  Prot2TextBASE  BLEU  35.11 Rouge-1  50.59 Rouge-2  42.71 Rouge-L  48.49  BERT  84.3 RGCN  ESM2-35  RGCN  vanilla-Transformer  Transformer  RGCN  vanilla-Transformer  10  BLEU  RGCN  6  BLEU  Prot2Text  RGCN + ESM2-25  ESM  ESM  Prot2Text \n\n![Table 1: Test set results for different encoder models, including unimodal encoders such as vanilla-Transformer, ESM2-35M, and RGCN, as well as multimodal encoders such as RGCNvanilla-Transformer and RGCN+ESM2-35M. All models share the same GPT-2 decoder. Prot2TextBASE achieves the highest performance across all evaluation metrics, including BLEU score, Rouge scores, and BERT Score.](./img/prot2text/table1.png)\n\n### Scaling to Larger Models\n\n Prot2Text  ESM  Prot2TextSMALLProt2TextBASEProt2TextMEDIUM  Prot2TextLARGE  ESM2-8MESM2-35MESM2-150M  ESM2-650M 2  ESM  Prot2Text Prot2TextMEDIUM398M  2  Prot2text  BLAST 20%  30% Prot2TextMEDIUM Prot2TextLARGE \n\n![Figure 2: The test BLEU score for Prot2Text models as a function of the percentage identity using BLAST hit between the test and the train sets.](./img/prot2text/fig2.png)\n\n![Table 2: Test set results for different size variations of Prot2Text. Larger models outperform their smaller counterparts across most evaluation metrics, indicating the benefits of employing larger language models in the Prot2Text framework. The Prot2TextMEDIUM model, strikes an optimal balance between performance and computational efficiency. This configuration demonstrates improved performance compared to the smaller model while still maintaining reasonable computational costs. The inference time is in seconds for text generation of each model on the whole test set. The inference time here is computed during text generation using two NVIDIA RTX 6000 with 48GB memory in parallel and batch size of four per device.](./img/prot2text/table2.png)\n\n### Visualization of Generated Descriptions\n\n Prot2Text  3 P36108Q8NG08  P35713 Prot2Text  3D  3 \n\n![Figure 3: Ground-truth labels vs text-free Generated functions: A textual comparison of the pre-defined labels and generated text outputs for 3 different proteins from the test set. The used text generation configuration if these examples are the following: length penalty = 2.0, no repeat ngram size=3 and early stopping=True.](./img/prot2text/fig3.png)\n\n### Training Details\n\n 256690  48,251 token 57.51 256 98.7% 4  Prot2Text  GPT-2  GPT-2 pad token token  token  Prot2Text - GPT-2 \n\n![Figure 4: Analyzing Protein Description Lengths: Distribution of Tokens per Sample with Threshold Highlight at 256 tokens (in red).](./img/prot2text/fig4.png)\n\n### Source\n\nGithubhttps://github.com/hadi-abdine/Prot2Text\n\nWeb serverhttp://nlp.polytechnique.fr/prot2text#proteins\n\nHugging facehttps://huggingface.co/collections/habdine/prot2text-suite-66e48fe3596fcff3e41be4e7\n","source":"_posts/prot2text.md","raw":"---\ntitle: Prot2Text\nmathjax: true\ndate: 2025/9/29 20:46:25\nimg: https://github.com/hadi-abdine/Prot2Text/raw/master/Prot2Text.drawio.png\nexcerpt: \n---\n![Architecture of the proposed Prot2Text framework for predicting protein function descriptions in free text. The model leverages a multimodal approach that integrates protein sequence, structure, and textual annotations. The EncoderDecoder framework forms the backbone of the model, with the encoder component utilizing a relational graph convolution network (RGCN) to process the protein graphs, and an ESM model to process the protein sequence. A cross-attention mechanism facilitates the exchange of relevant information between the graph-encoded and the sequence-encoded vectors, creating a fused representation synthesizing the structural and textual aspects. The decoder component employs a pre-trained GPT-2 model, to generate detailed and accurate protein descriptions from the fused protein representation. By combining the power of Graph Neural Networks and Large Language Models, Prot2Text enables a holistic representation of protein function, facilitating the generation of comprehensive protein descriptions.](./img/prot2text/fig1.png)\n\n## Expectation\n\n- RGCN is not pre-trained\n- Learning about BLEURouge-1Rouge-2 Rouge-L  and Bert score\n- Use the seq-structure-function pair dataset for Protein function task\n\n## Method\n\n### Graph Construction\n\n>  AlphaFold  3D  $G = V,E,R$ $V = [N] := {1,...,N }$ $E  V  V$ R  u  $x_u  R^d$  $i = v u$  $e_i  R$  3D \n\n `u`  $x_u$\n\n- **** \n- **** \n\n\n\n\n\n****\n\n `i`  `i+1`\n\n- ****\n- \n\n****\n\n3D-10\n\n- ****\n- \n\n****\n\n--\n\n- ****\n- \n\n### Graph Encoding\n\n G  $h_G  R_{d_{out}}$ RGCN $N_ru$  u  r $ N_ru = {v :(v,u)  E_r}$$ E_r$  r  GNN  k \n\n$x_i^k=\\sigma\\left(W_{root}^k\\cdot x_i^{k-1}+\\sum_{r\\in{R}}\\sum_{j\\in{N}_r(i)}\\frac{1}{|N_r(i)|}W_r^k\\cdot x_j^{k-1}\\right)$\n\n$W_k$k$W_r^k$$r$$k$$()$$ReLU$GNNK\n\n$h_G=\\frac{1}{N}\\sum_{i=1}^Nx_i^K$\n\n $h_G$ \n\n### Sequence Encoding\n\n $P_S$ ESM2-35MESM2  transformer  ESM ESM ESM $ H_S^0  R^{Nd_{out}} $\n\n$ H_S^0=ESM(P_S)W_p$\n\n$W_p$$W_p \\in R^{d_{esm}  d_{out}}$\n\n### MultiModal Fusion\n\n $H_S^0$$h_G$  $H_S^k$  $h_G$ $H_S^{k+1}$\n\n$H_S^{k+1}=(H_S^k+1_nh_GW_V^k)W_O^k$\n\n $W_V^k $ $W_O^k$ $k$ $1_n $ n1 transformer \n\n### Text Generation\n\n Transformer GPT-2 GPT-2 Transformer GPT2 CLM 256 \n\n### Dataset\n\n Prot2Text  256690 AlphaFold accession ID  SwissProt   UniProtKB  2016 2022 04  SwissProt  568363 1  AlphaFold  ID  AlphaFoldDB2345CD-HIT24831541724 203//CD-HIT  40%6PubMed AlphaFoldDB .PDB AlphaFoldDB  4\n\n### Baseline\n\n Prot2Text  RGCNESM  Transformer RGCN+ESM **** RGCN  vanilla-Transformer  Prot2Text  vanilla-Transformer  ESM2 ESM vanilla-Transformer ESM2-35M\n\n### Metrics\n\n BLEU Score  ngram BLEU  Rouge-1Rouge-2  Rouge-L BERT ScoreTransformer BioBERTLARGE-cased v1.1   BERT \n\n### Result\n\n 1  vanillaTransformerESM2-35M  RGCN RGCN  vanilla-Transformer  RGCN + ESM2-35 GPT-2 vanilla-Transformer RGCN RGCN  BLEU  vanillaTransformer  5  BERT  vanillaTransformer  3  RGCN  ESM2-35M  vanilla-Transformer Transformer ESM2-35M  16  BLEU  18  Rouge-L  ESM2-35M  Prot2TextBASE  BLEU  35.11 Rouge-1  50.59 Rouge-2  42.71 Rouge-L  48.49  BERT  84.3 RGCN  ESM2-35  RGCN  vanilla-Transformer  Transformer  RGCN  vanilla-Transformer  10  BLEU  RGCN  6  BLEU  Prot2Text  RGCN + ESM2-25  ESM  ESM  Prot2Text \n\n![Table 1: Test set results for different encoder models, including unimodal encoders such as vanilla-Transformer, ESM2-35M, and RGCN, as well as multimodal encoders such as RGCNvanilla-Transformer and RGCN+ESM2-35M. All models share the same GPT-2 decoder. Prot2TextBASE achieves the highest performance across all evaluation metrics, including BLEU score, Rouge scores, and BERT Score.](./img/prot2text/table1.png)\n\n### Scaling to Larger Models\n\n Prot2Text  ESM  Prot2TextSMALLProt2TextBASEProt2TextMEDIUM  Prot2TextLARGE  ESM2-8MESM2-35MESM2-150M  ESM2-650M 2  ESM  Prot2Text Prot2TextMEDIUM398M  2  Prot2text  BLAST 20%  30% Prot2TextMEDIUM Prot2TextLARGE \n\n![Figure 2: The test BLEU score for Prot2Text models as a function of the percentage identity using BLAST hit between the test and the train sets.](./img/prot2text/fig2.png)\n\n![Table 2: Test set results for different size variations of Prot2Text. Larger models outperform their smaller counterparts across most evaluation metrics, indicating the benefits of employing larger language models in the Prot2Text framework. The Prot2TextMEDIUM model, strikes an optimal balance between performance and computational efficiency. This configuration demonstrates improved performance compared to the smaller model while still maintaining reasonable computational costs. The inference time is in seconds for text generation of each model on the whole test set. The inference time here is computed during text generation using two NVIDIA RTX 6000 with 48GB memory in parallel and batch size of four per device.](./img/prot2text/table2.png)\n\n### Visualization of Generated Descriptions\n\n Prot2Text  3 P36108Q8NG08  P35713 Prot2Text  3D  3 \n\n![Figure 3: Ground-truth labels vs text-free Generated functions: A textual comparison of the pre-defined labels and generated text outputs for 3 different proteins from the test set. The used text generation configuration if these examples are the following: length penalty = 2.0, no repeat ngram size=3 and early stopping=True.](./img/prot2text/fig3.png)\n\n### Training Details\n\n 256690  48,251 token 57.51 256 98.7% 4  Prot2Text  GPT-2  GPT-2 pad token token  token  Prot2Text - GPT-2 \n\n![Figure 4: Analyzing Protein Description Lengths: Distribution of Tokens per Sample with Threshold Highlight at 256 tokens (in red).](./img/prot2text/fig4.png)\n\n### Source\n\nGithubhttps://github.com/hadi-abdine/Prot2Text\n\nWeb serverhttp://nlp.polytechnique.fr/prot2text#proteins\n\nHugging facehttps://huggingface.co/collections/habdine/prot2text-suite-66e48fe3596fcff3e41be4e7\n","slug":"prot2text","published":1,"updated":"2025-09-29T08:38:47.285Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff9000kss99gqvqaxiu","content":"<p><img src=\"/./img/prot2text/fig1.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/prot2text/fig1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Architecture of the proposed Prot2Text framework for predicting protein function descriptions in free text. The model leverages a multimodal approach that integrates protein sequence, structure, and textual annotations. The EncoderDecoder framework forms the backbone of the model, with the encoder component utilizing a relational graph convolution network (RGCN) to process the protein graphs, and an ESM model to process the protein sequence. A cross-attention mechanism facilitates the exchange of relevant information between the graph-encoded and the sequence-encoded vectors, creating a fused representation synthesizing the structural and textual aspects. The decoder component employs a pre-trained GPT-2 model, to generate detailed and accurate protein descriptions from the fused protein representation. By combining the power of Graph Neural Networks and Large Language Models, Prot2Text enables a holistic representation of protein function, facilitating the generation of comprehensive protein descriptions.\"></p>\n<h2 id=\"Expectation\"><a href=\"#Expectation\" class=\"headerlink\" title=\"Expectation\"></a>Expectation</h2><ul>\n<li>RGCN is not pre-trained</li>\n<li>Learning about BLEURouge-1Rouge-2 Rouge-L  and Bert score</li>\n<li>Use the seq-structure-function pair dataset for Protein function task</li>\n</ul>\n<h2 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method\"></a>Method</h2><h3 id=\"Graph-Construction\"><a href=\"#Graph-Construction\" class=\"headerlink\" title=\"Graph Construction\"></a>Graph Construction</h3><blockquote>\n<p> AlphaFold  3D  $G &#x3D; V,E,R$ $V &#x3D; [N] :&#x3D; {1,,N }$ $E  V  V$ R  u  $x_u  R^d$  $i &#x3D; v u$  $e_i  R$  3D </p>\n</blockquote>\n<p> <code>u</code>  $x_u$</p>\n<ul>\n<li><strong></strong> </li>\n<li><strong></strong> </li>\n</ul>\n<p></p>\n<p></p>\n<p><strong></strong></p>\n<p> <code>i</code>  <code>i+1</code></p>\n<ul>\n<li><strong></strong></li>\n<li></li>\n</ul>\n<p><strong></strong></p>\n<p>3D-10</p>\n<ul>\n<li><strong></strong></li>\n<li></li>\n</ul>\n<p><strong></strong></p>\n<p>--</p>\n<ul>\n<li><strong></strong></li>\n<li></li>\n</ul>\n<h3 id=\"Graph-Encoding\"><a href=\"#Graph-Encoding\" class=\"headerlink\" title=\"Graph Encoding\"></a>Graph Encoding</h3><p> G  $h_G  R_{d_{out}}$ RGCN $N_ru$  u  r $ N_ru &#x3D; {v :(v,u)  E_r}$$ E_r$  r  GNN  k </p>\n<p>$x_i^k&#x3D;\\sigma\\left(W_{root}^k\\cdot x_i^{k-1}+\\sum_{r\\in{R}}\\sum_{j\\in{N}_r(i)}\\frac{1}{|N_r(i)|}W_r^k\\cdot x_j^{k-1}\\right)$</p>\n<p>$W_k$k$W_r^k$$r$$k$$()$$ReLU$GNNK</p>\n<p>$h_G&#x3D;\\frac{1}{N}\\sum_{i&#x3D;1}^Nx_i^K$</p>\n<p> $h_G$ </p>\n<h3 id=\"Sequence-Encoding\"><a href=\"#Sequence-Encoding\" class=\"headerlink\" title=\"Sequence Encoding\"></a>Sequence Encoding</h3><p> $P_S$ ESM2-35MESM2  transformer  ESM ESM ESM $ H_S^0  R^{Nd_{out}} $</p>\n<p>$ H_S^0&#x3D;ESM(P_S)W_p$</p>\n<p>$W_p$$W_p \\in R^{d_{esm}  d_{out}}$</p>\n<h3 id=\"MultiModal-Fusion\"><a href=\"#MultiModal-Fusion\" class=\"headerlink\" title=\"MultiModal Fusion\"></a>MultiModal Fusion</h3><p> $H_S^0$$h_G$  $H_S^k$  $h_G$ $H_S^{k+1}$</p>\n<p>$H_S^{k+1}&#x3D;(H_S^k+1_nh_GW_V^k)W_O^k$</p>\n<p> $W_V^k $ $W_O^k$ $k$ $1_n $ n1 transformer </p>\n<h3 id=\"Text-Generation\"><a href=\"#Text-Generation\" class=\"headerlink\" title=\"Text Generation\"></a>Text Generation</h3><p> Transformer GPT-2 GPT-2 Transformer GPT2 CLM 256 </p>\n<h3 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h3><p> Prot2Text  256690 AlphaFold accession ID  SwissProt   UniProtKB  2016 2022 04  SwissProt  568363 1  AlphaFold  ID  AlphaFoldDB2345CD-HIT24831541724 203&#x2F;&#x2F;CD-HIT  40%6PubMed AlphaFoldDB .PDB AlphaFoldDB  4</p>\n<h3 id=\"Baseline\"><a href=\"#Baseline\" class=\"headerlink\" title=\"Baseline\"></a>Baseline</h3><p> Prot2Text  RGCNESM  Transformer RGCN+ESM <strong></strong> RGCN  vanilla-Transformer  Prot2Text  vanilla-Transformer  ESM2 ESM vanilla-Transformer ESM2-35M</p>\n<h3 id=\"Metrics\"><a href=\"#Metrics\" class=\"headerlink\" title=\"Metrics\"></a>Metrics</h3><p> BLEU Score  ngram BLEU  Rouge-1Rouge-2  Rouge-L BERT ScoreTransformer BioBERTLARGE-cased v1.1   BERT </p>\n<h3 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h3><p> 1  vanillaTransformerESM2-35M  RGCN RGCN  vanilla-Transformer  RGCN + ESM2-35 GPT-2 vanilla-Transformer RGCN RGCN  BLEU  vanillaTransformer  5  BERT  vanillaTransformer  3  RGCN  ESM2-35M  vanilla-Transformer Transformer ESM2-35M  16  BLEU  18  Rouge-L  ESM2-35M  Prot2TextBASE  BLEU  35.11 Rouge-1  50.59 Rouge-2  42.71 Rouge-L  48.49  BERT  84.3 RGCN  ESM2-35  RGCN  vanilla-Transformer  Transformer  RGCN  vanilla-Transformer  10  BLEU  RGCN  6  BLEU  Prot2Text  RGCN + ESM2-25  ESM  ESM  Prot2Text </p>\n<p><img src=\"/./img/prot2text/table1.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/prot2text/table1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Table 1: Test set results for different encoder models, including unimodal encoders such as vanilla-Transformer, ESM2-35M, and RGCN, as well as multimodal encoders such as RGCNvanilla-Transformer and RGCN+ESM2-35M. All models share the same GPT-2 decoder. Prot2TextBASE achieves the highest performance across all evaluation metrics, including BLEU score, Rouge scores, and BERT Score.\"></p>\n<h3 id=\"Scaling-to-Larger-Models\"><a href=\"#Scaling-to-Larger-Models\" class=\"headerlink\" title=\"Scaling to Larger Models\"></a>Scaling to Larger Models</h3><p> Prot2Text  ESM  Prot2TextSMALLProt2TextBASEProt2TextMEDIUM  Prot2TextLARGE  ESM2-8MESM2-35MESM2-150M  ESM2-650M 2  ESM  Prot2Text Prot2TextMEDIUM398M  2  Prot2text  BLAST 20%  30% Prot2TextMEDIUM Prot2TextLARGE </p>\n<p><img src=\"/./img/prot2text/fig2.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/prot2text/fig2.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Figure 2: The test BLEU score for Prot2Text models as a function of the percentage identity using BLAST hit between the test and the train sets.\"></p>\n<p><img src=\"/./img/prot2text/table2.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/prot2text/table2.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Table 2: Test set results for different size variations of Prot2Text. Larger models outperform their smaller counterparts across most evaluation metrics, indicating the benefits of employing larger language models in the Prot2Text framework. The Prot2TextMEDIUM model, strikes an optimal balance between performance and computational efficiency. This configuration demonstrates improved performance compared to the smaller model while still maintaining reasonable computational costs. The inference time is in seconds for text generation of each model on the whole test set. The inference time here is computed during text generation using two NVIDIA RTX 6000 with 48GB memory in parallel and batch size of four per device.\"></p>\n<h3 id=\"Visualization-of-Generated-Descriptions\"><a href=\"#Visualization-of-Generated-Descriptions\" class=\"headerlink\" title=\"Visualization of Generated Descriptions\"></a>Visualization of Generated Descriptions</h3><p> Prot2Text  3 P36108Q8NG08  P35713 Prot2Text  3D  3 </p>\n<p><img src=\"/./img/prot2text/fig3.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/prot2text/fig3.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Figure 3: Ground-truth labels vs text-free Generated functions: A textual comparison of the pre-defined labels and generated text outputs for 3 different proteins from the test set. The used text generation configuration if these examples are the following: length penalty = 2.0, no repeat ngram size=3 and early stopping=True.\"></p>\n<h3 id=\"Training-Details\"><a href=\"#Training-Details\" class=\"headerlink\" title=\"Training Details\"></a>Training Details</h3><p> 256690  48,251 token 57.51 256 98.7% 4  Prot2Text  GPT-2  GPT-2 pad token token  token  Prot2Text - GPT-2 </p>\n<p><img src=\"/./img/prot2text/fig4.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/prot2text/fig4.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Figure 4: Analyzing Protein Description Lengths: Distribution of Tokens per Sample with Threshold Highlight at 256 tokens (in red).\"></p>\n<h3 id=\"Source\"><a href=\"#Source\" class=\"headerlink\" title=\"Source\"></a>Source</h3><p>Github<a href=\"https://github.com/hadi-abdine/Prot2Text\">https://github.com/hadi-abdine/Prot2Text</a></p>\n<p>Web server<a href=\"http://nlp.polytechnique.fr/prot2text#proteins\">http://nlp.polytechnique.fr/prot2text#proteins</a></p>\n<p>Hugging face<a href=\"https://huggingface.co/collections/habdine/prot2text-suite-66e48fe3596fcff3e41be4e7\">https://huggingface.co/collections/habdine/prot2text-suite-66e48fe3596fcff3e41be4e7</a></p>\n","more":"<p><img src=\"/./img/prot2text/fig1.png\" alt=\"Architecture of the proposed Prot2Text framework for predicting protein function descriptions in free text. The model leverages a multimodal approach that integrates protein sequence, structure, and textual annotations. The EncoderDecoder framework forms the backbone of the model, with the encoder component utilizing a relational graph convolution network (RGCN) to process the protein graphs, and an ESM model to process the protein sequence. A cross-attention mechanism facilitates the exchange of relevant information between the graph-encoded and the sequence-encoded vectors, creating a fused representation synthesizing the structural and textual aspects. The decoder component employs a pre-trained GPT-2 model, to generate detailed and accurate protein descriptions from the fused protein representation. By combining the power of Graph Neural Networks and Large Language Models, Prot2Text enables a holistic representation of protein function, facilitating the generation of comprehensive protein descriptions.\"></p>\n<h2 id=\"Expectation\"><a href=\"#Expectation\" class=\"headerlink\" title=\"Expectation\"></a>Expectation</h2><ul>\n<li>RGCN is not pre-trained</li>\n<li>Learning about BLEURouge-1Rouge-2 Rouge-L  and Bert score</li>\n<li>Use the seq-structure-function pair dataset for Protein function task</li>\n</ul>\n<h2 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method\"></a>Method</h2><h3 id=\"Graph-Construction\"><a href=\"#Graph-Construction\" class=\"headerlink\" title=\"Graph Construction\"></a>Graph Construction</h3><blockquote>\n<p> AlphaFold  3D  $G &#x3D; V,E,R$ $V &#x3D; [N] :&#x3D; {1,,N }$ $E  V  V$ R  u  $x_u  R^d$  $i &#x3D; v u$  $e_i  R$  3D </p>\n</blockquote>\n<p> <code>u</code>  $x_u$</p>\n<ul>\n<li><strong></strong> </li>\n<li><strong></strong> </li>\n</ul>\n<p></p>\n<p></p>\n<p><strong></strong></p>\n<p> <code>i</code>  <code>i+1</code></p>\n<ul>\n<li><strong></strong></li>\n<li></li>\n</ul>\n<p><strong></strong></p>\n<p>3D-10</p>\n<ul>\n<li><strong></strong></li>\n<li></li>\n</ul>\n<p><strong></strong></p>\n<p>--</p>\n<ul>\n<li><strong></strong></li>\n<li></li>\n</ul>\n<h3 id=\"Graph-Encoding\"><a href=\"#Graph-Encoding\" class=\"headerlink\" title=\"Graph Encoding\"></a>Graph Encoding</h3><p> G  $h_G  R_{d_{out}}$ RGCN $N_ru$  u  r $ N_ru &#x3D; {v :(v,u)  E_r}$$ E_r$  r  GNN  k </p>\n<p>$x_i^k&#x3D;\\sigma\\left(W_{root}^k\\cdot x_i^{k-1}+\\sum_{r\\in{R}}\\sum_{j\\in{N}_r(i)}\\frac{1}{|N_r(i)|}W_r^k\\cdot x_j^{k-1}\\right)$</p>\n<p>$W_k$k$W_r^k$$r$$k$$()$$ReLU$GNNK</p>\n<p>$h_G&#x3D;\\frac{1}{N}\\sum_{i&#x3D;1}^Nx_i^K$</p>\n<p> $h_G$ </p>\n<h3 id=\"Sequence-Encoding\"><a href=\"#Sequence-Encoding\" class=\"headerlink\" title=\"Sequence Encoding\"></a>Sequence Encoding</h3><p> $P_S$ ESM2-35MESM2  transformer  ESM ESM ESM $ H_S^0  R^{Nd_{out}} $</p>\n<p>$ H_S^0&#x3D;ESM(P_S)W_p$</p>\n<p>$W_p$$W_p \\in R^{d_{esm}  d_{out}}$</p>\n<h3 id=\"MultiModal-Fusion\"><a href=\"#MultiModal-Fusion\" class=\"headerlink\" title=\"MultiModal Fusion\"></a>MultiModal Fusion</h3><p> $H_S^0$$h_G$  $H_S^k$  $h_G$ $H_S^{k+1}$</p>\n<p>$H_S^{k+1}&#x3D;(H_S^k+1_nh_GW_V^k)W_O^k$</p>\n<p> $W_V^k $ $W_O^k$ $k$ $1_n $ n1 transformer </p>\n<h3 id=\"Text-Generation\"><a href=\"#Text-Generation\" class=\"headerlink\" title=\"Text Generation\"></a>Text Generation</h3><p> Transformer GPT-2 GPT-2 Transformer GPT2 CLM 256 </p>\n<h3 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h3><p> Prot2Text  256690 AlphaFold accession ID  SwissProt   UniProtKB  2016 2022 04  SwissProt  568363 1  AlphaFold  ID  AlphaFoldDB2345CD-HIT24831541724 203&#x2F;&#x2F;CD-HIT  40%6PubMed AlphaFoldDB .PDB AlphaFoldDB  4</p>\n<h3 id=\"Baseline\"><a href=\"#Baseline\" class=\"headerlink\" title=\"Baseline\"></a>Baseline</h3><p> Prot2Text  RGCNESM  Transformer RGCN+ESM <strong></strong> RGCN  vanilla-Transformer  Prot2Text  vanilla-Transformer  ESM2 ESM vanilla-Transformer ESM2-35M</p>\n<h3 id=\"Metrics\"><a href=\"#Metrics\" class=\"headerlink\" title=\"Metrics\"></a>Metrics</h3><p> BLEU Score  ngram BLEU  Rouge-1Rouge-2  Rouge-L BERT ScoreTransformer BioBERTLARGE-cased v1.1   BERT </p>\n<h3 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h3><p> 1  vanillaTransformerESM2-35M  RGCN RGCN  vanilla-Transformer  RGCN + ESM2-35 GPT-2 vanilla-Transformer RGCN RGCN  BLEU  vanillaTransformer  5  BERT  vanillaTransformer  3  RGCN  ESM2-35M  vanilla-Transformer Transformer ESM2-35M  16  BLEU  18  Rouge-L  ESM2-35M  Prot2TextBASE  BLEU  35.11 Rouge-1  50.59 Rouge-2  42.71 Rouge-L  48.49  BERT  84.3 RGCN  ESM2-35  RGCN  vanilla-Transformer  Transformer  RGCN  vanilla-Transformer  10  BLEU  RGCN  6  BLEU  Prot2Text  RGCN + ESM2-25  ESM  ESM  Prot2Text </p>\n<p><img src=\"/./img/prot2text/table1.png\" alt=\"Table 1: Test set results for different encoder models, including unimodal encoders such as vanilla-Transformer, ESM2-35M, and RGCN, as well as multimodal encoders such as RGCNvanilla-Transformer and RGCN+ESM2-35M. All models share the same GPT-2 decoder. Prot2TextBASE achieves the highest performance across all evaluation metrics, including BLEU score, Rouge scores, and BERT Score.\"></p>\n<h3 id=\"Scaling-to-Larger-Models\"><a href=\"#Scaling-to-Larger-Models\" class=\"headerlink\" title=\"Scaling to Larger Models\"></a>Scaling to Larger Models</h3><p> Prot2Text  ESM  Prot2TextSMALLProt2TextBASEProt2TextMEDIUM  Prot2TextLARGE  ESM2-8MESM2-35MESM2-150M  ESM2-650M 2  ESM  Prot2Text Prot2TextMEDIUM398M  2  Prot2text  BLAST 20%  30% Prot2TextMEDIUM Prot2TextLARGE </p>\n<p><img src=\"/./img/prot2text/fig2.png\" alt=\"Figure 2: The test BLEU score for Prot2Text models as a function of the percentage identity using BLAST hit between the test and the train sets.\"></p>\n<p><img src=\"/./img/prot2text/table2.png\" alt=\"Table 2: Test set results for different size variations of Prot2Text. Larger models outperform their smaller counterparts across most evaluation metrics, indicating the benefits of employing larger language models in the Prot2Text framework. The Prot2TextMEDIUM model, strikes an optimal balance between performance and computational efficiency. This configuration demonstrates improved performance compared to the smaller model while still maintaining reasonable computational costs. The inference time is in seconds for text generation of each model on the whole test set. The inference time here is computed during text generation using two NVIDIA RTX 6000 with 48GB memory in parallel and batch size of four per device.\"></p>\n<h3 id=\"Visualization-of-Generated-Descriptions\"><a href=\"#Visualization-of-Generated-Descriptions\" class=\"headerlink\" title=\"Visualization of Generated Descriptions\"></a>Visualization of Generated Descriptions</h3><p> Prot2Text  3 P36108Q8NG08  P35713 Prot2Text  3D  3 </p>\n<p><img src=\"/./img/prot2text/fig3.png\" alt=\"Figure 3: Ground-truth labels vs text-free Generated functions: A textual comparison of the pre-defined labels and generated text outputs for 3 different proteins from the test set. The used text generation configuration if these examples are the following: length penalty = 2.0, no repeat ngram size=3 and early stopping=True.\"></p>\n<h3 id=\"Training-Details\"><a href=\"#Training-Details\" class=\"headerlink\" title=\"Training Details\"></a>Training Details</h3><p> 256690  48,251 token 57.51 256 98.7% 4  Prot2Text  GPT-2  GPT-2 pad token token  token  Prot2Text - GPT-2 </p>\n<p><img src=\"/./img/prot2text/fig4.png\" alt=\"Figure 4: Analyzing Protein Description Lengths: Distribution of Tokens per Sample with Threshold Highlight at 256 tokens (in red).\"></p>\n<h3 id=\"Source\"><a href=\"#Source\" class=\"headerlink\" title=\"Source\"></a>Source</h3><p>Github<a href=\"https://github.com/hadi-abdine/Prot2Text\">https://github.com/hadi-abdine/Prot2Text</a></p>\n<p>Web server<a href=\"http://nlp.polytechnique.fr/prot2text#proteins\">http://nlp.polytechnique.fr/prot2text#proteins</a></p>\n<p>Hugging face<a href=\"https://huggingface.co/collections/habdine/prot2text-suite-66e48fe3596fcff3e41be4e7\">https://huggingface.co/collections/habdine/prot2text-suite-66e48fe3596fcff3e41be4e7</a></p>\n"},{"title":"MiniMind","mathjax":true,"date":"2026-01-23T12:46:25.000Z","img":"https://raw.githubusercontent.com/jingyaogong/minimind/refs/heads/master/images/logo.png","excerpt":"Re-implement of MiniMind","_content":"\n# Minimind\n\nMiniMind  **Decoder-only Transformer** `MiniMindConfig` \n\n- **** LLaMA\n- ****`hidden_size=512`, `num_hidden_layers=8``vocab_size=6400` CPU \n- ****\n  - **MoE ()**\n  - **Weight Tying ()**Embedding LM Head\n\n## A. RoPE + YaRN (Rotary Positional Embeddings)\n\n- ** RoPE** LLM  BERT\n\nRoPE  token  embedding ****\n\n $d$  ( hidden_size=512)RoPE  $d/2$  2 \n $j$  ( $j \\in [0, d/2)$) $\\theta_j$\n\n$$\\theta_j = 10000^{-2j/d}$$\n\n- \n  - ** ($j$ )**$\\theta_j$  1****\n  - ** ($j$ )**$\\theta_j$  0****\n\n- **YaRN (Yet another RoPE extensioN)**\n  -  `if end / orig_max > 1.0:` \n  - ****`original_max_position_embeddings`Ramp function RoPE \n\n****\nYaRN  $m$ $\\theta_j$\n\n $\\theta'_j$ \n\n$$\\theta'_j = \\theta_j \\cdot (1 - \\gamma(r) + \\frac{\\gamma(r)}{s})$$\n\nYaRN \n\n$$\\gamma(r) = \\begin{cases} 0, & \\text{if } r < \\alpha \\quad (\\text{/}) \\\\ 1, & \\text{if } r > \\beta \\quad (\\text{/}) \\\\ \\frac{r - \\alpha}{\\beta - \\alpha}, & \\text{otherwise} \\quad (\\text{/}) \\end{cases}$$\n\nYaRN  $\\sqrt{t}$ \n\n$$\\text{Attention}(Q, K) = \\text{softmax}(\\frac{\\mathbf{q}^T \\mathbf{k}}{\\sqrt{d} \\cdot \\sqrt{t}})$$\n\n## B. GQA (Grouped Query Attention)\n\n### MHA: Multi-Head Attention\n\n Query  Key  Value \n- ****\n- ****KV Cache \n\n### MQA: Multi-Query Attention\n\n Query **** Key  Value \n- ****KV Cache \n- ****\n\n### GQA: Group Query Attention\n\n Query Group**** Query  Key/Value\n\n### KV-cache\n\nKV cache  Transformer decoder  token  Key / Value O(T)  O(T) \n\n$l$\n\n$$Q_t^{(l)} = h_t^{(l)} W_Q^{(l)}$$$$K_t^{(l)} = h_t^{(l)}W_K^{(l)}$$\n$$V_t^{(l)} = h_t^{(l)}W_V^{(l)}$$\n\nattention \n\n$$\\text{Attn}_t^{(l)} = \\text{softmax}\\left( \\frac{Q_t^{(l)} [K_1^{(l)}, \\dots, K_t^{(l)}]^T} {\\sqrt{d_h}} \\right) [V_1^{(l)}, \\dots, V_t^{(l)}]$$\n\n$$\\boxed{ \\text{KVCache}^{(l)} = \\left( \\{K_1^{(l)}, \\dots, K_{t-1}^{(l)}\\}, \\{V_1^{(l)}, \\dots, V_{t-1}^{(l)}\\} \\right) }$$\n\n$t$\n\n- $ Q_t, K_t, V_t$\n  \n- append  cache\n  \n-  $Q_t$ cache\n\n$$\\text{} = 2 \\times \\text{Batch} \\times \\text{Seq\\_Len} \\times \\text{KV\\_Heads} \\times \\text{Head\\_Dim} \\times \\text{Byte}$$\n### Flash Attention\n\n Attention \n\n$$\\text{Score} = \\text{Softmax}(Q K^T)$$\n\n$$\\text{Out} = \\text{Score} \\cdot V$$\n\n**Attention Score Matrix** $N \\times N$\n** (HBM)**  **GPU  (SRAM)**GPU \nFlash Attention ** (Tiling)**\n\n- **** $N \\times N$ \n  \n- **** $Q, K, V$  GPU  (SRAM) \n  \n- **** SRAM  Attention\n\n## C.  (Norm & Activation)\n\n### Normalization\n\n  **01**\n#### BatchNorm\n **Batch** \n- ** Batch Size** Batch Size BN \n  \n- ****NLP  Padding BN Padding  0 \n  \n- **RNN/Transformer ** Token Batch BN \n\n#### LayerNorm\n **Feature** \n** Batch Size ** Token Token  512 Hidden Size\n\n\n\n$$y = \\frac{x - \\mu}{\\sigma + \\epsilon} \\cdot \\gamma + \\beta$$\n\n- $\\mu$ (Center)\n  \n- $\\sigma$ (Scale)\n  \n- **** 0  1 \n\n/BSLN\n\n#### RMSNorm\n-  LayerNorm \n  \n    LayerNorm  $\\mu$\n    \n- \n    $$y = \\frac{x}{\\text{RMS}(x)} \\cdot \\gamma$$$$\\text{RMS}(x) = \\sqrt{\\frac{1}{d} \\sum x_i^2}$$\n\nRMSNorm  Bias ($\\beta$) Weight ($\\gamma$)\n\n### Activation Function\n\n#### Sigmoid/Tanh\n- ****S \n  \n- ******** 0\n\n#### ReLu(Rectified Linear Unit)\n- ****$f(x) = \\max(0, x)$\n  \n- **** 0  0 0 \n  \n- ****\n  \n- ******Dead ReLU** 0\n\n#### GELU (Gaussian Error Linear Unit)  BERT/GPT-2 \n\n- **** ReLU ReLU  0 GELU \n  \n- **** 0\n$$GELU(x)=x\\cdot \\Phi(x)$$\n\n\n\n$$\\Phi(x) = P(Z \\le x), \\quad Z \\sim \\mathcal{N}(0,1)$$\n|   |                |\n| ----- | ------------------ |\n| x  0 |  0 0 |\n| x  0 |            |\n| x  0 |  x    |\n#### SiLU(Sigmoid Linear Unit)/SwishLlama\n\n- ****$f(x) = x \\cdot \\text{sigmoid}(x)$\n  \n- **** GELU \n  \n- ****\n  \n    - ****\n      \n    - **** $x$  -2  0 ReLU \n    \n- ****Google  ReLU  GELU \n\n## FFN\n\n### Transformer\n\n Up -> Activation -> Down \n\n$$y = \\text{Down}(\\text{ReLU}(\\text{Up}(x)))$$\n\nUp  Down\n\n### SwiGLU FFN\n```python\nself.gate_proj = nn.Linear(...) #  \nself.up_proj = nn.Linear(...) #  \nself.down_proj = nn.Linear(...) #  \n# forward  \nreturn self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n```\n\n\n$$y = \\text{Down}(\\text{SiLU}(\\text{Gate}(x)) \\times \\text{Up}(x))$$\n\nGLU\n**SwiGLU  GeGLU > ReGLU**\nSiLU \n\n-   \n  \n-   \n  \n- \n\n## MoE(Mixture of Experts)\n\n###  (Shared + Routed)\n\n**Routed Experts** Token \n\n**Shared Experts******\n\n**** MoE \n\n###  (Gating)\n\n `MoEGate` \n\n- **Top-K ** `softmax`  K  (`num_experts_per_tok`)\n- ****`norm_topk_prob` 1\n\n###  (Load Balancing)\n\n `aux_loss`\n\n Token \n\n## \n\n**Training** `repeat_interleave`Mask GPU \n\n**Inference** `moe_infer` Token  (`argsort`) A  Token \n\n# Tokenizer\n\n**** JSONL \n\n**** **BPE (Byte-Pair Encoding)**  6400 \n\n**** `<|im_start|>`Chat Template HuggingFace \n\n- VOCAB_SIZE = 6400\n\n****Embedding  LM Head $6400 \\times Hidden\\_Dim$\n\n**** Token  Token\n\n- BPE+ByteLevel\n\n```python\ntokenizer = Tokenizer(models.BPE())\ntokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n```\n\n**BPE ()**GPT-2/3/4, Llama \n\n**ByteLevel** Unicode  **UTF-8 **\n\n -> `0xE4 0xB8 0xAD` (3)\n\n**** **OOV (Out of Vocabulary)**  Emoji `<UNK>`\n\n- chat_template\n\n```python\n\"chat_template\": \"{%- if tools %}\\n    {{- '<|im_start|>system\\\\n' }}\\n    {%- if messages[0].role == 'system' %}\\n        {{- messages[0].content + '\\\\n\\\\n' }}\\n    {%- endif %}\\n    {{- \\\"# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\" }}\\n    {%- for tool in tools %}\\n        {{- \\\"\\\\n\\\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \\\"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\\\"name\\\\\\\": <function-name>, \\\\\\\"arguments\\\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\\\" }}\\n{%- else %}\\n {%- if messages[0]['role'] == 'system' -%}\\n        {{- '<|im_start|>system\\\\n' + messages[0]['content'] + '<|im_end|>\\\\n' }}\\n    {%- else -%}\\n        {{- '<|im_start|>system\\\\nYou are a helpful assistant<|im_end|>\\\\n' }}\\n {%- endif %}\\n{%- endif %}\\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\\n{%- for message in messages[::-1] %}\\n    {%- set index = (messages|length - 1) - loop.index0 %}\\n    {%- if ns.multi_step_tool and message.role == \\\"user\\\" and message.content is string and not(message.content.startswith('<tool_response>') and message.content.endswith('</tool_response>')) %}\\n        {%- set ns.multi_step_tool = false %}\\n        {%- set ns.last_query_index = index %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- for message in messages %}\\n    {%- if message.content is string %}\\n        {%- set content = message.content %}\\n    {%- else %}\\n        {%- set content = '' %}\\n    {%- endif %}\\n    {%- if (message.role == \\\"user\\\") or (message.role == \\\"system\\\" and not loop.first) %}\\n        {{- '<|im_start|>' + message.role + '\\\\n' + content + '<|im_end|>' + '\\\\n' }}\\n    {%- elif message.role == \\\"assistant\\\" %}\\n   {{- '<|im_start|>' + message.role + '\\\\n' + content }}\\n  {%- if message.tool_calls %}\\n            {%- for tool_call in message.tool_calls %}\\n                {%- if (loop.first and content) or (not loop.first) %}\\n                    {{- '\\\\n' }}\\n                {%- endif %}\\n                {%- if tool_call.function %}\\n                    {%- set tool_call = tool_call.function %}\\n                {%- endif %}\\n                {{- '<tool_call>\\\\n{\\\"name\\\": \\\"' }}\\n                {{- tool_call.name }}\\n                {{- '\\\", \\\"arguments\\\": ' }}\\n                {%- if tool_call.arguments is string %}\\n                    {{- tool_call.arguments }}\\n                {%- else %}\\n                    {{- tool_call.arguments | tojson }}\\n                {%- endif %}\\n                {{- '}\\\\n</tool_call>' }}\\n            {%- endfor %}\\n        {%- endif %}\\n        {{- '<|im_end|>\\\\n' }}\\n    {%- elif message.role == \\\"tool\\\" %}\\n        {%- if loop.first or (messages[loop.index0 - 1].role != \\\"tool\\\") %}\\n            {{- '<|im_start|>user' }}\\n        {%- endif %}\\n        {{- '\\\\n<tool_response>\\\\n' }}\\n        {{- content }}\\n        {{- '\\\\n</tool_response>' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \\\"tool\\\") %}\\n            {{- '<|im_end|>\\\\n' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- '<|im_start|>assistant\\\\n' }}\\n    {%- if enable_thinking is defined and enable_thinking is false %}\\n        {{- '<think>\\\\n\\\\n</think>\\\\n\\\\n' }}\\n    {%- endif %}\\n{%- endif %}\"\n```\n\n** Jinja2 ** HuggingFace  `tokenizer.apply_chat_template` ** Python List of Dicts Tokenizer **System Prompt********Tools****\n\n- \n\n```python\n# \nfor tid in input_ids:\n    token_cache.append(tid)\n    current_decode = tokenizer.decode(token_cache)\n    if current_decode and '\\ufffd' not in current_decode:\n        # ...  ...\n        token_cache = []\n```\n\n UTF-8  **3**\n\n Token A (`E6`)  Decode `E6` `` ( \\ufffd, Replacement Character)\n\n**** `token_cache` `\\ufffd`**** Token B (`88 91`)  `E6 88 91``\\ufffd` \n\n# Pretrain\n\nLLM  ModelWiki  ****\n\n## Dataloader\n\n```python\nclass PretrainDataset(Dataset):\n    def __init__(self, data_path, tokenizer, max_length=512):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        # 1. \n        self.samples = load_dataset('json', data_files=data_path, split='train')\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, index):\n        sample = self.samples[index]\n        # 2.  (Tokenization)\n        encoding = self.tokenizer(\n            str(sample['text']),\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        # 3.  Labels ()\n        input_ids = encoding.input_ids.squeeze()\n        labels = input_ids.clone()\n        # 4. Masking Padding\n\t\t#  Pad Token  Label  -100\n\t\t# PyTorch  CrossEntropyLoss  -100\n        labels[input_ids == self.tokenizer.pad_token_id] = -100\n        return input_ids, labels\n```\n\n## Epoch\n\n```python\ndef train_epoch(epoch, loader, iters, start_step=0, wandb=None):\n    for step, (input_ids, labels) in enumerate(loader, start=start_step + 1):\n        #\n        input_ids = input_ids.to(args.device)\n        labels = labels.to(args.device)\n        #  Cosine Decay\n        lr = get_lr(epoch * iters + step, args.epochs * iters, args.learning_rate)\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n\t\t# autocast_ctx \n        #  float16  bfloat16 \n        with autocast_ctx:\n            res = model(input_ids, labels=labels)\n            # res.loss  Loss\n            # res.aux_loss  MoE  Loss\n            loss = res.loss + res.aux_loss\n            # \n            loss = loss / args.accumulation_steps\n\t\t# scaler  GradScaler float16 \n        #  scale float16 Loss  0.00001\n        #  0scaler  Loss  65536\n        # \n        scaler.scale(loss).backward()\n\n        if (step + 1) % args.accumulation_steps == 0:\n            # 1. Unscale\n            #  clip_grad_norm \n            scaler.unscale_(optimizer)\n            # 2.  (Gradient Clipping)\n            #  args.grad_clip ( 1.0)\n            #  LLM \n            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n\t\t\t# scaler.step  Inf/NaN\n            scaler.step(optimizer)\n            # 4. \n            scaler.update()\n\t\t\t# 5. \n            # set_to_none=True  =0 \n            optimizer.zero_grad(set_to_none=True)\n\t\t##.....\n\t\t\n        # Rank 0\n        if (step % args.save_interval == 0 or step == iters - 1) and is_main_process():\n            model.eval()\n            moe_suffix = '_moe' if lm_config.use_moe else ''\n            ckp = f'{args.save_dir}/{args.save_weight}_{lm_config.hidden_size}{moe_suffix}.pth'\n            #  DDP .module\n            raw_model = model.module if isinstance(model, DistributedDataParallel) else model\n            #  torch.compile _orig_mod\n            raw_model = getattr(raw_model, '_orig_mod', raw_model)\n            state_dict = raw_model.state_dict()\n            # 1.  (.pth)\n            # .half() float16 \n            # .cpu() CPU\n            torch.save({k: v.half().cpu() for k, v in state_dict.items()}, ckp)\n            # 2.  (Checkpoint)\n            #  optimizerscaler epoch  step\n            # Resume\n            lm_checkpoint(lm_config, weight=args.save_weight, model=model, optimizer=optimizer, scaler=scaler, epoch=epoch, step=step, wandb=wandb, save_dir='../checkpoints')\n            model.train()\n            del state_dict\n\n        del input_ids, labels, res, loss\n```\n\n## \n\n```python\n    # ========== 1.  ==========\n    local_rank = init_distributed_mode()\n    if dist.is_initialized(): args.device = f\"cuda:{local_rank}\"\n    setup_seed(42 + (dist.get_rank() if dist.is_initialized() else 0))\n    #  Dropout \n    \n    # ========== 2. ckp ==========\n    os.makedirs(args.save_dir, exist_ok=True)\n    lm_config = MiniMindConfig(hidden_size=args.hidden_size, num_hidden_layers=args.num_hidden_layers, use_moe=bool(args.use_moe))\n    # lm_checkpoint  ../checkpoints  args.save_weight \n\t# epochstep  ckp_data \n    ckp_data = lm_checkpoint(lm_config, weight=args.save_weight, save_dir='../checkpoints') if args.from_resume==1 else None\n    \n    # ========== 3.  ==========\n    device_type = \"cuda\" if \"cuda\" in args.device else \"cpu\"\n    dtype = torch.bfloat16 if args.dtype == \"bfloat16\" else torch.float16\n    #  train_epoch \n    autocast_ctx = nullcontext() if device_type == \"cpu\" else torch.cuda.amp.autocast(dtype=dtype)\n    \n    # ========== 4. wandb ==========\n\t# \n    \n    # ========== 5.  ==========\n    model, tokenizer = init_model(lm_config, args.from_weight, device=args.device)\n    if args.use_compile == 1:\n        model = torch.compile(model)\n        Logger('torch.compile enabled')\n    train_ds = PretrainDataset(args.data_path, tokenizer, max_length=args.max_seq_len)\n    #  DDP  N N=\n    train_sampler = DistributedSampler(train_ds) if dist.is_initialized() else None\n    # GradScaler float16 \n\t#  bfloat16enabled=False\n    scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype == 'float16'))\n    optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate)\n    \n    # ========== 6. ckp ==========\n    start_epoch, start_step = 0, 0\n    if ckp_data:\n        model.load_state_dict(ckp_data['model'])\n        optimizer.load_state_dict(ckp_data['optimizer'])\n        scaler.load_state_dict(ckp_data['scaler'])\n        start_epoch = ckp_data['epoch']\n        start_step = ckp_data.get('step', 0)\n    \n    # ========== 7. DDP ==========\n    if dist.is_initialized():\n        model._ddp_params_and_buffers_to_ignore = {\"freqs_cos\", \"freqs_sin\"}\n        model = DistributedDataParallel(model, device_ids=[local_rank])\n    \n    # ========== 8.  ==========\n    for epoch in range(start_epoch, args.epochs):\n        train_sampler and train_sampler.set_epoch(epoch)\n        if epoch == start_epoch and start_step > 0: # epoch\n            # SkipBatchSampler \n        \t#  1000  batch index\n        \t# Dataloader  1000 \n            batch_sampler = SkipBatchSampler(train_sampler or range(len(train_ds)), args.batch_size, start_step + 1)\n            loader = DataLoader(train_ds, batch_sampler=batch_sampler, num_workers=args.num_workers, pin_memory=True)\n            Logger(f'Epoch [{epoch + 1}/{args.epochs}]: {start_step}stepstep {start_step + 1}')\n            train_epoch(epoch, loader, len(loader) + start_step + 1, start_step, wandb)\n        else: # \n            loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=(train_sampler is None), sampler=train_sampler, num_workers=args.num_workers, pin_memory=True)\n            train_epoch(epoch, loader, len(loader), 0, wandb)\n    \n    # ========== 9.  ==========\n    if dist.is_initialized(): dist.destroy_process_group()\n```\n\n```bash\ntorchrun --nproc_per_node 1 train_pretrain.py # 1 (>=2)\n# or\npython train_pretrain.py\n```\n\n[](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data) `<512`1.6GB `pretrain_hq.jsonl`hqhigh quality\n\n`pretrain_hq.jsonl` \n\n```\n{\"text\": \" ...\"}\n```\n\n# SFT\n\nLLM SFTLLM ->->  MiniMind512200800 2k/4k/8kRoPE-NTK\n\n## DataLoader\n\n```python\nclass SFTDataset(Dataset):\n    def __init__(self, jsonl_path, tokenizer, max_length=1024):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.samples = load_dataset('json', data_files=jsonl_path, split='train')\n        self.bos_id = tokenizer(f'{tokenizer.bos_token}assistant\\n', add_special_tokens=False).input_ids\n        self.eos_id = tokenizer(f'{tokenizer.eos_token}\\n', add_special_tokens=False).input_ids\n\n    def __len__(self):\n        return len(self.samples)\n    \n\t# tokenizer  chat template prompt\n    def create_chat_prompt(self, cs):\n        messages = cs.copy()\n        tools = cs[0][\"functions\"] if (cs and cs[0][\"role\"] == \"system\" and cs[0].get(\"functions\")) else None\n        return self.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=False,\n            tools=tools\n        )\n\n    def generate_labels(self, input_ids):\n        # 1.  (-100)\n        labels = [-100] * len(input_ids)\n        # 2.  input_ids \n        i = 0\n        while i < len(input_ids):\n            # 3.  Assistant  (self.bos_id)\n            if input_ids[i:i + len(self.bos_id)] == self.bos_id:\n                start = i + len(self.bos_id)\n                # 4.  Assistant  (self.eos_id)\n                end = start\n                while end < len(input_ids):\n                    if input_ids[end:end + len(self.eos_id)] == self.eos_id:\n                        break\n                    end += 1\n                # 5.  Mask\n            \t#  [start, end]  labels  input_ids \n            \t#  Loss\n                for j in range(start, min(end + len(self.eos_id), self.max_length)):\n                    labels[j] = input_ids[j]\n                i = end + len(self.eos_id) if end < len(input_ids) else len(input_ids)\n            else:\n                i += 1\n        return labels\n\n    def __getitem__(self, index):\n        sample = self.samples[index]\n        prompt = self.create_chat_prompt(sample['conversations'])\n        input_ids = self.tokenizer(prompt).input_ids[:self.max_length]\n        input_ids += [self.tokenizer.pad_token_id] * (self.max_length - len(input_ids))\n        labels = self.generate_labels(input_ids)\n        # # ===  ===\n        # print(f\"\\n--- Sample {index} ---\")\n        # for i, (x, y) in enumerate(zip(input_ids[:-1], labels[1:])):\n        #     print(f\"{i:3d}: X={self.tokenizer.decode([x])!r:16s} ---> Y={self.tokenizer.decode([input_ids[i+1]])!r:16s} label={y}\")\n        # # ================\n        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n```\n\n## Epoch\n\npretrainSFTlabels-100PyTorch  `CrossEntropyLoss` ** -100  Label**\n\nloss\n\n## \n\npretrain\n\n```python\ntorchrun --nproc_per_node 1 train_full_sft.py\n# or\npython train_full_sft.py\n```\n\n# KD\n\n    SFTTokenhard labels 0  6400 softmaxsoft labelsKL-Loss SFTKD `1+1=2`a0b100c-99...   LLM/ GPT-4 SFTFT \n\n\n\n-  (`distillation_loss`)\n\n```python\ndef distillation_loss(student_logits, teacher_logits, temperature=1.0, reduction='batchmean'):\n    with torch.no_grad():\n        # 1.  (Soft Targets)\n        #  T (temperature) \n        teacher_probs = F.softmax(teacher_logits / temperature, dim=-1).detach()\n\n    # 2.  Log \n    student_log_probs = F.log_softmax(student_logits / temperature, dim=-1)\n\n    # 3.  KL  (Kullback-Leibler Divergence)\n    # \n    kl = F.kl_div(student_log_probs, teacher_probs, reduction=reduction)\n    \n    # 4. \n    #  T^2 T  1/T^2\n    return (temperature ** 2) * kl\n```\n\n-  (`train_epoch`)\n\n- $$Loss_{total} = \\alpha \\cdot Loss_{CE} + (1 - \\alpha) \\cdot Loss_{Distill}$$\n- Masking  SFT ****\n\n-  Teacher GradientsOptimizer States ** (Weights)**  ** (Activations)** \n\n# LoRA\n\nLoRAParameter-Efficient Fine-Tuning, PEFT Full Fine-TuningLoRA  LoRA \n\n- Lora\n\n```python\nclass LoRA(nn.Module):\n    def __init__(self, in_features, out_features, rank):\n        # rank:  in=512, out=512, rank=8\n        # 512*512 = 26\n        # LoRA512*8 + 8*512 = 8 32 \n        self.rank = rank\n        self.A = nn.Linear(in_features, rank, bias=False)  # \n        self.B = nn.Linear(rank, out_features, bias=False) # \n        \n        # A \n        self.A.weight.data.normal_(mean=0.0, std=0.02)\n        # B  0 \n        self.B.weight.data.zero_()\n\n    def forward(self, x):\n        # forward = B(A(x))\n        return self.B(self.A(x))\n```\n\n- Lora\n\n```python\ndef apply_lora(model, rank=8):\n    # \n    for name, module in model.named_modules():\n        #  Linear  (in == out)\n        # \n        #  Attention  Q, K, V, O  LoRA\n        #  Transformer  hidden_size -> hidden_size \n        if isinstance(module, nn.Linear) and module.weight.shape[0] == module.weight.shape[1]:\n            \n            # 1.  LoRA \n            lora = LoRA(..., rank=rank)\n            setattr(module, \"lora\", lora) #  module.lora = lora\n            \n            # 2.  forward \n            original_forward = module.forward #  forward\n\n            #  forward\n            def forward_with_lora(x, layer1=original_forward, layer2=lora):\n                #  = (x) + LoRA(x)\n                return layer1(x) + layer2(x)\n            \n            # 3. \n            module.forward = forward_with_lora\n```\n\n- \n\n```python\ndef save_lora(model, path):\n    # ...\n    #  'lora' \n    lora_state = {f'{clean_name}.lora.{k}': v for k, v in module.lora.state_dict().items()}\n    state_dict.update(lora_state)\n    #  MB GB\n    torch.save(state_dict, path)\n```\n\n- \n\n```python\nlora_params = []\nfor name, param in model.named_parameters():\n    if 'lora' in name:\n        param.requires_grad = True  # LoRA \n        lora_params.append(param)\n    else:\n        param.requires_grad = False # \noptimizer = optim.AdamW(lora_params, lr=args.learning_rate)\n```\n\n+LoRALoRA\n\nPSfull_sft\n\n# \n\nDeepSeek R1`>3B`RL  SFT+GRPO\n\nSFT\n\n```python\n{\n  \"conversations\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"<think>\\nMiniMind-R1-Lite-Preview\\n</think>\\n<answer>\\nMiniMind-R1-Lite-Preview\\n</answer>\"\n    }\n  ]\n}\n```\n\n\n\n```python\n<think>\\n\\n</think>\\n\n<answer>\\n\\n</answer>\n```\n\nGRPO\n\n- \n\n```python\nsp_ids = torch.isin(shift_labels.view(-1), torch.tensor(start_of_think_ids + ...))\nloss_mask_flat[sp_ids] = 10\n```\n\n `<think>`, `</think>`, `<answer>`, `</answer>`  Loss  **10**\n\n**** SFT \n\n** (SFT)** ** (Next Token Prediction)** DeepSeek-R1 \"AB\" \"AB\" \"B\"  \"B\" \"B\"\n\n** (RL - PPO/GRPO)** ** (Maximize Reward)** \"AC\" \"AB\"\n\n**** 10  Loss  (`loss_mask_flat[sp_ids] = 10`)  `<think>` `<answer>`**Chain-of-Thought, CoT**\n\n****R1\n\n- ** -> \n- ** ->  1 ->  2 -> \n- \n\n# \n\nLLM\n\n1. ** (Reinforcement Learning from Human Feedback, RLHF)**\n\n- ****\n\n1. **AI (Reinforcement Learning from AI Feedback, RLAIF)**\n\n- **AI**\n- AI/...\n\n|   |  |                |                  |\n| ----- | ---- | ------------------ | -------------------- |\n| RLHF  |  |  |        |\n| RLAIF |  |  |  |\n\n****\"****\"\n\n****\n\n## ** (Reinforcement Learning from Human Feedback, RLHF)**\n\n### DPO(Direct Preference Optimization)\n\nDPO\n\n\n\n\n\n- ****: f(rt)=logrwlogrl (chosen vs rejected)\n- ****: g(At) = / ()\n- ****: h(KLt) =    ()\n\n\n\n- DPOPPOKL\"chosenrejected\"Reward/ValueDPO`actor``ref`\n- offpolicyepochRef\n- DPO\"/\"\"\"\n\n```python\ntorchrun --nproc_per_node 1 train_dpo.py\n# or\npython train_dpo.py\n```\n\n## **AI (Reinforcement Learning from AI Feedback, RLAIF)**\n\n","source":"_posts/minimind.md","raw":"---\ntitle: MiniMind\nmathjax: true\ndate: 2026/01/23 20:46:25\nimg: https://raw.githubusercontent.com/jingyaogong/minimind/refs/heads/master/images/logo.png\nexcerpt: Re-implement of MiniMind\n---\n\n# Minimind\n\nMiniMind  **Decoder-only Transformer** `MiniMindConfig` \n\n- **** LLaMA\n- ****`hidden_size=512`, `num_hidden_layers=8``vocab_size=6400` CPU \n- ****\n  - **MoE ()**\n  - **Weight Tying ()**Embedding LM Head\n\n## A. RoPE + YaRN (Rotary Positional Embeddings)\n\n- ** RoPE** LLM  BERT\n\nRoPE  token  embedding ****\n\n $d$  ( hidden_size=512)RoPE  $d/2$  2 \n $j$  ( $j \\in [0, d/2)$) $\\theta_j$\n\n$$\\theta_j = 10000^{-2j/d}$$\n\n- \n  - ** ($j$ )**$\\theta_j$  1****\n  - ** ($j$ )**$\\theta_j$  0****\n\n- **YaRN (Yet another RoPE extensioN)**\n  -  `if end / orig_max > 1.0:` \n  - ****`original_max_position_embeddings`Ramp function RoPE \n\n****\nYaRN  $m$ $\\theta_j$\n\n $\\theta'_j$ \n\n$$\\theta'_j = \\theta_j \\cdot (1 - \\gamma(r) + \\frac{\\gamma(r)}{s})$$\n\nYaRN \n\n$$\\gamma(r) = \\begin{cases} 0, & \\text{if } r < \\alpha \\quad (\\text{/}) \\\\ 1, & \\text{if } r > \\beta \\quad (\\text{/}) \\\\ \\frac{r - \\alpha}{\\beta - \\alpha}, & \\text{otherwise} \\quad (\\text{/}) \\end{cases}$$\n\nYaRN  $\\sqrt{t}$ \n\n$$\\text{Attention}(Q, K) = \\text{softmax}(\\frac{\\mathbf{q}^T \\mathbf{k}}{\\sqrt{d} \\cdot \\sqrt{t}})$$\n\n## B. GQA (Grouped Query Attention)\n\n### MHA: Multi-Head Attention\n\n Query  Key  Value \n- ****\n- ****KV Cache \n\n### MQA: Multi-Query Attention\n\n Query **** Key  Value \n- ****KV Cache \n- ****\n\n### GQA: Group Query Attention\n\n Query Group**** Query  Key/Value\n\n### KV-cache\n\nKV cache  Transformer decoder  token  Key / Value O(T)  O(T) \n\n$l$\n\n$$Q_t^{(l)} = h_t^{(l)} W_Q^{(l)}$$$$K_t^{(l)} = h_t^{(l)}W_K^{(l)}$$\n$$V_t^{(l)} = h_t^{(l)}W_V^{(l)}$$\n\nattention \n\n$$\\text{Attn}_t^{(l)} = \\text{softmax}\\left( \\frac{Q_t^{(l)} [K_1^{(l)}, \\dots, K_t^{(l)}]^T} {\\sqrt{d_h}} \\right) [V_1^{(l)}, \\dots, V_t^{(l)}]$$\n\n$$\\boxed{ \\text{KVCache}^{(l)} = \\left( \\{K_1^{(l)}, \\dots, K_{t-1}^{(l)}\\}, \\{V_1^{(l)}, \\dots, V_{t-1}^{(l)}\\} \\right) }$$\n\n$t$\n\n- $ Q_t, K_t, V_t$\n  \n- append  cache\n  \n-  $Q_t$ cache\n\n$$\\text{} = 2 \\times \\text{Batch} \\times \\text{Seq\\_Len} \\times \\text{KV\\_Heads} \\times \\text{Head\\_Dim} \\times \\text{Byte}$$\n### Flash Attention\n\n Attention \n\n$$\\text{Score} = \\text{Softmax}(Q K^T)$$\n\n$$\\text{Out} = \\text{Score} \\cdot V$$\n\n**Attention Score Matrix** $N \\times N$\n** (HBM)**  **GPU  (SRAM)**GPU \nFlash Attention ** (Tiling)**\n\n- **** $N \\times N$ \n  \n- **** $Q, K, V$  GPU  (SRAM) \n  \n- **** SRAM  Attention\n\n## C.  (Norm & Activation)\n\n### Normalization\n\n  **01**\n#### BatchNorm\n **Batch** \n- ** Batch Size** Batch Size BN \n  \n- ****NLP  Padding BN Padding  0 \n  \n- **RNN/Transformer ** Token Batch BN \n\n#### LayerNorm\n **Feature** \n** Batch Size ** Token Token  512 Hidden Size\n\n\n\n$$y = \\frac{x - \\mu}{\\sigma + \\epsilon} \\cdot \\gamma + \\beta$$\n\n- $\\mu$ (Center)\n  \n- $\\sigma$ (Scale)\n  \n- **** 0  1 \n\n/BSLN\n\n#### RMSNorm\n-  LayerNorm \n  \n    LayerNorm  $\\mu$\n    \n- \n    $$y = \\frac{x}{\\text{RMS}(x)} \\cdot \\gamma$$$$\\text{RMS}(x) = \\sqrt{\\frac{1}{d} \\sum x_i^2}$$\n\nRMSNorm  Bias ($\\beta$) Weight ($\\gamma$)\n\n### Activation Function\n\n#### Sigmoid/Tanh\n- ****S \n  \n- ******** 0\n\n#### ReLu(Rectified Linear Unit)\n- ****$f(x) = \\max(0, x)$\n  \n- **** 0  0 0 \n  \n- ****\n  \n- ******Dead ReLU** 0\n\n#### GELU (Gaussian Error Linear Unit)  BERT/GPT-2 \n\n- **** ReLU ReLU  0 GELU \n  \n- **** 0\n$$GELU(x)=x\\cdot \\Phi(x)$$\n\n\n\n$$\\Phi(x) = P(Z \\le x), \\quad Z \\sim \\mathcal{N}(0,1)$$\n|   |                |\n| ----- | ------------------ |\n| x  0 |  0 0 |\n| x  0 |            |\n| x  0 |  x    |\n#### SiLU(Sigmoid Linear Unit)/SwishLlama\n\n- ****$f(x) = x \\cdot \\text{sigmoid}(x)$\n  \n- **** GELU \n  \n- ****\n  \n    - ****\n      \n    - **** $x$  -2  0 ReLU \n    \n- ****Google  ReLU  GELU \n\n## FFN\n\n### Transformer\n\n Up -> Activation -> Down \n\n$$y = \\text{Down}(\\text{ReLU}(\\text{Up}(x)))$$\n\nUp  Down\n\n### SwiGLU FFN\n```python\nself.gate_proj = nn.Linear(...) #  \nself.up_proj = nn.Linear(...) #  \nself.down_proj = nn.Linear(...) #  \n# forward  \nreturn self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n```\n\n\n$$y = \\text{Down}(\\text{SiLU}(\\text{Gate}(x)) \\times \\text{Up}(x))$$\n\nGLU\n**SwiGLU  GeGLU > ReGLU**\nSiLU \n\n-   \n  \n-   \n  \n- \n\n## MoE(Mixture of Experts)\n\n###  (Shared + Routed)\n\n**Routed Experts** Token \n\n**Shared Experts******\n\n**** MoE \n\n###  (Gating)\n\n `MoEGate` \n\n- **Top-K ** `softmax`  K  (`num_experts_per_tok`)\n- ****`norm_topk_prob` 1\n\n###  (Load Balancing)\n\n `aux_loss`\n\n Token \n\n## \n\n**Training** `repeat_interleave`Mask GPU \n\n**Inference** `moe_infer` Token  (`argsort`) A  Token \n\n# Tokenizer\n\n**** JSONL \n\n**** **BPE (Byte-Pair Encoding)**  6400 \n\n**** `<|im_start|>`Chat Template HuggingFace \n\n- VOCAB_SIZE = 6400\n\n****Embedding  LM Head $6400 \\times Hidden\\_Dim$\n\n**** Token  Token\n\n- BPE+ByteLevel\n\n```python\ntokenizer = Tokenizer(models.BPE())\ntokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n```\n\n**BPE ()**GPT-2/3/4, Llama \n\n**ByteLevel** Unicode  **UTF-8 **\n\n -> `0xE4 0xB8 0xAD` (3)\n\n**** **OOV (Out of Vocabulary)**  Emoji `<UNK>`\n\n- chat_template\n\n```python\n\"chat_template\": \"{%- if tools %}\\n    {{- '<|im_start|>system\\\\n' }}\\n    {%- if messages[0].role == 'system' %}\\n        {{- messages[0].content + '\\\\n\\\\n' }}\\n    {%- endif %}\\n    {{- \\\"# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\" }}\\n    {%- for tool in tools %}\\n        {{- \\\"\\\\n\\\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \\\"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{\\\\\\\"name\\\\\\\": <function-name>, \\\\\\\"arguments\\\\\\\": <args-json-object>}\\\\n</tool_call><|im_end|>\\\\n\\\" }}\\n{%- else %}\\n {%- if messages[0]['role'] == 'system' -%}\\n        {{- '<|im_start|>system\\\\n' + messages[0]['content'] + '<|im_end|>\\\\n' }}\\n    {%- else -%}\\n        {{- '<|im_start|>system\\\\nYou are a helpful assistant<|im_end|>\\\\n' }}\\n {%- endif %}\\n{%- endif %}\\n{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\\n{%- for message in messages[::-1] %}\\n    {%- set index = (messages|length - 1) - loop.index0 %}\\n    {%- if ns.multi_step_tool and message.role == \\\"user\\\" and message.content is string and not(message.content.startswith('<tool_response>') and message.content.endswith('</tool_response>')) %}\\n        {%- set ns.multi_step_tool = false %}\\n        {%- set ns.last_query_index = index %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- for message in messages %}\\n    {%- if message.content is string %}\\n        {%- set content = message.content %}\\n    {%- else %}\\n        {%- set content = '' %}\\n    {%- endif %}\\n    {%- if (message.role == \\\"user\\\") or (message.role == \\\"system\\\" and not loop.first) %}\\n        {{- '<|im_start|>' + message.role + '\\\\n' + content + '<|im_end|>' + '\\\\n' }}\\n    {%- elif message.role == \\\"assistant\\\" %}\\n   {{- '<|im_start|>' + message.role + '\\\\n' + content }}\\n  {%- if message.tool_calls %}\\n            {%- for tool_call in message.tool_calls %}\\n                {%- if (loop.first and content) or (not loop.first) %}\\n                    {{- '\\\\n' }}\\n                {%- endif %}\\n                {%- if tool_call.function %}\\n                    {%- set tool_call = tool_call.function %}\\n                {%- endif %}\\n                {{- '<tool_call>\\\\n{\\\"name\\\": \\\"' }}\\n                {{- tool_call.name }}\\n                {{- '\\\", \\\"arguments\\\": ' }}\\n                {%- if tool_call.arguments is string %}\\n                    {{- tool_call.arguments }}\\n                {%- else %}\\n                    {{- tool_call.arguments | tojson }}\\n                {%- endif %}\\n                {{- '}\\\\n</tool_call>' }}\\n            {%- endfor %}\\n        {%- endif %}\\n        {{- '<|im_end|>\\\\n' }}\\n    {%- elif message.role == \\\"tool\\\" %}\\n        {%- if loop.first or (messages[loop.index0 - 1].role != \\\"tool\\\") %}\\n            {{- '<|im_start|>user' }}\\n        {%- endif %}\\n        {{- '\\\\n<tool_response>\\\\n' }}\\n        {{- content }}\\n        {{- '\\\\n</tool_response>' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \\\"tool\\\") %}\\n            {{- '<|im_end|>\\\\n' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- '<|im_start|>assistant\\\\n' }}\\n    {%- if enable_thinking is defined and enable_thinking is false %}\\n        {{- '<think>\\\\n\\\\n</think>\\\\n\\\\n' }}\\n    {%- endif %}\\n{%- endif %}\"\n```\n\n** Jinja2 ** HuggingFace  `tokenizer.apply_chat_template` ** Python List of Dicts Tokenizer **System Prompt********Tools****\n\n- \n\n```python\n# \nfor tid in input_ids:\n    token_cache.append(tid)\n    current_decode = tokenizer.decode(token_cache)\n    if current_decode and '\\ufffd' not in current_decode:\n        # ...  ...\n        token_cache = []\n```\n\n UTF-8  **3**\n\n Token A (`E6`)  Decode `E6` `` ( \\ufffd, Replacement Character)\n\n**** `token_cache` `\\ufffd`**** Token B (`88 91`)  `E6 88 91``\\ufffd` \n\n# Pretrain\n\nLLM  ModelWiki  ****\n\n## Dataloader\n\n```python\nclass PretrainDataset(Dataset):\n    def __init__(self, data_path, tokenizer, max_length=512):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        # 1. \n        self.samples = load_dataset('json', data_files=data_path, split='train')\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, index):\n        sample = self.samples[index]\n        # 2.  (Tokenization)\n        encoding = self.tokenizer(\n            str(sample['text']),\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        # 3.  Labels ()\n        input_ids = encoding.input_ids.squeeze()\n        labels = input_ids.clone()\n        # 4. Masking Padding\n\t\t#  Pad Token  Label  -100\n\t\t# PyTorch  CrossEntropyLoss  -100\n        labels[input_ids == self.tokenizer.pad_token_id] = -100\n        return input_ids, labels\n```\n\n## Epoch\n\n```python\ndef train_epoch(epoch, loader, iters, start_step=0, wandb=None):\n    for step, (input_ids, labels) in enumerate(loader, start=start_step + 1):\n        #\n        input_ids = input_ids.to(args.device)\n        labels = labels.to(args.device)\n        #  Cosine Decay\n        lr = get_lr(epoch * iters + step, args.epochs * iters, args.learning_rate)\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n\t\t# autocast_ctx \n        #  float16  bfloat16 \n        with autocast_ctx:\n            res = model(input_ids, labels=labels)\n            # res.loss  Loss\n            # res.aux_loss  MoE  Loss\n            loss = res.loss + res.aux_loss\n            # \n            loss = loss / args.accumulation_steps\n\t\t# scaler  GradScaler float16 \n        #  scale float16 Loss  0.00001\n        #  0scaler  Loss  65536\n        # \n        scaler.scale(loss).backward()\n\n        if (step + 1) % args.accumulation_steps == 0:\n            # 1. Unscale\n            #  clip_grad_norm \n            scaler.unscale_(optimizer)\n            # 2.  (Gradient Clipping)\n            #  args.grad_clip ( 1.0)\n            #  LLM \n            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n\t\t\t# scaler.step  Inf/NaN\n            scaler.step(optimizer)\n            # 4. \n            scaler.update()\n\t\t\t# 5. \n            # set_to_none=True  =0 \n            optimizer.zero_grad(set_to_none=True)\n\t\t##.....\n\t\t\n        # Rank 0\n        if (step % args.save_interval == 0 or step == iters - 1) and is_main_process():\n            model.eval()\n            moe_suffix = '_moe' if lm_config.use_moe else ''\n            ckp = f'{args.save_dir}/{args.save_weight}_{lm_config.hidden_size}{moe_suffix}.pth'\n            #  DDP .module\n            raw_model = model.module if isinstance(model, DistributedDataParallel) else model\n            #  torch.compile _orig_mod\n            raw_model = getattr(raw_model, '_orig_mod', raw_model)\n            state_dict = raw_model.state_dict()\n            # 1.  (.pth)\n            # .half() float16 \n            # .cpu() CPU\n            torch.save({k: v.half().cpu() for k, v in state_dict.items()}, ckp)\n            # 2.  (Checkpoint)\n            #  optimizerscaler epoch  step\n            # Resume\n            lm_checkpoint(lm_config, weight=args.save_weight, model=model, optimizer=optimizer, scaler=scaler, epoch=epoch, step=step, wandb=wandb, save_dir='../checkpoints')\n            model.train()\n            del state_dict\n\n        del input_ids, labels, res, loss\n```\n\n## \n\n```python\n    # ========== 1.  ==========\n    local_rank = init_distributed_mode()\n    if dist.is_initialized(): args.device = f\"cuda:{local_rank}\"\n    setup_seed(42 + (dist.get_rank() if dist.is_initialized() else 0))\n    #  Dropout \n    \n    # ========== 2. ckp ==========\n    os.makedirs(args.save_dir, exist_ok=True)\n    lm_config = MiniMindConfig(hidden_size=args.hidden_size, num_hidden_layers=args.num_hidden_layers, use_moe=bool(args.use_moe))\n    # lm_checkpoint  ../checkpoints  args.save_weight \n\t# epochstep  ckp_data \n    ckp_data = lm_checkpoint(lm_config, weight=args.save_weight, save_dir='../checkpoints') if args.from_resume==1 else None\n    \n    # ========== 3.  ==========\n    device_type = \"cuda\" if \"cuda\" in args.device else \"cpu\"\n    dtype = torch.bfloat16 if args.dtype == \"bfloat16\" else torch.float16\n    #  train_epoch \n    autocast_ctx = nullcontext() if device_type == \"cpu\" else torch.cuda.amp.autocast(dtype=dtype)\n    \n    # ========== 4. wandb ==========\n\t# \n    \n    # ========== 5.  ==========\n    model, tokenizer = init_model(lm_config, args.from_weight, device=args.device)\n    if args.use_compile == 1:\n        model = torch.compile(model)\n        Logger('torch.compile enabled')\n    train_ds = PretrainDataset(args.data_path, tokenizer, max_length=args.max_seq_len)\n    #  DDP  N N=\n    train_sampler = DistributedSampler(train_ds) if dist.is_initialized() else None\n    # GradScaler float16 \n\t#  bfloat16enabled=False\n    scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype == 'float16'))\n    optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate)\n    \n    # ========== 6. ckp ==========\n    start_epoch, start_step = 0, 0\n    if ckp_data:\n        model.load_state_dict(ckp_data['model'])\n        optimizer.load_state_dict(ckp_data['optimizer'])\n        scaler.load_state_dict(ckp_data['scaler'])\n        start_epoch = ckp_data['epoch']\n        start_step = ckp_data.get('step', 0)\n    \n    # ========== 7. DDP ==========\n    if dist.is_initialized():\n        model._ddp_params_and_buffers_to_ignore = {\"freqs_cos\", \"freqs_sin\"}\n        model = DistributedDataParallel(model, device_ids=[local_rank])\n    \n    # ========== 8.  ==========\n    for epoch in range(start_epoch, args.epochs):\n        train_sampler and train_sampler.set_epoch(epoch)\n        if epoch == start_epoch and start_step > 0: # epoch\n            # SkipBatchSampler \n        \t#  1000  batch index\n        \t# Dataloader  1000 \n            batch_sampler = SkipBatchSampler(train_sampler or range(len(train_ds)), args.batch_size, start_step + 1)\n            loader = DataLoader(train_ds, batch_sampler=batch_sampler, num_workers=args.num_workers, pin_memory=True)\n            Logger(f'Epoch [{epoch + 1}/{args.epochs}]: {start_step}stepstep {start_step + 1}')\n            train_epoch(epoch, loader, len(loader) + start_step + 1, start_step, wandb)\n        else: # \n            loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=(train_sampler is None), sampler=train_sampler, num_workers=args.num_workers, pin_memory=True)\n            train_epoch(epoch, loader, len(loader), 0, wandb)\n    \n    # ========== 9.  ==========\n    if dist.is_initialized(): dist.destroy_process_group()\n```\n\n```bash\ntorchrun --nproc_per_node 1 train_pretrain.py # 1 (>=2)\n# or\npython train_pretrain.py\n```\n\n[](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data) `<512`1.6GB `pretrain_hq.jsonl`hqhigh quality\n\n`pretrain_hq.jsonl` \n\n```\n{\"text\": \" ...\"}\n```\n\n# SFT\n\nLLM SFTLLM ->->  MiniMind512200800 2k/4k/8kRoPE-NTK\n\n## DataLoader\n\n```python\nclass SFTDataset(Dataset):\n    def __init__(self, jsonl_path, tokenizer, max_length=1024):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.samples = load_dataset('json', data_files=jsonl_path, split='train')\n        self.bos_id = tokenizer(f'{tokenizer.bos_token}assistant\\n', add_special_tokens=False).input_ids\n        self.eos_id = tokenizer(f'{tokenizer.eos_token}\\n', add_special_tokens=False).input_ids\n\n    def __len__(self):\n        return len(self.samples)\n    \n\t# tokenizer  chat template prompt\n    def create_chat_prompt(self, cs):\n        messages = cs.copy()\n        tools = cs[0][\"functions\"] if (cs and cs[0][\"role\"] == \"system\" and cs[0].get(\"functions\")) else None\n        return self.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=False,\n            tools=tools\n        )\n\n    def generate_labels(self, input_ids):\n        # 1.  (-100)\n        labels = [-100] * len(input_ids)\n        # 2.  input_ids \n        i = 0\n        while i < len(input_ids):\n            # 3.  Assistant  (self.bos_id)\n            if input_ids[i:i + len(self.bos_id)] == self.bos_id:\n                start = i + len(self.bos_id)\n                # 4.  Assistant  (self.eos_id)\n                end = start\n                while end < len(input_ids):\n                    if input_ids[end:end + len(self.eos_id)] == self.eos_id:\n                        break\n                    end += 1\n                # 5.  Mask\n            \t#  [start, end]  labels  input_ids \n            \t#  Loss\n                for j in range(start, min(end + len(self.eos_id), self.max_length)):\n                    labels[j] = input_ids[j]\n                i = end + len(self.eos_id) if end < len(input_ids) else len(input_ids)\n            else:\n                i += 1\n        return labels\n\n    def __getitem__(self, index):\n        sample = self.samples[index]\n        prompt = self.create_chat_prompt(sample['conversations'])\n        input_ids = self.tokenizer(prompt).input_ids[:self.max_length]\n        input_ids += [self.tokenizer.pad_token_id] * (self.max_length - len(input_ids))\n        labels = self.generate_labels(input_ids)\n        # # ===  ===\n        # print(f\"\\n--- Sample {index} ---\")\n        # for i, (x, y) in enumerate(zip(input_ids[:-1], labels[1:])):\n        #     print(f\"{i:3d}: X={self.tokenizer.decode([x])!r:16s} ---> Y={self.tokenizer.decode([input_ids[i+1]])!r:16s} label={y}\")\n        # # ================\n        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n```\n\n## Epoch\n\npretrainSFTlabels-100PyTorch  `CrossEntropyLoss` ** -100  Label**\n\nloss\n\n## \n\npretrain\n\n```python\ntorchrun --nproc_per_node 1 train_full_sft.py\n# or\npython train_full_sft.py\n```\n\n# KD\n\n    SFTTokenhard labels 0  6400 softmaxsoft labelsKL-Loss SFTKD `1+1=2`a0b100c-99...   LLM/ GPT-4 SFTFT \n\n\n\n-  (`distillation_loss`)\n\n```python\ndef distillation_loss(student_logits, teacher_logits, temperature=1.0, reduction='batchmean'):\n    with torch.no_grad():\n        # 1.  (Soft Targets)\n        #  T (temperature) \n        teacher_probs = F.softmax(teacher_logits / temperature, dim=-1).detach()\n\n    # 2.  Log \n    student_log_probs = F.log_softmax(student_logits / temperature, dim=-1)\n\n    # 3.  KL  (Kullback-Leibler Divergence)\n    # \n    kl = F.kl_div(student_log_probs, teacher_probs, reduction=reduction)\n    \n    # 4. \n    #  T^2 T  1/T^2\n    return (temperature ** 2) * kl\n```\n\n-  (`train_epoch`)\n\n- $$Loss_{total} = \\alpha \\cdot Loss_{CE} + (1 - \\alpha) \\cdot Loss_{Distill}$$\n- Masking  SFT ****\n\n-  Teacher GradientsOptimizer States ** (Weights)**  ** (Activations)** \n\n# LoRA\n\nLoRAParameter-Efficient Fine-Tuning, PEFT Full Fine-TuningLoRA  LoRA \n\n- Lora\n\n```python\nclass LoRA(nn.Module):\n    def __init__(self, in_features, out_features, rank):\n        # rank:  in=512, out=512, rank=8\n        # 512*512 = 26\n        # LoRA512*8 + 8*512 = 8 32 \n        self.rank = rank\n        self.A = nn.Linear(in_features, rank, bias=False)  # \n        self.B = nn.Linear(rank, out_features, bias=False) # \n        \n        # A \n        self.A.weight.data.normal_(mean=0.0, std=0.02)\n        # B  0 \n        self.B.weight.data.zero_()\n\n    def forward(self, x):\n        # forward = B(A(x))\n        return self.B(self.A(x))\n```\n\n- Lora\n\n```python\ndef apply_lora(model, rank=8):\n    # \n    for name, module in model.named_modules():\n        #  Linear  (in == out)\n        # \n        #  Attention  Q, K, V, O  LoRA\n        #  Transformer  hidden_size -> hidden_size \n        if isinstance(module, nn.Linear) and module.weight.shape[0] == module.weight.shape[1]:\n            \n            # 1.  LoRA \n            lora = LoRA(..., rank=rank)\n            setattr(module, \"lora\", lora) #  module.lora = lora\n            \n            # 2.  forward \n            original_forward = module.forward #  forward\n\n            #  forward\n            def forward_with_lora(x, layer1=original_forward, layer2=lora):\n                #  = (x) + LoRA(x)\n                return layer1(x) + layer2(x)\n            \n            # 3. \n            module.forward = forward_with_lora\n```\n\n- \n\n```python\ndef save_lora(model, path):\n    # ...\n    #  'lora' \n    lora_state = {f'{clean_name}.lora.{k}': v for k, v in module.lora.state_dict().items()}\n    state_dict.update(lora_state)\n    #  MB GB\n    torch.save(state_dict, path)\n```\n\n- \n\n```python\nlora_params = []\nfor name, param in model.named_parameters():\n    if 'lora' in name:\n        param.requires_grad = True  # LoRA \n        lora_params.append(param)\n    else:\n        param.requires_grad = False # \noptimizer = optim.AdamW(lora_params, lr=args.learning_rate)\n```\n\n+LoRALoRA\n\nPSfull_sft\n\n# \n\nDeepSeek R1`>3B`RL  SFT+GRPO\n\nSFT\n\n```python\n{\n  \"conversations\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"<think>\\nMiniMind-R1-Lite-Preview\\n</think>\\n<answer>\\nMiniMind-R1-Lite-Preview\\n</answer>\"\n    }\n  ]\n}\n```\n\n\n\n```python\n<think>\\n\\n</think>\\n\n<answer>\\n\\n</answer>\n```\n\nGRPO\n\n- \n\n```python\nsp_ids = torch.isin(shift_labels.view(-1), torch.tensor(start_of_think_ids + ...))\nloss_mask_flat[sp_ids] = 10\n```\n\n `<think>`, `</think>`, `<answer>`, `</answer>`  Loss  **10**\n\n**** SFT \n\n** (SFT)** ** (Next Token Prediction)** DeepSeek-R1 \"AB\" \"AB\" \"B\"  \"B\" \"B\"\n\n** (RL - PPO/GRPO)** ** (Maximize Reward)** \"AC\" \"AB\"\n\n**** 10  Loss  (`loss_mask_flat[sp_ids] = 10`)  `<think>` `<answer>`**Chain-of-Thought, CoT**\n\n****R1\n\n- ** -> \n- ** ->  1 ->  2 -> \n- \n\n# \n\nLLM\n\n1. ** (Reinforcement Learning from Human Feedback, RLHF)**\n\n- ****\n\n1. **AI (Reinforcement Learning from AI Feedback, RLAIF)**\n\n- **AI**\n- AI/...\n\n|   |  |                |                  |\n| ----- | ---- | ------------------ | -------------------- |\n| RLHF  |  |  |        |\n| RLAIF |  |  |  |\n\n****\"****\"\n\n****\n\n## ** (Reinforcement Learning from Human Feedback, RLHF)**\n\n### DPO(Direct Preference Optimization)\n\nDPO\n\n\n\n\n\n- ****: f(rt)=logrwlogrl (chosen vs rejected)\n- ****: g(At) = / ()\n- ****: h(KLt) =    ()\n\n\n\n- DPOPPOKL\"chosenrejected\"Reward/ValueDPO`actor``ref`\n- offpolicyepochRef\n- DPO\"/\"\"\"\n\n```python\ntorchrun --nproc_per_node 1 train_dpo.py\n# or\npython train_dpo.py\n```\n\n## **AI (Reinforcement Learning from AI Feedback, RLAIF)**\n\n","slug":"minimind","published":1,"updated":"2026-01-24T07:56:47.557Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff9000lss994v899pd5","content":"<h1 id=\"Minimind\"><a href=\"#Minimind\" class=\"headerlink\" title=\"Minimind\"></a>Minimind</h1><p>MiniMind  <strong>Decoder-only Transformer</strong> <code>MiniMindConfig</code> </p>\n<ul>\n<li><strong></strong> LLaMA</li>\n<li><strong></strong><code>hidden_size=512</code>, <code>num_hidden_layers=8</code><code>vocab_size=6400</code> CPU </li>\n<li><strong></strong><ul>\n<li>**MoE ()**</li>\n<li>**Weight Tying ()**Embedding LM Head</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"A-RoPE-YaRN-Rotary-Positional-Embeddings\"><a href=\"#A-RoPE-YaRN-Rotary-Positional-Embeddings\" class=\"headerlink\" title=\"A. RoPE + YaRN (Rotary Positional Embeddings)\"></a>A. RoPE + YaRN (Rotary Positional Embeddings)</h2><ul>\n<li><strong> RoPE</strong> LLM  BERT</li>\n</ul>\n<p>RoPE  token  embedding <strong></strong></p>\n<p> $d$  ( hidden_size&#x3D;512)RoPE  $d&#x2F;2$  2 <br> $j$  ( $j \\in [0, d&#x2F;2)$) $\\theta_j$</p>\n<p>$$\\theta_j &#x3D; 10000^{-2j&#x2F;d}$$</p>\n<p>- </p>\n<ul>\n<li><p><strong> ($j$ )<strong>$\\theta_j$  1</strong></strong></p>\n</li>\n<li><p><strong> ($j$ )<strong>$\\theta_j$  0</strong></strong></p>\n</li>\n<li><p>**YaRN (Yet another RoPE extensioN)**</p>\n<ul>\n<li> <code>if end / orig_max &gt; 1.0:</code> </li>\n<li><strong></strong><code>original_max_position_embeddings</code>Ramp function RoPE </li>\n</ul>\n</li>\n</ul>\n<p><strong></strong><br>YaRN  $m$ $\\theta_j$</p>\n<p> $\\theta_j$ </p>\n<p>$$\\theta_j &#x3D; \\theta_j \\cdot (1 - \\gamma(r) + \\frac{\\gamma(r)}{s})$$</p>\n<p>YaRN </p>\n<p>$$\\gamma(r) &#x3D; \\begin{cases} 0, &amp; \\text{if } r &lt; \\alpha \\quad (\\text{&#x2F;}) \\ 1, &amp; \\text{if } r &gt; \\beta \\quad (\\text{&#x2F;}) \\ \\frac{r - \\alpha}{\\beta - \\alpha}, &amp; \\text{otherwise} \\quad (\\text{&#x2F;}) \\end{cases}$$</p>\n<p>YaRN  $\\sqrt{t}$ </p>\n<p>$$\\text{Attention}(Q, K) &#x3D; \\text{softmax}(\\frac{\\mathbf{q}^T \\mathbf{k}}{\\sqrt{d} \\cdot \\sqrt{t}})$$</p>\n<h2 id=\"B-GQA-Grouped-Query-Attention\"><a href=\"#B-GQA-Grouped-Query-Attention\" class=\"headerlink\" title=\"B. GQA (Grouped Query Attention)\"></a>B. GQA (Grouped Query Attention)</h2><h3 id=\"MHA-Multi-Head-Attention\"><a href=\"#MHA-Multi-Head-Attention\" class=\"headerlink\" title=\"MHA: Multi-Head Attention\"></a>MHA: Multi-Head Attention</h3><p> Query  Key  Value </p>\n<ul>\n<li><strong></strong></li>\n<li><strong></strong>KV Cache </li>\n</ul>\n<h3 id=\"MQA-Multi-Query-Attention\"><a href=\"#MQA-Multi-Query-Attention\" class=\"headerlink\" title=\"MQA: Multi-Query Attention\"></a>MQA: Multi-Query Attention</h3><p> Query <strong></strong> Key  Value </p>\n<ul>\n<li><strong></strong>KV Cache </li>\n<li><strong></strong></li>\n</ul>\n<h3 id=\"GQA-Group-Query-Attention\"><a href=\"#GQA-Group-Query-Attention\" class=\"headerlink\" title=\"GQA: Group Query Attention\"></a>GQA: Group Query Attention</h3><p> Query Group<strong></strong> Query  Key&#x2F;Value</p>\n<h3 id=\"KV-cache\"><a href=\"#KV-cache\" class=\"headerlink\" title=\"KV-cache\"></a>KV-cache</h3><p>KV cache  Transformer decoder  token  Key &#x2F; Value O(T)  O(T) </p>\n<p>$l$</p>\n<p>$$Q_t^{(l)} &#x3D; h_t^{(l)} W_Q^{(l)}$$$$K_t^{(l)} &#x3D; h_t^{(l)}W_K^{(l)}$$<br>$$V_t^{(l)} &#x3D; h_t^{(l)}W_V^{(l)}$$</p>\n<p>attention </p>\n<p>$$\\text{Attn}_t^{(l)} &#x3D; \\text{softmax}\\left( \\frac{Q_t^{(l)} [K_1^{(l)}, \\dots, K_t^{(l)}]^T} {\\sqrt{d_h}} \\right) [V_1^{(l)}, \\dots, V_t^{(l)}]$$</p>\n<p>$$\\boxed{ \\text{KVCache}^{(l)} &#x3D; \\left( {K_1^{(l)}, \\dots, K_{t-1}^{(l)}}, {V_1^{(l)}, \\dots, V_{t-1}^{(l)}} \\right) }$$</p>\n<p>$t$</p>\n<ul>\n<li><p>$ Q_t, K_t, V_t$</p>\n</li>\n<li><p>append  cache</p>\n</li>\n<li><p> $Q_t$ cache</p>\n</li>\n</ul>\n<p>$$\\text{} &#x3D; 2 \\times \\text{Batch} \\times \\text{Seq_Len} \\times \\text{KV_Heads} \\times \\text{Head_Dim} \\times \\text{Byte}$$</p>\n<h3 id=\"Flash-Attention\"><a href=\"#Flash-Attention\" class=\"headerlink\" title=\"Flash Attention\"></a>Flash Attention</h3><p> Attention </p>\n<p>$$\\text{Score} &#x3D; \\text{Softmax}(Q K^T)$$</p>\n<p>$$\\text{Out} &#x3D; \\text{Score} \\cdot V$$</p>\n<p><strong>Attention Score Matrix</strong> $N \\times N$<br><strong> (HBM)</strong>  **GPU  (SRAM)<strong>GPU <br>Flash Attention </strong> (Tiling)**</p>\n<ul>\n<li><p><strong></strong> $N \\times N$ </p>\n</li>\n<li><p><strong></strong> $Q, K, V$  GPU  (SRAM) </p>\n</li>\n<li><p><strong></strong> SRAM  Attention</p>\n</li>\n</ul>\n<h2 id=\"C--Norm-Activation\"><a href=\"#C--Norm-Activation\" class=\"headerlink\" title=\"C.  (Norm &amp; Activation)\"></a>C.  (Norm &amp; Activation)</h2><h3 id=\"Normalization\"><a href=\"#Normalization\" class=\"headerlink\" title=\"Normalization\"></a>Normalization</h3><p>  <strong>01</strong></p>\n<h4 id=\"BatchNorm\"><a href=\"#BatchNorm\" class=\"headerlink\" title=\"BatchNorm\"></a>BatchNorm</h4><p> <strong>Batch</strong> </p>\n<ul>\n<li><p><strong> Batch Size</strong> Batch Size BN </p>\n</li>\n<li><p><strong></strong>NLP  Padding BN Padding  0 </p>\n</li>\n<li><p><strong>RNN&#x2F;Transformer </strong> Token Batch BN </p>\n</li>\n</ul>\n<h4 id=\"LayerNorm\"><a href=\"#LayerNorm\" class=\"headerlink\" title=\"LayerNorm\"></a>LayerNorm</h4><p> <strong>Feature</strong> <br><strong> Batch Size </strong> Token Token  512 Hidden Size</p>\n<p></p>\n<p>$$y &#x3D; \\frac{x - \\mu}{\\sigma + \\epsilon} \\cdot \\gamma + \\beta$$</p>\n<ul>\n<li><p>$\\mu$ (Center)</p>\n</li>\n<li><p>$\\sigma$ (Scale)</p>\n</li>\n<li><p><strong></strong> 0  1 </p>\n</li>\n</ul>\n<p>&#x2F;BSLN</p>\n<h4 id=\"RMSNorm\"><a href=\"#RMSNorm\" class=\"headerlink\" title=\"RMSNorm\"></a>RMSNorm</h4><ul>\n<li><p> LayerNorm </p>\n<p>  LayerNorm  $\\mu$</p>\n</li>\n<li><p><br>  $$y &#x3D; \\frac{x}{\\text{RMS}(x)} \\cdot \\gamma$$$$\\text{RMS}(x) &#x3D; \\sqrt{\\frac{1}{d} \\sum x_i^2}$$</p>\n</li>\n</ul>\n<p>RMSNorm  Bias ($\\beta$) Weight ($\\gamma$)</p>\n<h3 id=\"Activation-Function\"><a href=\"#Activation-Function\" class=\"headerlink\" title=\"Activation Function\"></a>Activation Function</h3><h4 id=\"Sigmoid-Tanh\"><a href=\"#Sigmoid-Tanh\" class=\"headerlink\" title=\"Sigmoid&#x2F;Tanh\"></a>Sigmoid&#x2F;Tanh</h4><ul>\n<li><p><strong></strong>S </p>\n</li>\n<li><p><strong></strong><strong></strong> 0</p>\n</li>\n</ul>\n<h4 id=\"ReLu-Rectified-Linear-Unit\"><a href=\"#ReLu-Rectified-Linear-Unit\" class=\"headerlink\" title=\"ReLu(Rectified Linear Unit)\"></a>ReLu(Rectified Linear Unit)</h4><ul>\n<li><p><strong></strong>$f(x) &#x3D; \\max(0, x)$</p>\n</li>\n<li><p><strong></strong> 0  0 0 </p>\n</li>\n<li><p><strong></strong></p>\n</li>\n<li><p><strong></strong><strong>Dead ReLU</strong> 0</p>\n</li>\n</ul>\n<h4 id=\"GELU-Gaussian-Error-Linear-Unit--BERT-GPT-2-\"><a href=\"#GELU-Gaussian-Error-Linear-Unit--BERT-GPT-2-\" class=\"headerlink\" title=\"GELU (Gaussian Error Linear Unit)  BERT&#x2F;GPT-2 \"></a>GELU (Gaussian Error Linear Unit)  BERT&#x2F;GPT-2 </h4><ul>\n<li><p><strong></strong> ReLU ReLU  0 GELU </p>\n</li>\n<li><p><strong></strong> 0<br>$$GELU(x)&#x3D;x\\cdot \\Phi(x)$$</p>\n</li>\n</ul>\n<p></p>\n<p>$$\\Phi(x) &#x3D; P(Z \\le x), \\quad Z \\sim \\mathcal{N}(0,1)$$</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>x  0</td>\n<td> 0 0</td>\n</tr>\n<tr>\n<td>x  0</td>\n<td></td>\n</tr>\n<tr>\n<td>x  0</td>\n<td> x</td>\n</tr>\n</tbody></table>\n<h4 id=\"SiLU-Sigmoid-Linear-Unit-SwishLlama\"><a href=\"#SiLU-Sigmoid-Linear-Unit-SwishLlama\" class=\"headerlink\" title=\"SiLU(Sigmoid Linear Unit)&#x2F;SwishLlama\"></a>SiLU(Sigmoid Linear Unit)&#x2F;SwishLlama</h4><ul>\n<li><p><strong></strong>$f(x) &#x3D; x \\cdot \\text{sigmoid}(x)$</p>\n</li>\n<li><p><strong></strong> GELU </p>\n</li>\n<li><p><strong></strong></p>\n<ul>\n<li><p><strong></strong></p>\n</li>\n<li><p><strong></strong> $x$  -2  0 ReLU </p>\n</li>\n</ul>\n</li>\n<li><p><strong></strong>Google  ReLU  GELU </p>\n</li>\n</ul>\n<h2 id=\"FFN\"><a href=\"#FFN\" class=\"headerlink\" title=\"FFN\"></a>FFN</h2><h3 id=\"Transformer\"><a href=\"#Transformer\" class=\"headerlink\" title=\"Transformer\"></a>Transformer</h3><p> Up -&gt; Activation -&gt; Down </p>\n<p>$$y &#x3D; \\text{Down}(\\text{ReLU}(\\text{Up}(x)))$$</p>\n<p>Up  Down</p>\n<h3 id=\"SwiGLU-FFN\"><a href=\"#SwiGLU-FFN\" class=\"headerlink\" title=\"SwiGLU FFN\"></a>SwiGLU FFN</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable language_\">self</span>.gate_proj = nn.Linear(...) <span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"variable language_\">self</span>.up_proj = nn.Linear(...) <span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"variable language_\">self</span>.down_proj = nn.Linear(...) <span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># forward  </span></span><br><span class=\"line\"><span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.down_proj(<span class=\"variable language_\">self</span>.act_fn(<span class=\"variable language_\">self</span>.gate_proj(x)) * <span class=\"variable language_\">self</span>.up_proj(x))</span><br></pre></td></tr></table></figure>\n<p></p>\n<p>$$y &#x3D; \\text{Down}(\\text{SiLU}(\\text{Gate}(x)) \\times \\text{Up}(x))$$</p>\n<p>GLU<br><strong>SwiGLU  GeGLU &gt; ReGLU</strong><br>SiLU </p>\n<ul>\n<li><p>  </p>\n</li>\n<li><p>  </p>\n</li>\n<li><p></p>\n</li>\n</ul>\n<h2 id=\"MoE-Mixture-of-Experts-\"><a href=\"#MoE-Mixture-of-Experts-\" class=\"headerlink\" title=\"MoE(Mixture of Experts)\"></a>MoE(Mixture of Experts)</h2><h3 id=\"-Shared-Routed\"><a href=\"#-Shared-Routed\" class=\"headerlink\" title=\" (Shared + Routed)\"></a> (Shared + Routed)</h3><p><strong>Routed Experts</strong> Token </p>\n<p><strong>Shared Experts</strong><strong></strong></p>\n<p><strong></strong> MoE </p>\n<h3 id=\"-Gating\"><a href=\"#-Gating\" class=\"headerlink\" title=\" (Gating)\"></a> (Gating)</h3><p> <code>MoEGate</code> </p>\n<ul>\n<li><strong>Top-K </strong> <code>softmax</code>  K  (<code>num_experts_per_tok</code>)</li>\n<li><strong></strong><code>norm_topk_prob</code> 1</li>\n</ul>\n<h3 id=\"-Load-Balancing\"><a href=\"#-Load-Balancing\" class=\"headerlink\" title=\" (Load Balancing)\"></a> (Load Balancing)</h3><p> <code>aux_loss</code></p>\n<p> Token </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong>Training</strong> <code>repeat_interleave</code>Mask GPU </p>\n<p><strong>Inference</strong> <code>moe_infer</code> Token  (<code>argsort</code>) A  Token </p>\n<h1 id=\"Tokenizer\"><a href=\"#Tokenizer\" class=\"headerlink\" title=\"Tokenizer\"></a>Tokenizer</h1><p><strong></strong> JSONL </p>\n<p><strong></strong> <strong>BPE (Byte-Pair Encoding)</strong>  6400 </p>\n<p><strong></strong> <code>&lt;|im_start|&gt;</code>Chat Template HuggingFace </p>\n<ul>\n<li>VOCAB_SIZE &#x3D; 6400</li>\n</ul>\n<p><strong></strong>Embedding  LM Head $6400 \\times Hidden_Dim$</p>\n<p><strong></strong> Token  Token</p>\n<ul>\n<li>BPE+ByteLevel</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tokenizer = Tokenizer(models.BPE())</span><br><span class=\"line\">tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p>**BPE ()**GPT-2&#x2F;3&#x2F;4, Llama </p>\n<p><strong>ByteLevel</strong> Unicode  <strong>UTF-8 </strong></p>\n<p> -&gt; <code>0xE4 0xB8 0xAD</code> (3)</p>\n<p><strong></strong> <strong>OOV (Out of Vocabulary)</strong>  Emoji <code>&lt;UNK&gt;</code></p>\n<ul>\n<li>chat_template</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&quot;chat_template&quot;</span>: <span class=\"string\">&quot;&#123;%- if tools %&#125;\\n    &#123;&#123;- &#x27;&lt;|im_start|&gt;system\\\\n&#x27; &#125;&#125;\\n    &#123;%- if messages[0].role == &#x27;system&#x27; %&#125;\\n        &#123;&#123;- messages[0].content + &#x27;\\\\n\\\\n&#x27; &#125;&#125;\\n    &#123;%- endif %&#125;\\n    &#123;&#123;- \\&quot;# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:\\\\n&lt;tools&gt;\\&quot; &#125;&#125;\\n    &#123;%- for tool in tools %&#125;\\n        &#123;&#123;- \\&quot;\\\\n\\&quot; &#125;&#125;\\n        &#123;&#123;- tool | tojson &#125;&#125;\\n    &#123;%- endfor %&#125;\\n    &#123;&#123;- \\&quot;\\\\n&lt;/tools&gt;\\\\n\\\\nFor each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:\\\\n&lt;tool_call&gt;\\\\n&#123;\\\\\\&quot;name\\\\\\&quot;: &lt;function-name&gt;, \\\\\\&quot;arguments\\\\\\&quot;: &lt;args-json-object&gt;&#125;\\\\n&lt;/tool_call&gt;&lt;|im_end|&gt;\\\\n\\&quot; &#125;&#125;\\n&#123;%- else %&#125;\\n &#123;%- if messages[0][&#x27;role&#x27;] == &#x27;system&#x27; -%&#125;\\n        &#123;&#123;- &#x27;&lt;|im_start|&gt;system\\\\n&#x27; + messages[0][&#x27;content&#x27;] + &#x27;&lt;|im_end|&gt;\\\\n&#x27; &#125;&#125;\\n    &#123;%- else -%&#125;\\n        &#123;&#123;- &#x27;&lt;|im_start|&gt;system\\\\nYou are a helpful assistant&lt;|im_end|&gt;\\\\n&#x27; &#125;&#125;\\n &#123;%- endif %&#125;\\n&#123;%- endif %&#125;\\n&#123;%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %&#125;\\n&#123;%- for message in messages[::-1] %&#125;\\n    &#123;%- set index = (messages|length - 1) - loop.index0 %&#125;\\n    &#123;%- if ns.multi_step_tool and message.role == \\&quot;user\\&quot; and message.content is string and not(message.content.startswith(&#x27;&lt;tool_response&gt;&#x27;) and message.content.endswith(&#x27;&lt;/tool_response&gt;&#x27;)) %&#125;\\n        &#123;%- set ns.multi_step_tool = false %&#125;\\n        &#123;%- set ns.last_query_index = index %&#125;\\n    &#123;%- endif %&#125;\\n&#123;%- endfor %&#125;\\n&#123;%- for message in messages %&#125;\\n    &#123;%- if message.content is string %&#125;\\n        &#123;%- set content = message.content %&#125;\\n    &#123;%- else %&#125;\\n        &#123;%- set content = &#x27;&#x27; %&#125;\\n    &#123;%- endif %&#125;\\n    &#123;%- if (message.role == \\&quot;user\\&quot;) or (message.role == \\&quot;system\\&quot; and not loop.first) %&#125;\\n        &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\\\\n&#x27; + content + &#x27;&lt;|im_end|&gt;&#x27; + &#x27;\\\\n&#x27; &#125;&#125;\\n    &#123;%- elif message.role == \\&quot;assistant\\&quot; %&#125;\\n   &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\\\\n&#x27; + content &#125;&#125;\\n  &#123;%- if message.tool_calls %&#125;\\n            &#123;%- for tool_call in message.tool_calls %&#125;\\n                &#123;%- if (loop.first and content) or (not loop.first) %&#125;\\n                    &#123;&#123;- &#x27;\\\\n&#x27; &#125;&#125;\\n                &#123;%- endif %&#125;\\n                &#123;%- if tool_call.function %&#125;\\n                    &#123;%- set tool_call = tool_call.function %&#125;\\n                &#123;%- endif %&#125;\\n                &#123;&#123;- &#x27;&lt;tool_call&gt;\\\\n&#123;\\&quot;name\\&quot;: \\&quot;&#x27; &#125;&#125;\\n                &#123;&#123;- tool_call.name &#125;&#125;\\n                &#123;&#123;- &#x27;\\&quot;, \\&quot;arguments\\&quot;: &#x27; &#125;&#125;\\n                &#123;%- if tool_call.arguments is string %&#125;\\n                    &#123;&#123;- tool_call.arguments &#125;&#125;\\n                &#123;%- else %&#125;\\n                    &#123;&#123;- tool_call.arguments | tojson &#125;&#125;\\n                &#123;%- endif %&#125;\\n                &#123;&#123;- &#x27;&#125;\\\\n&lt;/tool_call&gt;&#x27; &#125;&#125;\\n            &#123;%- endfor %&#125;\\n        &#123;%- endif %&#125;\\n        &#123;&#123;- &#x27;&lt;|im_end|&gt;\\\\n&#x27; &#125;&#125;\\n    &#123;%- elif message.role == \\&quot;tool\\&quot; %&#125;\\n        &#123;%- if loop.first or (messages[loop.index0 - 1].role != \\&quot;tool\\&quot;) %&#125;\\n            &#123;&#123;- &#x27;&lt;|im_start|&gt;user&#x27; &#125;&#125;\\n        &#123;%- endif %&#125;\\n        &#123;&#123;- &#x27;\\\\n&lt;tool_response&gt;\\\\n&#x27; &#125;&#125;\\n        &#123;&#123;- content &#125;&#125;\\n        &#123;&#123;- &#x27;\\\\n&lt;/tool_response&gt;&#x27; &#125;&#125;\\n        &#123;%- if loop.last or (messages[loop.index0 + 1].role != \\&quot;tool\\&quot;) %&#125;\\n            &#123;&#123;- &#x27;&lt;|im_end|&gt;\\\\n&#x27; &#125;&#125;\\n        &#123;%- endif %&#125;\\n    &#123;%- endif %&#125;\\n&#123;%- endfor %&#125;\\n&#123;%- if add_generation_prompt %&#125;\\n    &#123;&#123;- &#x27;&lt;|im_start|&gt;assistant\\\\n&#x27; &#125;&#125;\\n    &#123;%- if enable_thinking is defined and enable_thinking is false %&#125;\\n        &#123;&#123;- &#x27;&lt;think&gt;\\\\n\\\\n&lt;/think&gt;\\\\n\\\\n&#x27; &#125;&#125;\\n    &#123;%- endif %&#125;\\n&#123;%- endif %&#125;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p><strong> Jinja2 </strong> HuggingFace  <code>tokenizer.apply_chat_template</code> <strong> Python List of Dicts Tokenizer </strong>System Prompt<strong></strong><strong></strong>Tools<strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"keyword\">for</span> tid <span class=\"keyword\">in</span> input_ids:</span><br><span class=\"line\">    token_cache.append(tid)</span><br><span class=\"line\">    current_decode = tokenizer.decode(token_cache)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> current_decode <span class=\"keyword\">and</span> <span class=\"string\">&#x27;\\ufffd&#x27;</span> <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> current_decode:</span><br><span class=\"line\">        <span class=\"comment\"># ...  ...</span></span><br><span class=\"line\">        token_cache = []</span><br></pre></td></tr></table></figure>\n\n<p> UTF-8  <strong>3</strong></p>\n<p> Token A (<code>E6</code>)  Decode <code>E6</code> &#96;&#96; ( \\ufffd, Replacement Character)</p>\n<p><strong></strong> <code>token_cache</code> <code>\\ufffd</code><strong></strong> Token B (<code>88 91</code>)  <code>E6 88 91</code><code>\\ufffd</code> </p>\n<h1 id=\"Pretrain\"><a href=\"#Pretrain\" class=\"headerlink\" title=\"Pretrain\"></a>Pretrain</h1><p>LLM  ModelWiki  <strong></strong></p>\n<h2 id=\"Dataloader\"><a href=\"#Dataloader\" class=\"headerlink\" title=\"Dataloader\"></a>Dataloader</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">PretrainDataset</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, data_path, tokenizer, max_length=<span class=\"number\">512</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.tokenizer = tokenizer</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.max_length = max_length</span><br><span class=\"line\">        <span class=\"comment\"># 1. </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.samples = load_dataset(<span class=\"string\">&#x27;json&#x27;</span>, data_files=data_path, split=<span class=\"string\">&#x27;train&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.samples)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, index</span>):</span><br><span class=\"line\">        sample = <span class=\"variable language_\">self</span>.samples[index]</span><br><span class=\"line\">        <span class=\"comment\"># 2.  (Tokenization)</span></span><br><span class=\"line\">        encoding = <span class=\"variable language_\">self</span>.tokenizer(</span><br><span class=\"line\">            <span class=\"built_in\">str</span>(sample[<span class=\"string\">&#x27;text&#x27;</span>]),</span><br><span class=\"line\">            max_length=<span class=\"variable language_\">self</span>.max_length,</span><br><span class=\"line\">            padding=<span class=\"string\">&#x27;max_length&#x27;</span>,</span><br><span class=\"line\">            truncation=<span class=\"literal\">True</span>,</span><br><span class=\"line\">            return_tensors=<span class=\"string\">&#x27;pt&#x27;</span></span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"comment\"># 3.  Labels ()</span></span><br><span class=\"line\">        input_ids = encoding.input_ids.squeeze()</span><br><span class=\"line\">        labels = input_ids.clone()</span><br><span class=\"line\">        <span class=\"comment\"># 4. Masking Padding</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#  Pad Token  Label  -100</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># PyTorch  CrossEntropyLoss  -100</span></span><br><span class=\"line\">        labels[input_ids == <span class=\"variable language_\">self</span>.tokenizer.pad_token_id] = -<span class=\"number\">100</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> input_ids, labels</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Epoch\"><a href=\"#Epoch\" class=\"headerlink\" title=\"Epoch\"></a>Epoch</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_epoch</span>(<span class=\"params\">epoch, loader, iters, start_step=<span class=\"number\">0</span>, wandb=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> step, (input_ids, labels) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(loader, start=start_step + <span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        input_ids = input_ids.to(args.device)</span><br><span class=\"line\">        labels = labels.to(args.device)</span><br><span class=\"line\">        <span class=\"comment\">#  Cosine Decay</span></span><br><span class=\"line\">        lr = get_lr(epoch * iters + step, args.epochs * iters, args.learning_rate)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> param_group <span class=\"keyword\">in</span> optimizer.param_groups:</span><br><span class=\"line\">            param_group[<span class=\"string\">&#x27;lr&#x27;</span>] = lr</span><br><span class=\"line\">\t\t<span class=\"comment\"># autocast_ctx </span></span><br><span class=\"line\">        <span class=\"comment\">#  float16  bfloat16 </span></span><br><span class=\"line\">        <span class=\"keyword\">with</span> autocast_ctx:</span><br><span class=\"line\">            res = model(input_ids, labels=labels)</span><br><span class=\"line\">            <span class=\"comment\"># res.loss  Loss</span></span><br><span class=\"line\">            <span class=\"comment\"># res.aux_loss  MoE  Loss</span></span><br><span class=\"line\">            loss = res.loss + res.aux_loss</span><br><span class=\"line\">            <span class=\"comment\"># </span></span><br><span class=\"line\">            loss = loss / args.accumulation_steps</span><br><span class=\"line\">\t\t<span class=\"comment\"># scaler  GradScaler float16 </span></span><br><span class=\"line\">        <span class=\"comment\">#  scale float16 Loss  0.00001</span></span><br><span class=\"line\">        <span class=\"comment\">#  0scaler  Loss  65536</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        scaler.scale(loss).backward()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (step + <span class=\"number\">1</span>) % args.accumulation_steps == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 1. Unscale</span></span><br><span class=\"line\">            <span class=\"comment\">#  clip_grad_norm </span></span><br><span class=\"line\">            scaler.unscale_(optimizer)</span><br><span class=\"line\">            <span class=\"comment\"># 2.  (Gradient Clipping)</span></span><br><span class=\"line\">            <span class=\"comment\">#  args.grad_clip ( 1.0)</span></span><br><span class=\"line\">            <span class=\"comment\">#  LLM </span></span><br><span class=\"line\">            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># scaler.step  Inf/NaN</span></span><br><span class=\"line\">            scaler.step(optimizer)</span><br><span class=\"line\">            <span class=\"comment\"># 4. </span></span><br><span class=\"line\">            scaler.update()</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 5. </span></span><br><span class=\"line\">            <span class=\"comment\"># set_to_none=True  =0 </span></span><br><span class=\"line\">            optimizer.zero_grad(set_to_none=<span class=\"literal\">True</span>)</span><br><span class=\"line\">\t\t<span class=\"comment\">##.....</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">        <span class=\"comment\"># Rank 0</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (step % args.save_interval == <span class=\"number\">0</span> <span class=\"keyword\">or</span> step == iters - <span class=\"number\">1</span>) <span class=\"keyword\">and</span> is_main_process():</span><br><span class=\"line\">            model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">            moe_suffix = <span class=\"string\">&#x27;_moe&#x27;</span> <span class=\"keyword\">if</span> lm_config.use_moe <span class=\"keyword\">else</span> <span class=\"string\">&#x27;&#x27;</span></span><br><span class=\"line\">            ckp = <span class=\"string\">f&#x27;<span class=\"subst\">&#123;args.save_dir&#125;</span>/<span class=\"subst\">&#123;args.save_weight&#125;</span>_<span class=\"subst\">&#123;lm_config.hidden_size&#125;</span><span class=\"subst\">&#123;moe_suffix&#125;</span>.pth&#x27;</span></span><br><span class=\"line\">            <span class=\"comment\">#  DDP .module</span></span><br><span class=\"line\">            raw_model = model.module <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(model, DistributedDataParallel) <span class=\"keyword\">else</span> model</span><br><span class=\"line\">            <span class=\"comment\">#  torch.compile _orig_mod</span></span><br><span class=\"line\">            raw_model = <span class=\"built_in\">getattr</span>(raw_model, <span class=\"string\">&#x27;_orig_mod&#x27;</span>, raw_model)</span><br><span class=\"line\">            state_dict = raw_model.state_dict()</span><br><span class=\"line\">            <span class=\"comment\"># 1.  (.pth)</span></span><br><span class=\"line\">            <span class=\"comment\"># .half() float16 </span></span><br><span class=\"line\">            <span class=\"comment\"># .cpu() CPU</span></span><br><span class=\"line\">            torch.save(&#123;k: v.half().cpu() <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> state_dict.items()&#125;, ckp)</span><br><span class=\"line\">            <span class=\"comment\"># 2.  (Checkpoint)</span></span><br><span class=\"line\">            <span class=\"comment\">#  optimizerscaler epoch  step</span></span><br><span class=\"line\">            <span class=\"comment\"># Resume</span></span><br><span class=\"line\">            lm_checkpoint(lm_config, weight=args.save_weight, model=model, optimizer=optimizer, scaler=scaler, epoch=epoch, step=step, wandb=wandb, save_dir=<span class=\"string\">&#x27;../checkpoints&#x27;</span>)</span><br><span class=\"line\">            model.train()</span><br><span class=\"line\">            <span class=\"keyword\">del</span> state_dict</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">del</span> input_ids, labels, res, loss</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"comment\"># ========== 1.  ==========</span></span><br><span class=\"line\">   local_rank = init_distributed_mode()</span><br><span class=\"line\">   <span class=\"keyword\">if</span> dist.is_initialized(): args.device = <span class=\"string\">f&quot;cuda:<span class=\"subst\">&#123;local_rank&#125;</span>&quot;</span></span><br><span class=\"line\">   setup_seed(<span class=\"number\">42</span> + (dist.get_rank() <span class=\"keyword\">if</span> dist.is_initialized() <span class=\"keyword\">else</span> <span class=\"number\">0</span>))</span><br><span class=\"line\">   <span class=\"comment\">#  Dropout </span></span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 2. ckp ==========</span></span><br><span class=\"line\">   os.makedirs(args.save_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">   lm_config = MiniMindConfig(hidden_size=args.hidden_size, num_hidden_layers=args.num_hidden_layers, use_moe=<span class=\"built_in\">bool</span>(args.use_moe))</span><br><span class=\"line\">   <span class=\"comment\"># lm_checkpoint  ../checkpoints  args.save_weight </span></span><br><span class=\"line\"><span class=\"comment\"># epochstep  ckp_data </span></span><br><span class=\"line\">   ckp_data = lm_checkpoint(lm_config, weight=args.save_weight, save_dir=<span class=\"string\">&#x27;../checkpoints&#x27;</span>) <span class=\"keyword\">if</span> args.from_resume==<span class=\"number\">1</span> <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 3.  ==========</span></span><br><span class=\"line\">   device_type = <span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">if</span> <span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">in</span> args.device <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span></span><br><span class=\"line\">   dtype = torch.bfloat16 <span class=\"keyword\">if</span> args.dtype == <span class=\"string\">&quot;bfloat16&quot;</span> <span class=\"keyword\">else</span> torch.float16</span><br><span class=\"line\">   <span class=\"comment\">#  train_epoch </span></span><br><span class=\"line\">   autocast_ctx = nullcontext() <span class=\"keyword\">if</span> device_type == <span class=\"string\">&quot;cpu&quot;</span> <span class=\"keyword\">else</span> torch.cuda.amp.autocast(dtype=dtype)</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 4. wandb ==========</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 5.  ==========</span></span><br><span class=\"line\">   model, tokenizer = init_model(lm_config, args.from_weight, device=args.device)</span><br><span class=\"line\">   <span class=\"keyword\">if</span> args.use_compile == <span class=\"number\">1</span>:</span><br><span class=\"line\">       model = torch.<span class=\"built_in\">compile</span>(model)</span><br><span class=\"line\">       Logger(<span class=\"string\">&#x27;torch.compile enabled&#x27;</span>)</span><br><span class=\"line\">   train_ds = PretrainDataset(args.data_path, tokenizer, max_length=args.max_seq_len)</span><br><span class=\"line\">   <span class=\"comment\">#  DDP  N N=</span></span><br><span class=\"line\">   train_sampler = DistributedSampler(train_ds) <span class=\"keyword\">if</span> dist.is_initialized() <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\">   <span class=\"comment\"># GradScaler float16 </span></span><br><span class=\"line\"><span class=\"comment\">#  bfloat16enabled=False</span></span><br><span class=\"line\">   scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype == <span class=\"string\">&#x27;float16&#x27;</span>))</span><br><span class=\"line\">   optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate)</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 6. ckp ==========</span></span><br><span class=\"line\">   start_epoch, start_step = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">   <span class=\"keyword\">if</span> ckp_data:</span><br><span class=\"line\">       model.load_state_dict(ckp_data[<span class=\"string\">&#x27;model&#x27;</span>])</span><br><span class=\"line\">       optimizer.load_state_dict(ckp_data[<span class=\"string\">&#x27;optimizer&#x27;</span>])</span><br><span class=\"line\">       scaler.load_state_dict(ckp_data[<span class=\"string\">&#x27;scaler&#x27;</span>])</span><br><span class=\"line\">       start_epoch = ckp_data[<span class=\"string\">&#x27;epoch&#x27;</span>]</span><br><span class=\"line\">       start_step = ckp_data.get(<span class=\"string\">&#x27;step&#x27;</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 7. DDP ==========</span></span><br><span class=\"line\">   <span class=\"keyword\">if</span> dist.is_initialized():</span><br><span class=\"line\">       model._ddp_params_and_buffers_to_ignore = &#123;<span class=\"string\">&quot;freqs_cos&quot;</span>, <span class=\"string\">&quot;freqs_sin&quot;</span>&#125;</span><br><span class=\"line\">       model = DistributedDataParallel(model, device_ids=[local_rank])</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 8.  ==========</span></span><br><span class=\"line\">   <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(start_epoch, args.epochs):</span><br><span class=\"line\">       train_sampler <span class=\"keyword\">and</span> train_sampler.set_epoch(epoch)</span><br><span class=\"line\">       <span class=\"keyword\">if</span> epoch == start_epoch <span class=\"keyword\">and</span> start_step &gt; <span class=\"number\">0</span>: <span class=\"comment\"># epoch</span></span><br><span class=\"line\">           <span class=\"comment\"># SkipBatchSampler </span></span><br><span class=\"line\">       \t<span class=\"comment\">#  1000  batch index</span></span><br><span class=\"line\">       \t<span class=\"comment\"># Dataloader  1000 </span></span><br><span class=\"line\">           batch_sampler = SkipBatchSampler(train_sampler <span class=\"keyword\">or</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(train_ds)), args.batch_size, start_step + <span class=\"number\">1</span>)</span><br><span class=\"line\">           loader = DataLoader(train_ds, batch_sampler=batch_sampler, num_workers=args.num_workers, pin_memory=<span class=\"literal\">True</span>)</span><br><span class=\"line\">           Logger(<span class=\"string\">f&#x27;Epoch [<span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>&#125;</span>/<span class=\"subst\">&#123;args.epochs&#125;</span>]: <span class=\"subst\">&#123;start_step&#125;</span>stepstep <span class=\"subst\">&#123;start_step + <span class=\"number\">1</span>&#125;</span>&#x27;</span>)</span><br><span class=\"line\">           train_epoch(epoch, loader, <span class=\"built_in\">len</span>(loader) + start_step + <span class=\"number\">1</span>, start_step, wandb)</span><br><span class=\"line\">       <span class=\"keyword\">else</span>: <span class=\"comment\"># </span></span><br><span class=\"line\">           loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=(train_sampler <span class=\"keyword\">is</span> <span class=\"literal\">None</span>), sampler=train_sampler, num_workers=args.num_workers, pin_memory=<span class=\"literal\">True</span>)</span><br><span class=\"line\">           train_epoch(epoch, loader, <span class=\"built_in\">len</span>(loader), <span class=\"number\">0</span>, wandb)</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 9.  ==========</span></span><br><span class=\"line\">   <span class=\"keyword\">if</span> dist.is_initialized(): dist.destroy_process_group()</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torchrun --nproc_per_node 1 train_pretrain.py <span class=\"comment\"># 1 (&gt;=2)</span></span><br><span class=\"line\"><span class=\"comment\"># or</span></span><br><span class=\"line\">python train_pretrain.py</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data\"></a> <code>&lt;512</code>1.6GB <code>pretrain_hq.jsonl</code>hqhigh quality</p>\n<p><code>pretrain_hq.jsonl</code> </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;text&quot;: &quot; ...&quot;&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"SFT\"><a href=\"#SFT\" class=\"headerlink\" title=\"SFT\"></a>SFT</h1><p>LLM SFTLLM -&gt;-&gt;  MiniMind512200800 2k&#x2F;4k&#x2F;8kRoPE-NTK</p>\n<h2 id=\"DataLoader\"><a href=\"#DataLoader\" class=\"headerlink\" title=\"DataLoader\"></a>DataLoader</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SFTDataset</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, jsonl_path, tokenizer, max_length=<span class=\"number\">1024</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.tokenizer = tokenizer</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.max_length = max_length</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.samples = load_dataset(<span class=\"string\">&#x27;json&#x27;</span>, data_files=jsonl_path, split=<span class=\"string\">&#x27;train&#x27;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.bos_id = tokenizer(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;tokenizer.bos_token&#125;</span>assistant\\n&#x27;</span>, add_special_tokens=<span class=\"literal\">False</span>).input_ids</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.eos_id = tokenizer(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;tokenizer.eos_token&#125;</span>\\n&#x27;</span>, add_special_tokens=<span class=\"literal\">False</span>).input_ids</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.samples)</span><br><span class=\"line\">    </span><br><span class=\"line\">\t<span class=\"comment\"># tokenizer  chat template prompt</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">create_chat_prompt</span>(<span class=\"params\">self, cs</span>):</span><br><span class=\"line\">        messages = cs.copy()</span><br><span class=\"line\">        tools = cs[<span class=\"number\">0</span>][<span class=\"string\">&quot;functions&quot;</span>] <span class=\"keyword\">if</span> (cs <span class=\"keyword\">and</span> cs[<span class=\"number\">0</span>][<span class=\"string\">&quot;role&quot;</span>] == <span class=\"string\">&quot;system&quot;</span> <span class=\"keyword\">and</span> cs[<span class=\"number\">0</span>].get(<span class=\"string\">&quot;functions&quot;</span>)) <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.tokenizer.apply_chat_template(</span><br><span class=\"line\">            messages,</span><br><span class=\"line\">            tokenize=<span class=\"literal\">False</span>,</span><br><span class=\"line\">            add_generation_prompt=<span class=\"literal\">False</span>,</span><br><span class=\"line\">            tools=tools</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">generate_labels</span>(<span class=\"params\">self, input_ids</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 1.  (-100)</span></span><br><span class=\"line\">        labels = [-<span class=\"number\">100</span>] * <span class=\"built_in\">len</span>(input_ids)</span><br><span class=\"line\">        <span class=\"comment\"># 2.  input_ids </span></span><br><span class=\"line\">        i = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> i &lt; <span class=\"built_in\">len</span>(input_ids):</span><br><span class=\"line\">            <span class=\"comment\"># 3.  Assistant  (self.bos_id)</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> input_ids[i:i + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.bos_id)] == <span class=\"variable language_\">self</span>.bos_id:</span><br><span class=\"line\">                start = i + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.bos_id)</span><br><span class=\"line\">                <span class=\"comment\"># 4.  Assistant  (self.eos_id)</span></span><br><span class=\"line\">                end = start</span><br><span class=\"line\">                <span class=\"keyword\">while</span> end &lt; <span class=\"built_in\">len</span>(input_ids):</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> input_ids[end:end + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.eos_id)] == <span class=\"variable language_\">self</span>.eos_id:</span><br><span class=\"line\">                        <span class=\"keyword\">break</span></span><br><span class=\"line\">                    end += <span class=\"number\">1</span></span><br><span class=\"line\">                <span class=\"comment\"># 5.  Mask</span></span><br><span class=\"line\">            \t<span class=\"comment\">#  [start, end]  labels  input_ids </span></span><br><span class=\"line\">            \t<span class=\"comment\">#  Loss</span></span><br><span class=\"line\">                <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(start, <span class=\"built_in\">min</span>(end + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.eos_id), <span class=\"variable language_\">self</span>.max_length)):</span><br><span class=\"line\">                    labels[j] = input_ids[j]</span><br><span class=\"line\">                i = end + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.eos_id) <span class=\"keyword\">if</span> end &lt; <span class=\"built_in\">len</span>(input_ids) <span class=\"keyword\">else</span> <span class=\"built_in\">len</span>(input_ids)</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                i += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> labels</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, index</span>):</span><br><span class=\"line\">        sample = <span class=\"variable language_\">self</span>.samples[index]</span><br><span class=\"line\">        prompt = <span class=\"variable language_\">self</span>.create_chat_prompt(sample[<span class=\"string\">&#x27;conversations&#x27;</span>])</span><br><span class=\"line\">        input_ids = <span class=\"variable language_\">self</span>.tokenizer(prompt).input_ids[:<span class=\"variable language_\">self</span>.max_length]</span><br><span class=\"line\">        input_ids += [<span class=\"variable language_\">self</span>.tokenizer.pad_token_id] * (<span class=\"variable language_\">self</span>.max_length - <span class=\"built_in\">len</span>(input_ids))</span><br><span class=\"line\">        labels = <span class=\"variable language_\">self</span>.generate_labels(input_ids)</span><br><span class=\"line\">        <span class=\"comment\"># # ===  ===</span></span><br><span class=\"line\">        <span class=\"comment\"># print(f&quot;\\n--- Sample &#123;index&#125; ---&quot;)</span></span><br><span class=\"line\">        <span class=\"comment\"># for i, (x, y) in enumerate(zip(input_ids[:-1], labels[1:])):</span></span><br><span class=\"line\">        <span class=\"comment\">#     print(f&quot;&#123;i:3d&#125;: X=&#123;self.tokenizer.decode([x])!r:16s&#125; ---&gt; Y=&#123;self.tokenizer.decode([input_ids[i+1]])!r:16s&#125; label=&#123;y&#125;&quot;)</span></span><br><span class=\"line\">        <span class=\"comment\"># # ================</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.tensor(input_ids, dtype=torch.long), torch.tensor(labels, dtype=torch.long)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Epoch-1\"><a href=\"#Epoch-1\" class=\"headerlink\" title=\"Epoch\"></a>Epoch</h2><p>pretrainSFTlabels-100PyTorch  <code>CrossEntropyLoss</code> <strong> -100  Label</strong></p>\n<p>loss</p>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><p>pretrain</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torchrun --nproc_per_node <span class=\"number\">1</span> train_full_sft.py</span><br><span class=\"line\"><span class=\"comment\"># or</span></span><br><span class=\"line\">python train_full_sft.py</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"KD\"><a href=\"#KD\" class=\"headerlink\" title=\"KD\"></a>KD</h1><p>    SFTTokenhard labels 0  6400 softmaxsoft labelsKL-Loss SFTKD <code>1+1=2</code>a0b100c-99   LLM&#x2F; GPT-4 SFTFT </p>\n<p></p>\n<ul>\n<li> (<code>distillation_loss</code>)</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">distillation_loss</span>(<span class=\"params\">student_logits, teacher_logits, temperature=<span class=\"number\">1.0</span>, reduction=<span class=\"string\">&#x27;batchmean&#x27;</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"comment\"># 1.  (Soft Targets)</span></span><br><span class=\"line\">        <span class=\"comment\">#  T (temperature) </span></span><br><span class=\"line\">        teacher_probs = F.softmax(teacher_logits / temperature, dim=-<span class=\"number\">1</span>).detach()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2.  Log </span></span><br><span class=\"line\">    student_log_probs = F.log_softmax(student_logits / temperature, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 3.  KL  (Kullback-Leibler Divergence)</span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    kl = F.kl_div(student_log_probs, teacher_probs, reduction=reduction)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 4. </span></span><br><span class=\"line\">    <span class=\"comment\">#  T^2 T  1/T^2</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (temperature ** <span class=\"number\">2</span>) * kl</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p> (<code>train_epoch</code>)</p>\n</li>\n<li><p>$$Loss_{total} &#x3D; \\alpha \\cdot Loss_{CE} + (1 - \\alpha) \\cdot Loss_{Distill}$$</p>\n</li>\n<li><p>Masking  SFT <strong></strong></p>\n</li>\n<li><p> Teacher GradientsOptimizer States <strong> (Weights)</strong>  <strong> (Activations)</strong> </p>\n</li>\n</ul>\n<h1 id=\"LoRA\"><a href=\"#LoRA\" class=\"headerlink\" title=\"LoRA\"></a>LoRA</h1><p>LoRAParameter-Efficient Fine-Tuning, PEFT Full Fine-TuningLoRA  LoRA </p>\n<ul>\n<li>Lora</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LoRA</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_features, out_features, rank</span>):</span><br><span class=\"line\">        <span class=\"comment\"># rank:  in=512, out=512, rank=8</span></span><br><span class=\"line\">        <span class=\"comment\"># 512*512 = 26</span></span><br><span class=\"line\">        <span class=\"comment\"># LoRA512*8 + 8*512 = 8 32 </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.rank = rank</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.A = nn.Linear(in_features, rank, bias=<span class=\"literal\">False</span>)  <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.B = nn.Linear(rank, out_features, bias=<span class=\"literal\">False</span>) <span class=\"comment\"># </span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># A </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.A.weight.data.normal_(mean=<span class=\"number\">0.0</span>, std=<span class=\"number\">0.02</span>)</span><br><span class=\"line\">        <span class=\"comment\"># B  0 </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.B.weight.data.zero_()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"comment\"># forward = B(A(x))</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.B(<span class=\"variable language_\">self</span>.A(x))</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Lora</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">apply_lora</span>(<span class=\"params\">model, rank=<span class=\"number\">8</span></span>):</span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> name, module <span class=\"keyword\">in</span> model.named_modules():</span><br><span class=\"line\">        <span class=\"comment\">#  Linear  (in == out)</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"comment\">#  Attention  Q, K, V, O  LoRA</span></span><br><span class=\"line\">        <span class=\"comment\">#  Transformer  hidden_size -&gt; hidden_size </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(module, nn.Linear) <span class=\"keyword\">and</span> module.weight.shape[<span class=\"number\">0</span>] == module.weight.shape[<span class=\"number\">1</span>]:</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 1.  LoRA </span></span><br><span class=\"line\">            lora = LoRA(..., rank=rank)</span><br><span class=\"line\">            <span class=\"built_in\">setattr</span>(module, <span class=\"string\">&quot;lora&quot;</span>, lora) <span class=\"comment\">#  module.lora = lora</span></span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 2.  forward </span></span><br><span class=\"line\">            original_forward = module.forward <span class=\"comment\">#  forward</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">#  forward</span></span><br><span class=\"line\">            <span class=\"keyword\">def</span> <span class=\"title function_\">forward_with_lora</span>(<span class=\"params\">x, layer1=original_forward, layer2=lora</span>):</span><br><span class=\"line\">                <span class=\"comment\">#  = (x) + LoRA(x)</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> layer1(x) + layer2(x)</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 3. </span></span><br><span class=\"line\">            module.forward = forward_with_lora</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">save_lora</span>(<span class=\"params\">model, path</span>):</span><br><span class=\"line\">    <span class=\"comment\"># ...</span></span><br><span class=\"line\">    <span class=\"comment\">#  &#x27;lora&#x27; </span></span><br><span class=\"line\">    lora_state = &#123;<span class=\"string\">f&#x27;<span class=\"subst\">&#123;clean_name&#125;</span>.lora.<span class=\"subst\">&#123;k&#125;</span>&#x27;</span>: v <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> module.lora.state_dict().items()&#125;</span><br><span class=\"line\">    state_dict.update(lora_state)</span><br><span class=\"line\">    <span class=\"comment\">#  MB GB</span></span><br><span class=\"line\">    torch.save(state_dict, path)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lora_params = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> name, param <span class=\"keyword\">in</span> model.named_parameters():</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"string\">&#x27;lora&#x27;</span> <span class=\"keyword\">in</span> name:</span><br><span class=\"line\">        param.requires_grad = <span class=\"literal\">True</span>  <span class=\"comment\"># LoRA </span></span><br><span class=\"line\">        lora_params.append(param)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        param.requires_grad = <span class=\"literal\">False</span> <span class=\"comment\"># </span></span><br><span class=\"line\">optimizer = optim.AdamW(lora_params, lr=args.learning_rate)</span><br></pre></td></tr></table></figure>\n\n<p>+LoRALoRA</p>\n<p>PSfull_sft</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>DeepSeek R1<code>&gt;3B</code>RL  SFT+GRPO</p>\n<p>SFT</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">&quot;conversations&quot;</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>,</span><br><span class=\"line\">      <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;assistant&quot;</span>,</span><br><span class=\"line\">      <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;&lt;think&gt;\\nMiniMind-R1-Lite-Preview\\n&lt;/think&gt;\\n&lt;answer&gt;\\nMiniMind-R1-Lite-Preview\\n&lt;/answer&gt;&quot;</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;think&gt;\\n\\n&lt;/think&gt;\\n</span><br><span class=\"line\">&lt;answer&gt;\\n\\n&lt;/answer&gt;</span><br></pre></td></tr></table></figure>\n\n<p>GRPO</p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sp_ids = torch.isin(shift_labels.view(-<span class=\"number\">1</span>), torch.tensor(start_of_think_ids + ...))</span><br><span class=\"line\">loss_mask_flat[sp_ids] = <span class=\"number\">10</span></span><br></pre></td></tr></table></figure>\n\n<p> <code>&lt;think&gt;</code>, <code>&lt;/think&gt;</code>, <code>&lt;answer&gt;</code>, <code>&lt;/answer&gt;</code>  Loss  <strong>10</strong></p>\n<p><strong></strong> SFT </p>\n<p>** (SFT)** ** (Next Token Prediction)** DeepSeek-R1 AB AB B  B B</p>\n<p>** (RL - PPO&#x2F;GRPO)** ** (Maximize Reward)** AC AB</p>\n<p><strong></strong> 10  Loss  (<code>loss_mask_flat[sp_ids] = 10</code>)  <code>&lt;think&gt;</code> <code>&lt;answer&gt;</code><strong>Chain-of-Thought, CoT</strong></p>\n<p><strong></strong>R1</p>\n<ul>\n<li><em></em> -&gt; </li>\n<li><em></em> -&gt;  1 -&gt;  2 -&gt; </li>\n<li></li>\n</ul>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>LLM</p>\n<ol>\n<li><strong> (Reinforcement Learning from Human Feedback, RLHF)</strong></li>\n</ol>\n<ul>\n<li><strong></strong></li>\n</ul>\n<ol>\n<li><strong>AI (Reinforcement Learning from AI Feedback, RLAIF)</strong></li>\n</ol>\n<ul>\n<li><strong>AI</strong></li>\n<li>AI&#x2F;</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RLHF</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>RLAIF</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p><strong></strong><strong></strong></p>\n<p><strong></strong></p>\n<h2 id=\"-Reinforcement-Learning-from-Human-Feedback-RLHF\"><a href=\"#-Reinforcement-Learning-from-Human-Feedback-RLHF\" class=\"headerlink\" title=\" (Reinforcement Learning from Human Feedback, RLHF)\"></a><strong> (Reinforcement Learning from Human Feedback, RLHF)</strong></h2><h3 id=\"DPO-Direct-Preference-Optimization\"><a href=\"#DPO-Direct-Preference-Optimization\" class=\"headerlink\" title=\"DPO(Direct Preference Optimization)\"></a>DPO(Direct Preference Optimization)</h3><p>DPO</p>\n<p></p>\n<ul>\n<li><strong></strong>: f(rt)&#x3D;logrwlogrl (chosen vs rejected)</li>\n<li><strong></strong>: g(At) &#x3D; &#x2F; ()</li>\n<li><strong></strong>: h(KLt) &#x3D;    ()</li>\n</ul>\n<p></p>\n<ul>\n<li>DPOPPOKLchosenrejectedReward&#x2F;ValueDPO<code>actor</code><code>ref</code></li>\n<li>offpolicyepochRef</li>\n<li>DPO&#x2F;</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torchrun --nproc_per_node <span class=\"number\">1</span> train_dpo.py</span><br><span class=\"line\"><span class=\"comment\"># or</span></span><br><span class=\"line\">python train_dpo.py</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"AI-Reinforcement-Learning-from-AI-Feedback-RLAIF\"><a href=\"#AI-Reinforcement-Learning-from-AI-Feedback-RLAIF\" class=\"headerlink\" title=\"AI (Reinforcement Learning from AI Feedback, RLAIF)\"></a><strong>AI (Reinforcement Learning from AI Feedback, RLAIF)</strong></h2>","more":"<h1 id=\"Minimind\"><a href=\"#Minimind\" class=\"headerlink\" title=\"Minimind\"></a>Minimind</h1><p>MiniMind  <strong>Decoder-only Transformer</strong> <code>MiniMindConfig</code> </p>\n<ul>\n<li><strong></strong> LLaMA</li>\n<li><strong></strong><code>hidden_size=512</code>, <code>num_hidden_layers=8</code><code>vocab_size=6400</code> CPU </li>\n<li><strong></strong><ul>\n<li>**MoE ()**</li>\n<li>**Weight Tying ()**Embedding LM Head</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"A-RoPE-YaRN-Rotary-Positional-Embeddings\"><a href=\"#A-RoPE-YaRN-Rotary-Positional-Embeddings\" class=\"headerlink\" title=\"A. RoPE + YaRN (Rotary Positional Embeddings)\"></a>A. RoPE + YaRN (Rotary Positional Embeddings)</h2><ul>\n<li><strong> RoPE</strong> LLM  BERT</li>\n</ul>\n<p>RoPE  token  embedding <strong></strong></p>\n<p> $d$  ( hidden_size&#x3D;512)RoPE  $d&#x2F;2$  2 <br> $j$  ( $j \\in [0, d&#x2F;2)$) $\\theta_j$</p>\n<p>$$\\theta_j &#x3D; 10000^{-2j&#x2F;d}$$</p>\n<p>- </p>\n<ul>\n<li><p><strong> ($j$ )<strong>$\\theta_j$  1</strong></strong></p>\n</li>\n<li><p><strong> ($j$ )<strong>$\\theta_j$  0</strong></strong></p>\n</li>\n<li><p>**YaRN (Yet another RoPE extensioN)**</p>\n<ul>\n<li> <code>if end / orig_max &gt; 1.0:</code> </li>\n<li><strong></strong><code>original_max_position_embeddings</code>Ramp function RoPE </li>\n</ul>\n</li>\n</ul>\n<p><strong></strong><br>YaRN  $m$ $\\theta_j$</p>\n<p> $\\theta_j$ </p>\n<p>$$\\theta_j &#x3D; \\theta_j \\cdot (1 - \\gamma(r) + \\frac{\\gamma(r)}{s})$$</p>\n<p>YaRN </p>\n<p>$$\\gamma(r) &#x3D; \\begin{cases} 0, &amp; \\text{if } r &lt; \\alpha \\quad (\\text{&#x2F;}) \\ 1, &amp; \\text{if } r &gt; \\beta \\quad (\\text{&#x2F;}) \\ \\frac{r - \\alpha}{\\beta - \\alpha}, &amp; \\text{otherwise} \\quad (\\text{&#x2F;}) \\end{cases}$$</p>\n<p>YaRN  $\\sqrt{t}$ </p>\n<p>$$\\text{Attention}(Q, K) &#x3D; \\text{softmax}(\\frac{\\mathbf{q}^T \\mathbf{k}}{\\sqrt{d} \\cdot \\sqrt{t}})$$</p>\n<h2 id=\"B-GQA-Grouped-Query-Attention\"><a href=\"#B-GQA-Grouped-Query-Attention\" class=\"headerlink\" title=\"B. GQA (Grouped Query Attention)\"></a>B. GQA (Grouped Query Attention)</h2><h3 id=\"MHA-Multi-Head-Attention\"><a href=\"#MHA-Multi-Head-Attention\" class=\"headerlink\" title=\"MHA: Multi-Head Attention\"></a>MHA: Multi-Head Attention</h3><p> Query  Key  Value </p>\n<ul>\n<li><strong></strong></li>\n<li><strong></strong>KV Cache </li>\n</ul>\n<h3 id=\"MQA-Multi-Query-Attention\"><a href=\"#MQA-Multi-Query-Attention\" class=\"headerlink\" title=\"MQA: Multi-Query Attention\"></a>MQA: Multi-Query Attention</h3><p> Query <strong></strong> Key  Value </p>\n<ul>\n<li><strong></strong>KV Cache </li>\n<li><strong></strong></li>\n</ul>\n<h3 id=\"GQA-Group-Query-Attention\"><a href=\"#GQA-Group-Query-Attention\" class=\"headerlink\" title=\"GQA: Group Query Attention\"></a>GQA: Group Query Attention</h3><p> Query Group<strong></strong> Query  Key&#x2F;Value</p>\n<h3 id=\"KV-cache\"><a href=\"#KV-cache\" class=\"headerlink\" title=\"KV-cache\"></a>KV-cache</h3><p>KV cache  Transformer decoder  token  Key &#x2F; Value O(T)  O(T) </p>\n<p>$l$</p>\n<p>$$Q_t^{(l)} &#x3D; h_t^{(l)} W_Q^{(l)}$$$$K_t^{(l)} &#x3D; h_t^{(l)}W_K^{(l)}$$<br>$$V_t^{(l)} &#x3D; h_t^{(l)}W_V^{(l)}$$</p>\n<p>attention </p>\n<p>$$\\text{Attn}_t^{(l)} &#x3D; \\text{softmax}\\left( \\frac{Q_t^{(l)} [K_1^{(l)}, \\dots, K_t^{(l)}]^T} {\\sqrt{d_h}} \\right) [V_1^{(l)}, \\dots, V_t^{(l)}]$$</p>\n<p>$$\\boxed{ \\text{KVCache}^{(l)} &#x3D; \\left( {K_1^{(l)}, \\dots, K_{t-1}^{(l)}}, {V_1^{(l)}, \\dots, V_{t-1}^{(l)}} \\right) }$$</p>\n<p>$t$</p>\n<ul>\n<li><p>$ Q_t, K_t, V_t$</p>\n</li>\n<li><p>append  cache</p>\n</li>\n<li><p> $Q_t$ cache</p>\n</li>\n</ul>\n<p>$$\\text{} &#x3D; 2 \\times \\text{Batch} \\times \\text{Seq_Len} \\times \\text{KV_Heads} \\times \\text{Head_Dim} \\times \\text{Byte}$$</p>\n<h3 id=\"Flash-Attention\"><a href=\"#Flash-Attention\" class=\"headerlink\" title=\"Flash Attention\"></a>Flash Attention</h3><p> Attention </p>\n<p>$$\\text{Score} &#x3D; \\text{Softmax}(Q K^T)$$</p>\n<p>$$\\text{Out} &#x3D; \\text{Score} \\cdot V$$</p>\n<p><strong>Attention Score Matrix</strong> $N \\times N$<br><strong> (HBM)</strong>  **GPU  (SRAM)<strong>GPU <br>Flash Attention </strong> (Tiling)**</p>\n<ul>\n<li><p><strong></strong> $N \\times N$ </p>\n</li>\n<li><p><strong></strong> $Q, K, V$  GPU  (SRAM) </p>\n</li>\n<li><p><strong></strong> SRAM  Attention</p>\n</li>\n</ul>\n<h2 id=\"C--Norm-Activation\"><a href=\"#C--Norm-Activation\" class=\"headerlink\" title=\"C.  (Norm &amp; Activation)\"></a>C.  (Norm &amp; Activation)</h2><h3 id=\"Normalization\"><a href=\"#Normalization\" class=\"headerlink\" title=\"Normalization\"></a>Normalization</h3><p>  <strong>01</strong></p>\n<h4 id=\"BatchNorm\"><a href=\"#BatchNorm\" class=\"headerlink\" title=\"BatchNorm\"></a>BatchNorm</h4><p> <strong>Batch</strong> </p>\n<ul>\n<li><p><strong> Batch Size</strong> Batch Size BN </p>\n</li>\n<li><p><strong></strong>NLP  Padding BN Padding  0 </p>\n</li>\n<li><p><strong>RNN&#x2F;Transformer </strong> Token Batch BN </p>\n</li>\n</ul>\n<h4 id=\"LayerNorm\"><a href=\"#LayerNorm\" class=\"headerlink\" title=\"LayerNorm\"></a>LayerNorm</h4><p> <strong>Feature</strong> <br><strong> Batch Size </strong> Token Token  512 Hidden Size</p>\n<p></p>\n<p>$$y &#x3D; \\frac{x - \\mu}{\\sigma + \\epsilon} \\cdot \\gamma + \\beta$$</p>\n<ul>\n<li><p>$\\mu$ (Center)</p>\n</li>\n<li><p>$\\sigma$ (Scale)</p>\n</li>\n<li><p><strong></strong> 0  1 </p>\n</li>\n</ul>\n<p>&#x2F;BSLN</p>\n<h4 id=\"RMSNorm\"><a href=\"#RMSNorm\" class=\"headerlink\" title=\"RMSNorm\"></a>RMSNorm</h4><ul>\n<li><p> LayerNorm </p>\n<p>  LayerNorm  $\\mu$</p>\n</li>\n<li><p><br>  $$y &#x3D; \\frac{x}{\\text{RMS}(x)} \\cdot \\gamma$$$$\\text{RMS}(x) &#x3D; \\sqrt{\\frac{1}{d} \\sum x_i^2}$$</p>\n</li>\n</ul>\n<p>RMSNorm  Bias ($\\beta$) Weight ($\\gamma$)</p>\n<h3 id=\"Activation-Function\"><a href=\"#Activation-Function\" class=\"headerlink\" title=\"Activation Function\"></a>Activation Function</h3><h4 id=\"Sigmoid-Tanh\"><a href=\"#Sigmoid-Tanh\" class=\"headerlink\" title=\"Sigmoid&#x2F;Tanh\"></a>Sigmoid&#x2F;Tanh</h4><ul>\n<li><p><strong></strong>S </p>\n</li>\n<li><p><strong></strong><strong></strong> 0</p>\n</li>\n</ul>\n<h4 id=\"ReLu-Rectified-Linear-Unit\"><a href=\"#ReLu-Rectified-Linear-Unit\" class=\"headerlink\" title=\"ReLu(Rectified Linear Unit)\"></a>ReLu(Rectified Linear Unit)</h4><ul>\n<li><p><strong></strong>$f(x) &#x3D; \\max(0, x)$</p>\n</li>\n<li><p><strong></strong> 0  0 0 </p>\n</li>\n<li><p><strong></strong></p>\n</li>\n<li><p><strong></strong><strong>Dead ReLU</strong> 0</p>\n</li>\n</ul>\n<h4 id=\"GELU-Gaussian-Error-Linear-Unit--BERT-GPT-2-\"><a href=\"#GELU-Gaussian-Error-Linear-Unit--BERT-GPT-2-\" class=\"headerlink\" title=\"GELU (Gaussian Error Linear Unit)  BERT&#x2F;GPT-2 \"></a>GELU (Gaussian Error Linear Unit)  BERT&#x2F;GPT-2 </h4><ul>\n<li><p><strong></strong> ReLU ReLU  0 GELU </p>\n</li>\n<li><p><strong></strong> 0<br>$$GELU(x)&#x3D;x\\cdot \\Phi(x)$$</p>\n</li>\n</ul>\n<p></p>\n<p>$$\\Phi(x) &#x3D; P(Z \\le x), \\quad Z \\sim \\mathcal{N}(0,1)$$</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>x  0</td>\n<td> 0 0</td>\n</tr>\n<tr>\n<td>x  0</td>\n<td></td>\n</tr>\n<tr>\n<td>x  0</td>\n<td> x</td>\n</tr>\n</tbody></table>\n<h4 id=\"SiLU-Sigmoid-Linear-Unit-SwishLlama\"><a href=\"#SiLU-Sigmoid-Linear-Unit-SwishLlama\" class=\"headerlink\" title=\"SiLU(Sigmoid Linear Unit)&#x2F;SwishLlama\"></a>SiLU(Sigmoid Linear Unit)&#x2F;SwishLlama</h4><ul>\n<li><p><strong></strong>$f(x) &#x3D; x \\cdot \\text{sigmoid}(x)$</p>\n</li>\n<li><p><strong></strong> GELU </p>\n</li>\n<li><p><strong></strong></p>\n<ul>\n<li><p><strong></strong></p>\n</li>\n<li><p><strong></strong> $x$  -2  0 ReLU </p>\n</li>\n</ul>\n</li>\n<li><p><strong></strong>Google  ReLU  GELU </p>\n</li>\n</ul>\n<h2 id=\"FFN\"><a href=\"#FFN\" class=\"headerlink\" title=\"FFN\"></a>FFN</h2><h3 id=\"Transformer\"><a href=\"#Transformer\" class=\"headerlink\" title=\"Transformer\"></a>Transformer</h3><p> Up -&gt; Activation -&gt; Down </p>\n<p>$$y &#x3D; \\text{Down}(\\text{ReLU}(\\text{Up}(x)))$$</p>\n<p>Up  Down</p>\n<h3 id=\"SwiGLU-FFN\"><a href=\"#SwiGLU-FFN\" class=\"headerlink\" title=\"SwiGLU FFN\"></a>SwiGLU FFN</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"variable language_\">self</span>.gate_proj = nn.Linear(...) <span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"variable language_\">self</span>.up_proj = nn.Linear(...) <span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"variable language_\">self</span>.down_proj = nn.Linear(...) <span class=\"comment\">#  </span></span><br><span class=\"line\"><span class=\"comment\"># forward  </span></span><br><span class=\"line\"><span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.down_proj(<span class=\"variable language_\">self</span>.act_fn(<span class=\"variable language_\">self</span>.gate_proj(x)) * <span class=\"variable language_\">self</span>.up_proj(x))</span><br></pre></td></tr></table></figure>\n<p></p>\n<p>$$y &#x3D; \\text{Down}(\\text{SiLU}(\\text{Gate}(x)) \\times \\text{Up}(x))$$</p>\n<p>GLU<br><strong>SwiGLU  GeGLU &gt; ReGLU</strong><br>SiLU </p>\n<ul>\n<li><p>  </p>\n</li>\n<li><p>  </p>\n</li>\n<li><p></p>\n</li>\n</ul>\n<h2 id=\"MoE-Mixture-of-Experts-\"><a href=\"#MoE-Mixture-of-Experts-\" class=\"headerlink\" title=\"MoE(Mixture of Experts)\"></a>MoE(Mixture of Experts)</h2><h3 id=\"-Shared-Routed\"><a href=\"#-Shared-Routed\" class=\"headerlink\" title=\" (Shared + Routed)\"></a> (Shared + Routed)</h3><p><strong>Routed Experts</strong> Token </p>\n<p><strong>Shared Experts</strong><strong></strong></p>\n<p><strong></strong> MoE </p>\n<h3 id=\"-Gating\"><a href=\"#-Gating\" class=\"headerlink\" title=\" (Gating)\"></a> (Gating)</h3><p> <code>MoEGate</code> </p>\n<ul>\n<li><strong>Top-K </strong> <code>softmax</code>  K  (<code>num_experts_per_tok</code>)</li>\n<li><strong></strong><code>norm_topk_prob</code> 1</li>\n</ul>\n<h3 id=\"-Load-Balancing\"><a href=\"#-Load-Balancing\" class=\"headerlink\" title=\" (Load Balancing)\"></a> (Load Balancing)</h3><p> <code>aux_loss</code></p>\n<p> Token </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong>Training</strong> <code>repeat_interleave</code>Mask GPU </p>\n<p><strong>Inference</strong> <code>moe_infer</code> Token  (<code>argsort</code>) A  Token </p>\n<h1 id=\"Tokenizer\"><a href=\"#Tokenizer\" class=\"headerlink\" title=\"Tokenizer\"></a>Tokenizer</h1><p><strong></strong> JSONL </p>\n<p><strong></strong> <strong>BPE (Byte-Pair Encoding)</strong>  6400 </p>\n<p><strong></strong> <code>&lt;|im_start|&gt;</code>Chat Template HuggingFace </p>\n<ul>\n<li>VOCAB_SIZE &#x3D; 6400</li>\n</ul>\n<p><strong></strong>Embedding  LM Head $6400 \\times Hidden_Dim$</p>\n<p><strong></strong> Token  Token</p>\n<ul>\n<li>BPE+ByteLevel</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tokenizer = Tokenizer(models.BPE())</span><br><span class=\"line\">tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p>**BPE ()**GPT-2&#x2F;3&#x2F;4, Llama </p>\n<p><strong>ByteLevel</strong> Unicode  <strong>UTF-8 </strong></p>\n<p> -&gt; <code>0xE4 0xB8 0xAD</code> (3)</p>\n<p><strong></strong> <strong>OOV (Out of Vocabulary)</strong>  Emoji <code>&lt;UNK&gt;</code></p>\n<ul>\n<li>chat_template</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">&quot;chat_template&quot;</span>: <span class=\"string\">&quot;&#123;%- if tools %&#125;\\n    &#123;&#123;- &#x27;&lt;|im_start|&gt;system\\\\n&#x27; &#125;&#125;\\n    &#123;%- if messages[0].role == &#x27;system&#x27; %&#125;\\n        &#123;&#123;- messages[0].content + &#x27;\\\\n\\\\n&#x27; &#125;&#125;\\n    &#123;%- endif %&#125;\\n    &#123;&#123;- \\&quot;# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:\\\\n&lt;tools&gt;\\&quot; &#125;&#125;\\n    &#123;%- for tool in tools %&#125;\\n        &#123;&#123;- \\&quot;\\\\n\\&quot; &#125;&#125;\\n        &#123;&#123;- tool | tojson &#125;&#125;\\n    &#123;%- endfor %&#125;\\n    &#123;&#123;- \\&quot;\\\\n&lt;/tools&gt;\\\\n\\\\nFor each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:\\\\n&lt;tool_call&gt;\\\\n&#123;\\\\\\&quot;name\\\\\\&quot;: &lt;function-name&gt;, \\\\\\&quot;arguments\\\\\\&quot;: &lt;args-json-object&gt;&#125;\\\\n&lt;/tool_call&gt;&lt;|im_end|&gt;\\\\n\\&quot; &#125;&#125;\\n&#123;%- else %&#125;\\n &#123;%- if messages[0][&#x27;role&#x27;] == &#x27;system&#x27; -%&#125;\\n        &#123;&#123;- &#x27;&lt;|im_start|&gt;system\\\\n&#x27; + messages[0][&#x27;content&#x27;] + &#x27;&lt;|im_end|&gt;\\\\n&#x27; &#125;&#125;\\n    &#123;%- else -%&#125;\\n        &#123;&#123;- &#x27;&lt;|im_start|&gt;system\\\\nYou are a helpful assistant&lt;|im_end|&gt;\\\\n&#x27; &#125;&#125;\\n &#123;%- endif %&#125;\\n&#123;%- endif %&#125;\\n&#123;%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %&#125;\\n&#123;%- for message in messages[::-1] %&#125;\\n    &#123;%- set index = (messages|length - 1) - loop.index0 %&#125;\\n    &#123;%- if ns.multi_step_tool and message.role == \\&quot;user\\&quot; and message.content is string and not(message.content.startswith(&#x27;&lt;tool_response&gt;&#x27;) and message.content.endswith(&#x27;&lt;/tool_response&gt;&#x27;)) %&#125;\\n        &#123;%- set ns.multi_step_tool = false %&#125;\\n        &#123;%- set ns.last_query_index = index %&#125;\\n    &#123;%- endif %&#125;\\n&#123;%- endfor %&#125;\\n&#123;%- for message in messages %&#125;\\n    &#123;%- if message.content is string %&#125;\\n        &#123;%- set content = message.content %&#125;\\n    &#123;%- else %&#125;\\n        &#123;%- set content = &#x27;&#x27; %&#125;\\n    &#123;%- endif %&#125;\\n    &#123;%- if (message.role == \\&quot;user\\&quot;) or (message.role == \\&quot;system\\&quot; and not loop.first) %&#125;\\n        &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\\\\n&#x27; + content + &#x27;&lt;|im_end|&gt;&#x27; + &#x27;\\\\n&#x27; &#125;&#125;\\n    &#123;%- elif message.role == \\&quot;assistant\\&quot; %&#125;\\n   &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\\\\n&#x27; + content &#125;&#125;\\n  &#123;%- if message.tool_calls %&#125;\\n            &#123;%- for tool_call in message.tool_calls %&#125;\\n                &#123;%- if (loop.first and content) or (not loop.first) %&#125;\\n                    &#123;&#123;- &#x27;\\\\n&#x27; &#125;&#125;\\n                &#123;%- endif %&#125;\\n                &#123;%- if tool_call.function %&#125;\\n                    &#123;%- set tool_call = tool_call.function %&#125;\\n                &#123;%- endif %&#125;\\n                &#123;&#123;- &#x27;&lt;tool_call&gt;\\\\n&#123;\\&quot;name\\&quot;: \\&quot;&#x27; &#125;&#125;\\n                &#123;&#123;- tool_call.name &#125;&#125;\\n                &#123;&#123;- &#x27;\\&quot;, \\&quot;arguments\\&quot;: &#x27; &#125;&#125;\\n                &#123;%- if tool_call.arguments is string %&#125;\\n                    &#123;&#123;- tool_call.arguments &#125;&#125;\\n                &#123;%- else %&#125;\\n                    &#123;&#123;- tool_call.arguments | tojson &#125;&#125;\\n                &#123;%- endif %&#125;\\n                &#123;&#123;- &#x27;&#125;\\\\n&lt;/tool_call&gt;&#x27; &#125;&#125;\\n            &#123;%- endfor %&#125;\\n        &#123;%- endif %&#125;\\n        &#123;&#123;- &#x27;&lt;|im_end|&gt;\\\\n&#x27; &#125;&#125;\\n    &#123;%- elif message.role == \\&quot;tool\\&quot; %&#125;\\n        &#123;%- if loop.first or (messages[loop.index0 - 1].role != \\&quot;tool\\&quot;) %&#125;\\n            &#123;&#123;- &#x27;&lt;|im_start|&gt;user&#x27; &#125;&#125;\\n        &#123;%- endif %&#125;\\n        &#123;&#123;- &#x27;\\\\n&lt;tool_response&gt;\\\\n&#x27; &#125;&#125;\\n        &#123;&#123;- content &#125;&#125;\\n        &#123;&#123;- &#x27;\\\\n&lt;/tool_response&gt;&#x27; &#125;&#125;\\n        &#123;%- if loop.last or (messages[loop.index0 + 1].role != \\&quot;tool\\&quot;) %&#125;\\n            &#123;&#123;- &#x27;&lt;|im_end|&gt;\\\\n&#x27; &#125;&#125;\\n        &#123;%- endif %&#125;\\n    &#123;%- endif %&#125;\\n&#123;%- endfor %&#125;\\n&#123;%- if add_generation_prompt %&#125;\\n    &#123;&#123;- &#x27;&lt;|im_start|&gt;assistant\\\\n&#x27; &#125;&#125;\\n    &#123;%- if enable_thinking is defined and enable_thinking is false %&#125;\\n        &#123;&#123;- &#x27;&lt;think&gt;\\\\n\\\\n&lt;/think&gt;\\\\n\\\\n&#x27; &#125;&#125;\\n    &#123;%- endif %&#125;\\n&#123;%- endif %&#125;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p><strong> Jinja2 </strong> HuggingFace  <code>tokenizer.apply_chat_template</code> <strong> Python List of Dicts Tokenizer </strong>System Prompt<strong></strong><strong></strong>Tools<strong></strong></p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"><span class=\"keyword\">for</span> tid <span class=\"keyword\">in</span> input_ids:</span><br><span class=\"line\">    token_cache.append(tid)</span><br><span class=\"line\">    current_decode = tokenizer.decode(token_cache)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> current_decode <span class=\"keyword\">and</span> <span class=\"string\">&#x27;\\ufffd&#x27;</span> <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> current_decode:</span><br><span class=\"line\">        <span class=\"comment\"># ...  ...</span></span><br><span class=\"line\">        token_cache = []</span><br></pre></td></tr></table></figure>\n\n<p> UTF-8  <strong>3</strong></p>\n<p> Token A (<code>E6</code>)  Decode <code>E6</code> &#96;&#96; ( \\ufffd, Replacement Character)</p>\n<p><strong></strong> <code>token_cache</code> <code>\\ufffd</code><strong></strong> Token B (<code>88 91</code>)  <code>E6 88 91</code><code>\\ufffd</code> </p>\n<h1 id=\"Pretrain\"><a href=\"#Pretrain\" class=\"headerlink\" title=\"Pretrain\"></a>Pretrain</h1><p>LLM  ModelWiki  <strong></strong></p>\n<h2 id=\"Dataloader\"><a href=\"#Dataloader\" class=\"headerlink\" title=\"Dataloader\"></a>Dataloader</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">PretrainDataset</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, data_path, tokenizer, max_length=<span class=\"number\">512</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.tokenizer = tokenizer</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.max_length = max_length</span><br><span class=\"line\">        <span class=\"comment\"># 1. </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.samples = load_dataset(<span class=\"string\">&#x27;json&#x27;</span>, data_files=data_path, split=<span class=\"string\">&#x27;train&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.samples)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, index</span>):</span><br><span class=\"line\">        sample = <span class=\"variable language_\">self</span>.samples[index]</span><br><span class=\"line\">        <span class=\"comment\"># 2.  (Tokenization)</span></span><br><span class=\"line\">        encoding = <span class=\"variable language_\">self</span>.tokenizer(</span><br><span class=\"line\">            <span class=\"built_in\">str</span>(sample[<span class=\"string\">&#x27;text&#x27;</span>]),</span><br><span class=\"line\">            max_length=<span class=\"variable language_\">self</span>.max_length,</span><br><span class=\"line\">            padding=<span class=\"string\">&#x27;max_length&#x27;</span>,</span><br><span class=\"line\">            truncation=<span class=\"literal\">True</span>,</span><br><span class=\"line\">            return_tensors=<span class=\"string\">&#x27;pt&#x27;</span></span><br><span class=\"line\">        )</span><br><span class=\"line\">        <span class=\"comment\"># 3.  Labels ()</span></span><br><span class=\"line\">        input_ids = encoding.input_ids.squeeze()</span><br><span class=\"line\">        labels = input_ids.clone()</span><br><span class=\"line\">        <span class=\"comment\"># 4. Masking Padding</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#  Pad Token  Label  -100</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># PyTorch  CrossEntropyLoss  -100</span></span><br><span class=\"line\">        labels[input_ids == <span class=\"variable language_\">self</span>.tokenizer.pad_token_id] = -<span class=\"number\">100</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> input_ids, labels</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Epoch\"><a href=\"#Epoch\" class=\"headerlink\" title=\"Epoch\"></a>Epoch</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train_epoch</span>(<span class=\"params\">epoch, loader, iters, start_step=<span class=\"number\">0</span>, wandb=<span class=\"literal\">None</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> step, (input_ids, labels) <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(loader, start=start_step + <span class=\"number\">1</span>):</span><br><span class=\"line\">        <span class=\"comment\">#</span></span><br><span class=\"line\">        input_ids = input_ids.to(args.device)</span><br><span class=\"line\">        labels = labels.to(args.device)</span><br><span class=\"line\">        <span class=\"comment\">#  Cosine Decay</span></span><br><span class=\"line\">        lr = get_lr(epoch * iters + step, args.epochs * iters, args.learning_rate)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> param_group <span class=\"keyword\">in</span> optimizer.param_groups:</span><br><span class=\"line\">            param_group[<span class=\"string\">&#x27;lr&#x27;</span>] = lr</span><br><span class=\"line\">\t\t<span class=\"comment\"># autocast_ctx </span></span><br><span class=\"line\">        <span class=\"comment\">#  float16  bfloat16 </span></span><br><span class=\"line\">        <span class=\"keyword\">with</span> autocast_ctx:</span><br><span class=\"line\">            res = model(input_ids, labels=labels)</span><br><span class=\"line\">            <span class=\"comment\"># res.loss  Loss</span></span><br><span class=\"line\">            <span class=\"comment\"># res.aux_loss  MoE  Loss</span></span><br><span class=\"line\">            loss = res.loss + res.aux_loss</span><br><span class=\"line\">            <span class=\"comment\"># </span></span><br><span class=\"line\">            loss = loss / args.accumulation_steps</span><br><span class=\"line\">\t\t<span class=\"comment\"># scaler  GradScaler float16 </span></span><br><span class=\"line\">        <span class=\"comment\">#  scale float16 Loss  0.00001</span></span><br><span class=\"line\">        <span class=\"comment\">#  0scaler  Loss  65536</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        scaler.scale(loss).backward()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (step + <span class=\"number\">1</span>) % args.accumulation_steps == <span class=\"number\">0</span>:</span><br><span class=\"line\">            <span class=\"comment\"># 1. Unscale</span></span><br><span class=\"line\">            <span class=\"comment\">#  clip_grad_norm </span></span><br><span class=\"line\">            scaler.unscale_(optimizer)</span><br><span class=\"line\">            <span class=\"comment\"># 2.  (Gradient Clipping)</span></span><br><span class=\"line\">            <span class=\"comment\">#  args.grad_clip ( 1.0)</span></span><br><span class=\"line\">            <span class=\"comment\">#  LLM </span></span><br><span class=\"line\">            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># scaler.step  Inf/NaN</span></span><br><span class=\"line\">            scaler.step(optimizer)</span><br><span class=\"line\">            <span class=\"comment\"># 4. </span></span><br><span class=\"line\">            scaler.update()</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 5. </span></span><br><span class=\"line\">            <span class=\"comment\"># set_to_none=True  =0 </span></span><br><span class=\"line\">            optimizer.zero_grad(set_to_none=<span class=\"literal\">True</span>)</span><br><span class=\"line\">\t\t<span class=\"comment\">##.....</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">        <span class=\"comment\"># Rank 0</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> (step % args.save_interval == <span class=\"number\">0</span> <span class=\"keyword\">or</span> step == iters - <span class=\"number\">1</span>) <span class=\"keyword\">and</span> is_main_process():</span><br><span class=\"line\">            model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">            moe_suffix = <span class=\"string\">&#x27;_moe&#x27;</span> <span class=\"keyword\">if</span> lm_config.use_moe <span class=\"keyword\">else</span> <span class=\"string\">&#x27;&#x27;</span></span><br><span class=\"line\">            ckp = <span class=\"string\">f&#x27;<span class=\"subst\">&#123;args.save_dir&#125;</span>/<span class=\"subst\">&#123;args.save_weight&#125;</span>_<span class=\"subst\">&#123;lm_config.hidden_size&#125;</span><span class=\"subst\">&#123;moe_suffix&#125;</span>.pth&#x27;</span></span><br><span class=\"line\">            <span class=\"comment\">#  DDP .module</span></span><br><span class=\"line\">            raw_model = model.module <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(model, DistributedDataParallel) <span class=\"keyword\">else</span> model</span><br><span class=\"line\">            <span class=\"comment\">#  torch.compile _orig_mod</span></span><br><span class=\"line\">            raw_model = <span class=\"built_in\">getattr</span>(raw_model, <span class=\"string\">&#x27;_orig_mod&#x27;</span>, raw_model)</span><br><span class=\"line\">            state_dict = raw_model.state_dict()</span><br><span class=\"line\">            <span class=\"comment\"># 1.  (.pth)</span></span><br><span class=\"line\">            <span class=\"comment\"># .half() float16 </span></span><br><span class=\"line\">            <span class=\"comment\"># .cpu() CPU</span></span><br><span class=\"line\">            torch.save(&#123;k: v.half().cpu() <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> state_dict.items()&#125;, ckp)</span><br><span class=\"line\">            <span class=\"comment\"># 2.  (Checkpoint)</span></span><br><span class=\"line\">            <span class=\"comment\">#  optimizerscaler epoch  step</span></span><br><span class=\"line\">            <span class=\"comment\"># Resume</span></span><br><span class=\"line\">            lm_checkpoint(lm_config, weight=args.save_weight, model=model, optimizer=optimizer, scaler=scaler, epoch=epoch, step=step, wandb=wandb, save_dir=<span class=\"string\">&#x27;../checkpoints&#x27;</span>)</span><br><span class=\"line\">            model.train()</span><br><span class=\"line\">            <span class=\"keyword\">del</span> state_dict</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">del</span> input_ids, labels, res, loss</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">   <span class=\"comment\"># ========== 1.  ==========</span></span><br><span class=\"line\">   local_rank = init_distributed_mode()</span><br><span class=\"line\">   <span class=\"keyword\">if</span> dist.is_initialized(): args.device = <span class=\"string\">f&quot;cuda:<span class=\"subst\">&#123;local_rank&#125;</span>&quot;</span></span><br><span class=\"line\">   setup_seed(<span class=\"number\">42</span> + (dist.get_rank() <span class=\"keyword\">if</span> dist.is_initialized() <span class=\"keyword\">else</span> <span class=\"number\">0</span>))</span><br><span class=\"line\">   <span class=\"comment\">#  Dropout </span></span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 2. ckp ==========</span></span><br><span class=\"line\">   os.makedirs(args.save_dir, exist_ok=<span class=\"literal\">True</span>)</span><br><span class=\"line\">   lm_config = MiniMindConfig(hidden_size=args.hidden_size, num_hidden_layers=args.num_hidden_layers, use_moe=<span class=\"built_in\">bool</span>(args.use_moe))</span><br><span class=\"line\">   <span class=\"comment\"># lm_checkpoint  ../checkpoints  args.save_weight </span></span><br><span class=\"line\"><span class=\"comment\"># epochstep  ckp_data </span></span><br><span class=\"line\">   ckp_data = lm_checkpoint(lm_config, weight=args.save_weight, save_dir=<span class=\"string\">&#x27;../checkpoints&#x27;</span>) <span class=\"keyword\">if</span> args.from_resume==<span class=\"number\">1</span> <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 3.  ==========</span></span><br><span class=\"line\">   device_type = <span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">if</span> <span class=\"string\">&quot;cuda&quot;</span> <span class=\"keyword\">in</span> args.device <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span></span><br><span class=\"line\">   dtype = torch.bfloat16 <span class=\"keyword\">if</span> args.dtype == <span class=\"string\">&quot;bfloat16&quot;</span> <span class=\"keyword\">else</span> torch.float16</span><br><span class=\"line\">   <span class=\"comment\">#  train_epoch </span></span><br><span class=\"line\">   autocast_ctx = nullcontext() <span class=\"keyword\">if</span> device_type == <span class=\"string\">&quot;cpu&quot;</span> <span class=\"keyword\">else</span> torch.cuda.amp.autocast(dtype=dtype)</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 4. wandb ==========</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 5.  ==========</span></span><br><span class=\"line\">   model, tokenizer = init_model(lm_config, args.from_weight, device=args.device)</span><br><span class=\"line\">   <span class=\"keyword\">if</span> args.use_compile == <span class=\"number\">1</span>:</span><br><span class=\"line\">       model = torch.<span class=\"built_in\">compile</span>(model)</span><br><span class=\"line\">       Logger(<span class=\"string\">&#x27;torch.compile enabled&#x27;</span>)</span><br><span class=\"line\">   train_ds = PretrainDataset(args.data_path, tokenizer, max_length=args.max_seq_len)</span><br><span class=\"line\">   <span class=\"comment\">#  DDP  N N=</span></span><br><span class=\"line\">   train_sampler = DistributedSampler(train_ds) <span class=\"keyword\">if</span> dist.is_initialized() <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\">   <span class=\"comment\"># GradScaler float16 </span></span><br><span class=\"line\"><span class=\"comment\">#  bfloat16enabled=False</span></span><br><span class=\"line\">   scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype == <span class=\"string\">&#x27;float16&#x27;</span>))</span><br><span class=\"line\">   optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate)</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 6. ckp ==========</span></span><br><span class=\"line\">   start_epoch, start_step = <span class=\"number\">0</span>, <span class=\"number\">0</span></span><br><span class=\"line\">   <span class=\"keyword\">if</span> ckp_data:</span><br><span class=\"line\">       model.load_state_dict(ckp_data[<span class=\"string\">&#x27;model&#x27;</span>])</span><br><span class=\"line\">       optimizer.load_state_dict(ckp_data[<span class=\"string\">&#x27;optimizer&#x27;</span>])</span><br><span class=\"line\">       scaler.load_state_dict(ckp_data[<span class=\"string\">&#x27;scaler&#x27;</span>])</span><br><span class=\"line\">       start_epoch = ckp_data[<span class=\"string\">&#x27;epoch&#x27;</span>]</span><br><span class=\"line\">       start_step = ckp_data.get(<span class=\"string\">&#x27;step&#x27;</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 7. DDP ==========</span></span><br><span class=\"line\">   <span class=\"keyword\">if</span> dist.is_initialized():</span><br><span class=\"line\">       model._ddp_params_and_buffers_to_ignore = &#123;<span class=\"string\">&quot;freqs_cos&quot;</span>, <span class=\"string\">&quot;freqs_sin&quot;</span>&#125;</span><br><span class=\"line\">       model = DistributedDataParallel(model, device_ids=[local_rank])</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 8.  ==========</span></span><br><span class=\"line\">   <span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(start_epoch, args.epochs):</span><br><span class=\"line\">       train_sampler <span class=\"keyword\">and</span> train_sampler.set_epoch(epoch)</span><br><span class=\"line\">       <span class=\"keyword\">if</span> epoch == start_epoch <span class=\"keyword\">and</span> start_step &gt; <span class=\"number\">0</span>: <span class=\"comment\"># epoch</span></span><br><span class=\"line\">           <span class=\"comment\"># SkipBatchSampler </span></span><br><span class=\"line\">       \t<span class=\"comment\">#  1000  batch index</span></span><br><span class=\"line\">       \t<span class=\"comment\"># Dataloader  1000 </span></span><br><span class=\"line\">           batch_sampler = SkipBatchSampler(train_sampler <span class=\"keyword\">or</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(train_ds)), args.batch_size, start_step + <span class=\"number\">1</span>)</span><br><span class=\"line\">           loader = DataLoader(train_ds, batch_sampler=batch_sampler, num_workers=args.num_workers, pin_memory=<span class=\"literal\">True</span>)</span><br><span class=\"line\">           Logger(<span class=\"string\">f&#x27;Epoch [<span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>&#125;</span>/<span class=\"subst\">&#123;args.epochs&#125;</span>]: <span class=\"subst\">&#123;start_step&#125;</span>stepstep <span class=\"subst\">&#123;start_step + <span class=\"number\">1</span>&#125;</span>&#x27;</span>)</span><br><span class=\"line\">           train_epoch(epoch, loader, <span class=\"built_in\">len</span>(loader) + start_step + <span class=\"number\">1</span>, start_step, wandb)</span><br><span class=\"line\">       <span class=\"keyword\">else</span>: <span class=\"comment\"># </span></span><br><span class=\"line\">           loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=(train_sampler <span class=\"keyword\">is</span> <span class=\"literal\">None</span>), sampler=train_sampler, num_workers=args.num_workers, pin_memory=<span class=\"literal\">True</span>)</span><br><span class=\"line\">           train_epoch(epoch, loader, <span class=\"built_in\">len</span>(loader), <span class=\"number\">0</span>, wandb)</span><br><span class=\"line\">   </span><br><span class=\"line\">   <span class=\"comment\"># ========== 9.  ==========</span></span><br><span class=\"line\">   <span class=\"keyword\">if</span> dist.is_initialized(): dist.destroy_process_group()</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torchrun --nproc_per_node 1 train_pretrain.py <span class=\"comment\"># 1 (&gt;=2)</span></span><br><span class=\"line\"><span class=\"comment\"># or</span></span><br><span class=\"line\">python train_pretrain.py</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data\"></a> <code>&lt;512</code>1.6GB <code>pretrain_hq.jsonl</code>hqhigh quality</p>\n<p><code>pretrain_hq.jsonl</code> </p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;&quot;text&quot;: &quot; ...&quot;&#125;</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"SFT\"><a href=\"#SFT\" class=\"headerlink\" title=\"SFT\"></a>SFT</h1><p>LLM SFTLLM -&gt;-&gt;  MiniMind512200800 2k&#x2F;4k&#x2F;8kRoPE-NTK</p>\n<h2 id=\"DataLoader\"><a href=\"#DataLoader\" class=\"headerlink\" title=\"DataLoader\"></a>DataLoader</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">SFTDataset</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, jsonl_path, tokenizer, max_length=<span class=\"number\">1024</span></span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.tokenizer = tokenizer</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.max_length = max_length</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.samples = load_dataset(<span class=\"string\">&#x27;json&#x27;</span>, data_files=jsonl_path, split=<span class=\"string\">&#x27;train&#x27;</span>)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.bos_id = tokenizer(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;tokenizer.bos_token&#125;</span>assistant\\n&#x27;</span>, add_special_tokens=<span class=\"literal\">False</span>).input_ids</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.eos_id = tokenizer(<span class=\"string\">f&#x27;<span class=\"subst\">&#123;tokenizer.eos_token&#125;</span>\\n&#x27;</span>, add_special_tokens=<span class=\"literal\">False</span>).input_ids</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__len__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.samples)</span><br><span class=\"line\">    </span><br><span class=\"line\">\t<span class=\"comment\"># tokenizer  chat template prompt</span></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">create_chat_prompt</span>(<span class=\"params\">self, cs</span>):</span><br><span class=\"line\">        messages = cs.copy()</span><br><span class=\"line\">        tools = cs[<span class=\"number\">0</span>][<span class=\"string\">&quot;functions&quot;</span>] <span class=\"keyword\">if</span> (cs <span class=\"keyword\">and</span> cs[<span class=\"number\">0</span>][<span class=\"string\">&quot;role&quot;</span>] == <span class=\"string\">&quot;system&quot;</span> <span class=\"keyword\">and</span> cs[<span class=\"number\">0</span>].get(<span class=\"string\">&quot;functions&quot;</span>)) <span class=\"keyword\">else</span> <span class=\"literal\">None</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.tokenizer.apply_chat_template(</span><br><span class=\"line\">            messages,</span><br><span class=\"line\">            tokenize=<span class=\"literal\">False</span>,</span><br><span class=\"line\">            add_generation_prompt=<span class=\"literal\">False</span>,</span><br><span class=\"line\">            tools=tools</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">generate_labels</span>(<span class=\"params\">self, input_ids</span>):</span><br><span class=\"line\">        <span class=\"comment\"># 1.  (-100)</span></span><br><span class=\"line\">        labels = [-<span class=\"number\">100</span>] * <span class=\"built_in\">len</span>(input_ids)</span><br><span class=\"line\">        <span class=\"comment\"># 2.  input_ids </span></span><br><span class=\"line\">        i = <span class=\"number\">0</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> i &lt; <span class=\"built_in\">len</span>(input_ids):</span><br><span class=\"line\">            <span class=\"comment\"># 3.  Assistant  (self.bos_id)</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> input_ids[i:i + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.bos_id)] == <span class=\"variable language_\">self</span>.bos_id:</span><br><span class=\"line\">                start = i + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.bos_id)</span><br><span class=\"line\">                <span class=\"comment\"># 4.  Assistant  (self.eos_id)</span></span><br><span class=\"line\">                end = start</span><br><span class=\"line\">                <span class=\"keyword\">while</span> end &lt; <span class=\"built_in\">len</span>(input_ids):</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> input_ids[end:end + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.eos_id)] == <span class=\"variable language_\">self</span>.eos_id:</span><br><span class=\"line\">                        <span class=\"keyword\">break</span></span><br><span class=\"line\">                    end += <span class=\"number\">1</span></span><br><span class=\"line\">                <span class=\"comment\"># 5.  Mask</span></span><br><span class=\"line\">            \t<span class=\"comment\">#  [start, end]  labels  input_ids </span></span><br><span class=\"line\">            \t<span class=\"comment\">#  Loss</span></span><br><span class=\"line\">                <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(start, <span class=\"built_in\">min</span>(end + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.eos_id), <span class=\"variable language_\">self</span>.max_length)):</span><br><span class=\"line\">                    labels[j] = input_ids[j]</span><br><span class=\"line\">                i = end + <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.eos_id) <span class=\"keyword\">if</span> end &lt; <span class=\"built_in\">len</span>(input_ids) <span class=\"keyword\">else</span> <span class=\"built_in\">len</span>(input_ids)</span><br><span class=\"line\">            <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                i += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> labels</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__getitem__</span>(<span class=\"params\">self, index</span>):</span><br><span class=\"line\">        sample = <span class=\"variable language_\">self</span>.samples[index]</span><br><span class=\"line\">        prompt = <span class=\"variable language_\">self</span>.create_chat_prompt(sample[<span class=\"string\">&#x27;conversations&#x27;</span>])</span><br><span class=\"line\">        input_ids = <span class=\"variable language_\">self</span>.tokenizer(prompt).input_ids[:<span class=\"variable language_\">self</span>.max_length]</span><br><span class=\"line\">        input_ids += [<span class=\"variable language_\">self</span>.tokenizer.pad_token_id] * (<span class=\"variable language_\">self</span>.max_length - <span class=\"built_in\">len</span>(input_ids))</span><br><span class=\"line\">        labels = <span class=\"variable language_\">self</span>.generate_labels(input_ids)</span><br><span class=\"line\">        <span class=\"comment\"># # ===  ===</span></span><br><span class=\"line\">        <span class=\"comment\"># print(f&quot;\\n--- Sample &#123;index&#125; ---&quot;)</span></span><br><span class=\"line\">        <span class=\"comment\"># for i, (x, y) in enumerate(zip(input_ids[:-1], labels[1:])):</span></span><br><span class=\"line\">        <span class=\"comment\">#     print(f&quot;&#123;i:3d&#125;: X=&#123;self.tokenizer.decode([x])!r:16s&#125; ---&gt; Y=&#123;self.tokenizer.decode([input_ids[i+1]])!r:16s&#125; label=&#123;y&#125;&quot;)</span></span><br><span class=\"line\">        <span class=\"comment\"># # ================</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> torch.tensor(input_ids, dtype=torch.long), torch.tensor(labels, dtype=torch.long)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Epoch-1\"><a href=\"#Epoch-1\" class=\"headerlink\" title=\"Epoch\"></a>Epoch</h2><p>pretrainSFTlabels-100PyTorch  <code>CrossEntropyLoss</code> <strong> -100  Label</strong></p>\n<p>loss</p>\n<h2 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h2><p>pretrain</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torchrun --nproc_per_node <span class=\"number\">1</span> train_full_sft.py</span><br><span class=\"line\"><span class=\"comment\"># or</span></span><br><span class=\"line\">python train_full_sft.py</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"KD\"><a href=\"#KD\" class=\"headerlink\" title=\"KD\"></a>KD</h1><p>    SFTTokenhard labels 0  6400 softmaxsoft labelsKL-Loss SFTKD <code>1+1=2</code>a0b100c-99   LLM&#x2F; GPT-4 SFTFT </p>\n<p></p>\n<ul>\n<li> (<code>distillation_loss</code>)</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">distillation_loss</span>(<span class=\"params\">student_logits, teacher_logits, temperature=<span class=\"number\">1.0</span>, reduction=<span class=\"string\">&#x27;batchmean&#x27;</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"comment\"># 1.  (Soft Targets)</span></span><br><span class=\"line\">        <span class=\"comment\">#  T (temperature) </span></span><br><span class=\"line\">        teacher_probs = F.softmax(teacher_logits / temperature, dim=-<span class=\"number\">1</span>).detach()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 2.  Log </span></span><br><span class=\"line\">    student_log_probs = F.log_softmax(student_logits / temperature, dim=-<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 3.  KL  (Kullback-Leibler Divergence)</span></span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    kl = F.kl_div(student_log_probs, teacher_probs, reduction=reduction)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 4. </span></span><br><span class=\"line\">    <span class=\"comment\">#  T^2 T  1/T^2</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> (temperature ** <span class=\"number\">2</span>) * kl</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p> (<code>train_epoch</code>)</p>\n</li>\n<li><p>$$Loss_{total} &#x3D; \\alpha \\cdot Loss_{CE} + (1 - \\alpha) \\cdot Loss_{Distill}$$</p>\n</li>\n<li><p>Masking  SFT <strong></strong></p>\n</li>\n<li><p> Teacher GradientsOptimizer States <strong> (Weights)</strong>  <strong> (Activations)</strong> </p>\n</li>\n</ul>\n<h1 id=\"LoRA\"><a href=\"#LoRA\" class=\"headerlink\" title=\"LoRA\"></a>LoRA</h1><p>LoRAParameter-Efficient Fine-Tuning, PEFT Full Fine-TuningLoRA  LoRA </p>\n<ul>\n<li>Lora</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">LoRA</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, in_features, out_features, rank</span>):</span><br><span class=\"line\">        <span class=\"comment\"># rank:  in=512, out=512, rank=8</span></span><br><span class=\"line\">        <span class=\"comment\"># 512*512 = 26</span></span><br><span class=\"line\">        <span class=\"comment\"># LoRA512*8 + 8*512 = 8 32 </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.rank = rank</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.A = nn.Linear(in_features, rank, bias=<span class=\"literal\">False</span>)  <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.B = nn.Linear(rank, out_features, bias=<span class=\"literal\">False</span>) <span class=\"comment\"># </span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># A </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.A.weight.data.normal_(mean=<span class=\"number\">0.0</span>, std=<span class=\"number\">0.02</span>)</span><br><span class=\"line\">        <span class=\"comment\"># B  0 </span></span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.B.weight.data.zero_()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"comment\"># forward = B(A(x))</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.B(<span class=\"variable language_\">self</span>.A(x))</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Lora</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">apply_lora</span>(<span class=\"params\">model, rank=<span class=\"number\">8</span></span>):</span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> name, module <span class=\"keyword\">in</span> model.named_modules():</span><br><span class=\"line\">        <span class=\"comment\">#  Linear  (in == out)</span></span><br><span class=\"line\">        <span class=\"comment\"># </span></span><br><span class=\"line\">        <span class=\"comment\">#  Attention  Q, K, V, O  LoRA</span></span><br><span class=\"line\">        <span class=\"comment\">#  Transformer  hidden_size -&gt; hidden_size </span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">isinstance</span>(module, nn.Linear) <span class=\"keyword\">and</span> module.weight.shape[<span class=\"number\">0</span>] == module.weight.shape[<span class=\"number\">1</span>]:</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 1.  LoRA </span></span><br><span class=\"line\">            lora = LoRA(..., rank=rank)</span><br><span class=\"line\">            <span class=\"built_in\">setattr</span>(module, <span class=\"string\">&quot;lora&quot;</span>, lora) <span class=\"comment\">#  module.lora = lora</span></span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 2.  forward </span></span><br><span class=\"line\">            original_forward = module.forward <span class=\"comment\">#  forward</span></span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"comment\">#  forward</span></span><br><span class=\"line\">            <span class=\"keyword\">def</span> <span class=\"title function_\">forward_with_lora</span>(<span class=\"params\">x, layer1=original_forward, layer2=lora</span>):</span><br><span class=\"line\">                <span class=\"comment\">#  = (x) + LoRA(x)</span></span><br><span class=\"line\">                <span class=\"keyword\">return</span> layer1(x) + layer2(x)</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 3. </span></span><br><span class=\"line\">            module.forward = forward_with_lora</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">save_lora</span>(<span class=\"params\">model, path</span>):</span><br><span class=\"line\">    <span class=\"comment\"># ...</span></span><br><span class=\"line\">    <span class=\"comment\">#  &#x27;lora&#x27; </span></span><br><span class=\"line\">    lora_state = &#123;<span class=\"string\">f&#x27;<span class=\"subst\">&#123;clean_name&#125;</span>.lora.<span class=\"subst\">&#123;k&#125;</span>&#x27;</span>: v <span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> module.lora.state_dict().items()&#125;</span><br><span class=\"line\">    state_dict.update(lora_state)</span><br><span class=\"line\">    <span class=\"comment\">#  MB GB</span></span><br><span class=\"line\">    torch.save(state_dict, path)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lora_params = []</span><br><span class=\"line\"><span class=\"keyword\">for</span> name, param <span class=\"keyword\">in</span> model.named_parameters():</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"string\">&#x27;lora&#x27;</span> <span class=\"keyword\">in</span> name:</span><br><span class=\"line\">        param.requires_grad = <span class=\"literal\">True</span>  <span class=\"comment\"># LoRA </span></span><br><span class=\"line\">        lora_params.append(param)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        param.requires_grad = <span class=\"literal\">False</span> <span class=\"comment\"># </span></span><br><span class=\"line\">optimizer = optim.AdamW(lora_params, lr=args.learning_rate)</span><br></pre></td></tr></table></figure>\n\n<p>+LoRALoRA</p>\n<p>PSfull_sft</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>DeepSeek R1<code>&gt;3B</code>RL  SFT+GRPO</p>\n<p>SFT</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">&quot;conversations&quot;</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;user&quot;</span>,</span><br><span class=\"line\">      <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;&quot;</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">&quot;role&quot;</span>: <span class=\"string\">&quot;assistant&quot;</span>,</span><br><span class=\"line\">      <span class=\"string\">&quot;content&quot;</span>: <span class=\"string\">&quot;&lt;think&gt;\\nMiniMind-R1-Lite-Preview\\n&lt;/think&gt;\\n&lt;answer&gt;\\nMiniMind-R1-Lite-Preview\\n&lt;/answer&gt;&quot;</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;think&gt;\\n\\n&lt;/think&gt;\\n</span><br><span class=\"line\">&lt;answer&gt;\\n\\n&lt;/answer&gt;</span><br></pre></td></tr></table></figure>\n\n<p>GRPO</p>\n<ul>\n<li></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sp_ids = torch.isin(shift_labels.view(-<span class=\"number\">1</span>), torch.tensor(start_of_think_ids + ...))</span><br><span class=\"line\">loss_mask_flat[sp_ids] = <span class=\"number\">10</span></span><br></pre></td></tr></table></figure>\n\n<p> <code>&lt;think&gt;</code>, <code>&lt;/think&gt;</code>, <code>&lt;answer&gt;</code>, <code>&lt;/answer&gt;</code>  Loss  <strong>10</strong></p>\n<p><strong></strong> SFT </p>\n<p>** (SFT)** ** (Next Token Prediction)** DeepSeek-R1 AB AB B  B B</p>\n<p>** (RL - PPO&#x2F;GRPO)** ** (Maximize Reward)** AC AB</p>\n<p><strong></strong> 10  Loss  (<code>loss_mask_flat[sp_ids] = 10</code>)  <code>&lt;think&gt;</code> <code>&lt;answer&gt;</code><strong>Chain-of-Thought, CoT</strong></p>\n<p><strong></strong>R1</p>\n<ul>\n<li><em></em> -&gt; </li>\n<li><em></em> -&gt;  1 -&gt;  2 -&gt; </li>\n<li></li>\n</ul>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>LLM</p>\n<ol>\n<li><strong> (Reinforcement Learning from Human Feedback, RLHF)</strong></li>\n</ol>\n<ul>\n<li><strong></strong></li>\n</ul>\n<ol>\n<li><strong>AI (Reinforcement Learning from AI Feedback, RLAIF)</strong></li>\n</ol>\n<ul>\n<li><strong>AI</strong></li>\n<li>AI&#x2F;</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RLHF</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>RLAIF</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p><strong></strong><strong></strong></p>\n<p><strong></strong></p>\n<h2 id=\"-Reinforcement-Learning-from-Human-Feedback-RLHF\"><a href=\"#-Reinforcement-Learning-from-Human-Feedback-RLHF\" class=\"headerlink\" title=\" (Reinforcement Learning from Human Feedback, RLHF)\"></a><strong> (Reinforcement Learning from Human Feedback, RLHF)</strong></h2><h3 id=\"DPO-Direct-Preference-Optimization\"><a href=\"#DPO-Direct-Preference-Optimization\" class=\"headerlink\" title=\"DPO(Direct Preference Optimization)\"></a>DPO(Direct Preference Optimization)</h3><p>DPO</p>\n<p></p>\n<ul>\n<li><strong></strong>: f(rt)&#x3D;logrwlogrl (chosen vs rejected)</li>\n<li><strong></strong>: g(At) &#x3D; &#x2F; ()</li>\n<li><strong></strong>: h(KLt) &#x3D;    ()</li>\n</ul>\n<p></p>\n<ul>\n<li>DPOPPOKLchosenrejectedReward&#x2F;ValueDPO<code>actor</code><code>ref</code></li>\n<li>offpolicyepochRef</li>\n<li>DPO&#x2F;</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torchrun --nproc_per_node <span class=\"number\">1</span> train_dpo.py</span><br><span class=\"line\"><span class=\"comment\"># or</span></span><br><span class=\"line\">python train_dpo.py</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"AI-Reinforcement-Learning-from-AI-Feedback-RLAIF\"><a href=\"#AI-Reinforcement-Learning-from-AI-Feedback-RLAIF\" class=\"headerlink\" title=\"AI (Reinforcement Learning from AI Feedback, RLAIF)\"></a><strong>AI (Reinforcement Learning from AI Feedback, RLAIF)</strong></h2>"},{"title":"","mathjax":true,"date":"2025-07-01T12:46:25.000Z","img":"https://i0.hdslb.com/bfs/archive/6bed0eae871f7232429009ad607d9b230cec6cc1.png","excerpt":"","_content":"## \n\nanaconda\n\ncudapytorch\n\n```python\ntorch.cuda.is_available()\n```\n\n## \n\n### Dataset\n\ndatasettorch.util.DataSet\n\n```python\nclass MyData(Dataset):\n\n    def __init__(self, root_dir, label_dir):\n        self.root_dir = root_dir\n        self.label_dir = label_dir\n        self.path = os.path.join(root_dir, label_dir)\n        self.my_list = os.listdir(self.path)\n\n    def get_item(self, idx):\n        img_name = self.my_list[idx]\n        img_path = os.path.join(self.path, img_name)\n        img = Image.open(img_path)\n        img.show()\n\n    def get_length(self):\n        return len(self.my_list)\n```\n\n### DataLoader\n\n```python\ntest_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=False)\n# dataset \n# batch_size \n# shuffle \n# num_workers  0\n# drop_last batch_size\nfor data in test_loader:\n    imgs, targets = data\n    print(imgs)\n    print(targets)\n```\n\n## TensorBoard\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nimport math\nimport numpy\nfrom PIL import Image\n\nwriter = SummaryWriter(\"logs\")\n\npath = \"../dataset/train/bees/16838648_415acd9e3f.jpg\"\nimg_PIL = Image.open(path)\nimg_array = numpy.array(img_PIL)\nwriter.add_image(\"test\", img_array, 1, dataformats=\"HWC\")\nfor i in range(-10, 10):\n    writer.add_scalar(\"y=sin(x)\", math.sin(i), i)\n\nwriter.close()\n```\n\n```bash\ntensorboard --logdir=logs --port=6006\n#tensorboard\n```\n\n## Transform\n\ntorchvisiontransform.py\n\n`__init__``__call__`\n\n```python\nMyTensor = transforms.ToTensor()\ntensor_img = MyTensor(img)  # Tensor\n\ntrans_nor = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\nnormal_img = trans_nor(tensor_img)\n\nsize = transforms.Resize((512, 512))\nimg_size = size(img)\n\nsize_2 = transforms.Resize(512)\ntrans_compose = transforms.Compose([size_2, MyTensor])\nimg_size_2 = trans_compose(img) #\n```\n\n## TorchVision\n\n```python\ntensor_transform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor()\n])\ntrain = torchvision.datasets.CIFAR10(\"mydata\", True, transform=tensor_transform, download=True)\ntest = torchvision.datasets.CIFAR10(\"mydata\", False, transform=tensor_transform, download=True)\n#true or false\n#(img, label)\n```\n\n## \n\n```python\nclass Kaz(nn.Module):\n    def __init__(self):\n        super(Kaz, self).__init__()\n        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)\n\n    def forward(self, x):\n        return self.conv1(x)\n```\n\n## \n\n- ****\n- ****\n- ****\n\nF.conv2dinputkernelstride\n\nConv2din_channelout_channel\n\n## \n\n- ****\n- ****\n- ****\n\n\n\nstride1kernel_size\n\npytorch\n\n## \n\ninplaceinput\n\nnn.Sequential()\n\n## \n\n```python\nx = torch.tensor([0.1, 0.2, 0.3])\ny = torch.tensor([1])\n\nx = torch.reshape(x, (1, 3))\nloss3 = nn.CrossEntropyLoss()\n\nresult = loss3(x, y)\n```\n\n```python\nloss = nn.CrossEntropyLoss()\nfor data in dataloader:\n    imgs, targets = data\n    output = huoyu(imgs)\n    result = loss(output, targets)\n    print(result)\n    result.backward() #\n```\n\n## \n\n```python\nhuoyu = Kaz()\nloss = nn.CrossEntropyLoss()\noptim = torch.optim.SGD(huoyu.parameters(), lr=0.01)\nfor i in range(20):\n    total_loss = 0.0\n    for data in dataloader:\n        imgs, targets = data\n        output = huoyu(imgs)\n        result = loss(output, targets)\n        optim.zero_grad() # \n        result.backward() # \n        optim.step()  # \n        total_loss += result\n    print(\"{0}:{1}\".format(i, total_loss))\n```\n\n## \n\n```python\nvgg16 = torchvision.models.vgg16(pretrained=True)\nvgg16.add_module('add_linear', nn.Linear(1000, 10))\nvgg16.classifier.add_module('7', nn.Linear(1000, 10)) #classifiervgg\nvgg16.classifier[6] = nn.Linear(4096, 10)\n```\n\n## \n\n```python\nvgg16 = torchvision.models.vgg16()\n# 1+\ntorch.save(vgg16, 'vgg16.pth')\nget_vgg16 = torch.load('vgg16.pth')\nprint(get_vgg16)\n\n# 2\ntorch.save(vgg16.state_dict(), 'vgg16_2.pth')\nget_vgg16_2 = torch.load('vgg16_2.pth')\nprint(get_vgg16_2)  # \nv = torchvision.models.vgg16()\nv.load_state_dict(get_vgg16_2)\nprint(v)\n```\n\n## \n\n```python\nprint(len(train_data))\nprint(len(test_data))\ntrain_loader = DataLoader(train_data, batch_size=64)\ntest_loader = DataLoader(test_data, batch_size=64)\n\n# \nhuoyu = Kaz()\n# \nloss_function = nn.CrossEntropyLoss()\n# \nlearning_rate = 0.01\noptim = torch.optim.SGD(huoyu.parameters(), lr=learning_rate)\n\n# \ntrain_step = 0\ntest_step = 0\nepoch = 10\nsw = SummaryWriter(\"logs\")\n\nfor i in range(epoch):\n    print(\"----------{0}----------\".format(i+1))\n    huoyu.train() # DropoutBatchNorm\n    for data in train_loader:\n        imgs, targets = data\n        outputs = huoyu(imgs)\n        loss = loss_function(outputs, targets)\n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n        train_step += 1\n        if train_step % 100 == 0 :\n            print(\"{0}loss:{1}\".format(train_step, loss.item()))\n            sw.add_scalar(\"train_loss\", loss.item(), train_step)\n    # \n    huoyu.eval() # DropoutBatchNorm\n    total_loss = 0\n    total_accuracy = 0\n    with torch.no_grad():\n        for data in test_loader:\n            imgs, targets = data\n            outputs = huoyu(imgs)\n            loss = loss_function(outputs, targets)\n            total_loss += loss.item()\n            accuracy = (outputs.argmax(1) == targets).sum() # argmax(1)\n            # output[64, 10] argmax(1)[64,1],target[64, 1]Boolsum\n            total_accuracy += accuracy\n    print(\":{0}\".format(total_loss))\n    sw.add_scalar(\"test_loss\", total_loss, test_step)\n    print(\":{0}\".format(total_accuracy/len(test_data)))\n    sw.add_scalar(\"test_accuracy\",total_accuracy/len(test_data), test_step)\n    test_step += 1\n\nsw.close()\n```\n\n## GPU\n\n1. .cuda()N \n\n```python\nloss_function = nn.CrossEntropyLoss()\nif torch.cuda.is_available():\n    loss_function = loss_function.cuda()\n```\n\n2. device\n\n```python\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nloss_function = nn.CrossEntropyLoss()\nloss_function = loss_function.to(device)\n```\n\n##  \n\n```python\npath = \"../pic/dog.png\"\nimage = Image.open(path)\nimage = image.convert(\"RGB\")\n\ntransform = torchvision.transforms.Compose(\n    [torchvision.transforms.Resize((32, 32)),\n     torchvision.transforms.ToTensor()])\n\nimage = transform(image)\n\nmodel = torch.load(\"model21.pth\", map_location=torch.device(\"cpu\")) #gpucpumap_location\n# print(model)\nimage = torch.reshape(image, (1, 3, 32, 32))\nmodel.eval()\nwith torch.no_grad():\n    output = model(image)\nprint(output.argmax(1))\n```\n\n","source":"_posts/tudui-pytorch.md","raw":"---\ntitle: \nmathjax: true\ndate: 2025/7/1 20:46:25\nimg: https://i0.hdslb.com/bfs/archive/6bed0eae871f7232429009ad607d9b230cec6cc1.png\nexcerpt: \n---\n## \n\nanaconda\n\ncudapytorch\n\n```python\ntorch.cuda.is_available()\n```\n\n## \n\n### Dataset\n\ndatasettorch.util.DataSet\n\n```python\nclass MyData(Dataset):\n\n    def __init__(self, root_dir, label_dir):\n        self.root_dir = root_dir\n        self.label_dir = label_dir\n        self.path = os.path.join(root_dir, label_dir)\n        self.my_list = os.listdir(self.path)\n\n    def get_item(self, idx):\n        img_name = self.my_list[idx]\n        img_path = os.path.join(self.path, img_name)\n        img = Image.open(img_path)\n        img.show()\n\n    def get_length(self):\n        return len(self.my_list)\n```\n\n### DataLoader\n\n```python\ntest_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=False)\n# dataset \n# batch_size \n# shuffle \n# num_workers  0\n# drop_last batch_size\nfor data in test_loader:\n    imgs, targets = data\n    print(imgs)\n    print(targets)\n```\n\n## TensorBoard\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nimport math\nimport numpy\nfrom PIL import Image\n\nwriter = SummaryWriter(\"logs\")\n\npath = \"../dataset/train/bees/16838648_415acd9e3f.jpg\"\nimg_PIL = Image.open(path)\nimg_array = numpy.array(img_PIL)\nwriter.add_image(\"test\", img_array, 1, dataformats=\"HWC\")\nfor i in range(-10, 10):\n    writer.add_scalar(\"y=sin(x)\", math.sin(i), i)\n\nwriter.close()\n```\n\n```bash\ntensorboard --logdir=logs --port=6006\n#tensorboard\n```\n\n## Transform\n\ntorchvisiontransform.py\n\n`__init__``__call__`\n\n```python\nMyTensor = transforms.ToTensor()\ntensor_img = MyTensor(img)  # Tensor\n\ntrans_nor = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\nnormal_img = trans_nor(tensor_img)\n\nsize = transforms.Resize((512, 512))\nimg_size = size(img)\n\nsize_2 = transforms.Resize(512)\ntrans_compose = transforms.Compose([size_2, MyTensor])\nimg_size_2 = trans_compose(img) #\n```\n\n## TorchVision\n\n```python\ntensor_transform = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor()\n])\ntrain = torchvision.datasets.CIFAR10(\"mydata\", True, transform=tensor_transform, download=True)\ntest = torchvision.datasets.CIFAR10(\"mydata\", False, transform=tensor_transform, download=True)\n#true or false\n#(img, label)\n```\n\n## \n\n```python\nclass Kaz(nn.Module):\n    def __init__(self):\n        super(Kaz, self).__init__()\n        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)\n\n    def forward(self, x):\n        return self.conv1(x)\n```\n\n## \n\n- ****\n- ****\n- ****\n\nF.conv2dinputkernelstride\n\nConv2din_channelout_channel\n\n## \n\n- ****\n- ****\n- ****\n\n\n\nstride1kernel_size\n\npytorch\n\n## \n\ninplaceinput\n\nnn.Sequential()\n\n## \n\n```python\nx = torch.tensor([0.1, 0.2, 0.3])\ny = torch.tensor([1])\n\nx = torch.reshape(x, (1, 3))\nloss3 = nn.CrossEntropyLoss()\n\nresult = loss3(x, y)\n```\n\n```python\nloss = nn.CrossEntropyLoss()\nfor data in dataloader:\n    imgs, targets = data\n    output = huoyu(imgs)\n    result = loss(output, targets)\n    print(result)\n    result.backward() #\n```\n\n## \n\n```python\nhuoyu = Kaz()\nloss = nn.CrossEntropyLoss()\noptim = torch.optim.SGD(huoyu.parameters(), lr=0.01)\nfor i in range(20):\n    total_loss = 0.0\n    for data in dataloader:\n        imgs, targets = data\n        output = huoyu(imgs)\n        result = loss(output, targets)\n        optim.zero_grad() # \n        result.backward() # \n        optim.step()  # \n        total_loss += result\n    print(\"{0}:{1}\".format(i, total_loss))\n```\n\n## \n\n```python\nvgg16 = torchvision.models.vgg16(pretrained=True)\nvgg16.add_module('add_linear', nn.Linear(1000, 10))\nvgg16.classifier.add_module('7', nn.Linear(1000, 10)) #classifiervgg\nvgg16.classifier[6] = nn.Linear(4096, 10)\n```\n\n## \n\n```python\nvgg16 = torchvision.models.vgg16()\n# 1+\ntorch.save(vgg16, 'vgg16.pth')\nget_vgg16 = torch.load('vgg16.pth')\nprint(get_vgg16)\n\n# 2\ntorch.save(vgg16.state_dict(), 'vgg16_2.pth')\nget_vgg16_2 = torch.load('vgg16_2.pth')\nprint(get_vgg16_2)  # \nv = torchvision.models.vgg16()\nv.load_state_dict(get_vgg16_2)\nprint(v)\n```\n\n## \n\n```python\nprint(len(train_data))\nprint(len(test_data))\ntrain_loader = DataLoader(train_data, batch_size=64)\ntest_loader = DataLoader(test_data, batch_size=64)\n\n# \nhuoyu = Kaz()\n# \nloss_function = nn.CrossEntropyLoss()\n# \nlearning_rate = 0.01\noptim = torch.optim.SGD(huoyu.parameters(), lr=learning_rate)\n\n# \ntrain_step = 0\ntest_step = 0\nepoch = 10\nsw = SummaryWriter(\"logs\")\n\nfor i in range(epoch):\n    print(\"----------{0}----------\".format(i+1))\n    huoyu.train() # DropoutBatchNorm\n    for data in train_loader:\n        imgs, targets = data\n        outputs = huoyu(imgs)\n        loss = loss_function(outputs, targets)\n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n        train_step += 1\n        if train_step % 100 == 0 :\n            print(\"{0}loss:{1}\".format(train_step, loss.item()))\n            sw.add_scalar(\"train_loss\", loss.item(), train_step)\n    # \n    huoyu.eval() # DropoutBatchNorm\n    total_loss = 0\n    total_accuracy = 0\n    with torch.no_grad():\n        for data in test_loader:\n            imgs, targets = data\n            outputs = huoyu(imgs)\n            loss = loss_function(outputs, targets)\n            total_loss += loss.item()\n            accuracy = (outputs.argmax(1) == targets).sum() # argmax(1)\n            # output[64, 10] argmax(1)[64,1],target[64, 1]Boolsum\n            total_accuracy += accuracy\n    print(\":{0}\".format(total_loss))\n    sw.add_scalar(\"test_loss\", total_loss, test_step)\n    print(\":{0}\".format(total_accuracy/len(test_data)))\n    sw.add_scalar(\"test_accuracy\",total_accuracy/len(test_data), test_step)\n    test_step += 1\n\nsw.close()\n```\n\n## GPU\n\n1. .cuda()N \n\n```python\nloss_function = nn.CrossEntropyLoss()\nif torch.cuda.is_available():\n    loss_function = loss_function.cuda()\n```\n\n2. device\n\n```python\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nloss_function = nn.CrossEntropyLoss()\nloss_function = loss_function.to(device)\n```\n\n##  \n\n```python\npath = \"../pic/dog.png\"\nimage = Image.open(path)\nimage = image.convert(\"RGB\")\n\ntransform = torchvision.transforms.Compose(\n    [torchvision.transforms.Resize((32, 32)),\n     torchvision.transforms.ToTensor()])\n\nimage = transform(image)\n\nmodel = torch.load(\"model21.pth\", map_location=torch.device(\"cpu\")) #gpucpumap_location\n# print(model)\nimage = torch.reshape(image, (1, 3, 32, 32))\nmodel.eval()\nwith torch.no_grad():\n    output = model(image)\nprint(output.argmax(1))\n```\n\n","slug":"tudui-pytorch","published":1,"updated":"2025-11-01T05:17:07.881Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff9000mss999xea583s","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>anaconda</p>\n<p>cudapytorch</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.cuda.is_available()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h3><p>datasettorch.util.DataSet</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MyData</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, root_dir, label_dir</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.root_dir = root_dir</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.label_dir = label_dir</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.path = os.path.join(root_dir, label_dir)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.my_list = os.listdir(<span class=\"variable language_\">self</span>.path)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_item</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        img_name = <span class=\"variable language_\">self</span>.my_list[idx]</span><br><span class=\"line\">        img_path = os.path.join(<span class=\"variable language_\">self</span>.path, img_name)</span><br><span class=\"line\">        img = Image.<span class=\"built_in\">open</span>(img_path)</span><br><span class=\"line\">        img.show()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_length</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.my_list)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"DataLoader\"><a href=\"#DataLoader\" class=\"headerlink\" title=\"DataLoader\"></a>DataLoader</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_loader = DataLoader(dataset=test_dataset, batch_size=<span class=\"number\">64</span>, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>, drop_last=<span class=\"literal\">False</span>)</span><br><span class=\"line\"><span class=\"comment\"># dataset </span></span><br><span class=\"line\"><span class=\"comment\"># batch_size </span></span><br><span class=\"line\"><span class=\"comment\"># shuffle </span></span><br><span class=\"line\"><span class=\"comment\"># num_workers  0</span></span><br><span class=\"line\"><span class=\"comment\"># drop_last batch_size</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> test_loader:</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(imgs)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(targets)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"TensorBoard\"><a href=\"#TensorBoard\" class=\"headerlink\" title=\"TensorBoard\"></a>TensorBoard</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&quot;logs&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">path = <span class=\"string\">&quot;../dataset/train/bees/16838648_415acd9e3f.jpg&quot;</span></span><br><span class=\"line\">img_PIL = Image.<span class=\"built_in\">open</span>(path)</span><br><span class=\"line\">img_array = numpy.array(img_PIL)</span><br><span class=\"line\">writer.add_image(<span class=\"string\">&quot;test&quot;</span>, img_array, <span class=\"number\">1</span>, dataformats=<span class=\"string\">&quot;HWC&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(-<span class=\"number\">10</span>, <span class=\"number\">10</span>):</span><br><span class=\"line\">    writer.add_scalar(<span class=\"string\">&quot;y=sin(x)&quot;</span>, math.sin(i), i)</span><br><span class=\"line\"></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensorboard --logdir=logs --port=6006</span><br><span class=\"line\"><span class=\"comment\">#tensorboard</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Transform\"><a href=\"#Transform\" class=\"headerlink\" title=\"Transform\"></a>Transform</h2><p>torchvisiontransform.py</p>\n<p><code>__init__</code><code>__call__</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MyTensor = transforms.ToTensor()</span><br><span class=\"line\">tensor_img = MyTensor(img)  <span class=\"comment\"># Tensor</span></span><br><span class=\"line\"></span><br><span class=\"line\">trans_nor = transforms.Normalize([<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>], [<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>])</span><br><span class=\"line\">normal_img = trans_nor(tensor_img)</span><br><span class=\"line\"></span><br><span class=\"line\">size = transforms.Resize((<span class=\"number\">512</span>, <span class=\"number\">512</span>))</span><br><span class=\"line\">img_size = size(img)</span><br><span class=\"line\"></span><br><span class=\"line\">size_2 = transforms.Resize(<span class=\"number\">512</span>)</span><br><span class=\"line\">trans_compose = transforms.Compose([size_2, MyTensor])</span><br><span class=\"line\">img_size_2 = trans_compose(img) <span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"TorchVision\"><a href=\"#TorchVision\" class=\"headerlink\" title=\"TorchVision\"></a>TorchVision</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor_transform = torchvision.transforms.Compose([</span><br><span class=\"line\">    torchvision.transforms.ToTensor()</span><br><span class=\"line\">])</span><br><span class=\"line\">train = torchvision.datasets.CIFAR10(<span class=\"string\">&quot;mydata&quot;</span>, <span class=\"literal\">True</span>, transform=tensor_transform, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">test = torchvision.datasets.CIFAR10(<span class=\"string\">&quot;mydata&quot;</span>, <span class=\"literal\">False</span>, transform=tensor_transform, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\">#true or false</span></span><br><span class=\"line\"><span class=\"comment\">#(img, label)</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Kaz</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Kaz, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv1 = Conv2d(in_channels=<span class=\"number\">3</span>, out_channels=<span class=\"number\">6</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.conv1(x)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><strong></strong></li>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ul>\n<p>F.conv2dinputkernelstride</p>\n<p>Conv2din_channelout_channel</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><strong></strong></li>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ul>\n<p></p>\n<p>stride1kernel_size</p>\n<p>pytorch</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>inplaceinput</p>\n<p>nn.Sequential()</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.tensor([<span class=\"number\">0.1</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.3</span>])</span><br><span class=\"line\">y = torch.tensor([<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.reshape(x, (<span class=\"number\">1</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\">loss3 = nn.CrossEntropyLoss()</span><br><span class=\"line\"></span><br><span class=\"line\">result = loss3(x, y)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss = nn.CrossEntropyLoss()</span><br><span class=\"line\"><span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> dataloader:</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    output = huoyu(imgs)</span><br><span class=\"line\">    result = loss(output, targets)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(result)</span><br><span class=\"line\">    result.backward() <span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">huoyu = Kaz()</span><br><span class=\"line\">loss = nn.CrossEntropyLoss()</span><br><span class=\"line\">optim = torch.optim.SGD(huoyu.parameters(), lr=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">20</span>):</span><br><span class=\"line\">    total_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> dataloader:</span><br><span class=\"line\">        imgs, targets = data</span><br><span class=\"line\">        output = huoyu(imgs)</span><br><span class=\"line\">        result = loss(output, targets)</span><br><span class=\"line\">        optim.zero_grad() <span class=\"comment\"># </span></span><br><span class=\"line\">        result.backward() <span class=\"comment\"># </span></span><br><span class=\"line\">        optim.step()  <span class=\"comment\"># </span></span><br><span class=\"line\">        total_loss += result</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;&#123;0&#125;:&#123;1&#125;&quot;</span>.<span class=\"built_in\">format</span>(i, total_loss))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vgg16 = torchvision.models.vgg16(pretrained=<span class=\"literal\">True</span>)</span><br><span class=\"line\">vgg16.add_module(<span class=\"string\">&#x27;add_linear&#x27;</span>, nn.Linear(<span class=\"number\">1000</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">vgg16.classifier.add_module(<span class=\"string\">&#x27;7&#x27;</span>, nn.Linear(<span class=\"number\">1000</span>, <span class=\"number\">10</span>)) <span class=\"comment\">#classifiervgg</span></span><br><span class=\"line\">vgg16.classifier[<span class=\"number\">6</span>] = nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vgg16 = torchvision.models.vgg16()</span><br><span class=\"line\"><span class=\"comment\"># 1+</span></span><br><span class=\"line\">torch.save(vgg16, <span class=\"string\">&#x27;vgg16.pth&#x27;</span>)</span><br><span class=\"line\">get_vgg16 = torch.load(<span class=\"string\">&#x27;vgg16.pth&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(get_vgg16)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2</span></span><br><span class=\"line\">torch.save(vgg16.state_dict(), <span class=\"string\">&#x27;vgg16_2.pth&#x27;</span>)</span><br><span class=\"line\">get_vgg16_2 = torch.load(<span class=\"string\">&#x27;vgg16_2.pth&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(get_vgg16_2)  <span class=\"comment\"># </span></span><br><span class=\"line\">v = torchvision.models.vgg16()</span><br><span class=\"line\">v.load_state_dict(get_vgg16_2)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(v)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(train_data))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(test_data))</span><br><span class=\"line\">train_loader = DataLoader(train_data, batch_size=<span class=\"number\">64</span>)</span><br><span class=\"line\">test_loader = DataLoader(test_data, batch_size=<span class=\"number\">64</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">huoyu = Kaz()</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">learning_rate = <span class=\"number\">0.01</span></span><br><span class=\"line\">optim = torch.optim.SGD(huoyu.parameters(), lr=learning_rate)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">train_step = <span class=\"number\">0</span></span><br><span class=\"line\">test_step = <span class=\"number\">0</span></span><br><span class=\"line\">epoch = <span class=\"number\">10</span></span><br><span class=\"line\">sw = SummaryWriter(<span class=\"string\">&quot;logs&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(epoch):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;----------&#123;0&#125;----------&quot;</span>.<span class=\"built_in\">format</span>(i+<span class=\"number\">1</span>))</span><br><span class=\"line\">    huoyu.train() <span class=\"comment\"># DropoutBatchNorm</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> train_loader:</span><br><span class=\"line\">        imgs, targets = data</span><br><span class=\"line\">        outputs = huoyu(imgs)</span><br><span class=\"line\">        loss = loss_function(outputs, targets)</span><br><span class=\"line\">        optim.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optim.step()</span><br><span class=\"line\">        train_step += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> train_step % <span class=\"number\">100</span> == <span class=\"number\">0</span> :</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&quot;&#123;0&#125;loss:&#123;1&#125;&quot;</span>.<span class=\"built_in\">format</span>(train_step, loss.item()))</span><br><span class=\"line\">            sw.add_scalar(<span class=\"string\">&quot;train_loss&quot;</span>, loss.item(), train_step)</span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    huoyu.<span class=\"built_in\">eval</span>() <span class=\"comment\"># DropoutBatchNorm</span></span><br><span class=\"line\">    total_loss = <span class=\"number\">0</span></span><br><span class=\"line\">    total_accuracy = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> test_loader:</span><br><span class=\"line\">            imgs, targets = data</span><br><span class=\"line\">            outputs = huoyu(imgs)</span><br><span class=\"line\">            loss = loss_function(outputs, targets)</span><br><span class=\"line\">            total_loss += loss.item()</span><br><span class=\"line\">            accuracy = (outputs.argmax(<span class=\"number\">1</span>) == targets).<span class=\"built_in\">sum</span>() <span class=\"comment\"># argmax(1)</span></span><br><span class=\"line\">            <span class=\"comment\"># output[64, 10] argmax(1)[64,1],target[64, 1]Boolsum</span></span><br><span class=\"line\">            total_accuracy += accuracy</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;:&#123;0&#125;&quot;</span>.<span class=\"built_in\">format</span>(total_loss))</span><br><span class=\"line\">    sw.add_scalar(<span class=\"string\">&quot;test_loss&quot;</span>, total_loss, test_step)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;:&#123;0&#125;&quot;</span>.<span class=\"built_in\">format</span>(total_accuracy/<span class=\"built_in\">len</span>(test_data)))</span><br><span class=\"line\">    sw.add_scalar(<span class=\"string\">&quot;test_accuracy&quot;</span>,total_accuracy/<span class=\"built_in\">len</span>(test_data), test_step)</span><br><span class=\"line\">    test_step += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">sw.close()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h2><ol>\n<li>.cuda()N</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\"><span class=\"keyword\">if</span> torch.cuda.is_available():</span><br><span class=\"line\">    loss_function = loss_function.cuda()</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>device</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">&quot;cuda:0&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">loss_function = loss_function.to(device)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">path = <span class=\"string\">&quot;../pic/dog.png&quot;</span></span><br><span class=\"line\">image = Image.<span class=\"built_in\">open</span>(path)</span><br><span class=\"line\">image = image.convert(<span class=\"string\">&quot;RGB&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">transform = torchvision.transforms.Compose(</span><br><span class=\"line\">    [torchvision.transforms.Resize((<span class=\"number\">32</span>, <span class=\"number\">32</span>)),</span><br><span class=\"line\">     torchvision.transforms.ToTensor()])</span><br><span class=\"line\"></span><br><span class=\"line\">image = transform(image)</span><br><span class=\"line\"></span><br><span class=\"line\">model = torch.load(<span class=\"string\">&quot;model21.pth&quot;</span>, map_location=torch.device(<span class=\"string\">&quot;cpu&quot;</span>)) <span class=\"comment\">#gpucpumap_location</span></span><br><span class=\"line\"><span class=\"comment\"># print(model)</span></span><br><span class=\"line\">image = torch.reshape(image, (<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>))</span><br><span class=\"line\">model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    output = model(image)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output.argmax(<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n\n","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>anaconda</p>\n<p>cudapytorch</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.cuda.is_available()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h3 id=\"Dataset\"><a href=\"#Dataset\" class=\"headerlink\" title=\"Dataset\"></a>Dataset</h3><p>datasettorch.util.DataSet</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">MyData</span>(<span class=\"title class_ inherited__\">Dataset</span>):</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, root_dir, label_dir</span>):</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.root_dir = root_dir</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.label_dir = label_dir</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.path = os.path.join(root_dir, label_dir)</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.my_list = os.listdir(<span class=\"variable language_\">self</span>.path)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_item</span>(<span class=\"params\">self, idx</span>):</span><br><span class=\"line\">        img_name = <span class=\"variable language_\">self</span>.my_list[idx]</span><br><span class=\"line\">        img_path = os.path.join(<span class=\"variable language_\">self</span>.path, img_name)</span><br><span class=\"line\">        img = Image.<span class=\"built_in\">open</span>(img_path)</span><br><span class=\"line\">        img.show()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">get_length</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">len</span>(<span class=\"variable language_\">self</span>.my_list)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"DataLoader\"><a href=\"#DataLoader\" class=\"headerlink\" title=\"DataLoader\"></a>DataLoader</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_loader = DataLoader(dataset=test_dataset, batch_size=<span class=\"number\">64</span>, shuffle=<span class=\"literal\">True</span>, num_workers=<span class=\"number\">0</span>, drop_last=<span class=\"literal\">False</span>)</span><br><span class=\"line\"><span class=\"comment\"># dataset </span></span><br><span class=\"line\"><span class=\"comment\"># batch_size </span></span><br><span class=\"line\"><span class=\"comment\"># shuffle </span></span><br><span class=\"line\"><span class=\"comment\"># num_workers  0</span></span><br><span class=\"line\"><span class=\"comment\"># drop_last batch_size</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> test_loader:</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(imgs)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(targets)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"TensorBoard\"><a href=\"#TensorBoard\" class=\"headerlink\" title=\"TensorBoard\"></a>TensorBoard</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torch.utils.tensorboard <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy</span><br><span class=\"line\"><span class=\"keyword\">from</span> PIL <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"></span><br><span class=\"line\">writer = SummaryWriter(<span class=\"string\">&quot;logs&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">path = <span class=\"string\">&quot;../dataset/train/bees/16838648_415acd9e3f.jpg&quot;</span></span><br><span class=\"line\">img_PIL = Image.<span class=\"built_in\">open</span>(path)</span><br><span class=\"line\">img_array = numpy.array(img_PIL)</span><br><span class=\"line\">writer.add_image(<span class=\"string\">&quot;test&quot;</span>, img_array, <span class=\"number\">1</span>, dataformats=<span class=\"string\">&quot;HWC&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(-<span class=\"number\">10</span>, <span class=\"number\">10</span>):</span><br><span class=\"line\">    writer.add_scalar(<span class=\"string\">&quot;y=sin(x)&quot;</span>, math.sin(i), i)</span><br><span class=\"line\"></span><br><span class=\"line\">writer.close()</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensorboard --logdir=logs --port=6006</span><br><span class=\"line\"><span class=\"comment\">#tensorboard</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Transform\"><a href=\"#Transform\" class=\"headerlink\" title=\"Transform\"></a>Transform</h2><p>torchvisiontransform.py</p>\n<p><code>__init__</code><code>__call__</code></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MyTensor = transforms.ToTensor()</span><br><span class=\"line\">tensor_img = MyTensor(img)  <span class=\"comment\"># Tensor</span></span><br><span class=\"line\"></span><br><span class=\"line\">trans_nor = transforms.Normalize([<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>], [<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>])</span><br><span class=\"line\">normal_img = trans_nor(tensor_img)</span><br><span class=\"line\"></span><br><span class=\"line\">size = transforms.Resize((<span class=\"number\">512</span>, <span class=\"number\">512</span>))</span><br><span class=\"line\">img_size = size(img)</span><br><span class=\"line\"></span><br><span class=\"line\">size_2 = transforms.Resize(<span class=\"number\">512</span>)</span><br><span class=\"line\">trans_compose = transforms.Compose([size_2, MyTensor])</span><br><span class=\"line\">img_size_2 = trans_compose(img) <span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"TorchVision\"><a href=\"#TorchVision\" class=\"headerlink\" title=\"TorchVision\"></a>TorchVision</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor_transform = torchvision.transforms.Compose([</span><br><span class=\"line\">    torchvision.transforms.ToTensor()</span><br><span class=\"line\">])</span><br><span class=\"line\">train = torchvision.datasets.CIFAR10(<span class=\"string\">&quot;mydata&quot;</span>, <span class=\"literal\">True</span>, transform=tensor_transform, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\">test = torchvision.datasets.CIFAR10(<span class=\"string\">&quot;mydata&quot;</span>, <span class=\"literal\">False</span>, transform=tensor_transform, download=<span class=\"literal\">True</span>)</span><br><span class=\"line\"><span class=\"comment\">#true or false</span></span><br><span class=\"line\"><span class=\"comment\">#(img, label)</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">Kaz</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>(Kaz, <span class=\"variable language_\">self</span>).__init__()</span><br><span class=\"line\">        <span class=\"variable language_\">self</span>.conv1 = Conv2d(in_channels=<span class=\"number\">3</span>, out_channels=<span class=\"number\">6</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, x</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"variable language_\">self</span>.conv1(x)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><strong></strong></li>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ul>\n<p>F.conv2dinputkernelstride</p>\n<p>Conv2din_channelout_channel</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><strong></strong></li>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ul>\n<p></p>\n<p>stride1kernel_size</p>\n<p>pytorch</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>inplaceinput</p>\n<p>nn.Sequential()</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.tensor([<span class=\"number\">0.1</span>, <span class=\"number\">0.2</span>, <span class=\"number\">0.3</span>])</span><br><span class=\"line\">y = torch.tensor([<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.reshape(x, (<span class=\"number\">1</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\">loss3 = nn.CrossEntropyLoss()</span><br><span class=\"line\"></span><br><span class=\"line\">result = loss3(x, y)</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss = nn.CrossEntropyLoss()</span><br><span class=\"line\"><span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> dataloader:</span><br><span class=\"line\">    imgs, targets = data</span><br><span class=\"line\">    output = huoyu(imgs)</span><br><span class=\"line\">    result = loss(output, targets)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(result)</span><br><span class=\"line\">    result.backward() <span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">huoyu = Kaz()</span><br><span class=\"line\">loss = nn.CrossEntropyLoss()</span><br><span class=\"line\">optim = torch.optim.SGD(huoyu.parameters(), lr=<span class=\"number\">0.01</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">20</span>):</span><br><span class=\"line\">    total_loss = <span class=\"number\">0.0</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> dataloader:</span><br><span class=\"line\">        imgs, targets = data</span><br><span class=\"line\">        output = huoyu(imgs)</span><br><span class=\"line\">        result = loss(output, targets)</span><br><span class=\"line\">        optim.zero_grad() <span class=\"comment\"># </span></span><br><span class=\"line\">        result.backward() <span class=\"comment\"># </span></span><br><span class=\"line\">        optim.step()  <span class=\"comment\"># </span></span><br><span class=\"line\">        total_loss += result</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;&#123;0&#125;:&#123;1&#125;&quot;</span>.<span class=\"built_in\">format</span>(i, total_loss))</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vgg16 = torchvision.models.vgg16(pretrained=<span class=\"literal\">True</span>)</span><br><span class=\"line\">vgg16.add_module(<span class=\"string\">&#x27;add_linear&#x27;</span>, nn.Linear(<span class=\"number\">1000</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">vgg16.classifier.add_module(<span class=\"string\">&#x27;7&#x27;</span>, nn.Linear(<span class=\"number\">1000</span>, <span class=\"number\">10</span>)) <span class=\"comment\">#classifiervgg</span></span><br><span class=\"line\">vgg16.classifier[<span class=\"number\">6</span>] = nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">10</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vgg16 = torchvision.models.vgg16()</span><br><span class=\"line\"><span class=\"comment\"># 1+</span></span><br><span class=\"line\">torch.save(vgg16, <span class=\"string\">&#x27;vgg16.pth&#x27;</span>)</span><br><span class=\"line\">get_vgg16 = torch.load(<span class=\"string\">&#x27;vgg16.pth&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(get_vgg16)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 2</span></span><br><span class=\"line\">torch.save(vgg16.state_dict(), <span class=\"string\">&#x27;vgg16_2.pth&#x27;</span>)</span><br><span class=\"line\">get_vgg16_2 = torch.load(<span class=\"string\">&#x27;vgg16_2.pth&#x27;</span>)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(get_vgg16_2)  <span class=\"comment\"># </span></span><br><span class=\"line\">v = torchvision.models.vgg16()</span><br><span class=\"line\">v.load_state_dict(get_vgg16_2)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(v)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(train_data))</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"built_in\">len</span>(test_data))</span><br><span class=\"line\">train_loader = DataLoader(train_data, batch_size=<span class=\"number\">64</span>)</span><br><span class=\"line\">test_loader = DataLoader(test_data, batch_size=<span class=\"number\">64</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">huoyu = Kaz()</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">learning_rate = <span class=\"number\">0.01</span></span><br><span class=\"line\">optim = torch.optim.SGD(huoyu.parameters(), lr=learning_rate)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">train_step = <span class=\"number\">0</span></span><br><span class=\"line\">test_step = <span class=\"number\">0</span></span><br><span class=\"line\">epoch = <span class=\"number\">10</span></span><br><span class=\"line\">sw = SummaryWriter(<span class=\"string\">&quot;logs&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(epoch):</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;----------&#123;0&#125;----------&quot;</span>.<span class=\"built_in\">format</span>(i+<span class=\"number\">1</span>))</span><br><span class=\"line\">    huoyu.train() <span class=\"comment\"># DropoutBatchNorm</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> train_loader:</span><br><span class=\"line\">        imgs, targets = data</span><br><span class=\"line\">        outputs = huoyu(imgs)</span><br><span class=\"line\">        loss = loss_function(outputs, targets)</span><br><span class=\"line\">        optim.zero_grad()</span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optim.step()</span><br><span class=\"line\">        train_step += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> train_step % <span class=\"number\">100</span> == <span class=\"number\">0</span> :</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&quot;&#123;0&#125;loss:&#123;1&#125;&quot;</span>.<span class=\"built_in\">format</span>(train_step, loss.item()))</span><br><span class=\"line\">            sw.add_scalar(<span class=\"string\">&quot;train_loss&quot;</span>, loss.item(), train_step)</span><br><span class=\"line\">    <span class=\"comment\"># </span></span><br><span class=\"line\">    huoyu.<span class=\"built_in\">eval</span>() <span class=\"comment\"># DropoutBatchNorm</span></span><br><span class=\"line\">    total_loss = <span class=\"number\">0</span></span><br><span class=\"line\">    total_accuracy = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> test_loader:</span><br><span class=\"line\">            imgs, targets = data</span><br><span class=\"line\">            outputs = huoyu(imgs)</span><br><span class=\"line\">            loss = loss_function(outputs, targets)</span><br><span class=\"line\">            total_loss += loss.item()</span><br><span class=\"line\">            accuracy = (outputs.argmax(<span class=\"number\">1</span>) == targets).<span class=\"built_in\">sum</span>() <span class=\"comment\"># argmax(1)</span></span><br><span class=\"line\">            <span class=\"comment\"># output[64, 10] argmax(1)[64,1],target[64, 1]Boolsum</span></span><br><span class=\"line\">            total_accuracy += accuracy</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;:&#123;0&#125;&quot;</span>.<span class=\"built_in\">format</span>(total_loss))</span><br><span class=\"line\">    sw.add_scalar(<span class=\"string\">&quot;test_loss&quot;</span>, total_loss, test_step)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;:&#123;0&#125;&quot;</span>.<span class=\"built_in\">format</span>(total_accuracy/<span class=\"built_in\">len</span>(test_data)))</span><br><span class=\"line\">    sw.add_scalar(<span class=\"string\">&quot;test_accuracy&quot;</span>,total_accuracy/<span class=\"built_in\">len</span>(test_data), test_step)</span><br><span class=\"line\">    test_step += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">sw.close()</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h2><ol>\n<li>.cuda()N</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\"><span class=\"keyword\">if</span> torch.cuda.is_available():</span><br><span class=\"line\">    loss_function = loss_function.cuda()</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li>device</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = torch.device(<span class=\"string\">&quot;cuda:0&quot;</span> <span class=\"keyword\">if</span> torch.cuda.is_available() <span class=\"keyword\">else</span> <span class=\"string\">&quot;cpu&quot;</span>)</span><br><span class=\"line\">loss_function = nn.CrossEntropyLoss()</span><br><span class=\"line\">loss_function = loss_function.to(device)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">path = <span class=\"string\">&quot;../pic/dog.png&quot;</span></span><br><span class=\"line\">image = Image.<span class=\"built_in\">open</span>(path)</span><br><span class=\"line\">image = image.convert(<span class=\"string\">&quot;RGB&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">transform = torchvision.transforms.Compose(</span><br><span class=\"line\">    [torchvision.transforms.Resize((<span class=\"number\">32</span>, <span class=\"number\">32</span>)),</span><br><span class=\"line\">     torchvision.transforms.ToTensor()])</span><br><span class=\"line\"></span><br><span class=\"line\">image = transform(image)</span><br><span class=\"line\"></span><br><span class=\"line\">model = torch.load(<span class=\"string\">&quot;model21.pth&quot;</span>, map_location=torch.device(<span class=\"string\">&quot;cpu&quot;</span>)) <span class=\"comment\">#gpucpumap_location</span></span><br><span class=\"line\"><span class=\"comment\"># print(model)</span></span><br><span class=\"line\">image = torch.reshape(image, (<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">32</span>, <span class=\"number\">32</span>))</span><br><span class=\"line\">model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\"><span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">    output = model(image)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(output.argmax(<span class=\"number\">1</span>))</span><br></pre></td></tr></table></figure>\n\n"},{"title":"VenusREM","mathjax":true,"date":"2025-10-23T12:46:25.000Z","img":"https://raw.githubusercontent.com/ai4protein/VenusREM/main/img/framework.png","excerpt":"","_content":"\n \n\n VENUSREMVENUSREM  ProteinGym  217  30  VHH  10  DNA  VENUSREM VENUSREM\n\nhttps://github.com/tyang816/VenusREM \n\nhttps://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bioinformatics/41/Supplement_1/10.1093_bioinformatics_btaf189/1/btaf189_supplementary_data.pdf?Expires=1763573535&Signature=RwBhhIoksIYTreWSThU1cwmKWxVWrfSI8UHWdHiTIap-ROAkAL4fzl1p8fzhzwWz64BRi7slEyDoxdyRxBYc0sQ2pD4NPB-HYlx3h0R3jSMt~b2vN0hugFD5HvCDqQHP0krEWviVi6OCJbJxM6zJS5LVKqr6fZfo9yOIxo23kWyO79ZaZMl9-r4~~r74PZ0zIADReEAjv~DqSJSTWwH3k1tRhHgjBWoYgEI~fYmPsSXUn5Gnm3zRnRN0K-AB0CXNvV32WONssRku82nmQUVIs7xd6cw1QNEG4KQkfsOuyGcgyZtzbDrOs2YqnM~n2Zir~LEZQzeuX4FIxESBn04Y7w__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA\n\n**benchmark**\n\n DMS  ProteinGymNotin 2024 \n\n\n\n****\n\n- \n\n  - Spearman\n\n  Spearman  **rho**\n\n  > \n\n  ****\n    X  Y $ R(X_i) $$ R(Y_i)$\n   \n\n  $d_i = R(X_i) - R(Y_i)$\n  \n\n  $\\rho = 1 - \\frac{6\\sum d_i^2}{n(n^2 - 1)}$\n\n  \n\n  - n\n  - $d_i$\n\n  $11$\n\n  - $=1$\n  - $=1$\n  - $=0$\n\n  |          | Spearman       | Pearson r      |\n  | -------------- | --------------- | -------------- |\n  |        | / |  |\n  |            |   |  |\n  |        |         |        |\n  |  |             |              |\n\n- \n  - VHH\n  - phi29DNAphi29 DNAP\n\n\n\n\n\n![Figure 1. Workflow of VENUSREM for predicting mutation effects. (a) For a given template protein, VENUSREM encodes structural, sequence, and MSA information to generate logits for each residue, which are used to calculate mutation fitness scores. (b) For each AA, its local structure is clustered into 2048 distinct structure tokens. (c) The vector representations of structural and sequence information are integrated using disentangled cross-attention through BERT-style pretraining. (d) Homologous information is retrieved via Jackhmmer and converted to a matrix representation of evolutionary logits.](./img/venusREM/p1.png)\n\nVENUSREM1a PLM  1b  c/1d AA \n\n|                  |                       |                 |                      |\n| ------------------------ | ----------------------------- | ----------------------- | ------------------------ |\n|  (Sequence)          |                 | Token embedding         |  RRR             |\n|  (Structure)         | AlphaFold/PDB             | GVP + K-means     |  SSS             |\n|  (Evolution/MSA) |  Jackhmmer  Foldseek  |  + logit  |  OevoO_{evo}Oevo |\n\n\n\n20+5token<pad>, <cls>, <eos>, <unk>, <mask>\n\n\n\n3dtoken\n\n- **10  40**\n-  = \n-  =  <10 \n-  =  $G_i$\n\n### \n\n- GVP \n-  C \n-  $\\pi_\\theta(G_i) \\in \\mathbb{R}^{256}$\n\nGVP \n\n> 3D\n\n### \n\n-  4,735,677 ****\n-  **K-means **\n-  **2048token**\n\ntoken0~2047\n\n$S \\in \\mathbb{R}^{L \\times 2048}$\n\n\n\n\n\nJackhmmer  **HMMER **\n\n>  (Hidden Markov Model, HMM) \n\n\n\n1. \n2.  profile HMM/\n3.  UniRef100 \n4.  (MSA) \n\n5HMM\n   `.a2m` alignment\n\n\n\n-  `.a2m` \n- gap `<pad>`\n-  $N\\times L$ $A$NL\n\n\n\n\n\n$C_{iv} = \\frac{\\sum_n I(A_{ni}=v)}{\\sum_v \\sum_n I(A_{ni}=v)}$\n\nVNLniv$I(A_{ni}=v)=1$\n\n\n\n$O^{evo}_{iv} = \\log \\frac{e^{C_{iv}}}{\\sum_v e^{C_{iv}}}$\n\n $O_{evo}$\n v \n\n|      |                               |  |                |\n| ------------ | --------------------------------- | -------- | ------------------ |\n| **** | One-hot + embedding               | L25     |  |\n| **** |   GVP  K-means      | L2048   | 3D     |\n| **** | Jackhmmer    | L25     |      |\n\n =0.8\n\n$O_{iv}^{out}=(1)O_{iv}^{native}+O_{iv}^{evo}$\n\n\n\n$F_x = \\sum_{t \\in T}(O_{i,v'}^{out} - O_{i,v}^{out})$\n\n\n\n- t\n- v\n- v\n\n\n\n**Result**\n\n![Spearmans  of mutation eect prediction (substitution) by zero-shot predictions on ProteinGym of dierent MSA depth and taxon.](./img/venusREM/p2.png)\n\n![Figure 2. A summary of baseline comparisons on the ProteinGym mutation effect prediction task. (a) Performance ranks across each assay. for instance, a Rank 1 for VENUSREM with a value of 49 indicates that VENUSREM achieves the highest performance on 49 out of 217 assays. (b) Performance of VENUSREMs ablation models with various homologous sequence search strategies and retrieval ratios, assessed on a 10% randomly split validation set.](./img/venusREM/p3.png)\n\n2aS3-S7VENUSREM310VENUSREM2b\n\n![Figure 3. Performance analysis on low-throughput experimental datasets. (a) Scatter plot of predicted fitness scores (by VENUSREM) versus experimentally obtained EC50 values. For both alkali resistance and binding affinity improvements, VENUSREMs scoring of 31 VHH antibody mutants by 14 sites shows a clear correlation with experimental data. (b) Performance of different models on the two assays of VHH antibody data. Only VENUSREM successfully generated fitness scores that are moderately negatively correlated with EC50 values. (c) 3D structure of the template phi29 DNAP. The AA sites targeted for mutation across the 10 single-site mutants are highlighted and labeled with their wild-type residues. (d) Activity improvements in phi29 DNAP mutants. Among the 10 single-site mutants experimentally tested, 8 shows significant activity enhancements, with the top mutant exhibiting an eight-fold increase. (e) Thermostability of phi29 DNAP mutants. Three mutants demonstrate improvements in both thermostability and activity, with two of them showing significant gains.](./img/venusREM/p4.png)\n\n3aVENUSREMKang2025 EC50  VHH   1 3bVENUSREMProteinGym ESM2  ESM1b  VHH \n\nVENUSREM42Cphi29 DNAPC3phi29 DNAP 42 C Fig. 3d  ssDNA Povilaitis 2016  10  C3  ssDNA  42 C  RCA  3c C3  Fig. 3dphi29 DNAPY449G6.5DSFTm3eVENUSREMphi29 DNAPphi29 DNAPL567Ephi29 DNAPS551L\n","source":"_posts/venusREM.md","raw":"---\ntitle: VenusREM\nmathjax: true\ndate: 2025/10/23 20:46:25\nimg: https://raw.githubusercontent.com/ai4protein/VenusREM/main/img/framework.png\nexcerpt: \n---\n\n \n\n VENUSREMVENUSREM  ProteinGym  217  30  VHH  10  DNA  VENUSREM VENUSREM\n\nhttps://github.com/tyang816/VenusREM \n\nhttps://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bioinformatics/41/Supplement_1/10.1093_bioinformatics_btaf189/1/btaf189_supplementary_data.pdf?Expires=1763573535&Signature=RwBhhIoksIYTreWSThU1cwmKWxVWrfSI8UHWdHiTIap-ROAkAL4fzl1p8fzhzwWz64BRi7slEyDoxdyRxBYc0sQ2pD4NPB-HYlx3h0R3jSMt~b2vN0hugFD5HvCDqQHP0krEWviVi6OCJbJxM6zJS5LVKqr6fZfo9yOIxo23kWyO79ZaZMl9-r4~~r74PZ0zIADReEAjv~DqSJSTWwH3k1tRhHgjBWoYgEI~fYmPsSXUn5Gnm3zRnRN0K-AB0CXNvV32WONssRku82nmQUVIs7xd6cw1QNEG4KQkfsOuyGcgyZtzbDrOs2YqnM~n2Zir~LEZQzeuX4FIxESBn04Y7w__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA\n\n**benchmark**\n\n DMS  ProteinGymNotin 2024 \n\n\n\n****\n\n- \n\n  - Spearman\n\n  Spearman  **rho**\n\n  > \n\n  ****\n    X  Y $ R(X_i) $$ R(Y_i)$\n   \n\n  $d_i = R(X_i) - R(Y_i)$\n  \n\n  $\\rho = 1 - \\frac{6\\sum d_i^2}{n(n^2 - 1)}$\n\n  \n\n  - n\n  - $d_i$\n\n  $11$\n\n  - $=1$\n  - $=1$\n  - $=0$\n\n  |          | Spearman       | Pearson r      |\n  | -------------- | --------------- | -------------- |\n  |        | / |  |\n  |            |   |  |\n  |        |         |        |\n  |  |             |              |\n\n- \n  - VHH\n  - phi29DNAphi29 DNAP\n\n\n\n\n\n![Figure 1. Workflow of VENUSREM for predicting mutation effects. (a) For a given template protein, VENUSREM encodes structural, sequence, and MSA information to generate logits for each residue, which are used to calculate mutation fitness scores. (b) For each AA, its local structure is clustered into 2048 distinct structure tokens. (c) The vector representations of structural and sequence information are integrated using disentangled cross-attention through BERT-style pretraining. (d) Homologous information is retrieved via Jackhmmer and converted to a matrix representation of evolutionary logits.](./img/venusREM/p1.png)\n\nVENUSREM1a PLM  1b  c/1d AA \n\n|                  |                       |                 |                      |\n| ------------------------ | ----------------------------- | ----------------------- | ------------------------ |\n|  (Sequence)          |                 | Token embedding         |  RRR             |\n|  (Structure)         | AlphaFold/PDB             | GVP + K-means     |  SSS             |\n|  (Evolution/MSA) |  Jackhmmer  Foldseek  |  + logit  |  OevoO_{evo}Oevo |\n\n\n\n20+5token<pad>, <cls>, <eos>, <unk>, <mask>\n\n\n\n3dtoken\n\n- **10  40**\n-  = \n-  =  <10 \n-  =  $G_i$\n\n### \n\n- GVP \n-  C \n-  $\\pi_\\theta(G_i) \\in \\mathbb{R}^{256}$\n\nGVP \n\n> 3D\n\n### \n\n-  4,735,677 ****\n-  **K-means **\n-  **2048token**\n\ntoken0~2047\n\n$S \\in \\mathbb{R}^{L \\times 2048}$\n\n\n\n\n\nJackhmmer  **HMMER **\n\n>  (Hidden Markov Model, HMM) \n\n\n\n1. \n2.  profile HMM/\n3.  UniRef100 \n4.  (MSA) \n\n5HMM\n   `.a2m` alignment\n\n\n\n-  `.a2m` \n- gap `<pad>`\n-  $N\\times L$ $A$NL\n\n\n\n\n\n$C_{iv} = \\frac{\\sum_n I(A_{ni}=v)}{\\sum_v \\sum_n I(A_{ni}=v)}$\n\nVNLniv$I(A_{ni}=v)=1$\n\n\n\n$O^{evo}_{iv} = \\log \\frac{e^{C_{iv}}}{\\sum_v e^{C_{iv}}}$\n\n $O_{evo}$\n v \n\n|      |                               |  |                |\n| ------------ | --------------------------------- | -------- | ------------------ |\n| **** | One-hot + embedding               | L25     |  |\n| **** |   GVP  K-means      | L2048   | 3D     |\n| **** | Jackhmmer    | L25     |      |\n\n =0.8\n\n$O_{iv}^{out}=(1)O_{iv}^{native}+O_{iv}^{evo}$\n\n\n\n$F_x = \\sum_{t \\in T}(O_{i,v'}^{out} - O_{i,v}^{out})$\n\n\n\n- t\n- v\n- v\n\n\n\n**Result**\n\n![Spearmans  of mutation eect prediction (substitution) by zero-shot predictions on ProteinGym of dierent MSA depth and taxon.](./img/venusREM/p2.png)\n\n![Figure 2. A summary of baseline comparisons on the ProteinGym mutation effect prediction task. (a) Performance ranks across each assay. for instance, a Rank 1 for VENUSREM with a value of 49 indicates that VENUSREM achieves the highest performance on 49 out of 217 assays. (b) Performance of VENUSREMs ablation models with various homologous sequence search strategies and retrieval ratios, assessed on a 10% randomly split validation set.](./img/venusREM/p3.png)\n\n2aS3-S7VENUSREM310VENUSREM2b\n\n![Figure 3. Performance analysis on low-throughput experimental datasets. (a) Scatter plot of predicted fitness scores (by VENUSREM) versus experimentally obtained EC50 values. For both alkali resistance and binding affinity improvements, VENUSREMs scoring of 31 VHH antibody mutants by 14 sites shows a clear correlation with experimental data. (b) Performance of different models on the two assays of VHH antibody data. Only VENUSREM successfully generated fitness scores that are moderately negatively correlated with EC50 values. (c) 3D structure of the template phi29 DNAP. The AA sites targeted for mutation across the 10 single-site mutants are highlighted and labeled with their wild-type residues. (d) Activity improvements in phi29 DNAP mutants. Among the 10 single-site mutants experimentally tested, 8 shows significant activity enhancements, with the top mutant exhibiting an eight-fold increase. (e) Thermostability of phi29 DNAP mutants. Three mutants demonstrate improvements in both thermostability and activity, with two of them showing significant gains.](./img/venusREM/p4.png)\n\n3aVENUSREMKang2025 EC50  VHH   1 3bVENUSREMProteinGym ESM2  ESM1b  VHH \n\nVENUSREM42Cphi29 DNAPC3phi29 DNAP 42 C Fig. 3d  ssDNA Povilaitis 2016  10  C3  ssDNA  42 C  RCA  3c C3  Fig. 3dphi29 DNAPY449G6.5DSFTm3eVENUSREMphi29 DNAPphi29 DNAPL567Ephi29 DNAPS551L\n","slug":"venusREM","published":1,"updated":"2025-10-24T08:03:54.135Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ff9000nss993ya63p21","content":"<p> </p>\n<p> VENUSREMVENUSREM  ProteinGym  217  30  VHH  10  DNA  VENUSREM VENUSREM</p>\n<p><a href=\"https://github.com/tyang816/VenusREM\">https://github.com/tyang816/VenusREM</a> </p>\n<p><a href=\"https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bioinformatics/41/Supplement_1/10.1093_bioinformatics_btaf189/1/btaf189_supplementary_data.pdf?Expires=1763573535&Signature=RwBhhIoksIYTreWSThU1cwmKWxVWrfSI8UHWdHiTIap-ROAkAL4fzl1p8fzhzwWz64BRi7slEyDoxdyRxBYc0sQ2pD4NPB-HYlx3h0R3jSMt~b2vN0hugFD5HvCDqQHP0krEWviVi6OCJbJxM6zJS5LVKqr6fZfo9yOIxo23kWyO79ZaZMl9-r4~~r74PZ0zIADReEAjv~DqSJSTWwH3k1tRhHgjBWoYgEI~fYmPsSXUn5Gnm3zRnRN0K-AB0CXNvV32WONssRku82nmQUVIs7xd6cw1QNEG4KQkfsOuyGcgyZtzbDrOs2YqnM~n2Zir~LEZQzeuX4FIxESBn04Y7w__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA\">https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bioinformatics/41/Supplement_1/10.1093_bioinformatics_btaf189/1/btaf189_supplementary_data.pdf?Expires=1763573535&amp;Signature=RwBhhIoksIYTreWSThU1cwmKWxVWrfSI8UHWdHiTIap-ROAkAL4fzl1p8fzhzwWz64BRi7slEyDoxdyRxBYc0sQ2pD4NPB-HYlx3h0R3jSMt~b2vN0hugFD5HvCDqQHP0krEWviVi6OCJbJxM6zJS5LVKqr6fZfo9yOIxo23kWyO79ZaZMl9-r4~~r74PZ0zIADReEAjv~DqSJSTWwH3k1tRhHgjBWoYgEI~fYmPsSXUn5Gnm3zRnRN0K-AB0CXNvV32WONssRku82nmQUVIs7xd6cw1QNEG4KQkfsOuyGcgyZtzbDrOs2YqnM~n2Zir~LEZQzeuX4FIxESBn04Y7w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA</a></p>\n<p><strong>benchmark</strong></p>\n<p> DMS  ProteinGymNotin 2024 </p>\n<p></p>\n<p><strong></strong></p>\n<ul>\n<li><p></p>\n<ul>\n<li>Spearman</li>\n</ul>\n<p>Spearman  <strong>rho</strong></p>\n<blockquote>\n<p></p>\n</blockquote>\n<p><strong></strong><br>  X  Y $ R(X_i) $$ R(Y_i)$<br> </p>\n<p>$d_i &#x3D; R(X_i) - R(Y_i)$<br></p>\n<p>$\\rho &#x3D; 1 - \\frac{6\\sum d_i^2}{n(n^2 - 1)}$</p>\n<p></p>\n<ul>\n<li>n</li>\n<li>$d_i$</li>\n</ul>\n<p>$11$</p>\n<ul>\n<li>$&#x3D;1$</li>\n<li>$&#x3D;1$</li>\n<li>$&#x3D;0$</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Spearman </th>\n<th>Pearson r</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td>&#x2F;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n</li>\n<li><p></p>\n<ul>\n<li>VHH</li>\n<li>phi29DNAphi29 DNAP</li>\n</ul>\n</li>\n</ul>\n<p></p>\n<p><img src=\"/./img/venusREM/p1.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/venusREM/p1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Figure 1. Workflow of VENUSREM for predicting mutation effects. (a) For a given template protein, VENUSREM encodes structural, sequence, and MSA information to generate logits for each residue, which are used to calculate mutation fitness scores. (b) For each AA, its local structure is clustered into 2048 distinct structure tokens. (c) The vector representations of structural and sequence information are integrated using disentangled cross-attention through BERT-style pretraining. (d) Homologous information is retrieved via Jackhmmer and converted to a matrix representation of evolutionary logits.\"></p>\n<p>VENUSREM1a PLM  1b  c&#x2F;1d AA </p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td> (Sequence)</td>\n<td></td>\n<td>Token embedding</td>\n<td> RRR</td>\n</tr>\n<tr>\n<td> (Structure)</td>\n<td>AlphaFold&#x2F;PDB</td>\n<td>GVP + K-means </td>\n<td> SSS</td>\n</tr>\n<tr>\n<td> (Evolution&#x2F;MSA)</td>\n<td> Jackhmmer  Foldseek </td>\n<td> + logit </td>\n<td> OevoO_{evo}Oevo</td>\n</tr>\n</tbody></table>\n<p></p>\n<p>20+5token<pad>, <cls>, <eos>, <unk>, <mask></p>\n<p></p>\n<p>3dtoken</p>\n<ul>\n<li><strong>10  40</strong></li>\n<li> &#x3D; </li>\n<li> &#x3D;  &lt;10 </li>\n<li> &#x3D;  $G_i$</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li>GVP </li>\n<li> C </li>\n<li> $\\pi_\\theta(G_i) \\in \\mathbb{R}^{256}$</li>\n</ul>\n<p>GVP </p>\n<blockquote>\n<p>3D</p>\n</blockquote>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li> 4,735,677 <strong></strong></li>\n<li> <strong>K-means </strong></li>\n<li> <strong>2048token</strong></li>\n</ul>\n<p>token0~2047</p>\n<p>$S \\in \\mathbb{R}^{L \\times 2048}$</p>\n<p></p>\n<p>Jackhmmer  <strong>HMMER </strong></p>\n<blockquote>\n<p> (Hidden Markov Model, HMM) </p>\n</blockquote>\n<p></p>\n<ol>\n<li></li>\n<li> profile HMM&#x2F;</li>\n<li> UniRef100 </li>\n<li> (MSA) </li>\n</ol>\n<p>5HMM<br>   <code>.a2m</code> alignment</p>\n<ul>\n<li> <code>.a2m</code> </li>\n<li>gap <code>&lt;pad&gt;</code></li>\n<li> $N\\times L$ $A$NL</li>\n</ul>\n<p></p>\n<p>$C_{iv} &#x3D; \\frac{\\sum_n I(A_{ni}&#x3D;v)}{\\sum_v \\sum_n I(A_{ni}&#x3D;v)}$</p>\n<p>VNLniv$I(A_{ni}&#x3D;v)&#x3D;1$</p>\n<p></p>\n<p>$O^{evo}<em>{iv} &#x3D; \\log \\frac{e^{C</em>{iv}}}{\\sum_v e^{C_{iv}}}$</p>\n<p> $O_{evo}$<br> v </p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong></strong></td>\n<td>One-hot + embedding</td>\n<td>L25</td>\n<td></td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td>  GVP  K-means</td>\n<td>L2048</td>\n<td>3D</td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td>Jackhmmer   </td>\n<td>L25</td>\n<td></td>\n</tr>\n</tbody></table>\n<p> &#x3D;0.8</p>\n<p>$O_{iv}^{out}&#x3D;(1)O_{iv}^{native}+O_{iv}^{evo}$</p>\n<p></p>\n<p>$F_x &#x3D; \\sum_{t \\in T}(O_{i,v}^{out} - O_{i,v}^{out})$</p>\n<p></p>\n<ul>\n<li>t</li>\n<li>v</li>\n<li>v</li>\n</ul>\n<p><strong>Result</strong></p>\n<p><img src=\"/./img/venusREM/p2.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/venusREM/p2.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Spearmans  of mutation eect prediction (substitution) by zero-shot predictions on ProteinGym of dierent MSA depth and taxon.\"></p>\n<p><img src=\"/./img/venusREM/p3.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/venusREM/p3.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Figure 2. A summary of baseline comparisons on the ProteinGym mutation effect prediction task. (a) Performance ranks across each assay. for instance, a Rank 1 for VENUSREM with a value of 49 indicates that VENUSREM achieves the highest performance on 49 out of 217 assays. (b) Performance of VENUSREMs ablation models with various homologous sequence search strategies and retrieval ratios, assessed on a 10% randomly split validation set.\"></p>\n<p>2aS3-S7VENUSREM310VENUSREM2b</p>\n<p><img src=\"/./img/venusREM/p4.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/venusREM/p4.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Figure 3. Performance analysis on low-throughput experimental datasets. (a) Scatter plot of predicted fitness scores (by VENUSREM) versus experimentally obtained EC50 values. For both alkali resistance and binding affinity improvements, VENUSREMs scoring of 31 VHH antibody mutants by 14 sites shows a clear correlation with experimental data. (b) Performance of different models on the two assays of VHH antibody data. Only VENUSREM successfully generated fitness scores that are moderately negatively correlated with EC50 values. (c) 3D structure of the template phi29 DNAP. The AA sites targeted for mutation across the 10 single-site mutants are highlighted and labeled with their wild-type residues. (d) Activity improvements in phi29 DNAP mutants. Among the 10 single-site mutants experimentally tested, 8 shows significant activity enhancements, with the top mutant exhibiting an eight-fold increase. (e) Thermostability of phi29 DNAP mutants. Three mutants demonstrate improvements in both thermostability and activity, with two of them showing significant gains.\"></p>\n<p>3aVENUSREMKang2025 EC50  VHH   1 3bVENUSREMProteinGym ESM2  ESM1b  VHH </p>\n<p>VENUSREM42Cphi29 DNAPC3phi29 DNAP 42 C Fig. 3d  ssDNA Povilaitis 2016  10  C3  ssDNA  42 C  RCA  3c C3  Fig. 3dphi29 DNAPY449G6.5DSFTm3eVENUSREMphi29 DNAPphi29 DNAPL567Ephi29 DNAPS551L</p>\n","more":"<p> </p>\n<p> VENUSREMVENUSREM  ProteinGym  217  30  VHH  10  DNA  VENUSREM VENUSREM</p>\n<p><a href=\"https://github.com/tyang816/VenusREM\">https://github.com/tyang816/VenusREM</a> </p>\n<p><a href=\"https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bioinformatics/41/Supplement_1/10.1093_bioinformatics_btaf189/1/btaf189_supplementary_data.pdf?Expires=1763573535&Signature=RwBhhIoksIYTreWSThU1cwmKWxVWrfSI8UHWdHiTIap-ROAkAL4fzl1p8fzhzwWz64BRi7slEyDoxdyRxBYc0sQ2pD4NPB-HYlx3h0R3jSMt~b2vN0hugFD5HvCDqQHP0krEWviVi6OCJbJxM6zJS5LVKqr6fZfo9yOIxo23kWyO79ZaZMl9-r4~~r74PZ0zIADReEAjv~DqSJSTWwH3k1tRhHgjBWoYgEI~fYmPsSXUn5Gnm3zRnRN0K-AB0CXNvV32WONssRku82nmQUVIs7xd6cw1QNEG4KQkfsOuyGcgyZtzbDrOs2YqnM~n2Zir~LEZQzeuX4FIxESBn04Y7w__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA\">https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/bioinformatics/41/Supplement_1/10.1093_bioinformatics_btaf189/1/btaf189_supplementary_data.pdf?Expires=1763573535&amp;Signature=RwBhhIoksIYTreWSThU1cwmKWxVWrfSI8UHWdHiTIap-ROAkAL4fzl1p8fzhzwWz64BRi7slEyDoxdyRxBYc0sQ2pD4NPB-HYlx3h0R3jSMt~b2vN0hugFD5HvCDqQHP0krEWviVi6OCJbJxM6zJS5LVKqr6fZfo9yOIxo23kWyO79ZaZMl9-r4~~r74PZ0zIADReEAjv~DqSJSTWwH3k1tRhHgjBWoYgEI~fYmPsSXUn5Gnm3zRnRN0K-AB0CXNvV32WONssRku82nmQUVIs7xd6cw1QNEG4KQkfsOuyGcgyZtzbDrOs2YqnM~n2Zir~LEZQzeuX4FIxESBn04Y7w__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA</a></p>\n<p><strong>benchmark</strong></p>\n<p> DMS  ProteinGymNotin 2024 </p>\n<p></p>\n<p><strong></strong></p>\n<ul>\n<li><p></p>\n<ul>\n<li>Spearman</li>\n</ul>\n<p>Spearman  <strong>rho</strong></p>\n<blockquote>\n<p></p>\n</blockquote>\n<p><strong></strong><br>  X  Y $ R(X_i) $$ R(Y_i)$<br> </p>\n<p>$d_i &#x3D; R(X_i) - R(Y_i)$<br></p>\n<p>$\\rho &#x3D; 1 - \\frac{6\\sum d_i^2}{n(n^2 - 1)}$</p>\n<p></p>\n<ul>\n<li>n</li>\n<li>$d_i$</li>\n</ul>\n<p>$11$</p>\n<ul>\n<li>$&#x3D;1$</li>\n<li>$&#x3D;1$</li>\n<li>$&#x3D;0$</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Spearman </th>\n<th>Pearson r</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td>&#x2F;</td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n</li>\n<li><p></p>\n<ul>\n<li>VHH</li>\n<li>phi29DNAphi29 DNAP</li>\n</ul>\n</li>\n</ul>\n<p></p>\n<p><img src=\"/./img/venusREM/p1.png\" alt=\"Figure 1. Workflow of VENUSREM for predicting mutation effects. (a) For a given template protein, VENUSREM encodes structural, sequence, and MSA information to generate logits for each residue, which are used to calculate mutation fitness scores. (b) For each AA, its local structure is clustered into 2048 distinct structure tokens. (c) The vector representations of structural and sequence information are integrated using disentangled cross-attention through BERT-style pretraining. (d) Homologous information is retrieved via Jackhmmer and converted to a matrix representation of evolutionary logits.\"></p>\n<p>VENUSREM1a PLM  1b  c&#x2F;1d AA </p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td> (Sequence)</td>\n<td></td>\n<td>Token embedding</td>\n<td> RRR</td>\n</tr>\n<tr>\n<td> (Structure)</td>\n<td>AlphaFold&#x2F;PDB</td>\n<td>GVP + K-means </td>\n<td> SSS</td>\n</tr>\n<tr>\n<td> (Evolution&#x2F;MSA)</td>\n<td> Jackhmmer  Foldseek </td>\n<td> + logit </td>\n<td> OevoO_{evo}Oevo</td>\n</tr>\n</tbody></table>\n<p></p>\n<p>20+5token<pad>, <cls>, <eos>, <unk>, <mask></p>\n<p></p>\n<p>3dtoken</p>\n<ul>\n<li><strong>10  40</strong></li>\n<li> &#x3D; </li>\n<li> &#x3D;  &lt;10 </li>\n<li> &#x3D;  $G_i$</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li>GVP </li>\n<li> C </li>\n<li> $\\pi_\\theta(G_i) \\in \\mathbb{R}^{256}$</li>\n</ul>\n<p>GVP </p>\n<blockquote>\n<p>3D</p>\n</blockquote>\n<h3 id=\"-1\"><a href=\"#-1\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li> 4,735,677 <strong></strong></li>\n<li> <strong>K-means </strong></li>\n<li> <strong>2048token</strong></li>\n</ul>\n<p>token0~2047</p>\n<p>$S \\in \\mathbb{R}^{L \\times 2048}$</p>\n<p></p>\n<p>Jackhmmer  <strong>HMMER </strong></p>\n<blockquote>\n<p> (Hidden Markov Model, HMM) </p>\n</blockquote>\n<p></p>\n<ol>\n<li></li>\n<li> profile HMM&#x2F;</li>\n<li> UniRef100 </li>\n<li> (MSA) </li>\n</ol>\n<p>5HMM<br>   <code>.a2m</code> alignment</p>\n<ul>\n<li> <code>.a2m</code> </li>\n<li>gap <code>&lt;pad&gt;</code></li>\n<li> $N\\times L$ $A$NL</li>\n</ul>\n<p></p>\n<p>$C_{iv} &#x3D; \\frac{\\sum_n I(A_{ni}&#x3D;v)}{\\sum_v \\sum_n I(A_{ni}&#x3D;v)}$</p>\n<p>VNLniv$I(A_{ni}&#x3D;v)&#x3D;1$</p>\n<p></p>\n<p>$O^{evo}<em>{iv} &#x3D; \\log \\frac{e^{C</em>{iv}}}{\\sum_v e^{C_{iv}}}$</p>\n<p> $O_{evo}$<br> v </p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong></strong></td>\n<td>One-hot + embedding</td>\n<td>L25</td>\n<td></td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td>  GVP  K-means</td>\n<td>L2048</td>\n<td>3D</td>\n</tr>\n<tr>\n<td><strong></strong></td>\n<td>Jackhmmer   </td>\n<td>L25</td>\n<td></td>\n</tr>\n</tbody></table>\n<p> &#x3D;0.8</p>\n<p>$O_{iv}^{out}&#x3D;(1)O_{iv}^{native}+O_{iv}^{evo}$</p>\n<p></p>\n<p>$F_x &#x3D; \\sum_{t \\in T}(O_{i,v}^{out} - O_{i,v}^{out})$</p>\n<p></p>\n<ul>\n<li>t</li>\n<li>v</li>\n<li>v</li>\n</ul>\n<p><strong>Result</strong></p>\n<p><img src=\"/./img/venusREM/p2.png\" alt=\"Spearmans  of mutation eect prediction (substitution) by zero-shot predictions on ProteinGym of dierent MSA depth and taxon.\"></p>\n<p><img src=\"/./img/venusREM/p3.png\" alt=\"Figure 2. A summary of baseline comparisons on the ProteinGym mutation effect prediction task. (a) Performance ranks across each assay. for instance, a Rank 1 for VENUSREM with a value of 49 indicates that VENUSREM achieves the highest performance on 49 out of 217 assays. (b) Performance of VENUSREMs ablation models with various homologous sequence search strategies and retrieval ratios, assessed on a 10% randomly split validation set.\"></p>\n<p>2aS3-S7VENUSREM310VENUSREM2b</p>\n<p><img src=\"/./img/venusREM/p4.png\" alt=\"Figure 3. Performance analysis on low-throughput experimental datasets. (a) Scatter plot of predicted fitness scores (by VENUSREM) versus experimentally obtained EC50 values. For both alkali resistance and binding affinity improvements, VENUSREMs scoring of 31 VHH antibody mutants by 14 sites shows a clear correlation with experimental data. (b) Performance of different models on the two assays of VHH antibody data. Only VENUSREM successfully generated fitness scores that are moderately negatively correlated with EC50 values. (c) 3D structure of the template phi29 DNAP. The AA sites targeted for mutation across the 10 single-site mutants are highlighted and labeled with their wild-type residues. (d) Activity improvements in phi29 DNAP mutants. Among the 10 single-site mutants experimentally tested, 8 shows significant activity enhancements, with the top mutant exhibiting an eight-fold increase. (e) Thermostability of phi29 DNAP mutants. Three mutants demonstrate improvements in both thermostability and activity, with two of them showing significant gains.\"></p>\n<p>3aVENUSREMKang2025 EC50  VHH   1 3bVENUSREMProteinGym ESM2  ESM1b  VHH </p>\n<p>VENUSREM42Cphi29 DNAPC3phi29 DNAP 42 C Fig. 3d  ssDNA Povilaitis 2016  10  C3  ssDNA  42 C  RCA  3c C3  Fig. 3dphi29 DNAPY449G6.5DSFTm3eVENUSREMphi29 DNAPphi29 DNAPL567Ephi29 DNAPS551L</p>\n"},{"title":"ProteinMPNN","mathjax":true,"date":"2025-10-27T12:46:25.000Z","img":"https://www.researchgate.net/publication/363608659/figure/fig1/AS:11431281127577573@1679077202382/ProteinMPNN-architecture.jpg","excerpt":" ProteinMPNN ","_content":"\n\n- MPNN  3  3  128 Ca-Ca  Ca-Ca-Ca  1 N  C CATH7PDB19.7k NCaCO  Cb  41.2% 49.0% 1 1; N-Ca-C  2 50.5%  3 16243248  64  Ca  S1A 32-48 \n\n![Table 1. Single chain sequence design performance on CATH held out test split. Test  accuracy (percentage of correct amino amino acids recovered) and test perplexity  (exponentiated categorical cross entropy loss per residue) are reported for models trained  on the native backbone coordinates (left, normal font) and models trained with Gaussian  noise (std=0.02A) added to the backbone coordinates (right, bold font); all test evaluations  are with no added noise. The final column shows sequence recovery on 5,000 AlphaFold  protein backbone models with average pLDDT > 80.0 randomly chosen from UniRef50  sequences.](./img/proteinMPNN/p1.png)\n\n\n\nACC\n\nPerplexity\n\nAF ACCAF\n\nstd=0.02A\n\n N  C  814; 1B329\n\n![Fig. 1. ProteinMPNN architecture. (A) Distances between N, Ca, C, O, and virtual Cb are  encoded and processed using a message passing neural network (Encoder) to obtain graph  node and edge features. The encoded features together with a partial sequence are used to  generate amino acids iteratively in a random decoding order. (B) A fixed left to right  decoding cannot use sequence context (green) for preceding positions (yellow) whereas a  model trained with random decoding orders can be used with arbitrary decoding order during  the inference. The decoding order can be chosen such that the fixed context is decoded first.  (C) Residue positions within and between chains can be tied together, enabling symmetric,  repeat protein, and multistate design. In this example, a homo-trimer is designed with  coupling of positions in different chains. Predicted logits for tied positions are averaged to  get a single probability distribution from which amino acids are sampled.](./img/proteinMPNN/p2.png)\n\nAEncoderNCaCOCbB C  logit \n\n\n\n![Fig. 2. In silico evaluation of ProteinMPNN. (A) ProteinMPNN has higher native sequence  recovery than Rosetta. The average Cb distance of the 8 closest neighbors (x axis) reports  on burial, with most buried positions on the left and more exposed on the right;  ProteinMPNN outperforms Rosetta at all levels of burial. Average sequence recovery for  ProteinMPNN was 52.4%, compared to 32.9% for Rosetta. (B) ProteinMPNN has similarly  high sequence recovery for monomers, homo-oligomers, and hetero-oligomers; violin plots  are for 690 monomers, 732 homomers, 98 heteromers. (C) Sequence recovery (black) and  relative AlphaFold success rates (blue) as a function of training noise level. For higher  accuracy predictions (circles) smaller amounts of noise are optimal (1.0 corresponds to 1.8%  success rate), while to maximize prediction success at a lower accuracy cutoff (squares),  models trained with more noise are better (1.0 corresponds to 6.7% success rate). (D)  Sequence recovery and diversity as a function of sampling temperature. Redesign of native  protein backbones with ProteinMPNN considerably increases AphaFold prediction accuracy compared to the original native sequence using no multiple sequence information. Single  sequences (designed or native) were input in both cases. (F) ProteinMPNN redesign of  previous Rosetta designed NTF2 fold proteins (3,000 backbones in total) results in  considerably improved AlphaFold single sequence prediction accuracy.](./img/proteinMPNN/p3.png)\n\nAProteinMPNNRosetta8Cbx; ProteinMPNN  RosettaProteinMPNN  52.4% Rosetta  32.9%BProteinMPNN; 690 732 98 CAlphaFold1.0  1.8% 1.0  6.7% D ProteinMPNN  AphaFold F  Rosetta  NTF2  3,000  ProteinMPNN  AlphaFold \n\n\n\nMPNN2DProteinMPNNS3A\n\n![Fig. 3. Structural characterization of ProteinMPNN designs. (A) Comparison of soluble  protein expression over a set of AlphaFold hallucinated monomers and homo-oligomers  (blue) and the same set of backbones with sequences designed using ProteinMPNN  (orange), N=129. The total soluble protein yield following expression in E. coli, obtained  from the integrated area unders size exclusion traces of nickel-NTA purified proteins,  increases considerably from the barely soluble protein of the original sequences following  ProteinMPNN rescue (median yields for 1 L of culture equivalent: 9 and 247 mg  respectively). (B), (C), (D) In depth characterization of a monomer hallucination and  corresponding ProteinMPNN rescue from the set in A. Like almost all of the designs in A, the sequence and structural similarity to the PDB of the design model are very low (E-value=2.8  against UniRef100 using HHblits, TM-score=0.56 against PDB). (B) The ProteinMPNN  rescued design has high thermostability, with a virtually unchanged circular dichroism profile  at 95 C compared to 25 C. (C) Size exclusion (SEC) profile of failed original design overlaid  with the ProteinMPNN sequence design, which has a clear monodisperse peak at the  expected retention volume. (D) Crystal structure of the ProteinMPNN (8CYK) design is  nearly identical to the design model (2.35 RMSD over 130 residues), see Figure S5 for  additional information. Right panel shows model sidechains in the electron density, in green  crystal side chains, in blue AlphaFold side chains. (E), (F) ProteinMPNN rescue of Rosetta  design made from a perfectly repeating structural and sequence unit (DHR82). Residues at  corresponding positions in the repeat unit were tied during ProteinMPNN sequence  inference. (E) Backbone design model and MPNN redesigned sequence AlphaFold model  with tied residues indicated by lines (~1.2A error over 232 residues). (F) SEC profile of IMAC  purified original Rosetta design and two ProteinMPNN redesigns. (G), (H) Tying residues  during ProteinMPNN sequence inference both within and between chains to enforce both  repeat protein and cyclic symmetries. (G) Side view of design model. A set of tied residues  are shown in red. (H) Top-down view of design model. (I) Negative stain electron  micrograph of purified design. (J) Class average of images from I closely match top down  view in H. (K) Rescue of the failed two-component Rosetta tetrahedral nanoparticle design  T33-27 (13) by ProteinMPNN interface design. Following ProteinMPNN rescue, the  nanoparticle assembled readily with high yield, and the crystal structure (grey) is very nearly  identical to the design model (green/purple) (backbone RMSD of 1.2 A over two complete  asymmetric units forming the ProteinMPNN rescued interface).](./img/proteinMPNN/p4.png)\n\nAAlphaFoldProteinMPNNN=129-NTAProteinMPNN1 L9247 mgBCD  A  ProteinMPNNAPDBHHblitsUniRef100E=2.8PDBTM=0.56BProteinMPNN25 C95 C CProteinMPNNSECDProteinMPNN8CYK1302.35 RMSDS5 AlphaFold EFDHR82RosettaMPNN ProteinMPNN EMPNNAlphaFold232~1.2FIMACRosettaProteinMPNNSECGH  ProteinMPNN GH IJ  I  H K  ProteinMPNN  Rosetta  T33-27 13 ProteinMPNN / ProteinMPNN  RMSD  1.2 \n\n![Fig. 4. Design of protein function with ProteinMPNN. (A) Design scheme. First panel;  structure (PDB 2W0Z) of the peptide APPPRPPKP bound to the human Grb2 C-term SH3  domain (peptide is in green, target in surface and colored blue). Second panel: helical  bundle scaffolds were docked to the exposed face of the peptide using RIFDOCK (19), and  Rosetta remodel was used to build loops connecting the peptide to the scaffolds. Rosetta  sequence design with layer design task operations was used to optimize the sequence of the  fusion (Cyan) for stability, rigidity of the peptide-helical bundle interface, and binding affinity  for the Grb2 SH3 domain. Third panel; ProteinMPNN redesign (orange) of the designed  binder sequence; hydrogen bonds involving asparagine sidechains between the peptide and  base scaffold are shown in green and in the inset. Fourth panel; Mutation of the two  asparagines to aspartates to disrupt the scaffolding of the target peptide. (B) Experimental  characterization of binding using biolayer interferometry. Biotinylated C-term SH3 domain  from human Grb2 was loaded onto Streptavidin (SA) Biosensors, which were then  immersed in solutions containing varying concentrations of the target peptide (left) of the  designs (right panels), and then transferred to buffer lacking added protein for dissociation measurements. The MPNN design (3rd panel from the left) has much greater binding signal  than the original Rosetta design (2nd panel from the left); this is greatly reduced by the  asparagine to aspartate mutations (last panel).](./img/proteinMPNN/p5.png)\n\n ProteinMPNN  Rosetta \n\nProteinMPNN  100  CPU  1.2  CPU  258.8 Rosetta 52.4%  32.9%  Rosetta  AlphaFold - 1-6 ProteinMPNN  TIM  6  S3 BC ; \n\n Rosetta ProteinMPNN ; Rosetta ; Rosetta   Rosetta  PDB  \n\nProteinMPNN Wicky ProteinMPNN ProteinMPNN  ProteinMPNN  ProteinMPNN \n\n## Methods\n\n### \n\n 1  CATH 4.2 40%  1 71Transformer2010%2110%226000tokenCa-Ca30\n\n### \n\n 10% 22  =  * / 2000  2000  [] Adambeta1 = 0.9beta2 = 0.98epsilon= 109 20  NVIDIA A100 GPU  pytorch 2410k  3D  150k  23,358  PDB  100  epoch\n\n## \n\n|                          |                              |                                          | /                                       |\n| -------------------------- | ------------------------------ | ---------------------------------------------- | --------------------------------------------- |\n| **Featurize()**            |      | Graph construction from backbone coordinates |  `(X, S, mask, chain_M, residue_idx, ...)`  |\n| **ProteinFeatures**        |  RBF | Feature construction and geometric encoding  |  `(X[B,L,4,3])`   `E[B,L,K,128]`      |\n| **Encoder (EncLayer  3)** |  message passing    | Structure encoder                            |  `(h_V[B,L,128], h_E[B,L,K,128])`           |\n| **Decoder (DecLayer  3)** |             | Autoregressive sequence decoder              |  `(h_V, h_E, h_S)`   `log_probs[B,L,21]` |\n| **Output Layer (W_out)**   |  logits              | Logits for amino acid types                  | `[B, L, 21]`                                  |\n\n- **Featurize(batch)**\n\n|                  |            |                                |\n| -------------------- | -------------- | ---------------------------------- |\n| `X`                  | `[B, L, 4, 3]` | N, CA, C, O  |\n| `S`                  | `[B, L]`       |              |\n| `mask`               | `[B, L]`       | 1                      |\n| `chain_M`            | `[B, L]`       | 1 masked chain |\n| `residue_idx`        | `[B, L]`       |        |\n| `chain_encoding_all` | `[B, L]`       |  ID                  |\n\n- **`ProteinFeatures`**\n\n`X (B,L,4,3)`\n\n\n- `E`: `[B, L, K, edge_dim=128]`\n- `E_idx`: `[B, L, K]`  top-K \n\n\n\n1.  **CC** \n2.  top-K \n3.  25 RBF NN, CC, OO, CCb, \n   -  `num_rbf=16`    `2516 = 400`\n4. offset embedding,  65 \n5.   `edge_features=128`\n6. LayerNorm\n\n>  E  message passing\n\nCb\n\nk-neighbor\n\nE_idx:\n\nD_neighbors:\n\n5*5=251616\\*25=400\n\nconcatlayernorm\n\nh_Eh_V\n\n- **Encoder**\n\n\n\n-  `h_V = zeros([B,L,128])`\n-  `h_E = W_e(E)`  `[B,L,K,128]`\n\n- \n  - `h_V [B,L,128]`\n  - `h_E [B,L,K,128]`\n- `h_EV = concat(h_V_i, h_E_ij, h_V_j)`  `[B,L,K,256]`\n- `W1  W2  W3` 128\n-  + LayerNorm + Dropout\n- FeedForward (128512128)\n-  `h_V, h_E` `[B,L,128]`, `[B,L,K,128]`\n\n- **Decoder**\n\n  \n\n  -  `h_V` encoder\n  -  `h_E`\n  -  `h_S = Embedding(S)`  `[B,L,128]`\n\n\n\n1. \n    `h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)`  `[B,L,K,256]`\n\n2. \n\n   -  masked \n   - mask_fwmask_bw\n\n3. \n    `h_EXV_encoder_fw = mask_fw * h_EXV_encoder`\n\n4. \n\n   ```\n   for i in range(3):\n       h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n       h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n       h_V = DecLayer(h_V, h_ESV)\n   ```\n\n5.  logits\n    `logits = W_out(h_V)`  `[B, L, 21]`\n    `log_probs = log_softmax(logits)`\n\n#### \n\n EncLayer \n\n- \n-  `[B,L,128]` `[B,L,128]`\n-  3  + GELU +  + LayerNorm\n- FeedForward (128512128)\n\n-  ****\n\n\n\n- `log_probs`: `[B, L, 21]`\n\n\n\n- `loss_nll`:  NLL\n- `loss_smoothed`:  label smoothing \n\n|                  |                 |          |                                                          |\n| -------------------- | ------------------- | ------------ | ------------------------------------------------------------ |\n| `X`                  | `[B, L_max, 4, 3]`  | float tensor |  N,CA,C,O  xyzpad  0 `mask`  0 |\n| `S`                  | `[B, L_max]`        | long tensor  | pad  0                               |\n| `mask`               | `[B, L_max]`        | float tensor | 1.0 0.0  pad         |\n| `lengths`            | `[B]`               | numpy int    |                                            |\n| `chain_M`            | `[B, L_max]`        | float tensor | 1.0 = masked0.0 = visible  |\n| `residue_idx`        | `[B, L_max]`        | long tensor  | /offset          |\n| `mask_self`          | `[B, L_max, L_max]` | float tensor | 0  interface1  interface loss |\n| `chain_encoding_all` | `[B, L_max]`        | long tensor  |  chain-aware embedding/              |\n\n**N, CA, C, O ** `C` `ProteinFeatures`  C RBF N,CA,C,O\n\n** NaN  padding** `isfinite`  0\n\n**`residue_idx` **offset/\n\n**`chain_M` ** + chain mask / order-agnostic decoding\n\n**`mask_self`** interface  interface loss \n\n\n\n==  == \n: features, : ProteinFeatures\n: W_e, : Linear #Encoder\n: W_s, : Embedding #Decoder\n: encoder_layers, : ModuleList\n: decoder_layers, : ModuleList\n: W_out, : Linear\n\n==  ==                                       \n: features.embeddings.linear.weight, : torch.Size([16, 66]), : 1,056\n: features.embeddings.linear.bias, : torch.Size([16]), : 16\n: features.edge_embedding.weight, : torch.Size([128, 416]), : 53,248\n: features.norm_edges.weight, : torch.Size([128]), : 128\n: features.norm_edges.bias, : torch.Size([128]), : 128\n: W_e.weight, : torch.Size([128, 128]), : 16,384\n: W_e.bias, : torch.Size([128]), : 128 \n: W_s.weight, : torch.Size([21, 128]), : 2,688\n: encoder_layers.0.norm1.weight, : torch.Size([128]), : 128\n: encoder_layers.0.norm1.bias, : torch.Size([128]), : 128\n: encoder_layers.0.norm2.weight, : torch.Size([128]), : 128\n: encoder_layers.0.norm2.bias, : torch.Size([128]), : 128\n: encoder_layers.0.norm3.weight, : torch.Size([128]), : 128\n: encoder_layers.0.norm3.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W1.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.0.W1.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W2.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.0.W2.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W3.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.0.W3.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W11.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.0.W11.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W12.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.0.W12.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W13.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.0.W13.bias, : torch.Size([128]), : 128\n: encoder_layers.0.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: encoder_layers.0.dense.W_in.bias, : torch.Size([512]), : 512\n: encoder_layers.0.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: encoder_layers.0.dense.W_out.bias, : torch.Size([128]), : 128\n: encoder_layers.1.norm1.weight, : torch.Size([128]), : 128\n: encoder_layers.1.norm1.bias, : torch.Size([128]), : 128\n: encoder_layers.1.norm2.weight, : torch.Size([128]), : 128\n: encoder_layers.1.norm2.bias, : torch.Size([128]), : 128\n: encoder_layers.1.norm3.weight, : torch.Size([128]), : 128\n: encoder_layers.1.norm3.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W1.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.1.W1.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W2.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.1.W2.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W3.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.1.W3.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W11.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.1.W11.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W12.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.1.W12.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W13.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.1.W13.bias, : torch.Size([128]), : 128\n: encoder_layers.1.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: encoder_layers.1.dense.W_in.bias, : torch.Size([512]), : 512\n: encoder_layers.1.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: encoder_layers.1.dense.W_out.bias, : torch.Size([128]), : 128\n: encoder_layers.2.norm1.weight, : torch.Size([128]), : 128\n: encoder_layers.2.norm1.bias, : torch.Size([128]), : 128\n: encoder_layers.2.norm2.weight, : torch.Size([128]), : 128\n: encoder_layers.2.norm2.bias, : torch.Size([128]), : 128\n: encoder_layers.2.norm3.weight, : torch.Size([128]), : 128\n: encoder_layers.2.norm3.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W1.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.2.W1.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W2.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.2.W2.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W3.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.2.W3.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W11.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.2.W11.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W12.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.2.W12.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W13.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.2.W13.bias, : torch.Size([128]), : 128\n: encoder_layers.2.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: encoder_layers.2.dense.W_in.bias, : torch.Size([512]), : 512\n: encoder_layers.2.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: encoder_layers.2.dense.W_out.bias, : torch.Size([128]), : 128\n: decoder_layers.0.norm1.weight, : torch.Size([128]), : 128\n: decoder_layers.0.norm1.bias, : torch.Size([128]), : 128\n: decoder_layers.0.norm2.weight, : torch.Size([128]), : 128\n: decoder_layers.0.norm2.bias, : torch.Size([128]), : 128\n: decoder_layers.0.W1.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.0.W1.bias, : torch.Size([128]), : 128\n: decoder_layers.0.W2.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.0.W2.bias, : torch.Size([128]), : 128\n: decoder_layers.0.W3.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.0.W3.bias, : torch.Size([128]), : 128\n: decoder_layers.0.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: decoder_layers.0.dense.W_in.bias, : torch.Size([512]), : 512\n: decoder_layers.0.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.0.dense.W_out.bias, : torch.Size([128]), : 128\n: decoder_layers.1.norm1.weight, : torch.Size([128]), : 128\n: decoder_layers.1.norm1.bias, : torch.Size([128]), : 128\n: decoder_layers.1.norm2.weight, : torch.Size([128]), : 128\n: decoder_layers.1.norm2.bias, : torch.Size([128]), : 128\n: decoder_layers.1.W1.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.1.W1.bias, : torch.Size([128]), : 128\n: decoder_layers.1.W2.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.1.W2.bias, : torch.Size([128]), : 128\n: decoder_layers.1.W3.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.1.W3.bias, : torch.Size([128]), : 128\n: decoder_layers.1.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: decoder_layers.1.dense.W_in.bias, : torch.Size([512]), : 512\n: decoder_layers.1.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.1.dense.W_out.bias, : torch.Size([128]), : 128\n: decoder_layers.2.norm1.weight, : torch.Size([128]), : 128\n: decoder_layers.2.norm1.bias, : torch.Size([128]), : 128\n: decoder_layers.2.norm2.weight, : torch.Size([128]), : 128\n: decoder_layers.2.norm2.bias, : torch.Size([128]), : 128\n: decoder_layers.2.W1.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.2.W1.bias, : torch.Size([128]), : 128\n: decoder_layers.2.W2.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.2.W2.bias, : torch.Size([128]), : 128\n: decoder_layers.2.W3.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.2.W3.bias, : torch.Size([128]), : 128\n: decoder_layers.2.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: decoder_layers.2.dense.W_in.bias, : torch.Size([512]), : 512\n: decoder_layers.2.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.2.dense.W_out.bias, : torch.Size([128]), : 128\n: W_out.weight, : torch.Size([21, 128]), : 2,688\n: W_out.bias, : torch.Size([21]), : 21","source":"_posts/proteinMPNN.md","raw":"---\ntitle: ProteinMPNN\nmathjax: true\ndate: 2025/10/27 20:46:25\nimg: https://www.researchgate.net/publication/363608659/figure/fig1/AS:11431281127577573@1679077202382/ProteinMPNN-architecture.jpg\nexcerpt:  ProteinMPNN \n---\n\n\n- MPNN  3  3  128 Ca-Ca  Ca-Ca-Ca  1 N  C CATH7PDB19.7k NCaCO  Cb  41.2% 49.0% 1 1; N-Ca-C  2 50.5%  3 16243248  64  Ca  S1A 32-48 \n\n![Table 1. Single chain sequence design performance on CATH held out test split. Test  accuracy (percentage of correct amino amino acids recovered) and test perplexity  (exponentiated categorical cross entropy loss per residue) are reported for models trained  on the native backbone coordinates (left, normal font) and models trained with Gaussian  noise (std=0.02A) added to the backbone coordinates (right, bold font); all test evaluations  are with no added noise. The final column shows sequence recovery on 5,000 AlphaFold  protein backbone models with average pLDDT > 80.0 randomly chosen from UniRef50  sequences.](./img/proteinMPNN/p1.png)\n\n\n\nACC\n\nPerplexity\n\nAF ACCAF\n\nstd=0.02A\n\n N  C  814; 1B329\n\n![Fig. 1. ProteinMPNN architecture. (A) Distances between N, Ca, C, O, and virtual Cb are  encoded and processed using a message passing neural network (Encoder) to obtain graph  node and edge features. The encoded features together with a partial sequence are used to  generate amino acids iteratively in a random decoding order. (B) A fixed left to right  decoding cannot use sequence context (green) for preceding positions (yellow) whereas a  model trained with random decoding orders can be used with arbitrary decoding order during  the inference. The decoding order can be chosen such that the fixed context is decoded first.  (C) Residue positions within and between chains can be tied together, enabling symmetric,  repeat protein, and multistate design. In this example, a homo-trimer is designed with  coupling of positions in different chains. Predicted logits for tied positions are averaged to  get a single probability distribution from which amino acids are sampled.](./img/proteinMPNN/p2.png)\n\nAEncoderNCaCOCbB C  logit \n\n\n\n![Fig. 2. In silico evaluation of ProteinMPNN. (A) ProteinMPNN has higher native sequence  recovery than Rosetta. The average Cb distance of the 8 closest neighbors (x axis) reports  on burial, with most buried positions on the left and more exposed on the right;  ProteinMPNN outperforms Rosetta at all levels of burial. Average sequence recovery for  ProteinMPNN was 52.4%, compared to 32.9% for Rosetta. (B) ProteinMPNN has similarly  high sequence recovery for monomers, homo-oligomers, and hetero-oligomers; violin plots  are for 690 monomers, 732 homomers, 98 heteromers. (C) Sequence recovery (black) and  relative AlphaFold success rates (blue) as a function of training noise level. For higher  accuracy predictions (circles) smaller amounts of noise are optimal (1.0 corresponds to 1.8%  success rate), while to maximize prediction success at a lower accuracy cutoff (squares),  models trained with more noise are better (1.0 corresponds to 6.7% success rate). (D)  Sequence recovery and diversity as a function of sampling temperature. Redesign of native  protein backbones with ProteinMPNN considerably increases AphaFold prediction accuracy compared to the original native sequence using no multiple sequence information. Single  sequences (designed or native) were input in both cases. (F) ProteinMPNN redesign of  previous Rosetta designed NTF2 fold proteins (3,000 backbones in total) results in  considerably improved AlphaFold single sequence prediction accuracy.](./img/proteinMPNN/p3.png)\n\nAProteinMPNNRosetta8Cbx; ProteinMPNN  RosettaProteinMPNN  52.4% Rosetta  32.9%BProteinMPNN; 690 732 98 CAlphaFold1.0  1.8% 1.0  6.7% D ProteinMPNN  AphaFold F  Rosetta  NTF2  3,000  ProteinMPNN  AlphaFold \n\n\n\nMPNN2DProteinMPNNS3A\n\n![Fig. 3. Structural characterization of ProteinMPNN designs. (A) Comparison of soluble  protein expression over a set of AlphaFold hallucinated monomers and homo-oligomers  (blue) and the same set of backbones with sequences designed using ProteinMPNN  (orange), N=129. The total soluble protein yield following expression in E. coli, obtained  from the integrated area unders size exclusion traces of nickel-NTA purified proteins,  increases considerably from the barely soluble protein of the original sequences following  ProteinMPNN rescue (median yields for 1 L of culture equivalent: 9 and 247 mg  respectively). (B), (C), (D) In depth characterization of a monomer hallucination and  corresponding ProteinMPNN rescue from the set in A. Like almost all of the designs in A, the sequence and structural similarity to the PDB of the design model are very low (E-value=2.8  against UniRef100 using HHblits, TM-score=0.56 against PDB). (B) The ProteinMPNN  rescued design has high thermostability, with a virtually unchanged circular dichroism profile  at 95 C compared to 25 C. (C) Size exclusion (SEC) profile of failed original design overlaid  with the ProteinMPNN sequence design, which has a clear monodisperse peak at the  expected retention volume. (D) Crystal structure of the ProteinMPNN (8CYK) design is  nearly identical to the design model (2.35 RMSD over 130 residues), see Figure S5 for  additional information. Right panel shows model sidechains in the electron density, in green  crystal side chains, in blue AlphaFold side chains. (E), (F) ProteinMPNN rescue of Rosetta  design made from a perfectly repeating structural and sequence unit (DHR82). Residues at  corresponding positions in the repeat unit were tied during ProteinMPNN sequence  inference. (E) Backbone design model and MPNN redesigned sequence AlphaFold model  with tied residues indicated by lines (~1.2A error over 232 residues). (F) SEC profile of IMAC  purified original Rosetta design and two ProteinMPNN redesigns. (G), (H) Tying residues  during ProteinMPNN sequence inference both within and between chains to enforce both  repeat protein and cyclic symmetries. (G) Side view of design model. A set of tied residues  are shown in red. (H) Top-down view of design model. (I) Negative stain electron  micrograph of purified design. (J) Class average of images from I closely match top down  view in H. (K) Rescue of the failed two-component Rosetta tetrahedral nanoparticle design  T33-27 (13) by ProteinMPNN interface design. Following ProteinMPNN rescue, the  nanoparticle assembled readily with high yield, and the crystal structure (grey) is very nearly  identical to the design model (green/purple) (backbone RMSD of 1.2 A over two complete  asymmetric units forming the ProteinMPNN rescued interface).](./img/proteinMPNN/p4.png)\n\nAAlphaFoldProteinMPNNN=129-NTAProteinMPNN1 L9247 mgBCD  A  ProteinMPNNAPDBHHblitsUniRef100E=2.8PDBTM=0.56BProteinMPNN25 C95 C CProteinMPNNSECDProteinMPNN8CYK1302.35 RMSDS5 AlphaFold EFDHR82RosettaMPNN ProteinMPNN EMPNNAlphaFold232~1.2FIMACRosettaProteinMPNNSECGH  ProteinMPNN GH IJ  I  H K  ProteinMPNN  Rosetta  T33-27 13 ProteinMPNN / ProteinMPNN  RMSD  1.2 \n\n![Fig. 4. Design of protein function with ProteinMPNN. (A) Design scheme. First panel;  structure (PDB 2W0Z) of the peptide APPPRPPKP bound to the human Grb2 C-term SH3  domain (peptide is in green, target in surface and colored blue). Second panel: helical  bundle scaffolds were docked to the exposed face of the peptide using RIFDOCK (19), and  Rosetta remodel was used to build loops connecting the peptide to the scaffolds. Rosetta  sequence design with layer design task operations was used to optimize the sequence of the  fusion (Cyan) for stability, rigidity of the peptide-helical bundle interface, and binding affinity  for the Grb2 SH3 domain. Third panel; ProteinMPNN redesign (orange) of the designed  binder sequence; hydrogen bonds involving asparagine sidechains between the peptide and  base scaffold are shown in green and in the inset. Fourth panel; Mutation of the two  asparagines to aspartates to disrupt the scaffolding of the target peptide. (B) Experimental  characterization of binding using biolayer interferometry. Biotinylated C-term SH3 domain  from human Grb2 was loaded onto Streptavidin (SA) Biosensors, which were then  immersed in solutions containing varying concentrations of the target peptide (left) of the  designs (right panels), and then transferred to buffer lacking added protein for dissociation measurements. The MPNN design (3rd panel from the left) has much greater binding signal  than the original Rosetta design (2nd panel from the left); this is greatly reduced by the  asparagine to aspartate mutations (last panel).](./img/proteinMPNN/p5.png)\n\n ProteinMPNN  Rosetta \n\nProteinMPNN  100  CPU  1.2  CPU  258.8 Rosetta 52.4%  32.9%  Rosetta  AlphaFold - 1-6 ProteinMPNN  TIM  6  S3 BC ; \n\n Rosetta ProteinMPNN ; Rosetta ; Rosetta   Rosetta  PDB  \n\nProteinMPNN Wicky ProteinMPNN ProteinMPNN  ProteinMPNN  ProteinMPNN \n\n## Methods\n\n### \n\n 1  CATH 4.2 40%  1 71Transformer2010%2110%226000tokenCa-Ca30\n\n### \n\n 10% 22  =  * / 2000  2000  [] Adambeta1 = 0.9beta2 = 0.98epsilon= 109 20  NVIDIA A100 GPU  pytorch 2410k  3D  150k  23,358  PDB  100  epoch\n\n## \n\n|                          |                              |                                          | /                                       |\n| -------------------------- | ------------------------------ | ---------------------------------------------- | --------------------------------------------- |\n| **Featurize()**            |      | Graph construction from backbone coordinates |  `(X, S, mask, chain_M, residue_idx, ...)`  |\n| **ProteinFeatures**        |  RBF | Feature construction and geometric encoding  |  `(X[B,L,4,3])`   `E[B,L,K,128]`      |\n| **Encoder (EncLayer  3)** |  message passing    | Structure encoder                            |  `(h_V[B,L,128], h_E[B,L,K,128])`           |\n| **Decoder (DecLayer  3)** |             | Autoregressive sequence decoder              |  `(h_V, h_E, h_S)`   `log_probs[B,L,21]` |\n| **Output Layer (W_out)**   |  logits              | Logits for amino acid types                  | `[B, L, 21]`                                  |\n\n- **Featurize(batch)**\n\n|                  |            |                                |\n| -------------------- | -------------- | ---------------------------------- |\n| `X`                  | `[B, L, 4, 3]` | N, CA, C, O  |\n| `S`                  | `[B, L]`       |              |\n| `mask`               | `[B, L]`       | 1                      |\n| `chain_M`            | `[B, L]`       | 1 masked chain |\n| `residue_idx`        | `[B, L]`       |        |\n| `chain_encoding_all` | `[B, L]`       |  ID                  |\n\n- **`ProteinFeatures`**\n\n`X (B,L,4,3)`\n\n\n- `E`: `[B, L, K, edge_dim=128]`\n- `E_idx`: `[B, L, K]`  top-K \n\n\n\n1.  **CC** \n2.  top-K \n3.  25 RBF NN, CC, OO, CCb, \n   -  `num_rbf=16`    `2516 = 400`\n4. offset embedding,  65 \n5.   `edge_features=128`\n6. LayerNorm\n\n>  E  message passing\n\nCb\n\nk-neighbor\n\nE_idx:\n\nD_neighbors:\n\n5*5=251616\\*25=400\n\nconcatlayernorm\n\nh_Eh_V\n\n- **Encoder**\n\n\n\n-  `h_V = zeros([B,L,128])`\n-  `h_E = W_e(E)`  `[B,L,K,128]`\n\n- \n  - `h_V [B,L,128]`\n  - `h_E [B,L,K,128]`\n- `h_EV = concat(h_V_i, h_E_ij, h_V_j)`  `[B,L,K,256]`\n- `W1  W2  W3` 128\n-  + LayerNorm + Dropout\n- FeedForward (128512128)\n-  `h_V, h_E` `[B,L,128]`, `[B,L,K,128]`\n\n- **Decoder**\n\n  \n\n  -  `h_V` encoder\n  -  `h_E`\n  -  `h_S = Embedding(S)`  `[B,L,128]`\n\n\n\n1. \n    `h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)`  `[B,L,K,256]`\n\n2. \n\n   -  masked \n   - mask_fwmask_bw\n\n3. \n    `h_EXV_encoder_fw = mask_fw * h_EXV_encoder`\n\n4. \n\n   ```\n   for i in range(3):\n       h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)\n       h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw\n       h_V = DecLayer(h_V, h_ESV)\n   ```\n\n5.  logits\n    `logits = W_out(h_V)`  `[B, L, 21]`\n    `log_probs = log_softmax(logits)`\n\n#### \n\n EncLayer \n\n- \n-  `[B,L,128]` `[B,L,128]`\n-  3  + GELU +  + LayerNorm\n- FeedForward (128512128)\n\n-  ****\n\n\n\n- `log_probs`: `[B, L, 21]`\n\n\n\n- `loss_nll`:  NLL\n- `loss_smoothed`:  label smoothing \n\n|                  |                 |          |                                                          |\n| -------------------- | ------------------- | ------------ | ------------------------------------------------------------ |\n| `X`                  | `[B, L_max, 4, 3]`  | float tensor |  N,CA,C,O  xyzpad  0 `mask`  0 |\n| `S`                  | `[B, L_max]`        | long tensor  | pad  0                               |\n| `mask`               | `[B, L_max]`        | float tensor | 1.0 0.0  pad         |\n| `lengths`            | `[B]`               | numpy int    |                                            |\n| `chain_M`            | `[B, L_max]`        | float tensor | 1.0 = masked0.0 = visible  |\n| `residue_idx`        | `[B, L_max]`        | long tensor  | /offset          |\n| `mask_self`          | `[B, L_max, L_max]` | float tensor | 0  interface1  interface loss |\n| `chain_encoding_all` | `[B, L_max]`        | long tensor  |  chain-aware embedding/              |\n\n**N, CA, C, O ** `C` `ProteinFeatures`  C RBF N,CA,C,O\n\n** NaN  padding** `isfinite`  0\n\n**`residue_idx` **offset/\n\n**`chain_M` ** + chain mask / order-agnostic decoding\n\n**`mask_self`** interface  interface loss \n\n\n\n==  == \n: features, : ProteinFeatures\n: W_e, : Linear #Encoder\n: W_s, : Embedding #Decoder\n: encoder_layers, : ModuleList\n: decoder_layers, : ModuleList\n: W_out, : Linear\n\n==  ==                                       \n: features.embeddings.linear.weight, : torch.Size([16, 66]), : 1,056\n: features.embeddings.linear.bias, : torch.Size([16]), : 16\n: features.edge_embedding.weight, : torch.Size([128, 416]), : 53,248\n: features.norm_edges.weight, : torch.Size([128]), : 128\n: features.norm_edges.bias, : torch.Size([128]), : 128\n: W_e.weight, : torch.Size([128, 128]), : 16,384\n: W_e.bias, : torch.Size([128]), : 128 \n: W_s.weight, : torch.Size([21, 128]), : 2,688\n: encoder_layers.0.norm1.weight, : torch.Size([128]), : 128\n: encoder_layers.0.norm1.bias, : torch.Size([128]), : 128\n: encoder_layers.0.norm2.weight, : torch.Size([128]), : 128\n: encoder_layers.0.norm2.bias, : torch.Size([128]), : 128\n: encoder_layers.0.norm3.weight, : torch.Size([128]), : 128\n: encoder_layers.0.norm3.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W1.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.0.W1.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W2.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.0.W2.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W3.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.0.W3.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W11.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.0.W11.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W12.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.0.W12.bias, : torch.Size([128]), : 128\n: encoder_layers.0.W13.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.0.W13.bias, : torch.Size([128]), : 128\n: encoder_layers.0.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: encoder_layers.0.dense.W_in.bias, : torch.Size([512]), : 512\n: encoder_layers.0.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: encoder_layers.0.dense.W_out.bias, : torch.Size([128]), : 128\n: encoder_layers.1.norm1.weight, : torch.Size([128]), : 128\n: encoder_layers.1.norm1.bias, : torch.Size([128]), : 128\n: encoder_layers.1.norm2.weight, : torch.Size([128]), : 128\n: encoder_layers.1.norm2.bias, : torch.Size([128]), : 128\n: encoder_layers.1.norm3.weight, : torch.Size([128]), : 128\n: encoder_layers.1.norm3.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W1.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.1.W1.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W2.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.1.W2.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W3.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.1.W3.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W11.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.1.W11.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W12.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.1.W12.bias, : torch.Size([128]), : 128\n: encoder_layers.1.W13.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.1.W13.bias, : torch.Size([128]), : 128\n: encoder_layers.1.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: encoder_layers.1.dense.W_in.bias, : torch.Size([512]), : 512\n: encoder_layers.1.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: encoder_layers.1.dense.W_out.bias, : torch.Size([128]), : 128\n: encoder_layers.2.norm1.weight, : torch.Size([128]), : 128\n: encoder_layers.2.norm1.bias, : torch.Size([128]), : 128\n: encoder_layers.2.norm2.weight, : torch.Size([128]), : 128\n: encoder_layers.2.norm2.bias, : torch.Size([128]), : 128\n: encoder_layers.2.norm3.weight, : torch.Size([128]), : 128\n: encoder_layers.2.norm3.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W1.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.2.W1.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W2.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.2.W2.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W3.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.2.W3.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W11.weight, : torch.Size([128, 384]), : 49,152\n: encoder_layers.2.W11.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W12.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.2.W12.bias, : torch.Size([128]), : 128\n: encoder_layers.2.W13.weight, : torch.Size([128, 128]), : 16,384\n: encoder_layers.2.W13.bias, : torch.Size([128]), : 128\n: encoder_layers.2.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: encoder_layers.2.dense.W_in.bias, : torch.Size([512]), : 512\n: encoder_layers.2.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: encoder_layers.2.dense.W_out.bias, : torch.Size([128]), : 128\n: decoder_layers.0.norm1.weight, : torch.Size([128]), : 128\n: decoder_layers.0.norm1.bias, : torch.Size([128]), : 128\n: decoder_layers.0.norm2.weight, : torch.Size([128]), : 128\n: decoder_layers.0.norm2.bias, : torch.Size([128]), : 128\n: decoder_layers.0.W1.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.0.W1.bias, : torch.Size([128]), : 128\n: decoder_layers.0.W2.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.0.W2.bias, : torch.Size([128]), : 128\n: decoder_layers.0.W3.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.0.W3.bias, : torch.Size([128]), : 128\n: decoder_layers.0.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: decoder_layers.0.dense.W_in.bias, : torch.Size([512]), : 512\n: decoder_layers.0.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.0.dense.W_out.bias, : torch.Size([128]), : 128\n: decoder_layers.1.norm1.weight, : torch.Size([128]), : 128\n: decoder_layers.1.norm1.bias, : torch.Size([128]), : 128\n: decoder_layers.1.norm2.weight, : torch.Size([128]), : 128\n: decoder_layers.1.norm2.bias, : torch.Size([128]), : 128\n: decoder_layers.1.W1.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.1.W1.bias, : torch.Size([128]), : 128\n: decoder_layers.1.W2.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.1.W2.bias, : torch.Size([128]), : 128\n: decoder_layers.1.W3.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.1.W3.bias, : torch.Size([128]), : 128\n: decoder_layers.1.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: decoder_layers.1.dense.W_in.bias, : torch.Size([512]), : 512\n: decoder_layers.1.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.1.dense.W_out.bias, : torch.Size([128]), : 128\n: decoder_layers.2.norm1.weight, : torch.Size([128]), : 128\n: decoder_layers.2.norm1.bias, : torch.Size([128]), : 128\n: decoder_layers.2.norm2.weight, : torch.Size([128]), : 128\n: decoder_layers.2.norm2.bias, : torch.Size([128]), : 128\n: decoder_layers.2.W1.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.2.W1.bias, : torch.Size([128]), : 128\n: decoder_layers.2.W2.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.2.W2.bias, : torch.Size([128]), : 128\n: decoder_layers.2.W3.weight, : torch.Size([128, 128]), : 16,384\n: decoder_layers.2.W3.bias, : torch.Size([128]), : 128\n: decoder_layers.2.dense.W_in.weight, : torch.Size([512, 128]), : 65,536\n: decoder_layers.2.dense.W_in.bias, : torch.Size([512]), : 512\n: decoder_layers.2.dense.W_out.weight, : torch.Size([128, 512]), : 65,536\n: decoder_layers.2.dense.W_out.bias, : torch.Size([128]), : 128\n: W_out.weight, : torch.Size([21, 128]), : 2,688\n: W_out.bias, : torch.Size([21]), : 21","slug":"proteinMPNN","published":1,"updated":"2026-01-23T07:34:45.449Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ffa000oss992u051m1v","content":"<p></p>\n<p>- MPNN  3  3  128 Ca-Ca  Ca-Ca-Ca  1 N  C CATH7PDB19.7k NCaCO  Cb  41.2% 49.0% 1 1; N-Ca-C  2 50.5%  3 16243248  64  Ca  S1A 32-48 </p>\n<p><img src=\"/./img/proteinMPNN/p1.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/proteinMPNN/p1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Table 1. Single chain sequence design performance on CATH held out test split. Test  accuracy (percentage of correct amino amino acids recovered) and test perplexity  (exponentiated categorical cross entropy loss per residue) are reported for models trained  on the native backbone coordinates (left, normal font) and models trained with Gaussian  noise (std=0.02A) added to the backbone coordinates (right, bold font); all test evaluations  are with no added noise. The final column shows sequence recovery on 5,000 AlphaFold  protein backbone models with average pLDDT &gt; 80.0 randomly chosen from UniRef50  sequences.\"></p>\n<p></p>\n<p>ACC</p>\n<p>Perplexity</p>\n<p>AF ACCAF</p>\n<p>std&#x3D;0.02A</p>\n<p> N  C  814; 1B329</p>\n<p><img src=\"/./img/proteinMPNN/p2.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/proteinMPNN/p2.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Fig. 1. ProteinMPNN architecture. (A) Distances between N, Ca, C, O, and virtual Cb are  encoded and processed using a message passing neural network (Encoder) to obtain graph  node and edge features. The encoded features together with a partial sequence are used to  generate amino acids iteratively in a random decoding order. (B) A fixed left to right  decoding cannot use sequence context (green) for preceding positions (yellow) whereas a  model trained with random decoding orders can be used with arbitrary decoding order during  the inference. The decoding order can be chosen such that the fixed context is decoded first.  (C) Residue positions within and between chains can be tied together, enabling symmetric,  repeat protein, and multistate design. In this example, a homo-trimer is designed with  coupling of positions in different chains. Predicted logits for tied positions are averaged to  get a single probability distribution from which amino acids are sampled.\"></p>\n<p>AEncoderNCaCOCbB C  logit </p>\n<p></p>\n<p><img src=\"/./img/proteinMPNN/p3.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/proteinMPNN/p3.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Fig. 2. In silico evaluation of ProteinMPNN. (A) ProteinMPNN has higher native sequence  recovery than Rosetta. The average Cb distance of the 8 closest neighbors (x axis) reports  on burial, with most buried positions on the left and more exposed on the right;  ProteinMPNN outperforms Rosetta at all levels of burial. Average sequence recovery for  ProteinMPNN was 52.4%, compared to 32.9% for Rosetta. (B) ProteinMPNN has similarly  high sequence recovery for monomers, homo-oligomers, and hetero-oligomers; violin plots  are for 690 monomers, 732 homomers, 98 heteromers. (C) Sequence recovery (black) and  relative AlphaFold success rates (blue) as a function of training noise level. For higher  accuracy predictions (circles) smaller amounts of noise are optimal (1.0 corresponds to 1.8%  success rate), while to maximize prediction success at a lower accuracy cutoff (squares),  models trained with more noise are better (1.0 corresponds to 6.7% success rate). (D)  Sequence recovery and diversity as a function of sampling temperature. Redesign of native  protein backbones with ProteinMPNN considerably increases AphaFold prediction accuracy compared to the original native sequence using no multiple sequence information. Single  sequences (designed or native) were input in both cases. (F) ProteinMPNN redesign of  previous Rosetta designed NTF2 fold proteins (3,000 backbones in total) results in  considerably improved AlphaFold single sequence prediction accuracy.\"></p>\n<p>AProteinMPNNRosetta8Cbx; ProteinMPNN  RosettaProteinMPNN  52.4% Rosetta  32.9%BProteinMPNN; 690 732 98 CAlphaFold1.0  1.8% 1.0  6.7% D ProteinMPNN  AphaFold F  Rosetta  NTF2  3,000  ProteinMPNN  AlphaFold </p>\n<p></p>\n<p>MPNN2DProteinMPNNS3A</p>\n<p><img src=\"/./img/proteinMPNN/p4.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/proteinMPNN/p4.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Fig. 3. Structural characterization of ProteinMPNN designs. (A) Comparison of soluble  protein expression over a set of AlphaFold hallucinated monomers and homo-oligomers  (blue) and the same set of backbones with sequences designed using ProteinMPNN  (orange), N=129. The total soluble protein yield following expression in E. coli, obtained  from the integrated area unders size exclusion traces of nickel-NTA purified proteins,  increases considerably from the barely soluble protein of the original sequences following  ProteinMPNN rescue (median yields for 1 L of culture equivalent: 9 and 247 mg  respectively). (B), (C), (D) In depth characterization of a monomer hallucination and  corresponding ProteinMPNN rescue from the set in A. Like almost all of the designs in A, the sequence and structural similarity to the PDB of the design model are very low (E-value=2.8  against UniRef100 using HHblits, TM-score=0.56 against PDB). (B) The ProteinMPNN  rescued design has high thermostability, with a virtually unchanged circular dichroism profile  at 95 C compared to 25 C. (C) Size exclusion (SEC) profile of failed original design overlaid  with the ProteinMPNN sequence design, which has a clear monodisperse peak at the  expected retention volume. (D) Crystal structure of the ProteinMPNN (8CYK) design is  nearly identical to the design model (2.35 RMSD over 130 residues), see Figure S5 for  additional information. Right panel shows model sidechains in the electron density, in green  crystal side chains, in blue AlphaFold side chains. (E), (F) ProteinMPNN rescue of Rosetta  design made from a perfectly repeating structural and sequence unit (DHR82). Residues at  corresponding positions in the repeat unit were tied during ProteinMPNN sequence  inference. (E) Backbone design model and MPNN redesigned sequence AlphaFold model  with tied residues indicated by lines (~1.2A error over 232 residues). (F) SEC profile of IMAC  purified original Rosetta design and two ProteinMPNN redesigns. (G), (H) Tying residues  during ProteinMPNN sequence inference both within and between chains to enforce both  repeat protein and cyclic symmetries. (G) Side view of design model. A set of tied residues  are shown in red. (H) Top-down view of design model. (I) Negative stain electron  micrograph of purified design. (J) Class average of images from I closely match top down  view in H. (K) Rescue of the failed two-component Rosetta tetrahedral nanoparticle design  T33-27 (13) by ProteinMPNN interface design. Following ProteinMPNN rescue, the  nanoparticle assembled readily with high yield, and the crystal structure (grey) is very nearly  identical to the design model (green/purple) (backbone RMSD of 1.2 A over two complete  asymmetric units forming the ProteinMPNN rescued interface).\"></p>\n<p>AAlphaFoldProteinMPNNN&#x3D;129-NTAProteinMPNN1 L9247 mgBCD  A  ProteinMPNNAPDBHHblitsUniRef100E&#x3D;2.8PDBTM&#x3D;0.56BProteinMPNN25 C95 C CProteinMPNNSECDProteinMPNN8CYK1302.35 RMSDS5 AlphaFold EFDHR82RosettaMPNN ProteinMPNN EMPNNAlphaFold232~1.2FIMACRosettaProteinMPNNSECGH  ProteinMPNN GH IJ  I  H K  ProteinMPNN  Rosetta  T33-27 13 ProteinMPNN &#x2F; ProteinMPNN  RMSD  1.2 </p>\n<p><img src=\"/./img/proteinMPNN/p5.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/proteinMPNN/p5.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Fig. 4. Design of protein function with ProteinMPNN. (A) Design scheme. First panel;  structure (PDB 2W0Z) of the peptide APPPRPPKP bound to the human Grb2 C-term SH3  domain (peptide is in green, target in surface and colored blue). Second panel: helical  bundle scaffolds were docked to the exposed face of the peptide using RIFDOCK (19), and  Rosetta remodel was used to build loops connecting the peptide to the scaffolds. Rosetta  sequence design with layer design task operations was used to optimize the sequence of the  fusion (Cyan) for stability, rigidity of the peptide-helical bundle interface, and binding affinity  for the Grb2 SH3 domain. Third panel; ProteinMPNN redesign (orange) of the designed  binder sequence; hydrogen bonds involving asparagine sidechains between the peptide and  base scaffold are shown in green and in the inset. Fourth panel; Mutation of the two  asparagines to aspartates to disrupt the scaffolding of the target peptide. (B) Experimental  characterization of binding using biolayer interferometry. Biotinylated C-term SH3 domain  from human Grb2 was loaded onto Streptavidin (SA) Biosensors, which were then  immersed in solutions containing varying concentrations of the target peptide (left) of the  designs (right panels), and then transferred to buffer lacking added protein for dissociation measurements. The MPNN design (3rd panel from the left) has much greater binding signal  than the original Rosetta design (2nd panel from the left); this is greatly reduced by the  asparagine to aspartate mutations (last panel).\"></p>\n<p> ProteinMPNN  Rosetta </p>\n<p>ProteinMPNN  100  CPU  1.2  CPU  258.8 Rosetta 52.4%  32.9%  Rosetta  AlphaFold - 1-6 ProteinMPNN  TIM  6  S3 BC ; </p>\n<p> Rosetta ProteinMPNN ; Rosetta ; Rosetta   Rosetta  PDB  </p>\n<p>ProteinMPNN Wicky ProteinMPNN ProteinMPNN  ProteinMPNN  ProteinMPNN </p>\n<h2 id=\"Methods\"><a href=\"#Methods\" class=\"headerlink\" title=\"Methods\"></a>Methods</h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 1  CATH 4.2 40%  1 71Transformer2010%2110%226000tokenCa-Ca30</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 10% 22  &#x3D;  * &#x2F; 2000  2000  [] Adambeta1 &#x3D; 0.9beta2 &#x3D; 0.98epsilon&#x3D; 109 20  NVIDIA A100 GPU  pytorch 2410k  3D  150k  23,358  PDB  100  epoch</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th>&#x2F;</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Featurize()</strong></td>\n<td></td>\n<td>Graph construction from backbone coordinates</td>\n<td> <code>(X, S, mask, chain_M, residue_idx, ...)</code></td>\n</tr>\n<tr>\n<td><strong>ProteinFeatures</strong></td>\n<td> RBF</td>\n<td>Feature construction and geometric encoding</td>\n<td> <code>(X[B,L,4,3])</code>   <code>E[B,L,K,128]</code></td>\n</tr>\n<tr>\n<td><strong>Encoder (EncLayer  3)</strong></td>\n<td> message passing</td>\n<td>Structure encoder</td>\n<td> <code>(h_V[B,L,128], h_E[B,L,K,128])</code></td>\n</tr>\n<tr>\n<td><strong>Decoder (DecLayer  3)</strong></td>\n<td></td>\n<td>Autoregressive sequence decoder</td>\n<td> <code>(h_V, h_E, h_S)</code>   <code>log_probs[B,L,21]</code></td>\n</tr>\n<tr>\n<td><strong>Output Layer (W_out)</strong></td>\n<td> logits</td>\n<td>Logits for amino acid types</td>\n<td><code>[B, L, 21]</code></td>\n</tr>\n</tbody></table>\n<ul>\n<li><strong>Featurize(batch)</strong></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>X</code></td>\n<td><code>[B, L, 4, 3]</code></td>\n<td>N, CA, C, O</td>\n</tr>\n<tr>\n<td><code>S</code></td>\n<td><code>[B, L]</code></td>\n<td></td>\n</tr>\n<tr>\n<td><code>mask</code></td>\n<td><code>[B, L]</code></td>\n<td>1 </td>\n</tr>\n<tr>\n<td><code>chain_M</code></td>\n<td><code>[B, L]</code></td>\n<td>1 masked chain</td>\n</tr>\n<tr>\n<td><code>residue_idx</code></td>\n<td><code>[B, L]</code></td>\n<td></td>\n</tr>\n<tr>\n<td><code>chain_encoding_all</code></td>\n<td><code>[B, L]</code></td>\n<td> ID</td>\n</tr>\n</tbody></table>\n<ul>\n<li><strong><code>ProteinFeatures</code></strong></li>\n</ul>\n<p><code>X (B,L,4,3)</code><br></p>\n<ul>\n<li><code>E</code>: <code>[B, L, K, edge_dim=128]</code></li>\n<li><code>E_idx</code>: <code>[B, L, K]</code>  top-K </li>\n</ul>\n<p></p>\n<ol>\n<li> <strong>CC</strong> </li>\n<li> top-K </li>\n<li> 25 RBF NN, CC, OO, CCb, <ul>\n<li> <code>num_rbf=16</code>    <code>2516 = 400</code></li>\n</ul>\n</li>\n<li>offset embedding,  65 </li>\n<li>  <code>edge_features=128</code></li>\n<li>LayerNorm</li>\n</ol>\n<blockquote>\n<p> E  message passing</p>\n</blockquote>\n<p>Cb</p>\n<p>k-neighbor</p>\n<p>E_idx:</p>\n<p>D_neighbors:</p>\n<p>5*5&#x3D;251616*25&#x3D;400</p>\n<p>concatlayernorm</p>\n<p>h_Eh_V</p>\n<ul>\n<li><strong>Encoder</strong></li>\n</ul>\n<p></p>\n<ul>\n<li><p> <code>h_V = zeros([B,L,128])</code></p>\n</li>\n<li><p> <code>h_E = W_e(E)</code>  <code>[B,L,K,128]</code></p>\n</li>\n<li><p></p>\n<ul>\n<li><code>h_V [B,L,128]</code></li>\n<li><code>h_E [B,L,K,128]</code></li>\n</ul>\n</li>\n<li><p><code>h_EV = concat(h_V_i, h_E_ij, h_V_j)</code>  <code>[B,L,K,256]</code></p>\n</li>\n<li><p><code>W1  W2  W3</code> 128</p>\n</li>\n<li><p> + LayerNorm + Dropout</p>\n</li>\n<li><p>FeedForward (128512128)</p>\n</li>\n<li><p> <code>h_V, h_E</code> <code>[B,L,128]</code>, <code>[B,L,K,128]</code></p>\n</li>\n<li><p><strong>Decoder</strong></p>\n<p></p>\n<ul>\n<li> <code>h_V</code> encoder</li>\n<li> <code>h_E</code></li>\n<li> <code>h_S = Embedding(S)</code>  <code>[B,L,128]</code></li>\n</ul>\n</li>\n</ul>\n<p></p>\n<ol>\n<li><p><br> <code>h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)</code>  <code>[B,L,K,256]</code></p>\n</li>\n<li><p></p>\n<ul>\n<li> masked </li>\n<li>mask_fwmask_bw</li>\n</ul>\n</li>\n<li><p><br> <code>h_EXV_encoder_fw = mask_fw * h_EXV_encoder</code></p>\n</li>\n<li><p></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for i in range(3):</span><br><span class=\"line\">    h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)</span><br><span class=\"line\">    h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw</span><br><span class=\"line\">    h_V = DecLayer(h_V, h_ESV)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p> logits<br> <code>logits = W_out(h_V)</code>  <code>[B, L, 21]</code><br> <code>log_probs = log_softmax(logits)</code></p>\n</li>\n</ol>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p> EncLayer </p>\n<ul>\n<li><p></p>\n</li>\n<li><p> <code>[B,L,128]</code> <code>[B,L,128]</code></p>\n</li>\n<li><p> 3  + GELU +  + LayerNorm</p>\n</li>\n<li><p>FeedForward (128512128)</p>\n</li>\n<li><p><strong></strong></p>\n</li>\n</ul>\n<p></p>\n<ul>\n<li><code>log_probs</code>: <code>[B, L, 21]</code></li>\n</ul>\n<p></p>\n<ul>\n<li><code>loss_nll</code>:  NLL</li>\n<li><code>loss_smoothed</code>:  label smoothing </li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>X</code></td>\n<td><code>[B, L_max, 4, 3]</code></td>\n<td>float tensor</td>\n<td> N,CA,C,O  xyzpad  0 <code>mask</code>  0</td>\n</tr>\n<tr>\n<td><code>S</code></td>\n<td><code>[B, L_max]</code></td>\n<td>long tensor</td>\n<td>pad  0</td>\n</tr>\n<tr>\n<td><code>mask</code></td>\n<td><code>[B, L_max]</code></td>\n<td>float tensor</td>\n<td>1.0 0.0  pad</td>\n</tr>\n<tr>\n<td><code>lengths</code></td>\n<td><code>[B]</code></td>\n<td>numpy int</td>\n<td></td>\n</tr>\n<tr>\n<td><code>chain_M</code></td>\n<td><code>[B, L_max]</code></td>\n<td>float tensor</td>\n<td>1.0 &#x3D; masked0.0 &#x3D; visible</td>\n</tr>\n<tr>\n<td><code>residue_idx</code></td>\n<td><code>[B, L_max]</code></td>\n<td>long tensor</td>\n<td>&#x2F;offset</td>\n</tr>\n<tr>\n<td><code>mask_self</code></td>\n<td><code>[B, L_max, L_max]</code></td>\n<td>float tensor</td>\n<td>0  interface1  interface loss</td>\n</tr>\n<tr>\n<td><code>chain_encoding_all</code></td>\n<td><code>[B, L_max]</code></td>\n<td>long tensor</td>\n<td> chain-aware embedding&#x2F;</td>\n</tr>\n</tbody></table>\n<p><strong>N, CA, C, O </strong> <code>C</code> <code>ProteinFeatures</code>  C RBF N,CA,C,O</p>\n<p><strong> NaN  padding</strong> <code>isfinite</code>  0</p>\n<p><strong><code>residue_idx</code> </strong>offset&#x2F;</p>\n<p><strong><code>chain_M</code> </strong> + chain mask &#x2F; order-agnostic decoding</p>\n<p>**<code>mask_self</code>** interface  interface loss </p>\n<p>&#x3D;&#x3D;  &#x3D;&#x3D;<br>: features, : ProteinFeatures<br>: W_e, : Linear #Encoder<br>: W_s, : Embedding #Decoder<br>: encoder_layers, : ModuleList<br>: decoder_layers, : ModuleList<br>: W_out, : Linear</p>\n<p>&#x3D;&#x3D;  &#x3D;&#x3D;<br>: features.embeddings.linear.weight, : torch.Size([16, 66]), : 1,056<br>: features.embeddings.linear.bias, : torch.Size([16]), : 16<br>: features.edge_embedding.weight, : torch.Size([128, 416]), : 53,248<br>: features.norm_edges.weight, : torch.Size([128]), : 128<br>: features.norm_edges.bias, : torch.Size([128]), : 128<br>: W_e.weight, : torch.Size([128, 128]), : 16,384<br>: W_e.bias, : torch.Size([128]), : 128<br>: W_s.weight, : torch.Size([21, 128]), : 2,688<br>: encoder_layers.0.norm1.weight, : torch.Size([128]), : 128<br>: encoder_layers.0.norm1.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.norm2.weight, : torch.Size([128]), : 128<br>: encoder_layers.0.norm2.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.norm3.weight, : torch.Size([128]), : 128<br>: encoder_layers.0.norm3.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W1.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.0.W1.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W2.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.0.W2.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W3.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.0.W3.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W11.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.0.W11.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W12.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.0.W12.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W13.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.0.W13.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: encoder_layers.0.dense.W_in.bias, : torch.Size([512]), : 512<br>: encoder_layers.0.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: encoder_layers.0.dense.W_out.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.norm1.weight, : torch.Size([128]), : 128<br>: encoder_layers.1.norm1.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.norm2.weight, : torch.Size([128]), : 128<br>: encoder_layers.1.norm2.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.norm3.weight, : torch.Size([128]), : 128<br>: encoder_layers.1.norm3.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W1.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.1.W1.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W2.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.1.W2.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W3.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.1.W3.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W11.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.1.W11.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W12.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.1.W12.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W13.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.1.W13.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: encoder_layers.1.dense.W_in.bias, : torch.Size([512]), : 512<br>: encoder_layers.1.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: encoder_layers.1.dense.W_out.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.norm1.weight, : torch.Size([128]), : 128<br>: encoder_layers.2.norm1.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.norm2.weight, : torch.Size([128]), : 128<br>: encoder_layers.2.norm2.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.norm3.weight, : torch.Size([128]), : 128<br>: encoder_layers.2.norm3.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W1.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.2.W1.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W2.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.2.W2.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W3.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.2.W3.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W11.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.2.W11.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W12.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.2.W12.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W13.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.2.W13.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: encoder_layers.2.dense.W_in.bias, : torch.Size([512]), : 512<br>: encoder_layers.2.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: encoder_layers.2.dense.W_out.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.norm1.weight, : torch.Size([128]), : 128<br>: decoder_layers.0.norm1.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.norm2.weight, : torch.Size([128]), : 128<br>: decoder_layers.0.norm2.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.W1.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.0.W1.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.W2.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.0.W2.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.W3.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.0.W3.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: decoder_layers.0.dense.W_in.bias, : torch.Size([512]), : 512<br>: decoder_layers.0.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.0.dense.W_out.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.norm1.weight, : torch.Size([128]), : 128<br>: decoder_layers.1.norm1.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.norm2.weight, : torch.Size([128]), : 128<br>: decoder_layers.1.norm2.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.W1.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.1.W1.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.W2.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.1.W2.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.W3.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.1.W3.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: decoder_layers.1.dense.W_in.bias, : torch.Size([512]), : 512<br>: decoder_layers.1.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.1.dense.W_out.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.norm1.weight, : torch.Size([128]), : 128<br>: decoder_layers.2.norm1.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.norm2.weight, : torch.Size([128]), : 128<br>: decoder_layers.2.norm2.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.W1.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.2.W1.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.W2.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.2.W2.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.W3.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.2.W3.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: decoder_layers.2.dense.W_in.bias, : torch.Size([512]), : 512<br>: decoder_layers.2.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.2.dense.W_out.bias, : torch.Size([128]), : 128<br>: W_out.weight, : torch.Size([21, 128]), : 2,688<br>: W_out.bias, : torch.Size([21]), : 21</p>\n","more":"<p></p>\n<p>- MPNN  3  3  128 Ca-Ca  Ca-Ca-Ca  1 N  C CATH7PDB19.7k NCaCO  Cb  41.2% 49.0% 1 1; N-Ca-C  2 50.5%  3 16243248  64  Ca  S1A 32-48 </p>\n<p><img src=\"/./img/proteinMPNN/p1.png\" alt=\"Table 1. Single chain sequence design performance on CATH held out test split. Test  accuracy (percentage of correct amino amino acids recovered) and test perplexity  (exponentiated categorical cross entropy loss per residue) are reported for models trained  on the native backbone coordinates (left, normal font) and models trained with Gaussian  noise (std=0.02A) added to the backbone coordinates (right, bold font); all test evaluations  are with no added noise. The final column shows sequence recovery on 5,000 AlphaFold  protein backbone models with average pLDDT &gt; 80.0 randomly chosen from UniRef50  sequences.\"></p>\n<p></p>\n<p>ACC</p>\n<p>Perplexity</p>\n<p>AF ACCAF</p>\n<p>std&#x3D;0.02A</p>\n<p> N  C  814; 1B329</p>\n<p><img src=\"/./img/proteinMPNN/p2.png\" alt=\"Fig. 1. ProteinMPNN architecture. (A) Distances between N, Ca, C, O, and virtual Cb are  encoded and processed using a message passing neural network (Encoder) to obtain graph  node and edge features. The encoded features together with a partial sequence are used to  generate amino acids iteratively in a random decoding order. (B) A fixed left to right  decoding cannot use sequence context (green) for preceding positions (yellow) whereas a  model trained with random decoding orders can be used with arbitrary decoding order during  the inference. The decoding order can be chosen such that the fixed context is decoded first.  (C) Residue positions within and between chains can be tied together, enabling symmetric,  repeat protein, and multistate design. In this example, a homo-trimer is designed with  coupling of positions in different chains. Predicted logits for tied positions are averaged to  get a single probability distribution from which amino acids are sampled.\"></p>\n<p>AEncoderNCaCOCbB C  logit </p>\n<p></p>\n<p><img src=\"/./img/proteinMPNN/p3.png\" alt=\"Fig. 2. In silico evaluation of ProteinMPNN. (A) ProteinMPNN has higher native sequence  recovery than Rosetta. The average Cb distance of the 8 closest neighbors (x axis) reports  on burial, with most buried positions on the left and more exposed on the right;  ProteinMPNN outperforms Rosetta at all levels of burial. Average sequence recovery for  ProteinMPNN was 52.4%, compared to 32.9% for Rosetta. (B) ProteinMPNN has similarly  high sequence recovery for monomers, homo-oligomers, and hetero-oligomers; violin plots  are for 690 monomers, 732 homomers, 98 heteromers. (C) Sequence recovery (black) and  relative AlphaFold success rates (blue) as a function of training noise level. For higher  accuracy predictions (circles) smaller amounts of noise are optimal (1.0 corresponds to 1.8%  success rate), while to maximize prediction success at a lower accuracy cutoff (squares),  models trained with more noise are better (1.0 corresponds to 6.7% success rate). (D)  Sequence recovery and diversity as a function of sampling temperature. Redesign of native  protein backbones with ProteinMPNN considerably increases AphaFold prediction accuracy compared to the original native sequence using no multiple sequence information. Single  sequences (designed or native) were input in both cases. (F) ProteinMPNN redesign of  previous Rosetta designed NTF2 fold proteins (3,000 backbones in total) results in  considerably improved AlphaFold single sequence prediction accuracy.\"></p>\n<p>AProteinMPNNRosetta8Cbx; ProteinMPNN  RosettaProteinMPNN  52.4% Rosetta  32.9%BProteinMPNN; 690 732 98 CAlphaFold1.0  1.8% 1.0  6.7% D ProteinMPNN  AphaFold F  Rosetta  NTF2  3,000  ProteinMPNN  AlphaFold </p>\n<p></p>\n<p>MPNN2DProteinMPNNS3A</p>\n<p><img src=\"/./img/proteinMPNN/p4.png\" alt=\"Fig. 3. Structural characterization of ProteinMPNN designs. (A) Comparison of soluble  protein expression over a set of AlphaFold hallucinated monomers and homo-oligomers  (blue) and the same set of backbones with sequences designed using ProteinMPNN  (orange), N=129. The total soluble protein yield following expression in E. coli, obtained  from the integrated area unders size exclusion traces of nickel-NTA purified proteins,  increases considerably from the barely soluble protein of the original sequences following  ProteinMPNN rescue (median yields for 1 L of culture equivalent: 9 and 247 mg  respectively). (B), (C), (D) In depth characterization of a monomer hallucination and  corresponding ProteinMPNN rescue from the set in A. Like almost all of the designs in A, the sequence and structural similarity to the PDB of the design model are very low (E-value=2.8  against UniRef100 using HHblits, TM-score=0.56 against PDB). (B) The ProteinMPNN  rescued design has high thermostability, with a virtually unchanged circular dichroism profile  at 95 C compared to 25 C. (C) Size exclusion (SEC) profile of failed original design overlaid  with the ProteinMPNN sequence design, which has a clear monodisperse peak at the  expected retention volume. (D) Crystal structure of the ProteinMPNN (8CYK) design is  nearly identical to the design model (2.35 RMSD over 130 residues), see Figure S5 for  additional information. Right panel shows model sidechains in the electron density, in green  crystal side chains, in blue AlphaFold side chains. (E), (F) ProteinMPNN rescue of Rosetta  design made from a perfectly repeating structural and sequence unit (DHR82). Residues at  corresponding positions in the repeat unit were tied during ProteinMPNN sequence  inference. (E) Backbone design model and MPNN redesigned sequence AlphaFold model  with tied residues indicated by lines (~1.2A error over 232 residues). (F) SEC profile of IMAC  purified original Rosetta design and two ProteinMPNN redesigns. (G), (H) Tying residues  during ProteinMPNN sequence inference both within and between chains to enforce both  repeat protein and cyclic symmetries. (G) Side view of design model. A set of tied residues  are shown in red. (H) Top-down view of design model. (I) Negative stain electron  micrograph of purified design. (J) Class average of images from I closely match top down  view in H. (K) Rescue of the failed two-component Rosetta tetrahedral nanoparticle design  T33-27 (13) by ProteinMPNN interface design. Following ProteinMPNN rescue, the  nanoparticle assembled readily with high yield, and the crystal structure (grey) is very nearly  identical to the design model (green/purple) (backbone RMSD of 1.2 A over two complete  asymmetric units forming the ProteinMPNN rescued interface).\"></p>\n<p>AAlphaFoldProteinMPNNN&#x3D;129-NTAProteinMPNN1 L9247 mgBCD  A  ProteinMPNNAPDBHHblitsUniRef100E&#x3D;2.8PDBTM&#x3D;0.56BProteinMPNN25 C95 C CProteinMPNNSECDProteinMPNN8CYK1302.35 RMSDS5 AlphaFold EFDHR82RosettaMPNN ProteinMPNN EMPNNAlphaFold232~1.2FIMACRosettaProteinMPNNSECGH  ProteinMPNN GH IJ  I  H K  ProteinMPNN  Rosetta  T33-27 13 ProteinMPNN &#x2F; ProteinMPNN  RMSD  1.2 </p>\n<p><img src=\"/./img/proteinMPNN/p5.png\" alt=\"Fig. 4. Design of protein function with ProteinMPNN. (A) Design scheme. First panel;  structure (PDB 2W0Z) of the peptide APPPRPPKP bound to the human Grb2 C-term SH3  domain (peptide is in green, target in surface and colored blue). Second panel: helical  bundle scaffolds were docked to the exposed face of the peptide using RIFDOCK (19), and  Rosetta remodel was used to build loops connecting the peptide to the scaffolds. Rosetta  sequence design with layer design task operations was used to optimize the sequence of the  fusion (Cyan) for stability, rigidity of the peptide-helical bundle interface, and binding affinity  for the Grb2 SH3 domain. Third panel; ProteinMPNN redesign (orange) of the designed  binder sequence; hydrogen bonds involving asparagine sidechains between the peptide and  base scaffold are shown in green and in the inset. Fourth panel; Mutation of the two  asparagines to aspartates to disrupt the scaffolding of the target peptide. (B) Experimental  characterization of binding using biolayer interferometry. Biotinylated C-term SH3 domain  from human Grb2 was loaded onto Streptavidin (SA) Biosensors, which were then  immersed in solutions containing varying concentrations of the target peptide (left) of the  designs (right panels), and then transferred to buffer lacking added protein for dissociation measurements. The MPNN design (3rd panel from the left) has much greater binding signal  than the original Rosetta design (2nd panel from the left); this is greatly reduced by the  asparagine to aspartate mutations (last panel).\"></p>\n<p> ProteinMPNN  Rosetta </p>\n<p>ProteinMPNN  100  CPU  1.2  CPU  258.8 Rosetta 52.4%  32.9%  Rosetta  AlphaFold - 1-6 ProteinMPNN  TIM  6  S3 BC ; </p>\n<p> Rosetta ProteinMPNN ; Rosetta ; Rosetta   Rosetta  PDB  </p>\n<p>ProteinMPNN Wicky ProteinMPNN ProteinMPNN  ProteinMPNN  ProteinMPNN </p>\n<h2 id=\"Methods\"><a href=\"#Methods\" class=\"headerlink\" title=\"Methods\"></a>Methods</h2><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 1  CATH 4.2 40%  1 71Transformer2010%2110%226000tokenCa-Ca30</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 10% 22  &#x3D;  * &#x2F; 2000  2000  [] Adambeta1 &#x3D; 0.9beta2 &#x3D; 0.98epsilon&#x3D; 109 20  NVIDIA A100 GPU  pytorch 2410k  3D  150k  23,358  PDB  100  epoch</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th>&#x2F;</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Featurize()</strong></td>\n<td></td>\n<td>Graph construction from backbone coordinates</td>\n<td> <code>(X, S, mask, chain_M, residue_idx, ...)</code></td>\n</tr>\n<tr>\n<td><strong>ProteinFeatures</strong></td>\n<td> RBF</td>\n<td>Feature construction and geometric encoding</td>\n<td> <code>(X[B,L,4,3])</code>   <code>E[B,L,K,128]</code></td>\n</tr>\n<tr>\n<td><strong>Encoder (EncLayer  3)</strong></td>\n<td> message passing</td>\n<td>Structure encoder</td>\n<td> <code>(h_V[B,L,128], h_E[B,L,K,128])</code></td>\n</tr>\n<tr>\n<td><strong>Decoder (DecLayer  3)</strong></td>\n<td></td>\n<td>Autoregressive sequence decoder</td>\n<td> <code>(h_V, h_E, h_S)</code>   <code>log_probs[B,L,21]</code></td>\n</tr>\n<tr>\n<td><strong>Output Layer (W_out)</strong></td>\n<td> logits</td>\n<td>Logits for amino acid types</td>\n<td><code>[B, L, 21]</code></td>\n</tr>\n</tbody></table>\n<ul>\n<li><strong>Featurize(batch)</strong></li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>X</code></td>\n<td><code>[B, L, 4, 3]</code></td>\n<td>N, CA, C, O</td>\n</tr>\n<tr>\n<td><code>S</code></td>\n<td><code>[B, L]</code></td>\n<td></td>\n</tr>\n<tr>\n<td><code>mask</code></td>\n<td><code>[B, L]</code></td>\n<td>1 </td>\n</tr>\n<tr>\n<td><code>chain_M</code></td>\n<td><code>[B, L]</code></td>\n<td>1 masked chain</td>\n</tr>\n<tr>\n<td><code>residue_idx</code></td>\n<td><code>[B, L]</code></td>\n<td></td>\n</tr>\n<tr>\n<td><code>chain_encoding_all</code></td>\n<td><code>[B, L]</code></td>\n<td> ID</td>\n</tr>\n</tbody></table>\n<ul>\n<li><strong><code>ProteinFeatures</code></strong></li>\n</ul>\n<p><code>X (B,L,4,3)</code><br></p>\n<ul>\n<li><code>E</code>: <code>[B, L, K, edge_dim=128]</code></li>\n<li><code>E_idx</code>: <code>[B, L, K]</code>  top-K </li>\n</ul>\n<p></p>\n<ol>\n<li> <strong>CC</strong> </li>\n<li> top-K </li>\n<li> 25 RBF NN, CC, OO, CCb, <ul>\n<li> <code>num_rbf=16</code>    <code>2516 = 400</code></li>\n</ul>\n</li>\n<li>offset embedding,  65 </li>\n<li>  <code>edge_features=128</code></li>\n<li>LayerNorm</li>\n</ol>\n<blockquote>\n<p> E  message passing</p>\n</blockquote>\n<p>Cb</p>\n<p>k-neighbor</p>\n<p>E_idx:</p>\n<p>D_neighbors:</p>\n<p>5*5&#x3D;251616*25&#x3D;400</p>\n<p>concatlayernorm</p>\n<p>h_Eh_V</p>\n<ul>\n<li><strong>Encoder</strong></li>\n</ul>\n<p></p>\n<ul>\n<li><p> <code>h_V = zeros([B,L,128])</code></p>\n</li>\n<li><p> <code>h_E = W_e(E)</code>  <code>[B,L,K,128]</code></p>\n</li>\n<li><p></p>\n<ul>\n<li><code>h_V [B,L,128]</code></li>\n<li><code>h_E [B,L,K,128]</code></li>\n</ul>\n</li>\n<li><p><code>h_EV = concat(h_V_i, h_E_ij, h_V_j)</code>  <code>[B,L,K,256]</code></p>\n</li>\n<li><p><code>W1  W2  W3</code> 128</p>\n</li>\n<li><p> + LayerNorm + Dropout</p>\n</li>\n<li><p>FeedForward (128512128)</p>\n</li>\n<li><p> <code>h_V, h_E</code> <code>[B,L,128]</code>, <code>[B,L,K,128]</code></p>\n</li>\n<li><p><strong>Decoder</strong></p>\n<p></p>\n<ul>\n<li> <code>h_V</code> encoder</li>\n<li> <code>h_E</code></li>\n<li> <code>h_S = Embedding(S)</code>  <code>[B,L,128]</code></li>\n</ul>\n</li>\n</ul>\n<p></p>\n<ol>\n<li><p><br> <code>h_ES = cat_neighbors_nodes(h_S, h_E, E_idx)</code>  <code>[B,L,K,256]</code></p>\n</li>\n<li><p></p>\n<ul>\n<li> masked </li>\n<li>mask_fwmask_bw</li>\n</ul>\n</li>\n<li><p><br> <code>h_EXV_encoder_fw = mask_fw * h_EXV_encoder</code></p>\n</li>\n<li><p></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for i in range(3):</span><br><span class=\"line\">    h_ESV = cat_neighbors_nodes(h_V, h_ES, E_idx)</span><br><span class=\"line\">    h_ESV = mask_bw * h_ESV + h_EXV_encoder_fw</span><br><span class=\"line\">    h_V = DecLayer(h_V, h_ESV)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p> logits<br> <code>logits = W_out(h_V)</code>  <code>[B, L, 21]</code><br> <code>log_probs = log_softmax(logits)</code></p>\n</li>\n</ol>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p> EncLayer </p>\n<ul>\n<li><p></p>\n</li>\n<li><p> <code>[B,L,128]</code> <code>[B,L,128]</code></p>\n</li>\n<li><p> 3  + GELU +  + LayerNorm</p>\n</li>\n<li><p>FeedForward (128512128)</p>\n</li>\n<li><p><strong></strong></p>\n</li>\n</ul>\n<p></p>\n<ul>\n<li><code>log_probs</code>: <code>[B, L, 21]</code></li>\n</ul>\n<p></p>\n<ul>\n<li><code>loss_nll</code>:  NLL</li>\n<li><code>loss_smoothed</code>:  label smoothing </li>\n</ul>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>X</code></td>\n<td><code>[B, L_max, 4, 3]</code></td>\n<td>float tensor</td>\n<td> N,CA,C,O  xyzpad  0 <code>mask</code>  0</td>\n</tr>\n<tr>\n<td><code>S</code></td>\n<td><code>[B, L_max]</code></td>\n<td>long tensor</td>\n<td>pad  0</td>\n</tr>\n<tr>\n<td><code>mask</code></td>\n<td><code>[B, L_max]</code></td>\n<td>float tensor</td>\n<td>1.0 0.0  pad</td>\n</tr>\n<tr>\n<td><code>lengths</code></td>\n<td><code>[B]</code></td>\n<td>numpy int</td>\n<td></td>\n</tr>\n<tr>\n<td><code>chain_M</code></td>\n<td><code>[B, L_max]</code></td>\n<td>float tensor</td>\n<td>1.0 &#x3D; masked0.0 &#x3D; visible</td>\n</tr>\n<tr>\n<td><code>residue_idx</code></td>\n<td><code>[B, L_max]</code></td>\n<td>long tensor</td>\n<td>&#x2F;offset</td>\n</tr>\n<tr>\n<td><code>mask_self</code></td>\n<td><code>[B, L_max, L_max]</code></td>\n<td>float tensor</td>\n<td>0  interface1  interface loss</td>\n</tr>\n<tr>\n<td><code>chain_encoding_all</code></td>\n<td><code>[B, L_max]</code></td>\n<td>long tensor</td>\n<td> chain-aware embedding&#x2F;</td>\n</tr>\n</tbody></table>\n<p><strong>N, CA, C, O </strong> <code>C</code> <code>ProteinFeatures</code>  C RBF N,CA,C,O</p>\n<p><strong> NaN  padding</strong> <code>isfinite</code>  0</p>\n<p><strong><code>residue_idx</code> </strong>offset&#x2F;</p>\n<p><strong><code>chain_M</code> </strong> + chain mask &#x2F; order-agnostic decoding</p>\n<p>**<code>mask_self</code>** interface  interface loss </p>\n<p>&#x3D;&#x3D;  &#x3D;&#x3D;<br>: features, : ProteinFeatures<br>: W_e, : Linear #Encoder<br>: W_s, : Embedding #Decoder<br>: encoder_layers, : ModuleList<br>: decoder_layers, : ModuleList<br>: W_out, : Linear</p>\n<p>&#x3D;&#x3D;  &#x3D;&#x3D;<br>: features.embeddings.linear.weight, : torch.Size([16, 66]), : 1,056<br>: features.embeddings.linear.bias, : torch.Size([16]), : 16<br>: features.edge_embedding.weight, : torch.Size([128, 416]), : 53,248<br>: features.norm_edges.weight, : torch.Size([128]), : 128<br>: features.norm_edges.bias, : torch.Size([128]), : 128<br>: W_e.weight, : torch.Size([128, 128]), : 16,384<br>: W_e.bias, : torch.Size([128]), : 128<br>: W_s.weight, : torch.Size([21, 128]), : 2,688<br>: encoder_layers.0.norm1.weight, : torch.Size([128]), : 128<br>: encoder_layers.0.norm1.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.norm2.weight, : torch.Size([128]), : 128<br>: encoder_layers.0.norm2.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.norm3.weight, : torch.Size([128]), : 128<br>: encoder_layers.0.norm3.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W1.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.0.W1.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W2.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.0.W2.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W3.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.0.W3.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W11.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.0.W11.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W12.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.0.W12.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.W13.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.0.W13.bias, : torch.Size([128]), : 128<br>: encoder_layers.0.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: encoder_layers.0.dense.W_in.bias, : torch.Size([512]), : 512<br>: encoder_layers.0.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: encoder_layers.0.dense.W_out.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.norm1.weight, : torch.Size([128]), : 128<br>: encoder_layers.1.norm1.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.norm2.weight, : torch.Size([128]), : 128<br>: encoder_layers.1.norm2.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.norm3.weight, : torch.Size([128]), : 128<br>: encoder_layers.1.norm3.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W1.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.1.W1.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W2.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.1.W2.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W3.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.1.W3.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W11.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.1.W11.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W12.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.1.W12.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.W13.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.1.W13.bias, : torch.Size([128]), : 128<br>: encoder_layers.1.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: encoder_layers.1.dense.W_in.bias, : torch.Size([512]), : 512<br>: encoder_layers.1.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: encoder_layers.1.dense.W_out.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.norm1.weight, : torch.Size([128]), : 128<br>: encoder_layers.2.norm1.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.norm2.weight, : torch.Size([128]), : 128<br>: encoder_layers.2.norm2.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.norm3.weight, : torch.Size([128]), : 128<br>: encoder_layers.2.norm3.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W1.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.2.W1.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W2.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.2.W2.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W3.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.2.W3.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W11.weight, : torch.Size([128, 384]), : 49,152<br>: encoder_layers.2.W11.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W12.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.2.W12.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.W13.weight, : torch.Size([128, 128]), : 16,384<br>: encoder_layers.2.W13.bias, : torch.Size([128]), : 128<br>: encoder_layers.2.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: encoder_layers.2.dense.W_in.bias, : torch.Size([512]), : 512<br>: encoder_layers.2.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: encoder_layers.2.dense.W_out.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.norm1.weight, : torch.Size([128]), : 128<br>: decoder_layers.0.norm1.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.norm2.weight, : torch.Size([128]), : 128<br>: decoder_layers.0.norm2.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.W1.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.0.W1.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.W2.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.0.W2.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.W3.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.0.W3.bias, : torch.Size([128]), : 128<br>: decoder_layers.0.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: decoder_layers.0.dense.W_in.bias, : torch.Size([512]), : 512<br>: decoder_layers.0.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.0.dense.W_out.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.norm1.weight, : torch.Size([128]), : 128<br>: decoder_layers.1.norm1.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.norm2.weight, : torch.Size([128]), : 128<br>: decoder_layers.1.norm2.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.W1.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.1.W1.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.W2.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.1.W2.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.W3.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.1.W3.bias, : torch.Size([128]), : 128<br>: decoder_layers.1.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: decoder_layers.1.dense.W_in.bias, : torch.Size([512]), : 512<br>: decoder_layers.1.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.1.dense.W_out.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.norm1.weight, : torch.Size([128]), : 128<br>: decoder_layers.2.norm1.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.norm2.weight, : torch.Size([128]), : 128<br>: decoder_layers.2.norm2.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.W1.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.2.W1.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.W2.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.2.W2.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.W3.weight, : torch.Size([128, 128]), : 16,384<br>: decoder_layers.2.W3.bias, : torch.Size([128]), : 128<br>: decoder_layers.2.dense.W_in.weight, : torch.Size([512, 128]), : 65,536<br>: decoder_layers.2.dense.W_in.bias, : torch.Size([512]), : 512<br>: decoder_layers.2.dense.W_out.weight, : torch.Size([128, 512]), : 65,536<br>: decoder_layers.2.dense.W_out.bias, : torch.Size([128]), : 128<br>: W_out.weight, : torch.Size([21, 128]), : 2,688<br>: W_out.bias, : torch.Size([21]), : 21</p>\n"},{"title":"ProTrek","mathjax":true,"date":"2025-09-26T12:46:25.000Z","img":"https://cbirt.net/wp-content/uploads/2024/06/ProTrek.webp","excerpt":"","_content":"![Fig. 1: Illustration of ProTrek. a, ProTrek architecture and tri-modal contrast learning. b, Cross-modal and uni-modal retrieval. ProTrek supports nine searching tasks. c, After the tri-modal contrast learning, the protein sequence encoder encodes almost universal representation of proteins, which can be fine-tuned to predict diverse downstream tasks, such as protein fitness and stability prediction. d, Using ProTreks natural language capabilities to decode the protein universe. Each cluster represents proteins with close embedding distances. Over 99% of protein entries in UniProt remain unreviewed, as shown in the top right.](./img/protrek/fig1.png)\n\n![Fig. 2: ProTrek performance on protein search and representation tasks. a, Top chart: Search protein functional descriptions using sequences/structures. Bottom chart: Search protein sequences/structures using textual descriptions. x-axis: Specific protein function categories left of the dashed line; aggregated categories (residue-, protein-, all-level) right of it. Global retrieval indicates a search across the entire database, not within individual categories. The y-axis is MAP (mean average precision), a commonly used ranking metric for searching tasks. b, ProTrek employs zinc ion binding as the query term, while Foldseek utilizes P13243 as a query template, which is the protein with the most hits. In the testing set, 220 proteins share similar functional annotations with P13243. Foldseek identified 18 true hits, whereas ProTrek discovered 198 true hits. The TM-score results in the right subfigure reveal that proteins with similar functions can exhibit diverse structures. Conversely, proteins with similar structures (e.g., A9L2CB) may encode different functions. c, Searching proteins with similar functions using protein sequence/structure as input. TP (true-positive): Matches sharing 1 GO term. FP: Matches sharing no GO terms. d, Comparing alignment speed (CPU time) for 100 query proteins on UniRef50 with 50 million candidate proteins, utilizing 24 CPU cores. e, Evaluating the protein representation ability of the ProTrek AA sequence encoder.](./img/protrek/fig2.png)\n\n## Expectation\n\n- Text-guided Protein Design\n\nFengyuan Dai, Yuliang Fan, Jin Su, Chentong Wang, Chenchen Han, Xibin Zhou, Jianming Liu, Hui Qian, Shunzhi Wang, Anping Zeng, et al. Toward de novo protein design from natural language. bioRxiv, pages 202408, 2024.\n\nShengchao Liu, Yutao Zhu, Jiarui Lu, Zhao Xu, Weili Nie, Anthony Gitter, Chaowei Xiao, Jian Tang, Hongyu Guo, and Anima Anandkumar. A text-guided protein design framework. arXiv preprint arXiv:2302.04611, 2023.\n\n- Advanced Protein ChatGPT\n\nChao Wang, Hehe Fan, Ruijie Quan, and Yi Yang. Protchatgpt: Towards understanding proteins with large language models. arXiv preprint arXiv:2402.09649, 2024.\n\n## Method\n\n### -\n\n **UniProt ** [7] -****  **** 2\n\n- ****\n- ****\n\n **GPT-4** [39]  GPT-4  **** **-**\n\n------\n\n### \n\n **Swiss-Prot ** [5]  **50% ** 1000  1000 - **1400 -** ProTrek  **35M ** 12  **NVIDIA 80G A100 GPU**  **100K **\n\n ProTrek  **UniRef50 ** [7]  **3 -** Swiss-Prot - **2500 ** 2500  1400  ****\n\n### \n\n **InfoNCE ** [43] InfoNCE \n\n$L_{InfoNCE}=-log\\frac{exp(f(z_i,z_j)/\\tau)}{\\sum_{k=1}^Nexp(f(z_i,z_k)/\\tau)}$\n\n$z_i$ $z_j$ $f(z_i,z_j)$ $N$ $\\tau$  ****  InfoNCE  **6 **\n\n ProTrek  ****  ****  **Masked Language Modeling, MLM** [40]  3Di token  token\n\n$L_{MLM}=\\sum_{i\\in T}-logP(s_i|S_{\\setminus T})$\n\nT  token $S_{\\setminus T}$ token /\n\n **2  MLM **  **6  InfoNCE ** \n\n### \n\n ProTrek  ****  **ESM-2 650M** [19]****  **PubMedBERT** [15] **** \n\n **DeepSpeed ** [44]  **AdamW ** [42]\n\n- $\\beta_1$=0.9$\\beta_2$=0.98\n- L2  0.01\n\n **2000 **  0 ** 4e-4** **** [41]  **4e-5** **100K ** **20  NVIDIA 80G A100 GPU** \n\n ** 512  token** ** 100  token** **1280 ---** **** \n\n### -\n\n **Swiss-Prot ** **4,000 **- ProTrek  ** UniProt  100,000 **\n\n **** Swiss-Prot  **** **104,000 ** Swiss-Prot \n\n ** 33 **\n\n------\n\n### \n\n ProTrek  Swiss-Prot 4,000  **all-versus-all search** ** GO **\n\n GO  $G_q$ GO  $G_h$ GO $G_q \\cap G_h \\neq \\emptyset$\n\n **correct hit**\n\n 2c y  ****\n\n------\n\n### Mean Average PrecisionMAP\n\n**Mean Average Precision, MAP**  **AP** \n\n**AP** \n\n$AP = \\frac{1}{R} \\sum_{i=1}^{N} P(i) \\cdot r(i)$\n\n\n\n- $R$\n- $N$ \n- $P(i)$ $i$\n- $r(i)$$ i $ 1 0\n\n**MAP**  AP \n\n$AP = \\frac{1}{Q} \\sum_{q=1}^{Q} AP_q$\n\n### \n\n- ProTrek  **ProtST** [35]  **ProtST-ESM-1b**  **ProteinDT** [20]  **ProtBERT BFD-512-1e-5-1e-1-text-512-1e-5-1e-1-InfoNCE-0.1-batch-9-gpu-8-epoch-5** \n  **ESM-2 650M ** [19]  **ProtST-ESM-1b** \n\n------\n\n### \n\n **SaprotHub** [27] \n\n------\n\n### \n\n**Foldseek**\n  **Foldseek**  `ef4e960ab84fc502665eb7b84573dfff9c2aa89d`\n\n```bash\nfoldseek easy-search pdb dir targetDB aln.m8 tmpFolder\n```\n\n**MMseqs2**\n  **MMseqs2**  `edb8223d1ea07385ffe63d4f103af0eb12b2058e`\n\n```bash\nmmseqs easy-search seqs.fasta targetDB alnRes.m8 tmp\n```\n\n#### **BLASTP**\n\n **Protein-Protein BLAST 2.15.0+** \n\n```bash\nblastp -query seqs.fasta -db db -outfmt 6 -out blastp_result\n```\n\n------\n\n#### **DIAMOND**\n\n **DIAMOND v2.1.9.163**  **very-sensitive** \n\n```bash\ndiamond blastp -q seqs.fasta -d db -o result.tsv --very-sensitive -k 0\n```\n","source":"_posts/protrek.md","raw":"---\ntitle: ProTrek\nmathjax: true\ndate: 2025/9/26 20:46:25\nimg: https://cbirt.net/wp-content/uploads/2024/06/ProTrek.webp\nexcerpt: \n---\n![Fig. 1: Illustration of ProTrek. a, ProTrek architecture and tri-modal contrast learning. b, Cross-modal and uni-modal retrieval. ProTrek supports nine searching tasks. c, After the tri-modal contrast learning, the protein sequence encoder encodes almost universal representation of proteins, which can be fine-tuned to predict diverse downstream tasks, such as protein fitness and stability prediction. d, Using ProTreks natural language capabilities to decode the protein universe. Each cluster represents proteins with close embedding distances. Over 99% of protein entries in UniProt remain unreviewed, as shown in the top right.](./img/protrek/fig1.png)\n\n![Fig. 2: ProTrek performance on protein search and representation tasks. a, Top chart: Search protein functional descriptions using sequences/structures. Bottom chart: Search protein sequences/structures using textual descriptions. x-axis: Specific protein function categories left of the dashed line; aggregated categories (residue-, protein-, all-level) right of it. Global retrieval indicates a search across the entire database, not within individual categories. The y-axis is MAP (mean average precision), a commonly used ranking metric for searching tasks. b, ProTrek employs zinc ion binding as the query term, while Foldseek utilizes P13243 as a query template, which is the protein with the most hits. In the testing set, 220 proteins share similar functional annotations with P13243. Foldseek identified 18 true hits, whereas ProTrek discovered 198 true hits. The TM-score results in the right subfigure reveal that proteins with similar functions can exhibit diverse structures. Conversely, proteins with similar structures (e.g., A9L2CB) may encode different functions. c, Searching proteins with similar functions using protein sequence/structure as input. TP (true-positive): Matches sharing 1 GO term. FP: Matches sharing no GO terms. d, Comparing alignment speed (CPU time) for 100 query proteins on UniRef50 with 50 million candidate proteins, utilizing 24 CPU cores. e, Evaluating the protein representation ability of the ProTrek AA sequence encoder.](./img/protrek/fig2.png)\n\n## Expectation\n\n- Text-guided Protein Design\n\nFengyuan Dai, Yuliang Fan, Jin Su, Chentong Wang, Chenchen Han, Xibin Zhou, Jianming Liu, Hui Qian, Shunzhi Wang, Anping Zeng, et al. Toward de novo protein design from natural language. bioRxiv, pages 202408, 2024.\n\nShengchao Liu, Yutao Zhu, Jiarui Lu, Zhao Xu, Weili Nie, Anthony Gitter, Chaowei Xiao, Jian Tang, Hongyu Guo, and Anima Anandkumar. A text-guided protein design framework. arXiv preprint arXiv:2302.04611, 2023.\n\n- Advanced Protein ChatGPT\n\nChao Wang, Hehe Fan, Ruijie Quan, and Yi Yang. Protchatgpt: Towards understanding proteins with large language models. arXiv preprint arXiv:2402.09649, 2024.\n\n## Method\n\n### -\n\n **UniProt ** [7] -****  **** 2\n\n- ****\n- ****\n\n **GPT-4** [39]  GPT-4  **** **-**\n\n------\n\n### \n\n **Swiss-Prot ** [5]  **50% ** 1000  1000 - **1400 -** ProTrek  **35M ** 12  **NVIDIA 80G A100 GPU**  **100K **\n\n ProTrek  **UniRef50 ** [7]  **3 -** Swiss-Prot - **2500 ** 2500  1400  ****\n\n### \n\n **InfoNCE ** [43] InfoNCE \n\n$L_{InfoNCE}=-log\\frac{exp(f(z_i,z_j)/\\tau)}{\\sum_{k=1}^Nexp(f(z_i,z_k)/\\tau)}$\n\n$z_i$ $z_j$ $f(z_i,z_j)$ $N$ $\\tau$  ****  InfoNCE  **6 **\n\n ProTrek  ****  ****  **Masked Language Modeling, MLM** [40]  3Di token  token\n\n$L_{MLM}=\\sum_{i\\in T}-logP(s_i|S_{\\setminus T})$\n\nT  token $S_{\\setminus T}$ token /\n\n **2  MLM **  **6  InfoNCE ** \n\n### \n\n ProTrek  ****  **ESM-2 650M** [19]****  **PubMedBERT** [15] **** \n\n **DeepSpeed ** [44]  **AdamW ** [42]\n\n- $\\beta_1$=0.9$\\beta_2$=0.98\n- L2  0.01\n\n **2000 **  0 ** 4e-4** **** [41]  **4e-5** **100K ** **20  NVIDIA 80G A100 GPU** \n\n ** 512  token** ** 100  token** **1280 ---** **** \n\n### -\n\n **Swiss-Prot ** **4,000 **- ProTrek  ** UniProt  100,000 **\n\n **** Swiss-Prot  **** **104,000 ** Swiss-Prot \n\n ** 33 **\n\n------\n\n### \n\n ProTrek  Swiss-Prot 4,000  **all-versus-all search** ** GO **\n\n GO  $G_q$ GO  $G_h$ GO $G_q \\cap G_h \\neq \\emptyset$\n\n **correct hit**\n\n 2c y  ****\n\n------\n\n### Mean Average PrecisionMAP\n\n**Mean Average Precision, MAP**  **AP** \n\n**AP** \n\n$AP = \\frac{1}{R} \\sum_{i=1}^{N} P(i) \\cdot r(i)$\n\n\n\n- $R$\n- $N$ \n- $P(i)$ $i$\n- $r(i)$$ i $ 1 0\n\n**MAP**  AP \n\n$AP = \\frac{1}{Q} \\sum_{q=1}^{Q} AP_q$\n\n### \n\n- ProTrek  **ProtST** [35]  **ProtST-ESM-1b**  **ProteinDT** [20]  **ProtBERT BFD-512-1e-5-1e-1-text-512-1e-5-1e-1-InfoNCE-0.1-batch-9-gpu-8-epoch-5** \n  **ESM-2 650M ** [19]  **ProtST-ESM-1b** \n\n------\n\n### \n\n **SaprotHub** [27] \n\n------\n\n### \n\n**Foldseek**\n  **Foldseek**  `ef4e960ab84fc502665eb7b84573dfff9c2aa89d`\n\n```bash\nfoldseek easy-search pdb dir targetDB aln.m8 tmpFolder\n```\n\n**MMseqs2**\n  **MMseqs2**  `edb8223d1ea07385ffe63d4f103af0eb12b2058e`\n\n```bash\nmmseqs easy-search seqs.fasta targetDB alnRes.m8 tmp\n```\n\n#### **BLASTP**\n\n **Protein-Protein BLAST 2.15.0+** \n\n```bash\nblastp -query seqs.fasta -db db -outfmt 6 -out blastp_result\n```\n\n------\n\n#### **DIAMOND**\n\n **DIAMOND v2.1.9.163**  **very-sensitive** \n\n```bash\ndiamond blastp -q seqs.fasta -d db -o result.tsv --very-sensitive -k 0\n```\n","slug":"protrek","published":1,"updated":"2025-09-26T08:48:54.443Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ffa000pss99506b0z6f","content":"<p><img src=\"/./img/protrek/fig1.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/protrek/fig1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Fig. 1: Illustration of ProTrek. a, ProTrek architecture and tri-modal contrast learning. b, Cross-modal and uni-modal retrieval. ProTrek supports nine searching tasks. c, After the tri-modal contrast learning, the protein sequence encoder encodes almost universal representation of proteins, which can be fine-tuned to predict diverse downstream tasks, such as protein fitness and stability prediction. d, Using ProTreks natural language capabilities to decode the protein universe. Each cluster represents proteins with close embedding distances. Over 99% of protein entries in UniProt remain unreviewed, as shown in the top right.\"></p>\n<p><img src=\"/./img/protrek/fig2.png\" class=\"lazyload placeholder\" data-srcset=\"/./img/protrek/fig2.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"Fig. 2: ProTrek performance on protein search and representation tasks. a, Top chart: Search protein functional descriptions using sequences/structures. Bottom chart: Search protein sequences/structures using textual descriptions. x-axis: Specific protein function categories left of the dashed line; aggregated categories (residue-, protein-, all-level) right of it. Global retrieval indicates a search across the entire database, not within individual categories. The y-axis is MAP (mean average precision), a commonly used ranking metric for searching tasks. b, ProTrek employs zinc ion binding as the query term, while Foldseek utilizes P13243 as a query template, which is the protein with the most hits. In the testing set, 220 proteins share similar functional annotations with P13243. Foldseek identified 18 true hits, whereas ProTrek discovered 198 true hits. The TM-score results in the right subfigure reveal that proteins with similar functions can exhibit diverse structures. Conversely, proteins with similar structures (e.g., A9L2CB) may encode different functions. c, Searching proteins with similar functions using protein sequence/structure as input. TP (true-positive): Matches sharing 1 GO term. FP: Matches sharing no GO terms. d, Comparing alignment speed (CPU time) for 100 query proteins on UniRef50 with 50 million candidate proteins, utilizing 24 CPU cores. e, Evaluating the protein representation ability of the ProTrek AA sequence encoder.\"></p>\n<h2 id=\"Expectation\"><a href=\"#Expectation\" class=\"headerlink\" title=\"Expectation\"></a>Expectation</h2><ul>\n<li>Text-guided Protein Design</li>\n</ul>\n<p>Fengyuan Dai, Yuliang Fan, Jin Su, Chentong Wang, Chenchen Han, Xibin Zhou, Jianming Liu, Hui Qian, Shunzhi Wang, Anping Zeng, et al. Toward de novo protein design from natural language. bioRxiv, pages 202408, 2024.</p>\n<p>Shengchao Liu, Yutao Zhu, Jiarui Lu, Zhao Xu, Weili Nie, Anthony Gitter, Chaowei Xiao, Jian Tang, Hongyu Guo, and Anima Anandkumar. A text-guided protein design framework. arXiv preprint arXiv:2302.04611, 2023.</p>\n<ul>\n<li>Advanced Protein ChatGPT</li>\n</ul>\n<p>Chao Wang, Hehe Fan, Ruijie Quan, and Yi Yang. Protchatgpt: Towards understanding proteins with large language models. arXiv preprint arXiv:2402.09649, 2024.</p>\n<h2 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method\"></a>Method</h2><h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"-\"></a>-</h3><p> <strong>UniProt </strong> [7] -<strong></strong>  <strong></strong> 2</p>\n<ul>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ul>\n<p> <strong>GPT-4</strong> [39]  GPT-4  <strong></strong> <strong>-</strong></p>\n<hr>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> <strong>Swiss-Prot </strong> [5]  <strong>50% </strong> 1000  1000 - <strong>1400 -</strong> ProTrek  <strong>35M </strong> 12  <strong>NVIDIA 80G A100 GPU</strong>  <strong>100K </strong></p>\n<p> ProTrek  <strong>UniRef50 </strong> [7]  <strong>3 -</strong> Swiss-Prot - <strong>2500 </strong> 2500  1400  <strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> <strong>InfoNCE </strong> [43] InfoNCE </p>\n<p>$L_{InfoNCE}&#x3D;-log\\frac{exp(f(z_i,z_j)&#x2F;\\tau)}{\\sum_{k&#x3D;1}^Nexp(f(z_i,z_k)&#x2F;\\tau)}$</p>\n<p>$z_i$ $z_j$ $f(z_i,z_j)$ $N$ $\\tau$  <strong></strong>  InfoNCE  <strong>6 </strong></p>\n<p> ProTrek  <strong></strong>  <strong></strong>  <strong>Masked Language Modeling, MLM</strong> [40]  3Di token  token</p>\n<p>$L_{MLM}&#x3D;\\sum_{i\\in T}-logP(s_i|S_{\\setminus T})$</p>\n<p>T  token $S_{\\setminus T}$ token &#x2F;</p>\n<p> <strong>2  MLM </strong>  <strong>6  InfoNCE </strong> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> ProTrek  <strong></strong>  <strong>ESM-2 650M</strong> [19]<strong></strong>  <strong>PubMedBERT</strong> [15] <strong></strong> </p>\n<p> <strong>DeepSpeed </strong> [44]  <strong>AdamW </strong> [42]</p>\n<ul>\n<li>$\\beta_1$&#x3D;0.9$\\beta_2$&#x3D;0.98</li>\n<li>L2  0.01</li>\n</ul>\n<p> <strong>2000 </strong>  0 <strong> 4e-4</strong> <strong></strong> [41]  <strong>4e-5</strong> <strong>100K </strong> <strong>20  NVIDIA 80G A100 GPU</strong> </p>\n<p> <strong> 512  token</strong> <strong> 100  token</strong> <strong>1280 ---</strong> <strong></strong> </p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"-\"></a>-</h3><p> <strong>Swiss-Prot </strong> <strong>4,000 </strong>- ProTrek  <strong> UniProt  100,000 </strong></p>\n<p> <strong></strong> Swiss-Prot  <strong></strong> <strong>104,000 </strong> Swiss-Prot </p>\n<p> <strong> 33 </strong></p>\n<hr>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> ProTrek  Swiss-Prot 4,000  <strong>all-versus-all search</strong> <strong> GO </strong></p>\n<p> GO  $G_q$ GO  $G_h$ GO $G_q \\cap G_h \\neq \\emptyset$</p>\n<p> <strong>correct hit</strong></p>\n<p> 2c y  <strong></strong></p>\n<hr>\n<h3 id=\"Mean-Average-PrecisionMAP\"><a href=\"#Mean-Average-PrecisionMAP\" class=\"headerlink\" title=\"Mean Average PrecisionMAP\"></a>Mean Average PrecisionMAP</h3><p><strong>Mean Average Precision, MAP</strong>  <strong>AP</strong> </p>\n<p><strong>AP</strong> </p>\n<p>$AP &#x3D; \\frac{1}{R} \\sum_{i&#x3D;1}^{N} P(i) \\cdot r(i)$</p>\n<p></p>\n<ul>\n<li>$R$</li>\n<li>$N$ </li>\n<li>$P(i)$ $i$</li>\n<li>$r(i)$$ i $ 1 0</li>\n</ul>\n<p><strong>MAP</strong>  AP </p>\n<p>$AP &#x3D; \\frac{1}{Q} \\sum_{q&#x3D;1}^{Q} AP_q$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>- ProTrek  <strong>ProtST</strong> [35]  <strong>ProtST-ESM-1b</strong>  <strong>ProteinDT</strong> [20]  <strong>ProtBERT BFD-512-1e-5-1e-1-text-512-1e-5-1e-1-InfoNCE-0.1-batch-9-gpu-8-epoch-5</strong> <br>  <strong>ESM-2 650M </strong> [19]  <strong>ProtST-ESM-1b</strong> </p>\n<hr>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> <strong>SaprotHub</strong> [27] </p>\n<hr>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Foldseek</strong><br>  <strong>Foldseek</strong>  <code>ef4e960ab84fc502665eb7b84573dfff9c2aa89d</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foldseek easy-search pdb <span class=\"built_in\">dir</span> targetDB aln.m8 tmpFolder</span><br></pre></td></tr></table></figure>\n\n<p><strong>MMseqs2</strong><br>  <strong>MMseqs2</strong>  <code>edb8223d1ea07385ffe63d4f103af0eb12b2058e</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mmseqs easy-search seqs.fasta targetDB alnRes.m8 tmp</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"BLASTP\"><a href=\"#BLASTP\" class=\"headerlink\" title=\"BLASTP\"></a><strong>BLASTP</strong></h4><p> <strong>Protein-Protein BLAST 2.15.0+</strong> </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">blastp -query seqs.fasta -db db -outfmt 6 -out blastp_result</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"DIAMOND\"><a href=\"#DIAMOND\" class=\"headerlink\" title=\"DIAMOND\"></a><strong>DIAMOND</strong></h4><p> <strong>DIAMOND v2.1.9.163</strong>  <strong>very-sensitive</strong> </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">diamond blastp -q seqs.fasta -d db -o result.tsv --very-sensitive -k 0</span><br></pre></td></tr></table></figure>\n","more":"<p><img src=\"/./img/protrek/fig1.png\" alt=\"Fig. 1: Illustration of ProTrek. a, ProTrek architecture and tri-modal contrast learning. b, Cross-modal and uni-modal retrieval. ProTrek supports nine searching tasks. c, After the tri-modal contrast learning, the protein sequence encoder encodes almost universal representation of proteins, which can be fine-tuned to predict diverse downstream tasks, such as protein fitness and stability prediction. d, Using ProTreks natural language capabilities to decode the protein universe. Each cluster represents proteins with close embedding distances. Over 99% of protein entries in UniProt remain unreviewed, as shown in the top right.\"></p>\n<p><img src=\"/./img/protrek/fig2.png\" alt=\"Fig. 2: ProTrek performance on protein search and representation tasks. a, Top chart: Search protein functional descriptions using sequences/structures. Bottom chart: Search protein sequences/structures using textual descriptions. x-axis: Specific protein function categories left of the dashed line; aggregated categories (residue-, protein-, all-level) right of it. Global retrieval indicates a search across the entire database, not within individual categories. The y-axis is MAP (mean average precision), a commonly used ranking metric for searching tasks. b, ProTrek employs zinc ion binding as the query term, while Foldseek utilizes P13243 as a query template, which is the protein with the most hits. In the testing set, 220 proteins share similar functional annotations with P13243. Foldseek identified 18 true hits, whereas ProTrek discovered 198 true hits. The TM-score results in the right subfigure reveal that proteins with similar functions can exhibit diverse structures. Conversely, proteins with similar structures (e.g., A9L2CB) may encode different functions. c, Searching proteins with similar functions using protein sequence/structure as input. TP (true-positive): Matches sharing 1 GO term. FP: Matches sharing no GO terms. d, Comparing alignment speed (CPU time) for 100 query proteins on UniRef50 with 50 million candidate proteins, utilizing 24 CPU cores. e, Evaluating the protein representation ability of the ProTrek AA sequence encoder.\"></p>\n<h2 id=\"Expectation\"><a href=\"#Expectation\" class=\"headerlink\" title=\"Expectation\"></a>Expectation</h2><ul>\n<li>Text-guided Protein Design</li>\n</ul>\n<p>Fengyuan Dai, Yuliang Fan, Jin Su, Chentong Wang, Chenchen Han, Xibin Zhou, Jianming Liu, Hui Qian, Shunzhi Wang, Anping Zeng, et al. Toward de novo protein design from natural language. bioRxiv, pages 202408, 2024.</p>\n<p>Shengchao Liu, Yutao Zhu, Jiarui Lu, Zhao Xu, Weili Nie, Anthony Gitter, Chaowei Xiao, Jian Tang, Hongyu Guo, and Anima Anandkumar. A text-guided protein design framework. arXiv preprint arXiv:2302.04611, 2023.</p>\n<ul>\n<li>Advanced Protein ChatGPT</li>\n</ul>\n<p>Chao Wang, Hehe Fan, Ruijie Quan, and Yi Yang. Protchatgpt: Towards understanding proteins with large language models. arXiv preprint arXiv:2402.09649, 2024.</p>\n<h2 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method\"></a>Method</h2><h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"-\"></a>-</h3><p> <strong>UniProt </strong> [7] -<strong></strong>  <strong></strong> 2</p>\n<ul>\n<li><strong></strong></li>\n<li><strong></strong></li>\n</ul>\n<p> <strong>GPT-4</strong> [39]  GPT-4  <strong></strong> <strong>-</strong></p>\n<hr>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> <strong>Swiss-Prot </strong> [5]  <strong>50% </strong> 1000  1000 - <strong>1400 -</strong> ProTrek  <strong>35M </strong> 12  <strong>NVIDIA 80G A100 GPU</strong>  <strong>100K </strong></p>\n<p> ProTrek  <strong>UniRef50 </strong> [7]  <strong>3 -</strong> Swiss-Prot - <strong>2500 </strong> 2500  1400  <strong></strong></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> <strong>InfoNCE </strong> [43] InfoNCE </p>\n<p>$L_{InfoNCE}&#x3D;-log\\frac{exp(f(z_i,z_j)&#x2F;\\tau)}{\\sum_{k&#x3D;1}^Nexp(f(z_i,z_k)&#x2F;\\tau)}$</p>\n<p>$z_i$ $z_j$ $f(z_i,z_j)$ $N$ $\\tau$  <strong></strong>  InfoNCE  <strong>6 </strong></p>\n<p> ProTrek  <strong></strong>  <strong></strong>  <strong>Masked Language Modeling, MLM</strong> [40]  3Di token  token</p>\n<p>$L_{MLM}&#x3D;\\sum_{i\\in T}-logP(s_i|S_{\\setminus T})$</p>\n<p>T  token $S_{\\setminus T}$ token &#x2F;</p>\n<p> <strong>2  MLM </strong>  <strong>6  InfoNCE </strong> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> ProTrek  <strong></strong>  <strong>ESM-2 650M</strong> [19]<strong></strong>  <strong>PubMedBERT</strong> [15] <strong></strong> </p>\n<p> <strong>DeepSpeed </strong> [44]  <strong>AdamW </strong> [42]</p>\n<ul>\n<li>$\\beta_1$&#x3D;0.9$\\beta_2$&#x3D;0.98</li>\n<li>L2  0.01</li>\n</ul>\n<p> <strong>2000 </strong>  0 <strong> 4e-4</strong> <strong></strong> [41]  <strong>4e-5</strong> <strong>100K </strong> <strong>20  NVIDIA 80G A100 GPU</strong> </p>\n<p> <strong> 512  token</strong> <strong> 100  token</strong> <strong>1280 ---</strong> <strong></strong> </p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\"-\"></a>-</h3><p> <strong>Swiss-Prot </strong> <strong>4,000 </strong>- ProTrek  <strong> UniProt  100,000 </strong></p>\n<p> <strong></strong> Swiss-Prot  <strong></strong> <strong>104,000 </strong> Swiss-Prot </p>\n<p> <strong> 33 </strong></p>\n<hr>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> ProTrek  Swiss-Prot 4,000  <strong>all-versus-all search</strong> <strong> GO </strong></p>\n<p> GO  $G_q$ GO  $G_h$ GO $G_q \\cap G_h \\neq \\emptyset$</p>\n<p> <strong>correct hit</strong></p>\n<p> 2c y  <strong></strong></p>\n<hr>\n<h3 id=\"Mean-Average-PrecisionMAP\"><a href=\"#Mean-Average-PrecisionMAP\" class=\"headerlink\" title=\"Mean Average PrecisionMAP\"></a>Mean Average PrecisionMAP</h3><p><strong>Mean Average Precision, MAP</strong>  <strong>AP</strong> </p>\n<p><strong>AP</strong> </p>\n<p>$AP &#x3D; \\frac{1}{R} \\sum_{i&#x3D;1}^{N} P(i) \\cdot r(i)$</p>\n<p></p>\n<ul>\n<li>$R$</li>\n<li>$N$ </li>\n<li>$P(i)$ $i$</li>\n<li>$r(i)$$ i $ 1 0</li>\n</ul>\n<p><strong>MAP</strong>  AP </p>\n<p>$AP &#x3D; \\frac{1}{Q} \\sum_{q&#x3D;1}^{Q} AP_q$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>- ProTrek  <strong>ProtST</strong> [35]  <strong>ProtST-ESM-1b</strong>  <strong>ProteinDT</strong> [20]  <strong>ProtBERT BFD-512-1e-5-1e-1-text-512-1e-5-1e-1-InfoNCE-0.1-batch-9-gpu-8-epoch-5</strong> <br>  <strong>ESM-2 650M </strong> [19]  <strong>ProtST-ESM-1b</strong> </p>\n<hr>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> <strong>SaprotHub</strong> [27] </p>\n<hr>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p><strong>Foldseek</strong><br>  <strong>Foldseek</strong>  <code>ef4e960ab84fc502665eb7b84573dfff9c2aa89d</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">foldseek easy-search pdb <span class=\"built_in\">dir</span> targetDB aln.m8 tmpFolder</span><br></pre></td></tr></table></figure>\n\n<p><strong>MMseqs2</strong><br>  <strong>MMseqs2</strong>  <code>edb8223d1ea07385ffe63d4f103af0eb12b2058e</code></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mmseqs easy-search seqs.fasta targetDB alnRes.m8 tmp</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"BLASTP\"><a href=\"#BLASTP\" class=\"headerlink\" title=\"BLASTP\"></a><strong>BLASTP</strong></h4><p> <strong>Protein-Protein BLAST 2.15.0+</strong> </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">blastp -query seqs.fasta -db db -outfmt 6 -out blastp_result</span><br></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"DIAMOND\"><a href=\"#DIAMOND\" class=\"headerlink\" title=\"DIAMOND\"></a><strong>DIAMOND</strong></h4><p> <strong>DIAMOND v2.1.9.163</strong>  <strong>very-sensitive</strong> </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">diamond blastp -q seqs.fasta -d db -o result.tsv --very-sensitive -k 0</span><br></pre></td></tr></table></figure>\n"},{"title":"Attention Is All You Need","mathjax":true,"date":"2025-03-11T12:46:25.000Z","img":"https://img0.baidu.com/it/u=3520508,2967101156&fm=253&fmt=auto&app=138&f=JPEG?w=786&h=500","excerpt":"transformer","_content":"\n![img](https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/attention-%E8%AE%A1%E7%AE%97%E5%9B%BE.png)\n\n# \n\nRNN \n\nLSTM \n\nTransformerAttention\n\n# \n\n$(x_1,x_2,...,x_n)$$(z_1,z_2,...,z_n)$$z_t$$x_t$$y_1$$y_{t-1}$$z_t$$y_t$\n\nauto-regressive)\n\n![pic-1](/img/transformer-notes/pic-1.png)\n\n## \n\nN=6(Add & Norm)\n\n$LayerNorm(x + Sublayer(x))$\n\n$d_k = 512$\n\n### LayerNorm & BatchNorm\n\n|     |                                 |                        |\n| :------------ | :---------------------------------------- | :----------------------------- |\n| **BatchNorm** | Batch   | CNN        |\n| **LayerNorm** | Channel | RNNTransformer |\n\n![pic-3](/img/transformer-notes/pic-3.png)\n\nbatchnormlayernorm\n\nBN****mini-batch\n\nseqseqfeaturebatch\n\nLN****mini-batch\n\n\n\n![pic-4](/img/transformer-notes/pic-4.png)\n\n## \n\nN=6encoder\n\n\n\n## \n\nQKV\n\nTransformer\n\n![img](https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/QKV-%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA.jpg)\n\n## Scaled Dot-Product Attention\n\nQK$d_k$V$d_v$\n\nQK$\\sqrt{d_k}$`softmax`dim=1V\n\n$Attention(Q,K,V) = softmax( \\frac{QK^T}{\\sqrt{d_k}}  )V$\n\ndksoftmax01softmax$\\sqrt{d_k}$\n\n![pic-5](/img/transformer-notes/pic-5.png)\n\n## \n\nh=8\n\n** Source  multi-head attention  attention **\n\nQKVhhLinear\n\n$z_i \\in R^{23}$$R^{224}$$W^O \\in R^{244}$$Z \\in R^{24}$\n\n![img](https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/multi-head-%E6%8B%BC%E6%8E%A5.jpg)\n\n\n\n$W^Q_i \\in R^{d_{model}d_k}$ \n\n$W^K_i \\in R^{d_{model}d_k}$  , \n\n$W^V_i \\in R^{d_{model}d_v}$ \n\n$W_O \\in R^{ {hd_v}d_{model} }$\n\ndk = dv = dmodel/h = 64\n\n\n\n## masked\n\noutput embedding\n\ninputQ\n\n![img](https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map-softmax.jpg)\n\n## Encoder-Decoder\n\nKVQ\n\n## \n\nReLU\n\n$FFN(x) = ReLU(xW1 + b1)W2 + b2$\n\n2048\n\n512->(W1)2048->(W2)512\n\nattentionMLP2048\n\n## Softmax\n\n$\\sqrt{d_{model}}$\n\nL2scale\n\n## \n\n** Attention  Attention  Attention  X1**\n\nAttention\n\n\n$PE(pos,2i) = sin(pos/10000^{2i/d_{model}})$\n\n$PE(pos,2i + 1) = cos(pos/10000^{2i/d_{model}})$\n\nPE[-1,1]$PE_{pos_k}$$PE_{pos}$\n\n****\n\n$X_{final\\_embedding}=Embedding+PositionalEmbedding$\n\n## \n\n| Layer Type     | Complexity per Layer | Sequential Operations | Maximum Path Length |\n| -------------- | -------------------- | --------------------- | ------------------- |\n| Self-Attention | O(n2  d)            | O(1)                  | O(1)                |\n| Recurrent      | O(n  d2)            | O(n)                  | O(n)                |\n| Convolutional  | O(k  n  d2)        | O(1)                  | O(logk(n)           |\n\n","source":"_posts/transformer-notes.md","raw":"---\ntitle: Attention Is All You Need\nmathjax: true\ndate: 2025/3/11 20:46:25\nimg: https://img0.baidu.com/it/u=3520508,2967101156&fm=253&fmt=auto&app=138&f=JPEG?w=786&h=500\nexcerpt: transformer\n---\n\n![img](https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/attention-%E8%AE%A1%E7%AE%97%E5%9B%BE.png)\n\n# \n\nRNN \n\nLSTM \n\nTransformerAttention\n\n# \n\n$(x_1,x_2,...,x_n)$$(z_1,z_2,...,z_n)$$z_t$$x_t$$y_1$$y_{t-1}$$z_t$$y_t$\n\nauto-regressive)\n\n![pic-1](/img/transformer-notes/pic-1.png)\n\n## \n\nN=6(Add & Norm)\n\n$LayerNorm(x + Sublayer(x))$\n\n$d_k = 512$\n\n### LayerNorm & BatchNorm\n\n|     |                                 |                        |\n| :------------ | :---------------------------------------- | :----------------------------- |\n| **BatchNorm** | Batch   | CNN        |\n| **LayerNorm** | Channel | RNNTransformer |\n\n![pic-3](/img/transformer-notes/pic-3.png)\n\nbatchnormlayernorm\n\nBN****mini-batch\n\nseqseqfeaturebatch\n\nLN****mini-batch\n\n\n\n![pic-4](/img/transformer-notes/pic-4.png)\n\n## \n\nN=6encoder\n\n\n\n## \n\nQKV\n\nTransformer\n\n![img](https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/QKV-%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA.jpg)\n\n## Scaled Dot-Product Attention\n\nQK$d_k$V$d_v$\n\nQK$\\sqrt{d_k}$`softmax`dim=1V\n\n$Attention(Q,K,V) = softmax( \\frac{QK^T}{\\sqrt{d_k}}  )V$\n\ndksoftmax01softmax$\\sqrt{d_k}$\n\n![pic-5](/img/transformer-notes/pic-5.png)\n\n## \n\nh=8\n\n** Source  multi-head attention  attention **\n\nQKVhhLinear\n\n$z_i \\in R^{23}$$R^{224}$$W^O \\in R^{244}$$Z \\in R^{24}$\n\n![img](https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/multi-head-%E6%8B%BC%E6%8E%A5.jpg)\n\n\n\n$W^Q_i \\in R^{d_{model}d_k}$ \n\n$W^K_i \\in R^{d_{model}d_k}$  , \n\n$W^V_i \\in R^{d_{model}d_v}$ \n\n$W_O \\in R^{ {hd_v}d_{model} }$\n\ndk = dv = dmodel/h = 64\n\n\n\n## masked\n\noutput embedding\n\ninputQ\n\n![img](https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map-softmax.jpg)\n\n## Encoder-Decoder\n\nKVQ\n\n## \n\nReLU\n\n$FFN(x) = ReLU(xW1 + b1)W2 + b2$\n\n2048\n\n512->(W1)2048->(W2)512\n\nattentionMLP2048\n\n## Softmax\n\n$\\sqrt{d_{model}}$\n\nL2scale\n\n## \n\n** Attention  Attention  Attention  X1**\n\nAttention\n\n\n$PE(pos,2i) = sin(pos/10000^{2i/d_{model}})$\n\n$PE(pos,2i + 1) = cos(pos/10000^{2i/d_{model}})$\n\nPE[-1,1]$PE_{pos_k}$$PE_{pos}$\n\n****\n\n$X_{final\\_embedding}=Embedding+PositionalEmbedding$\n\n## \n\n| Layer Type     | Complexity per Layer | Sequential Operations | Maximum Path Length |\n| -------------- | -------------------- | --------------------- | ------------------- |\n| Self-Attention | O(n2  d)            | O(1)                  | O(1)                |\n| Recurrent      | O(n  d2)            | O(n)                  | O(n)                |\n| Convolutional  | O(k  n  d2)        | O(1)                  | O(logk(n)           |\n\n","slug":"transformer-notes","published":1,"updated":"2025-08-09T07:40:15.514Z","comments":1,"layout":"post","photos":[],"_id":"cmkul7ffb000qss99fzx80rz0","content":"<p><img src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/attention-%E8%AE%A1%E7%AE%97%E5%9B%BE.png\" class=\"lazyload placeholder\" data-srcset=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/attention-%E8%AE%A1%E7%AE%97%E5%9B%BE.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>RNN </p>\n<p>LSTM </p>\n<p>TransformerAttention</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>$(x_1,x_2,,x_n)$$(z_1,z_2,,z_n)$$z_t$$x_t$$y_1$$y_{t-1}$$z_t$$y_t$</p>\n<p>auto-regressive)</p>\n<p><img src=\"/img/transformer-notes/pic-1.png\" class=\"lazyload placeholder\" data-srcset=\"/img/transformer-notes/pic-1.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"pic-1\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>N&#x3D;6(Add &amp; Norm)</p>\n<p>$LayerNorm(x + Sublayer(x))$</p>\n<p>$d_k &#x3D; 512$</p>\n<h3 id=\"LayerNorm-BatchNorm\"><a href=\"#LayerNorm-BatchNorm\" class=\"headerlink\" title=\"LayerNorm &amp; BatchNorm\"></a>LayerNorm &amp; BatchNorm</h3><table>\n<thead>\n<tr>\n<th align=\"left\"></th>\n<th align=\"left\"></th>\n<th align=\"left\"></th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><strong>BatchNorm</strong></td>\n<td align=\"left\">Batch</td>\n<td align=\"left\">CNN</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>LayerNorm</strong></td>\n<td align=\"left\">Channel</td>\n<td align=\"left\">RNNTransformer</td>\n</tr>\n</tbody></table>\n<p><img src=\"/img/transformer-notes/pic-3.png\" class=\"lazyload placeholder\" data-srcset=\"/img/transformer-notes/pic-3.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"pic-3\"></p>\n<p>batchnormlayernorm</p>\n<p>BN<strong></strong>mini-batch</p>\n<p>seqseqfeaturebatch</p>\n<p>LN<strong></strong>mini-batch</p>\n<p></p>\n<p><img src=\"/img/transformer-notes/pic-4.png\" class=\"lazyload placeholder\" data-srcset=\"/img/transformer-notes/pic-4.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"pic-4\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>N&#x3D;6encoder</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>QKV</p>\n<p>Transformer</p>\n<p><img src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/QKV-%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/QKV-%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h2 id=\"Scaled-Dot-Product-Attention\"><a href=\"#Scaled-Dot-Product-Attention\" class=\"headerlink\" title=\"Scaled Dot-Product Attention\"></a>Scaled Dot-Product Attention</h2><p>QK$d_k$V$d_v$</p>\n<p>QK$\\sqrt{d_k}$<code>softmax</code>dim&#x3D;1V</p>\n<p>$Attention(Q,K,V) &#x3D; softmax( \\frac{QK^T}{\\sqrt{d_k}}  )V$</p>\n<p>dksoftmax01softmax$\\sqrt{d_k}$</p>\n<p><img src=\"/img/transformer-notes/pic-5.png\" class=\"lazyload placeholder\" data-srcset=\"/img/transformer-notes/pic-5.png\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"pic-5\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>h&#x3D;8</p>\n<p><strong> Source  multi-head attention  attention </strong></p>\n<p>QKVhhLinear</p>\n<p>$z_i \\in R^{23}$$R^{224}$$W^O \\in R^{244}$$Z \\in R^{24}$</p>\n<p><img src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/multi-head-%E6%8B%BC%E6%8E%A5.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/multi-head-%E6%8B%BC%E6%8E%A5.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<p></p>\n<p>$W^Q_i \\in R^{d_{model}d_k}$ </p>\n<p>$W^K_i \\in R^{d_{model}d_k}$  , </p>\n<p>$W^V_i \\in R^{d_{model}d_v}$ </p>\n<p>$W_O \\in R^{ {hd_v}d_{model} }$</p>\n<p>dk &#x3D; dv &#x3D; dmodel&#x2F;h &#x3D; 64</p>\n<p></p>\n<h2 id=\"masked\"><a href=\"#masked\" class=\"headerlink\" title=\"masked\"></a>masked</h2><p>output embedding</p>\n<p>inputQ</p>\n<p><img src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map-softmax.jpg\" class=\"lazyload placeholder\" data-srcset=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map-softmax.jpg\" srcset=\"https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp\" alt=\"img\"></p>\n<h2 id=\"Encoder-Decoder\"><a href=\"#Encoder-Decoder\" class=\"headerlink\" title=\"Encoder-Decoder\"></a>Encoder-Decoder</h2><p>KVQ</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>ReLU</p>\n<p>$FFN(x) &#x3D; ReLU(xW1 + b1)W2 + b2$</p>\n<p>2048</p>\n<p>512-&gt;(W1)2048-&gt;(W2)512</p>\n<p>attentionMLP2048</p>\n<h2 id=\"Softmax\"><a href=\"#Softmax\" class=\"headerlink\" title=\"Softmax\"></a>Softmax</h2><p>$\\sqrt{d_{model}}$</p>\n<p>L2scale</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong> Attention  Attention  Attention  X1</strong></p>\n<p>Attention<br></p>\n<p>$PE(pos,2i) &#x3D; sin(pos&#x2F;10000^{2i&#x2F;d_{model}})$</p>\n<p>$PE(pos,2i + 1) &#x3D; cos(pos&#x2F;10000^{2i&#x2F;d_{model}})$</p>\n<p>PE[-1,1]$PE_{pos_k}$$PE_{pos}$</p>\n<p><strong></strong></p>\n<p>$X_{final_embedding}&#x3D;Embedding+PositionalEmbedding$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><table>\n<thead>\n<tr>\n<th>Layer Type</th>\n<th>Complexity per Layer</th>\n<th>Sequential Operations</th>\n<th>Maximum Path Length</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Self-Attention</td>\n<td>O(n2  d)</td>\n<td>O(1)</td>\n<td>O(1)</td>\n</tr>\n<tr>\n<td>Recurrent</td>\n<td>O(n  d2)</td>\n<td>O(n)</td>\n<td>O(n)</td>\n</tr>\n<tr>\n<td>Convolutional</td>\n<td>O(k  n  d2)</td>\n<td>O(1)</td>\n<td>O(logk(n)</td>\n</tr>\n</tbody></table>\n","more":"<p><img src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/attention-%E8%AE%A1%E7%AE%97%E5%9B%BE.png\" alt=\"img\"></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>RNN </p>\n<p>LSTM </p>\n<p>TransformerAttention</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>$(x_1,x_2,,x_n)$$(z_1,z_2,,z_n)$$z_t$$x_t$$y_1$$y_{t-1}$$z_t$$y_t$</p>\n<p>auto-regressive)</p>\n<p><img src=\"/img/transformer-notes/pic-1.png\" alt=\"pic-1\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>N&#x3D;6(Add &amp; Norm)</p>\n<p>$LayerNorm(x + Sublayer(x))$</p>\n<p>$d_k &#x3D; 512$</p>\n<h3 id=\"LayerNorm-BatchNorm\"><a href=\"#LayerNorm-BatchNorm\" class=\"headerlink\" title=\"LayerNorm &amp; BatchNorm\"></a>LayerNorm &amp; BatchNorm</h3><table>\n<thead>\n<tr>\n<th align=\"left\"></th>\n<th align=\"left\"></th>\n<th align=\"left\"></th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\"><strong>BatchNorm</strong></td>\n<td align=\"left\">Batch</td>\n<td align=\"left\">CNN</td>\n</tr>\n<tr>\n<td align=\"left\"><strong>LayerNorm</strong></td>\n<td align=\"left\">Channel</td>\n<td align=\"left\">RNNTransformer</td>\n</tr>\n</tbody></table>\n<p><img src=\"/img/transformer-notes/pic-3.png\" alt=\"pic-3\"></p>\n<p>batchnormlayernorm</p>\n<p>BN<strong></strong>mini-batch</p>\n<p>seqseqfeaturebatch</p>\n<p>LN<strong></strong>mini-batch</p>\n<p></p>\n<p><img src=\"/img/transformer-notes/pic-4.png\" alt=\"pic-4\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>N&#x3D;6encoder</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>QKV</p>\n<p>Transformer</p>\n<p><img src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/QKV-%E7%9F%A9%E9%98%B5%E8%A1%A8%E7%A4%BA.jpg\" alt=\"img\"></p>\n<h2 id=\"Scaled-Dot-Product-Attention\"><a href=\"#Scaled-Dot-Product-Attention\" class=\"headerlink\" title=\"Scaled Dot-Product Attention\"></a>Scaled Dot-Product Attention</h2><p>QK$d_k$V$d_v$</p>\n<p>QK$\\sqrt{d_k}$<code>softmax</code>dim&#x3D;1V</p>\n<p>$Attention(Q,K,V) &#x3D; softmax( \\frac{QK^T}{\\sqrt{d_k}}  )V$</p>\n<p>dksoftmax01softmax$\\sqrt{d_k}$</p>\n<p><img src=\"/img/transformer-notes/pic-5.png\" alt=\"pic-5\"></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>h&#x3D;8</p>\n<p><strong> Source  multi-head attention  attention </strong></p>\n<p>QKVhhLinear</p>\n<p>$z_i \\in R^{23}$$R^{224}$$W^O \\in R^{244}$$Z \\in R^{24}$</p>\n<p><img src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/multi-head-%E6%8B%BC%E6%8E%A5.jpg\" alt=\"img\"></p>\n<p></p>\n<p>$W^Q_i \\in R^{d_{model}d_k}$ </p>\n<p>$W^K_i \\in R^{d_{model}d_k}$  , </p>\n<p>$W^V_i \\in R^{d_{model}d_v}$ </p>\n<p>$W_O \\in R^{ {hd_v}d_{model} }$</p>\n<p>dk &#x3D; dv &#x3D; dmodel&#x2F;h &#x3D; 64</p>\n<p></p>\n<h2 id=\"masked\"><a href=\"#masked\" class=\"headerlink\" title=\"masked\"></a>masked</h2><p>output embedding</p>\n<p>inputQ</p>\n<p><img src=\"https://imgmd.oss-cn-shanghai.aliyuncs.com/BERT_IMG/mask-attention-map-softmax.jpg\" alt=\"img\"></p>\n<h2 id=\"Encoder-Decoder\"><a href=\"#Encoder-Decoder\" class=\"headerlink\" title=\"Encoder-Decoder\"></a>Encoder-Decoder</h2><p>KVQ</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>ReLU</p>\n<p>$FFN(x) &#x3D; ReLU(xW1 + b1)W2 + b2$</p>\n<p>2048</p>\n<p>512-&gt;(W1)2048-&gt;(W2)512</p>\n<p>attentionMLP2048</p>\n<h2 id=\"Softmax\"><a href=\"#Softmax\" class=\"headerlink\" title=\"Softmax\"></a>Softmax</h2><p>$\\sqrt{d_{model}}$</p>\n<p>L2scale</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong> Attention  Attention  Attention  X1</strong></p>\n<p>Attention<br></p>\n<p>$PE(pos,2i) &#x3D; sin(pos&#x2F;10000^{2i&#x2F;d_{model}})$</p>\n<p>$PE(pos,2i + 1) &#x3D; cos(pos&#x2F;10000^{2i&#x2F;d_{model}})$</p>\n<p>PE[-1,1]$PE_{pos_k}$$PE_{pos}$</p>\n<p><strong></strong></p>\n<p>$X_{final_embedding}&#x3D;Embedding+PositionalEmbedding$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><table>\n<thead>\n<tr>\n<th>Layer Type</th>\n<th>Complexity per Layer</th>\n<th>Sequential Operations</th>\n<th>Maximum Path Length</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Self-Attention</td>\n<td>O(n2  d)</td>\n<td>O(1)</td>\n<td>O(1)</td>\n</tr>\n<tr>\n<td>Recurrent</td>\n<td>O(n  d2)</td>\n<td>O(n)</td>\n<td>O(n)</td>\n</tr>\n<tr>\n<td>Convolutional</td>\n<td>O(k  n  d2)</td>\n<td>O(1)</td>\n<td>O(logk(n)</td>\n</tr>\n</tbody></table>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}