---
title: RethinkFun-DL
mathjax: true
date: 2026/1/27 20:46:25
img: http://rethink.fun/imgs/catdog.jpg
excerpt: rethinkfun深度学习笔记
---

# 线性变换和矩阵

你可以将线性变换理解成对向量的一个函数，输入是一个向量，输出还是一个向量。但是这个函数必须满足对数乘和向量加法的封闭性：

**加法封闭性**：对于任意两个向量**u**和**v**，线性变换**T**满足:

$T(u+v)=T(u)+T(v)$

**数乘封闭性**：对于任意向量**v**和标量**c**，线性变换**T**满足：

$T(cv)=cT(v)$

线性变换有两个非常好的性质：

**直线保持**：线性变换前多个终点在一条线上的向量，经过线性变换后，这些向量的终点仍在一条直线上。

**原点不变**：线性变换后原点仍然在原点位置。

一个向量可以理解为用它的各个分量对标准基里的对应向量进行缩放，再将缩放后的基向量相加。 我们只需要记录标准基里的向量$(i,j)$经过线性变换后的向量$(i',j')$​。原始向量各个分量对变换后的基向量的线性组合就是对该向量的线性变换后的向量。按照这样规则生成的向量就保证了线性变换对向量加法和数乘的封闭性。

不是方阵的矩阵$C \in R ^{n \times m}$，可以将一个$m$维向量映射成$n$维向量

矩阵A代表线性变换，类似函数。矩阵B是一组列向量的组合，类似函数的输入。矩阵乘法的结果就是函数的输出。这种理解就是用B里的列向量的分量对A里的列向量进行线性组合。也就是从列向量的角度去理解矩阵乘法。

另一种不同的视角是行向量视角。在深度学习行向量视角更常用。行向量视角下，A是待变换的行向量的集合，B是线性变换的函数。用A里行向量的每个维度的分量，对B里的行向量进行线性组合

# 点乘和叉乘

## 点乘

两个向量**a**和**b**。它们在同一个向量空间，也就说它们的分量个数相同。它们两个的点乘为：

$a⋅b=∣a∣∣b∣cosθ$

**交换律**

$a⋅b=b⋅a$

**数乘结合率**

$(λa)⋅b=a⋅(λb)=λ(a⋅b)$

对于$a⋅b$的结果等于**a**的模长乘以**b**的模长再乘以$cosθ$。当**b**变为原来的$ λ$倍后，它的模长变为原来的$ λ$倍，而**a**的模长和$cosθ$都不变，所以$a⋅(λb)=λ(a⋅b)=(λa)⋅b$

**分配率** 点乘的分配率公式为：

$(a+b)⋅c=a⋅c+b⋅c$

![](http://rethink.fun/imgs/0213.png)

对于**a+b**与**c**的点乘，等于**a+b**在**c**上的投影长度，乘以**c**的长度。而**a+b**在**c**上的投影的长度就等于**a**在**c**上投影的长度加上**b**在**c**上投影的长度。而**a**在**c**上投影的长度乘以**c**的长度就是**a**与**c**的点乘，对于**b**也同理。所以上式成立。

有了以上几个向量点乘的计算法则，我们就可以来推导点乘的计算公式了。

以三维向量a⋅b*a*⋅*b*为例： 将向量**a，b**用标准基向量**i,j,k**表示。比如对于**a**来说，它在x，y，z轴的分量分别为$a_x,a_y,a——z$,则：

$a⋅b=(a_xi+a_yj+a_zk)⋅(b_xi+b_yj+b_zk)$

根据分配率和数乘结合律有：

$a⋅b=a_xb_x(i⋅i)+a_xb_y(i⋅j)+a_xb_z(i⋅k)+a_yb_x(j⋅i)+a_yb_y(j⋅j)+a_yb_z(j⋅k)+a_zb_x(k⋅i)+a_zb_y(k⋅j)+a_zb_z(k⋅k)$

上式中$ax,ay,az,bx,by,bz$都为标量，$i,j,k$为标准基向量。 接下来我们计算上式中括号内的标准基向量之间的点乘。因为标准基向量的模长为1，又加之它们与自身夹角为0度，cos值为1，所以它们与自身的点乘为1。

又因为标准基向量之间都互相垂直，cos值为0，所以只要是不同标准基向量的点乘都为0。

带入上边式中有：

$a⋅b=a_xb_x+a_yb_y+a_zb_z$

可以看到点乘有一个非常简单的计算规则，就是两个向量的点乘等于两个向量各个分量的值相乘再加和，这个规则可以推广到任意维度的向量点乘上,即：

$a\cdot b = \sum_{i = 1}^{n} a_i b_i$

为什么深度学习会用Cos相似度来衡量向量之间的相似性呢？而不用欧式距离呢？

一是因为点乘计算简单，效率高。

二是不同维度向量之间的Cos相似度有可比性，不论两个向量的维度为多少，只要两个向量方向完全一样，Cos相似度的值就是1; 两个向量垂直，也就是完全无关，值为0；两个向量方向相反，也就是负相关，值为-1。但是欧式距离不同维度向量之间的距离可能相差很远，没有可比性。

## 叉乘

![](http://rethink.fun/imgs/0215.png)

在线性代数里，我们把类似于力矩这种运算叫做叉乘（叉积，向量积）。用符号××表示。

$a×b=∣a∣∣b∣sinθ$

**叉乘的方向** 力矩是一个向量，它不光有大小，还有方向。因为力矩描述的是使物体旋转的容易程度。但是旋转有可能是顺指针方向，也有可能是逆时针方向。叉乘也是一个向量，有自己的方向。怎么确定这个方向呢？这就要用的右手法则了。

![](http://rethink.fun/imgs/0216.png)

根据右手法则，$a×b$和$b×a$的方向是不同的。所以叉乘不满足交换律

**分配率**

$(a+b)×c=a×c+b×c$

$c×(a+b)=c×a+c×b$

**数乘结合率**

$(λa)×b=a×(λb)=λ(a×b)$

$a×b=(a_yb_z−a_zb_y)i+(a_zb_x−a_xb_z)j+(a_xb_y−a_yb_x)k$

可以看到，最终的结果为一个向量。

# 方向导数和梯度

函数$z=f(x,y)$在$(x_0,y_0)$点可以分别对x和y求偏导。对x求偏导时，保持y不变，$y=y_0$，只考虑x变化时，对z的影响。对y求偏导时，保持x不变，$x=x_0$，只考虑y变化时，对z的影响。

但现实情况是自变量在点$(x_0,y_0)$处不光可以沿着平行于x轴（x的偏导），或者沿着平行于y轴（y的偏导）变化，它是可以沿着各个方向进行运动变化的，我们想要研究当自变量沿着不同方向进行变化时，因变量的变化率，这就是方向导数需要研究的内容。

最终可以得到函数$z=f(x,y)$在$(x_0,y_0)$点，沿单位方向向量$e_u$的方向导数为：

$f_x(x_0,y_0)cos⁡α+f_y(x_0,y_0)cos⁡β$

这个式子可以看做是向量$[fx(x0,y0),fy(x0,y0)]$和向量$[cos⁡α,cos⁡β]$的点乘。

方向导数研究的是自变量沿着不同方向变化时，因变量的变化率。那么我们自然就关心自变量沿着哪个方向变化，因变量增加最快。根据上边对方向导数的推导，方向导数的值等于方向向量与函数对不同自变量求偏导形成的向量之间的点乘。我们之前介绍过向量点乘的结果是个标量，它的值就等于两个向量的模长乘以它们之间夹角的cos值。方向向量的模长为1，偏导数向量的模长固定，那么能改动的就是这两个向量之间的夹角了，只有让两个向量之间的夹角为0，cos值为1，可以让方向导数取到最大值。也就是让单位方向向量的方向与偏导数向量的方向一致，这时函数变化率最大。

看来用函数在某点，不同维度偏导数作为向量元素，构成的偏导数向量是个特殊的向量，沿着它的方向，可以让函数在此点变化率最大。我们就把这个向量叫做梯度。

如果有一个函数$f(x_1,x_2,...,x_n)$,它的梯度记作$∇f$或者$grad f,$表示为：

$∇f=(f_{x1},f_{x2},...,f_{xn})$

其中$f_{xi}$是$f$关于$x_i$的偏导数。

梯度在深度学习中起着至关重要的作用，是优化和训练过程中的核心工具。深度学习的本质是通过不断调整模型的参数，使其在输入数据上表现得更好，而实现这一目标的关键方法就是利用梯度信息。

梯度是损失函数（通常用来衡量模型预测值和真实值之间的差异）对模型参数的偏导数。它提供了两个重要的信息：

1. 方向：梯度的方向指向使损失函数值增长最快的方向，沿着负梯度方向移动，则可以使损失函数值最快的减少。
2. 速率：梯度的模长反映了参数变化对损失函数变化的影响程度，模长越大，参数的变化对损失的影响越大。

在深度学习训练过程中，模型利用梯度来指导参数更新，这一过程被称为优化。通过计算损失函数相对于模型参数的梯度，优化算法可以确定如何调整参数，使得模型的损失逐步减小，从而提高模型的性能。

# 随机变量及其分布

在随机实验E中，S是相应的样本空间，如果对S中的每一个样本点$ω$，有唯一一个实数$X(ω)$与它对应，那么就把这个定义域为S的单值实值函数：

$X=X(ω)$

称为是随机变量。一般用大写字母X，Y，Z表示。

## 离散随机变量分布

**概率质量函数**，数学上定义为：

$P(X=x)=p(x)$

**累计概率分布函数**的数学定义为：

给定一个随机变量X，对任意实数$x∈(−∞,+∞)$称函数$F(x)=P(X≤x)$为随机变量X的累积概率分布函数。并且对于任意满足条件$−∞<a<b<+∞$的实数a,b，有：

$P(a<X<b)=F(b)−F(a)$

![](http://rethink.fun/imgs/0403.png)

## 连续随机变量分布

**概率密度函数**

我们用频率值除以每个分组的组距。这样做的目的是让所有区域的面积和为1

如果随机试验的人无穷大，间隔分的无穷小，就可以得到一个分布如下：

![](http://rethink.fun/imgs/0407.png)

这样我们就得到了连续性变量的概率密度曲线。它形象的刻画了在不同取值区间的概率大小。并且它的面积为1。

概率密度函数（Probability Density Function, PDF）是描述连续型随机变量概率分布的重要工具。概率密度函数f(x)*f*(*x*)是一个非负函数，用来描述随机变量在某一点附近取值的“相对可能性”。

连续型随机变量X，其结果取一固定值的概率为0。因为取一个固定值在概率密度曲线图上对应一条线，一条线的面积为0。

对于连续型变量的概率估计，我们一般是估计某个值落在一个区间的概率，其概率为：

$P(a<X<b)=\int_{a}^{b}f(x)dx $

与离散随机变量相同，连续型变量也有累积概率分布函数。定义也是类似：

累积分布函数F(x)表示随机变量X小于或者等于某个值x的概率：

$F(x)=P(X≤x)$

对于连续型随机变量，F(x) 是通过概率密度函数$f(x)$的积分来定义的：

$F(x)=\int_{-∞}^{x}f(t)dt$

对于同一个随机变量X的概率密度函数f(x)*f*(*x*)与累积概率分布函数F(x)*F*(*x*)有如下关系：

$f(x) = \frac{dF(x)}{dx}$

![](http://rethink.fun/imgs/0408.png)

# 数学期望和方差

数学期望，简称期望，是概率论研究的内容，已经知道了概率分布，研究随机变量可能取值与其出现概率的加权平均数。它反映了随机变量分布的中心趋势，是对随机现象结果的“平均值”的一种数学描述。

对于离散型随机变量X，其数学期望定义为：

$E(X)=\sum_{i}x_i P(X=x_i)$

其中：

- $x_i$：随机变量X的可能取值。
- $P(X=x_i)$: 对应取值$x_i$的概率。

对于连续型随机变量X，其数学期望定义为：

$E(x) = \int_{-\infty}^{+\infty}xf(x)dx$

其中：

- $f(x)$: 随机变量X的概率密度函数。

方差是用来衡量随机变量取值偏离其期望程度的重要指标。在概率论里它表示随机变量与其期望值之间差的平方的期望，因为随机变量与其期望的差值有正有负，直接相加会互相抵消，所以这里用随机变量与其期望差的平方来衡量差异大小。方差可以看作是随机变量“波动”的大小。

方差通常用$Var(X)$或$σ^2$表示，其数学表达式为：

$Var(X)=E[(X−E[X])^2]]=E[X^2] - (E[X])^2$

其中：

- X是随机变量。
- $E[X]$是随机变量X的数学期望。
- $E[(X−E[X])^2]]$是X偏离期望的平方的期望。

**总体方差和样本方差**

**总体方差** 总体方差和样本方差是统计学中衡量数据分布离散程度的重要概念。

如果你采集了一个分布的所有样本。那么你可以计算总体方差。总体方差描述整个总体中数据的分布离散程度。它反映总体中每个数据点与总体均值的偏差平方的平均值。

设总体中的数据点为$x_1,x_2,...,x_n$，总体均值为$μ$，总体方差$σ^2$定义为：

$σ^2=\frac{1}{n} \sum_{i=1}^{n}(x_i−μ)^2$

**样本方差**

当我们进行一项统计实验，无法获取所有样本时，只是对一些样本采样进行统计。比如你要对一批灯泡做预期寿命测试，你只能抽样进行测试寿命，不可能对所有灯泡进行寿命测试。这时候你只能计算样本方差，它的公式和总体方差不同。

设样本中的数据点为$x_1,x_2,...,x_n$，样本均值为$\bar{x}$，样本方差$s^2$定义为：

$s^2=\frac{1}{n-1} \sum_{i=1}^{n}(x_i−\bar{x})^2$

因为样本方差只采集了部分样本，不是整体样本，利用部分样本来评估总体方差，如果除以n是会产生偏差的，需要通过除以n-1来对偏差进行纠正。

首先，如果采样的样本数为1，采样值为x，那么均值还是x, 如果除以n=1的话，那么方差为0。因为分子部分x和均值相等。这显然是不合理的。用一个数来评估均值是有偏的。如果公式定义分母部分为n-1，那么采样数为1计算样本方差就无效，这样更合理。

另外通过采样样本计算均值，然后用样本值减去这个均值得到的值，总是小于样本值减去整体分布的均值。

标准差（Standard Deviation）是方差的平方根，用来衡量数据偏离均值的程度，反映数据的离散程度或波动性。相比方差，标准差与数据的原始单位相同，更直观、更容易理解。

# 大数定律

描述了大量独立随机变量的平均值在重复实验中表现出的统计规律性。通俗来说，大数定律表明，当试验次数足够多时，随机变量的平均值会趋近于理论期望值。

$X_1,X_2,...,X_n$为来自总体$X$的随机样本，$X$的数学期望为E[X]，
$\bar{X}=\frac{X_1+X_2+...+X_n}{n}$

则有：

$\lim_{n->\infty}\bar{X}=E[X]$

# 中心极限定理

无论单个随机变量的原始分布是什么样的，只要随机变量是独立同分布的，且具有有限的均值和方差，那么这些随机变量的和（或均值）在样本量足够大的情况下，其分布将趋近于正态分布。

# 极大似然估计

概率与似然的区别

- 概率：固定概率分布参数θ*θ*，研究随机变量 X*X*的分布。
- 似然：固定观测数据 x*x*，研究概率分布参数θ*θ*的可能性。

似然函数就是把概率分布的参数作为未知变量，描述事件发生可能性的函数。

事件已经发生了，似然函数表达了不同的分布参数让这个事件发生的可能性。自然我们会想到，最有可能的参数必然是让事件发生可能性最大的那个参数。

因为似然函数一般都是多个概率相乘，多个数值相乘在进行极大值计算时不方便，一般会对似然函数取对数。因为对数运算时一个单增函数，不会改变原函数的极值。同时，对数运算和将多个数相乘，变化为多个数相加。这就大大简化了求极值的过程。

极大似然估计（Maximum Likelihood Estimation，简称 MLE）是一种统计方法，用于估计模型参数，使得在已知数据样本的情况下，模型生成这些数据的概率最大。

**核心思想**

假设我们有一个参数化的概率模型，其参数为θ，观测到的数据为$X={x_1,x_2,...,x_n}$。极大似然估计的目标是找到一个参数θ，使得这些观测数据在这个概率模型下出现的可能性最大，即最大化似然函数：

$L(θ∣X)=P(X∣θ)=\prod_{i=1}^{n}P(x_i∣θ)$

其中：

- $P(X∣θ)$:样本数据X在参数θ下的联合概率。
- $P(x_i∣θ)$:单个数据点$x_i$在参数θ下的概率。

为了计算方便，通常取对数，将似然函数转换为对数似然函数：

$ℓ(θ∣X)=logL(θ∣X)=\sum_{i=1}^{n}P(x_i∣θ)$

极大似然估计的目标就变为最大化对数似然函数$ℓ(θ∣X)$。

# Normalization

**归一化**

除以最大值

**标准化**

实际上在深度学习里，更常用的是对特征进行标准化处理。也就是对每个feature减去自己的均值，再除以自己的标准差。这样就把这个feature转化为均值为0，标准差为1的分布了。在归一化操作里，是对每个feature除以这个feature所有样本中绝对值最大的值。只有这一个值决定缩放大小。但这个值有可能是个异常值。相比之下标准化处理会考虑所有样本的分布情况，避免缩放受异常值的影响，训练起来会更稳定。

为归一化仅对参数空间进行了可逆的线性变换，模型的理论表达能力不变，不改变数据的本质关系。这一现象类似于“换单位不会影响物理规律”。 归一化不会影响深度学习模型的训练结果，因为它只是数据的线性变换，保留了所有必要的信息，模型可以通过权重调整完全补偿这种变换。

严格来说，归一化指的是将数据变化调整到[-1,1]或者[0,1]之间。标准化是将数据减去均值除以标准差。但是在机器学习里，由于历史原因，都是用Normalization来表示。如果有人说他对数据进行了归一化，但是实际代码里是做了标准化，你也不用感到奇怪。

# 正则化

## L1正则化

L1正则化的思想是在损失函数中额外加入模型所有参数的绝对值之和作为惩罚项。这样模型在训练过程中，会尽可能的让参数变小来降低Loss值，直到让某些参数为0。如果一个参数降为0，则等价于这个参数消失，起到了降低模型复杂度的作用。同样减小参数的值也是降低模型复杂度的一种方式。L1正则化的公式为：

$Loss_{L1}=Loss(θ)+λ \sum_{i}|θ_i|$

其中θ是模型参数，λ是控制正则化强度的参数，一般初始设置为1e-3或者1e-4。设置过大会导致模型欠拟合。在训练过程中可以进根据实际情况进行调整，调整原则为如果数据量越少，模型越复杂，输入特征越多，那么λ就越大。因为这些情况都更容易出现过拟合。反之则可以减小λ。

## L2正则化

L2正则化与L1正则化非常类似，它在损失函数中加入模型参数的平方和作为惩罚项。同样可以达到控制模型复杂度的效果。它的公式为：

$Loss_{L2}=Loss(θ)+λ \sum_{i}θ_i^2$

# 指数加权平均

每天指数加权平均的值我们用$V_i$表示，每天实际值用$θ_i$表示。

$V_i = \beta V_{i-1} + (1-\beta)\theta_i$

越老数据的系数β的指数越大，因为β小于1，所以指数越大，权重越小

这样我们就可以用前t天的指数加权平均值来作为对t+1天预测。

我们发现对于前几天的指数加权平均，得到的值非常小，和实际值偏差较大，这是由于初始设置V0=0导致的。如果你计算的序列很长，越到后边的指数加权平均计算，V0的影响就会越小，结果自然得到修正。如果你计算的序列短的话，有什么办法解决吗？ 办法是对V进行修正，在我们计算完V后，让它除以$1-\beta^t$。t表示第几天。

$V_0=0$

$V_t=βV_{t−1}+(1−β)θ_t$

$V_t^{correct}=\frac{V_t}{1-\beta^t}$

# 动量梯度下降

动量梯度下降的做法是每次不用当前每个参数的梯度值来更新参数，而是用梯度值的**指数加权平均**来更新参数。它可以很好的解决训练振荡和局部最优

以对w参数的更新为例，首先计算w的梯度：

$g_w = \frac{\partial loss}{\partial w} $

我们定义变量$V_w$, 表示$g_w$的指数加权平均值，每个batch按照下边的公式更新自身值：

$V_w = \beta V_w + (1 - \beta)g_w$

更新$w$参数, $lr$是学习率：

$w = w - lrV_w$

可以看到在训练过程中，对于参数w，一直需要保存一个指数加权平均值$V_w$。另外β的取值一般为0.9。

# RMSProp优化器

RMSProp（Root Mean Square Propagation optimizer）均方根传播优化器，也是在标准梯度下降优化器上进行了改进。

我们在进行深度神经网络的训练时，所有的参数都用同一个学习率。这会导致一个问题，有的参数梯度大，有的参数梯度小。如果你设置的学习率过大，会导致梯度大的参数在最优值附近来回震荡，不能收敛。如果你设置学习率过小，导致梯度小的参数学习停滞不前。

RMSProp就是让每个参数有自适应的学习率。让梯度值大的参数的学习率相对小一些，让梯度值小的参数的学习率相对大一些。这样训练过程就会稳定且快速。 RMSProp的思想是让一个参数更新的梯度值都除以一个数，如果历史上这个梯度值一直都很大，那就除一个大的数，相当于减小了学习率。如果这个梯度值一直很小，那就除一个小的数。相当于增大了学习率。

RMSProp的做法是记录每个参数梯度平方的指数加权平均值$S$，更新参数时的梯度除以$\sqrt{S}$

$g_w = \frac{\partial loss}{\partial w} $

计算$g_w^2$指数加权平均值：

$S_w = \beta S_w + (1 - \beta)g_w^2$

更新参数, $lr$是学习率：

$w = w - \frac{lr}{S_w + \epsilon }g_w$

其中β一般取0.9。ε是为了防止除0，加的一个很小的数，一般是1e-8。

# Adam

Adam(Adaptive Moment Estimation)，结合了Momentum优化器和RMSProp优化器的优点，目前已经是深度学习领域默认的优化器。 Adam优化器同时利用动量来给梯度更新增加惯性和震荡阻尼，也利用历史梯度的均方根来自适应调整学习率

$g_w = \frac{\partial loss}{\partial w} $​

然以后计算并更新一阶矩指数加权平均值$V_w$，和二阶矩指数加权平均值$S_w$。

$V_w = \beta V_w + (1 - \beta)g_w$

$S_w = \beta S_w + (1 - \beta)g_w^2$

$\beta_1 = 0.9;\beta_2 = 0.999$

接着对这两个值进行校正：

$V_w^{correct} = \frac{V_w}{1 - \beta_1^t}$

$S_w^{correct} = \frac{S_w}{1 - \beta_2^t}$

最后更新参数：

$w = w - lr\frac{V_w^{correct}}{\sqrt{S_w^{correct}+ \epsilon}}$

Adam优化器可以稳定且迅速的训练深度神经网络，但是它需要为每个参数额外在显存里保存两个值：V和S，来记录梯度的一阶和二阶指数加权平均值。这占据了大量宝贵的显存空间。

# Weight Decay

权重衰减（Weight Decay）是一种在模型训练过程中防止模型过拟合的技术。权重衰减的思想很简单，就是在训练的每一步用梯度更新参数时，同时缩小参数值。防止参数的绝对值过大。权重衰减的思想和L1、L2正则是类似的，都是减少参数的绝对值。不同的是L1、L2正则是在loss函数里增加额外项实现的。而权重衰减的做法更直接，直接减小参数的绝对值。

它的具体做法为：

$w_t=w_t - lr \times g_w - lr \times \lambda w_t$

其中$lr$是学习率，$λ$是权重衰减系数。一般取值在1e-2到1e-4。如果你的模型过拟合现象比较严重，λ*λ*就设置大一些。

对标准的梯度下降算法应用权重衰减和L2正则，效果是一样的。

但是对于Adam优化器来说，权重衰减和L2正则就不一样了。因为添加在Loss里的L2正则，梯度经过动量和平方根调整后，已经和直接减小参数值不一样了。

# Dropout

## 训练阶段

在训练阶段，Dropout会按照超参数p的设置，随机禁用一些神经元。被禁用的神经元不接受任何输入也不为下一层的神经元提供输出。Dropout一般应用在隐藏层，不对输入和输出层应用。

对于保留的神经元的输出也需要做一些调整，对于未被禁用的神经元的输出需要除以$1−p$来进行缩放。这样就确保了下一层进行线性计算时，输入加权累加值的期望不变。

Dropout可以理解成每次都在训练一个简化的神经网络，让网络每个神经元都学到通用的特征，而不是过份依赖某几个神经元。

## 推理阶段

Dropout不起作用，所有神经元都起作用。因为之前在训练时对起作用的神经元做过缩放操作，它保证了推理阶段的数值稳定。

p的值我们一般取0.1-0.5。p值越大，正则化效果越强。 还有一点需要注意，Dropout 在训练阶段与推理阶段的行为是不同的，所以你一定在训练前调用`model.train()`，推理前调用`model.eval()`函数。

# Batch Normalization

标准化+线性变化

初始化时，一般设置线性变化参数$γ=1,β=0$大多数情况下它都限制了输出的均值在零，标准差在1附近。保证了输出分布的稳定性。

在推理时你可以能只有一条数据，那此时该如何获得均值和方差呢？答案是，在训练时，BatchNorm会使用当前batch的z值的均值和标准差进行归一化，并用指数加权平均的办法，更新和维护z值的均值和标准差（每一个batch更新一次指数加权平均）。在推理时，就用这个指数加权平均得到的均值和标准差来归一化推理时的z值。

